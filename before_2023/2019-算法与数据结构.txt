




冒泡排序
平均时间复杂度，最坏时间复杂度，最好时间复杂度，空间复杂度，稳定性
O(n^2)			O(n^2)			O(n)			O(1)	稳定

比较相邻的元素。如果第一个比第二个大，就交换它们两个；
对每一对相邻元素作同样的工作，从开始第一对到结尾的最后一对，这样在最后的元素应该会是最大的数；
针对所有的元素重复以上的步骤，除了最后一个；
重复步骤1~3，直到排序完成。

。。加个flag，如果本次没有发生交换，就说明已经有序。


选择排序
O(n^2)		O(n^2)		O(n^2)		O(1)		不稳定

初始状态：无序区为R[1..n]，有序区为空；
第i趟排序(i=1,2,3…n-1)开始时，当前有序区和无序区分别为R[1..i-1]和R(i..n）。该趟排序从当前无序区中-选出关键字最小的记录 R[k]，将它与无序区的第1个记录R交换，使R[1..i]和R[i+1..n)分别变为记录个数增加1个的新有序区和记录个数减少1个的新无序区；
n-1趟结束，数组有序化了。

。。每次选值剩下的元素中值最小的，然后放到应该放的位置。


快速排序
O(nlogn/log2)	O(n^2)	O(nlogn/log2)	O(nlogn/log2)	不稳定


从数列中挑出一个元素，称为 “基准”（pivot）；
重新排序数列，所有元素比基准值小的摆放在基准前面，所有元素比基准值大的摆在基准的后面（相同的数可以到任一边）。在这个分区退出之后，该基准就处于数列的中间位置。这个称为分区（partition）操作；
递归地（recursive）把小于基准值元素的子数列和大于基准值元素的子数列排序。



插入排序
O(n^2)		O(n^2)		O(n)		O(1)		稳定

从第一个元素开始，该元素可以认为已经被排序；
取出下一个元素，在已经排序的元素序列中从后向前扫描；
如果该元素（已排序）大于新元素，将该元素移到下一位置；
重复步骤3，直到找到已排序的元素小于或者等于新元素的位置；
将新元素插入到该位置后；
重复步骤2~5。

。。从后向前扫描+后移一起完成，从前向后的话，扫描完，得把后面的数据后移，然后插入。


shell排序
O(n^1.3)	O(n^2)		O(n)		O(1)		不稳定

是简单插入排序的改进版。它与插入排序的不同之处在于，它会优先比较距离较远的元素。希尔排序又叫缩小增量排序。

选择一个增量序列t1，t2，…，tk，其中ti>tj，tk=1；
按增量序列个数k，对序列进行k 趟排序；
每趟排序，根据对应的增量ti，将待排序列分割成若干长度为m 的子序列，分别对各子表进行直接插入排序。仅增量因子为1 时，整个序列作为一个表来处理，表长度即为整个序列的长度。



归并排序
O(nlogn/log2)	O(nlogn/log2)	O(nlogn/log2)	O(n)	稳定

把长度为n的输入序列分成两个长度为n/2的子序列；
对这两个子序列分别采用归并排序；
将两个排序好的子序列合并成一个最终的排序序列。




堆排序
O(nlogn/log2)	O(nlogn/log2)	O(nlogn/log2)	O(1)	不稳定
。。堆空间不要钱？
。。不要，数组作为堆。。
。。看gif，很简单的样子。
https://www.cnblogs.com/onepixel/articles/7674659.html

将初始待排序关键字序列(R1,R2….Rn)构建成大顶堆，此堆为初始的无序区；
将堆顶元素R[1]与最后一个元素R[n]交换，此时得到新的无序区(R1,R2,……Rn-1)和新的有序区(Rn),且满足R[1,2…n-1]<=R[n]；
由于交换后新的堆顶R[1]可能违反堆的性质，因此需要对当前无序区(R1,R2,……Rn-1)调整为新堆，然后再次将R[1]与无序区最后一个元素交换，得到新的无序区(R1,R2….Rn-2)和新的有序区(Rn-1,Rn)。不断重复此过程直到有序区的元素个数为n-1，则整个排序过程完成。

。。建立大项堆，大项堆只需要节点都大于子节点就可以了，不需要BST那种左右关系，所以只需要从倒数第二层开始，每次比较节点和它的子节点，最大值作为父节点。然后往上一层，直到根。
。。有序是把最大堆的根节点和最后一个节点互换(就是最大值放到最后)。互换后的根节点一路下降(和它的2个子节点比较，和大的那个互换)。此时就是一个大项堆。


计数排序
O(n+k)		O(n+k)		O(n+k)		(n+k)		稳定

计数排序不是基于比较的排序算法，其核心在于将输入的数据值转化为键存储在额外开辟的数组空间中。 作为一种线性时间复杂度的排序，计数排序要求输入的数据必须是有确定范围的整数。


找出待排序的数组中最大和最小的元素；
统计数组中每个值为i的元素出现的次数，存入数组C的第i项；
对所有的计数累加（从C中的第一个元素开始，每一项和前一项相加）；
反向填充目标数组：将每个元素i放在新数组的第C(i)项，每放一个元素就将C(i)减去1。


桶排序
O(n+k)		O(n^2)		O(n)		O(n+k)		稳定

桶排序是计数排序的升级版。它利用了函数的映射关系，高效与否的关键就在于这个映射函数的确定。桶排序 (Bucket sort)的工作的原理：假设输入数据服从均匀分布，将数据分到有限数量的桶里，每个桶再分别排序（有可能再使用别的排序算法或是以递归方式继续使用桶排序进行排）。


设置一个定量的数组当作空桶；
遍历输入数据，并且把数据一个一个放到对应的桶里去；
对每个不是空的桶进行排序；
从不是空的桶里把排好序的数据拼接起来。 

。。都是2位数，以首位作为不同桶的依据，对每个桶排序，然后从1开始一个个桶遍历过去，就可以了。。如果有1位数的话，那么从0这个桶开始。
。。链表的话速度慢，数组的话空间浪费大。



基数排序
O(n*k)		O(n*k)		O(n*k)		O(n+k)		稳定

基数排序是按照低位先排序，然后收集；再按照高位排序，然后再收集；依次类推，直到最高位。有时候有些属性是有优先级顺序的，先按低优先级排序，再按高优先级排序。最后的次序就是高优先级高的在前，高优先级相同的低优先级高的在前。

取得数组中的最大数，并取得位数；
arr为原始数组，从最低位开始取每个位组成radix数组；
对radix进行计数排序（利用计数排序适用于小范围数的特点）；

。。先优先级低的位，再优先级高的位。


二叉树排序
构建BST，中序遍历。

。。红黑树呢？
。。B树，类似桶排序。











Dijkstra
单源最短路径，O(n^2)
不能有负权边
-------------主要是第3,4,5点。
1.指定一个节点，例如我们要计算 'A' 到其他节点的最短路径
2.引入两个集合（S、U），S集合包含已求出的最短路径的点（以及相应的最短长度），U集合包含未求出最短路径的点（以及A到该点的路径，注意 如上图所示，A->C由于没有直接相连 初始时为∞）
3.初始化两个集合，S集合初始时 只有当前要计算的节点，A->A = 0，U集合初始时为 A->B = 4, A->C = ∞, A->D = 2, A->E = ∞，敲黑板！！！接下来要进行核心两步骤了
4.从U集合中找出路径最短的点，加入S集合，例如 A->D = 2
5.更新U集合路径，if ( 'D 到 B,C,E 的距离' + 'AD 距离' < 'A 到 B,C,E 的距离' ) 则更新U
6.循环执行 4、5 两步骤，直至遍历结束，得到A 到其他节点的最短路径

-------------这个就是缺了更新的具体动作(就是上面的第5点)
1、当到一个时间点时，图上部分的点的最短距离已确定，部分点的最短距离未确定。
2、选一个所有未确定点中离源点最近的点，把他认为成最短距离。
3、再把这个点所有出边遍历一边，更新所有的点。

-------------
（1）首先设置两个顶点集合T和S
S中存放已找到最短路径的顶点，初始时，集合S中只有一个顶点，即源点v0
T中存放当前还未找到最短路径的顶点

（2）在集合T中选取当前长度最短的一条最短路径（v0......vk），从而将vk加入到顶点集合S中，并修改远点v0到T中各个顶点的最短路径长度；重复这一步骤，直至所有点加入S为止。


dist[n]:dist[i]表示当前找到的从源点v0出发到终点vi的最短路径的长度，初始化时，dist[i] = edge[v0][i]
S[n]:S[i]为0表示顶点vi还未加入到集合S中，初始化时S[v0]=1，其余为0
path[n]:path[i]表示v0到vi的最短路径上顶点vi的前一个顶点序号。采用“倒向追踪”方法，确定v0到vi的最短路径上的每个顶点

初始化：dist[k] = edge[v0][k]v0是源点S[v0]=1

递推：
　　u = min{dist[t]}s[vt] = 0;
　　u表示当前T集合中dist数组元素值最小的顶点的序号，以后u加入集合S。
　　dist[k] = min(dist[k], dist[u] + edge[u][k])S[vk] = 0;
------------

。。需要一个辅助数组保存源点到每个点最近的距离。
..只需要用dist[k]和dist[u]+edge[u][k]来对比就可以了。只需要更新u的边。
。。如果多条路径指向k，那么k之前已经被min过，或者之后会被min。





Prim算法
在加权连通图中搜索最小生成树
。。这个应该也不能负权吧？能
。。最小生成树是整棵树的权值最小。

最小边、权的数据结构							时间复杂度（总计）
邻接矩阵、搜索								O(V^2)
二叉堆（后文伪代码中使用的数据结构）、邻接表	O((V + E) log(V)) = O(E log(V))
斐波那契堆、邻接表							O(E + V log(V))

1).输入：一个加权连通图，其中顶点集合为V，边集合为E；
2).初始化：Vnew = {x}，其中x为集合V中的任一节点（起始点），Enew = {},为空；
3).重复下列操作，直到Vnew = V：
a.在集合E中选取权值最小的边<u, v>，其中u为集合Vnew中的元素，而v不在Vnew集合当中，并且v∈V（如果存在有多条满足前述条件即具有相同权值的边，则可任意选取其中之一）；
b.将v加入集合Vnew中，将<u, v>边加入集合Enew中；
4).输出：使用集合Vnew和Enew来描述所得到的最小生成树。

。。就是两个集合，一个保存已经在树中的节点，一个保存剩下的，每次都是取这样的边：两端不在同一个集合中且权值最小。把节点加入到树中。



kruskal
加权连通图的最小生成树的算法。

。。每次选择 不形成环的最小权值的边。直到边数为n-1,n是顶点个数。
Kruskal算法的时间复杂度由排序算法决定，若采用快速排序算法则时间复杂度为O(N log N)。

。。并查集确认边的2点是否都在已有的集合内，在就说明成环，不在就把这2点加入到，，错的，正方形，对边加入后，4个点就全在集合里了。。

红色顶点和红色边会形成一个或多个连通分支，它们都是G的子树。一条边与红色边形成圈当且仅当这条边的两个端点属于同一个子树。因此判定一条边是否与红色边形成圈，只需判断这条边的两端点是否属于同一个子树。
。。map就行吧，key是顶点，value是父节点，root的value是null，这样合并只要把一个root的value指向另一个root就ok了。



floyd

for(k=1;k<=n;k++)
	for(i=1;i<=n;i++)
		for(j=1;j<=n;j++)
			if(e[i][j]>e[i][k]+e[k][j])
				 e[i][j]=e[i][k]+e[k][j];

..每对顶点间的最短路径












gcd(greatest common divisor) 最大公约数，指两个整数所有公共约数中最大的。

gcd(a,b)=gcd(b,a%b)，就是著名的欧几里得公式。

扩展欧几里得就是：对于ax+by=gcd(a,b)，一定有一组整数解x，y。


gcd算法
第一种方法：辗转相除法, 即如果i>j, 那么先用i%j得到余数k.将问题转换成求k和j的最大公约数.依此类推,直到余数为0.
该方法有一个比较大的问题问题是取模的性能。
。。余数和小的数

第二种方法：九章算术的更相减损术，即如果i>j,那么先用i-j得到其差k.然后将问题转换成求k和j的最大公约数.依此类推,直到差为0.
这个方法也有一个问题,就是如果i和j想差的比较大,那么这个方法存在较高的时间复杂度.
。。差和较小数比较，k和j相等，那么k就是gcd(或者*2)
。。如果都是偶数，可以先都处以2，最后再乘上2

第三种方法：更相减损术 + 辗转相除法，即
当a和b均为偶数，gcb(a,b) = 2*gcb(a/2, b/2) = 2*gcb(a>>1, b>>1)
当a为偶数，b为奇数，gcb(a,b) = gcb(a/2, b) = gcb(a>>1, b)
当a为奇数，b为偶数，gcb(a,b) = gcb(a, b/2) = gcb(a, b>>1)
当a和b均为奇数，利用更相减损术运算一次，gcb(a,b) = gcb(b, a-b)， 此时a-b必然是偶数，又可以继续进行移位运算。

Stein算法
1、如果An=Bn,那么An(或Bn)*Cn是最大公约数,算法结束
2、如果An=0，Bn是最大公约数，算法结束
3、如果Bn=0，An是最大公约数，算法结束
4、设置A1=A、B1=B和C1=1
5、如果An和Bn都是偶数，则An+1=An/2，Bn+1=Bn/2，Cn+1=Cn*2(注意，乘2只要把整数左移一位即可，除2只要把整数右移一位即可)
6、如果An是偶数，Bn不是偶数，则An+1=An/2，Bn+1=Bn，Cn+1=Cn(很显然啦，2不是奇数的约数)
7、如果Bn是偶数，An不是偶数，则Bn+1=Bn/2，An+1=An，Cn+1=Cn(很显然啦，2不是奇数的约数)
8、如果An和Bn都不是偶数，则An+1=|An-Bn|/2，Bn+1=min(An,Bn)，Cn+1=Cn
9、n加1，转1
。。上面的第3种方法就是stein方法，而且第3种好像不全，没有c。



最小公倍数
a * b = 最小公倍数 * 最大公约数。




单链表反转
1.stack

2.新建一个node作为head。指向节点1，然后节点2插入到head和节点1之间
head
1-2-3-4
head-1
2-3-4
head-2-1
3-4

。。看到一个，是：
head-1-2-3-4
head-2-1-3-4
head-3-2-1-4
head-4-3-2-1
..1的下一个节点放到最前面

dummy是head，prev指向1，pCur指向2
1 prev.next = pCur.next;
2 pCur.next = dummy.next;	// 等于pCur.next = prev
3 dummy.next = pCur;
4 pCur = prev.next;



3.原地反转。
Node p1,p2;
1-2-3-4-5
forEach(node)
{
	p1 = node.next;
	node.next = p2;
	p2 = p1;
}
需要一个额外的node来指向链表头。
。。错的。forEach由于next变了，无法搞定的。除非有其他方法能确定顺序。(Array之类的)
。。也不是？
p1 = 1; p2 = null, p3 = null;
while(p1 != null)
{
	p3 = p1;
	p1 = p1.next;
	p3.next = p2;
	p2 = p3;
}
1-2-3-4-5
2-1-3-4-5
2-3-1-4-5
...不是反转。。

p1 = 1; p2, p3;
while(p1 != null)
{
	p3 = p1.next;
	p1.next = p2;
//	p3.next = p1;
	p2 = p1;
	p1 = p3;
}
。。这个ok的。






链表成环
定义两个指针，一个一次走两步，一个一次走一步，如果相遇了就说明有环。

环的起始位置
有个定理，第一问中两个指针相遇点到环起始位置的距离与从链表头到环起始位置的距离是相等的。这样就不难找到环开始的节点了。


求链表倒数第k个节点。
先让一个指针A前进k个，然后一个指针B指向头，A前进到tail，B就是倒数第K个。




Trie (音同tree，虽然音标是try的，但是小喇叭是tree)

Trie的核心思想是空间换时间，利用字符串的公共前缀来降低查询时间的开销以达到提高效率的目的。它有3个基本性质：
根节点不包含字符，除根节点外每一个节点都只包含一个字符。
从根节点到某一节点，路径上经过的字符连接起来，为该节点对应的字符串。
每个节点的所有子节点包含的字符都不相同。


应用
串的快速检索
“串”排序：给定N个互不相同的仅由一个单词构成的英文名，让你将他们按字典序从小到大输出
最长公共前缀：对所有串建立字典树，对于两个串的最长公共前缀的长度即他们所在的结点的公共祖先个数，于是，问题就转化为当时公共祖先问题。







AC多模式匹配算法
AC自动机首先将模式组记录为Trie字典树的形式，以节点表示不同状态，边上标以字母表中的字符，表示状态的转移。根节点状态记为0状态，表示起始状态。当一个状态处有一个模式串终结则标记一下。









KMP





大数组的随机值。
forEach
	if (rand(i) % i == 0) ans = arr[i];
.rand(i)会返回[0, i-1]的值。
这种可以一次遍历后就得出结果，而不必遍历得到length，然后再rand，再遍历。
适合于list，array，。。。vector之类的可以直接length。










哈夫曼树















LCS
https://www.cnblogs.com/moomcake/p/9385170.html


























































































================================
数据结构 data structure






二叉堆是一种特殊的堆，二叉堆是完全二元树（二叉树）或者是近似完全二元树（二叉树）。二叉堆有两种：最大堆和最小堆。最大堆：父结点的键值总是大于或等于任何一个子节点的键值；最小堆：父结点的键值总是小于或等于任何一个子节点的键值。
最大堆，最小堆。

在二叉堆上可以进行插入节点、删除节点、取出值最小的节点、减小节点的值等基本操作。

插入节点
在数组的最末尾插入新节点。然后自下而上调整子节点与父节点：比较当前节点与父节点，不满足堆性质则交换。从而使得当前子树满足二叉堆的性质。

删除根节点
删除根节点用于堆排序。
对于最大堆，删除根节点就是删除最大值；对于最小堆，是删除最小值。然后，把堆存储的最后那个节点移到填在根节点处。再从上而下调整父节点与它的子节点：对于最大堆，父节点如果小于具有最大值的子节点，则交换二者。直至当前节点与它的子节点满足堆性质为止。


构造二叉堆
一个直观办法是从单节点的二叉堆开始，每次插入一个节点。
最优算法是从一个节点元素任意放置的二叉树开始，自底向上对每一个子树执行删除根节点时的Max-Heapify算法（这是对最大堆而言）使得当前子树成为一个二叉堆。具体而言，假设高度为h的子树均已完成二叉堆化，那么对于高度为h+1的子树，把其根节点沿着最大子节点的分枝做调整，最多需要h步完成二叉堆化。可以证明，这个算法的时间复杂度为O(n)。


合并两个二叉堆
最优方法是把两个二叉堆首尾相连放在一个数组中，然后构造新的二叉堆。
如果经常需要合并两个堆的操作，那么使用二项式堆更好。




邻接矩阵
逻辑结构分为两部分：V和E集合。因此，用一个一维数组存放图中所有顶点数据；用一个二维数组存放顶点间关系（边或弧）的数据，这个二维数组称为邻接矩阵。邻接矩阵又分为有向图邻接矩阵和无向图邻接矩阵





邻接表，存储方法跟树的孩子链表示法相类似，是一种顺序分配和链式分配相结合的存储结构。如这个表头结点所对应的顶点存在相邻顶点，则把相邻顶点依次存放于表头结点所指向的单向链表中。
对于无向图来说，使用邻接表进行存储也会出现数据冗余，表头结点A所指链表中存在一个指向C的表结点的同时，表头结点C所指链表也会存在一个指向A的表结点。





斐波那契堆(Fibonacci heap)是计算机科学中树的集合。它比二项式堆具有更好的平摊分析性能，可用于实现合并优先队列。不涉及删除元素的操作有O(1)的平摊时间。 Extract-Min和Delete的数目和其它相比，较小时效率更佳。


斐波那契堆是由一组最小堆有序树构成的。每个节点的度数为其子节点的数目。树的度数为其根节点的度数。
斐波那契堆中的树都是有根的但是无序。每个节点x包含指向父节点的指针p[x]和指向任意一个子结点的child[x]。x的所有子节点都用双向循环链表链接起来，叫做x的子链表。子链表中的每一个节点y都有指向它的左兄弟的left[y]和右兄弟的right[y]。如果节点y是x仅有的子节点，则left[y]=right[y]=y。
斐波那契堆中所有树的根节点也用一个双向循环链表链接起来。
使用一个指针指向斐波那契堆中最小元素。

每个结点x的域
父节点p[x]
指向任一子女的指针child[x]――结点x的子女被链接成一个环形双链表，称为x的子女表
左兄弟left[x]
右兄弟right[x]――当left[x] = right[x] = x时，说明x是独子。
子女的个数degree[x]
布尔值域mark[x]――标记是否失去了一个孩子

插入一个节点
创建一个仅包含一个节点的新的斐波纳契堆，然后执行堆合并。

查找最小的节点
由于用一个指针指向了具有最小值的根节点，因此查找最小的节点是简单的操作。

合并两个斐波纳契堆
简单合并两个斐波纳契堆的根表。即把两个斐波纳契堆的所有树的根首尾衔接并置。

释放（删除）最小的节点
分为三步：
查找最小的根节点并删除它，其所有的子节点都加入堆的根表，即它的子树都成为堆所包含的树；
需要查找并维护堆的最小根节点，但这耗时较大。为此，同时完成堆的维护：对堆当前包含的树的度数从低到高，迭代执行具有相同度数的树的合并并实现最小树化调整，使得堆包含的树具有不同的度数。这一步使用一个数组，数组下标为根节点的度数，数组的值为指向该根节点指针。如果发现具有相同度数的其他根节点则合并两棵树并维护该数组的状态。
对当前堆的所有根节点查找最小的根节点。

降低一个节点的键值
对一个节点的键值降低后，自键值降低的节点开始自下而上的迭代执行下述操作，直至到根节点或一个未被标记（marked）节点为止：
如果当前节点键值小于其父节点的键值，则把该节点及其子树摘下来作为堆的新树的根节点；其原父节点如果是被标记（marked）节点，则也被摘下来作为堆的新树的根节点；如果其原父节点不是被标记（marked）节点且不是根节点，则其原父节点被加标记。
如果堆的新树的根节点被标记（marked），则去除该标记。

删除节点
把被删除节点的键值调整为负无穷小，然后执行“降低一个节点的键值”算法，然后再执行“删除最小节点”算法。







并查集，在一些有N个元素的集合应用问题中，我们通常是在开始时让每个元素构成一个单元素的集合，然后按一定顺序将属于同一组的元素所在的集合合并，其间要反复查找一个元素在哪个集合中。这一类问题近几年来反复出现在信息学的国际国内赛题中，其特点是看似并不复杂，但数据量极大，若用正常的数据结构来描述的话，往往在空间上过大，计算机无法承受；即使在空间上勉强通过，运行的时间复杂度也极高，根本就不可能在比赛规定的运行时间（1～3秒）内计算出试题需要的结果，只能用并_查集来描述。
并_查集是一种树型的数据结构，用于处理一些不相交集合（Disjoint Sets）的合并及查询问题。常常在使用中以森林来表示。


初始化
把每个点所在集合初始化为其自身。
通常来说，这个步骤在每次使用该数据结构时只需要执行一次，无论何种实现方式，时间复杂度均为O(N)。
查找
查找元素所在的集合，即根节点。
合并
将两个元素所在的集合合并为一个集合。
通常来说，合并之前，应先判断两个元素是否属于同一集合，这可用上面的“查找”操作实现。

。。图的任意两个节点是否可达。但是floyd是O(n^3)的，上万的数据就。。。


单链表实现
一个节点对应一个人，在同一个集合中的节点串成一条链表就得到了单链表的实现。在集合中我们以单链表的第一个节点作为集合的代表元。于是每个节点x（x也是人的编号）应包含这些信息：指向代表元即表首的指针head[x]，指向表尾的指针tail[x]，下一个节点的指针next[x]。

。。指向头是为了知道节点属于哪个森林，指向尾是为了能快速找到尾巴，然后添加元素/链表。应该是长度短的放前面，只需要把短的链表的节点的head指向长链表的head，tail指向长链表的tail。。这样也导致head这个并不是在链表头，不过无所谓的，链表头.head必然就是这个点了。。最好这个节点是新增的节点，这样能保存长度，不然每个节点都要增加一个int来保存长度。
。。baike上也看不出这个是什么结构，这语言都不会。。
。。而且单链表的寻找是个瓶颈啊。每次都要遍历全部才能找到。构建数据也得O(n^2)吧。
。。LinkedList.addAll(Collection)里面也没有判断是否是LinkedList，而是用过col.toArray,然后forEach添加的。

。。个人觉得 并_查集 数据结构：
Map<Object, List<Object>>.每个元素都保存了包含它的集合。并且集合的第一个元素作为key用于分辨是否属于一个集合，如果属于，那么就List.addAll。唯一遗憾就是LinkedList.addAll没有为LinkedList写一个特殊方法，只能转数组，然后forEach。
Map<Object, Set<Object>>也行，只不过判断是否属于同一个集合需要hash。而且addAll没有提速的空间，只能forEach。而且底层是Hash_Map.add，每次都得hash，而且会n次集合合并，会重复hash好多次。
当然应该是小的集合加入到大集合中。
。。end

并查集森林
并_查集的另一种更快的实现是用有根树来表示集合：每棵树表示一个集合，树中的节点对应一个人。

。。这种情况需要，，不，不需要修改Person数据结构。，而是Person作为Tree的一个属性就可以了。
。。并且只是树，所以没有指针指向叶子，只有指向父类的。那怎么查找。。

启发式合并，深度较小的树附到深度较深的树上，防止树的退化(这里说的应该是深度不要变深)。

路径压缩。将路径上所有节点的父节点改为根节点。

。。问题，怎么知道用户输入的2个人分别属于哪两棵树？遍历？如果hashMap的话，那就不需要树了。






双链表，单链表

福丽社，有序双链表
现在想来。为了速度应该设置3个或更多指针，指向头，尾，中间。这样增加/搜索的时候能很快就确认属于哪一块。不过中间指针也不需要保证必然中间，有个弹性区间，超过区间就进行修正，不然每次修正。。好像也不是。加入一个元素，必然知道是前半部分还是后半部分，前半部分连续两次insert就后移一位。
直接用int，<-2后移，>2前移，并清0.



如果速度还要更快的话，可以使用跳表。
把部分节点复制出来，作为索引。
可以多层索引。
得修改Node，毕竟索引需要指向下层。所以需要增加一个指针。

跳表的插入
需要先确定元素将要占据的层数K。这里使用随机数。不过%可以限定最高。
然后添加到K层以下面的链表中。(最底层是真正的数据，其他是索引)

跳表维护了一个head指针，指向最左上角。如果K高于现有层数，则head指针指向的竖列list需要扩充至K，然后最上面一个元素指向新添加的元素。

head
 |
-1-------------21-----------37
 |				|			|
-1----7--------21-----------37----71
 |	  |			|			|	  |
-1----7----14--21----32-----37----71----81

如果K是2
head
 |
-1-------------21-----------37
 |				|			|
-1----7--------21-----------37----71---------119
 |	  |			|			|	  |			  |
-1----7----14--21----32-----37----71----81---119


如果K是4

head
 |
-1-------------------------------------------119
 |											  |
-1-------------21-----------37---------------119
 |				|			|				  |
-1----7--------21-----------37----71---------119
 |	  |			|			|	  |			  |
-1----7----14--21----32-----37----71----81---119


random%x，确保最多x层。用户应该要估算最多多少级。
x%，每个元素必然在最底层，并且有x%的可能往上一层。可以重复往上。
levels，保存现在已有的行数，如果新元素的层数太高，则限制到levels+1，并且levels++。

我觉得上面3个因子应该需要一起用。至少需要一个默认值。就像hash_Map。









BIT
BIT(Binary Index Tree),又称二分索引树

while (i > 0) {
	num +=tree[i];
	i -= i&(-i);
}

while (i < tree.length) {
	tree[i] ++;
	i += i & (-i);
}


后继：可以理解为节点的父亲节点。是离它最近的，且编号末位连续0比它多的就是它的父亲,如e[2]是e[1]的后继；e[4]是e[2]的后继。
前驱：节点前驱的编号即为比自己小的，最近的，最末连续0比自己多的节点。如e[7]的前驱是e[6],e[6]的前驱是e[4]。
lowbit(i) = ( (i-1) ^ i) & i ;
节点e[i]的前驱为 e[ i - lowbit(i) ]；
节点e[i]的后继为 e[ i + lowbit(i) ]

。。不清楚哪个对。
i & (-i) 和 ( (i-1) ^ i) & i  在int值上是一样的。。






红黑树是每个节点都带有颜色属性的二叉查找树，颜色或红色或黑色。在二叉查找树强制一般要求以外，对于任何有效的红_黑树我们增加了如下的额外要求:
性质1. 节点是红色或黑色。
性质2. 根节点是黑色。
性质3 每个叶节点（NIL节点，空节点）是黑色的。
性质4 每个红色节点的两个子节点都是黑色。(从每个叶子到根的所有路径上不能有两个连续的红色节点)
性质5. 从任一节点到其每个叶子的所有路径都包含相同数目的黑色节点。
这些约束强制了红_黑树的关键性质: 从根到叶子的最长的可能路径不多于最短的可能路径的两倍长。结果是这个树大致上是平衡的。因为操作比如插入、删除和查找某个值的最坏情况时间都要求与树的高度成比例，这个在高度上的理论上限允许红_黑树在最坏情况下都是高效的，而不同于普通的二叉查找树。






红黑树



avl树



伸展树（Splay Tree）










java.util.HashMap

public HashMap(int initialCapacity, float loadFactor)
初始容量 和 loadFactor(0.75f)

static final int DEFAULT_INITIAL_CAPACITY = 1 << 4;
static final int MAXIMUM_CAPACITY = 1 << 30;
static final float DEFAULT_LOAD_FACTOR = 0.75f;

put-putVal中
if (++size > threshold)
	resize();
里面一般情况下是，
newThr = oldThr << 1; // double threshold

。。？？？。loadFactor好像没什么用的啊。。。
始终都是size>threshold的时候扩容2倍。和loadFactor无关。。
loadFactor用处有限。。
看代码里，只是new HashMap<>(Map)和putAll(Map)的时候会调用putMapEntries。这里才会用到，float ft = ((float)s / loadFactor) + 1.0F;而且是很苛刻的条件下才会用的。(hashMap.table==null)

还有就是resize中，但是也很苛刻啊。只有oldCap<=0&&oldThr>0或者oldThr==0才可能使用loadFactor，这基本不可能出现的。这对于正常情况根本不可能出现。
。。..也不是
主要还是resize
刚开始table==null，所以oldCap==0，oldThr一般是15
。。HashMap()是单独的，只会设置loadFactor=0.75，
HashMap(int,float),HashMap(int),都会对threshold进行初始化。初始化为initialCapacity的最近最大2^n-1(如果capacity正好2^n，也是2^n-1).
..no,后来就+1，所以只2^n
。。所以查找table时，用&(table.length-1)，

resize中如果是HashMap()的话，threshold是0.
newCap = DEFAULT_INITIAL_CAPACITY;
newThr = (int)(DEFAULT_LOAD_FACTOR * DEFAULT_INITIAL_CAPACITY);

其他的HashMap构造器，第一次进入的时候，table==null，threshold是2^n-1.
newCap = oldThr;
float ft = (float)newCap * loadFactor;
newThr = (newCap < MAXIMUM_CAPACITY && ft < (float)MAXIMUM_CAPACITY ? (int)ft : Integer.MAX_VALUE);

嗯，基本threshold都受到了loadFactor的影响。
capacity是容量。
threshold是界限。
毕竟putVal的最后
if (++size > threshold)
	resize();
>threshold就会触发resize，并没有满capacity。

后续的resize基本就是不越界就，cap,thr>>1，越界就thr=Integer.MAX_VALUE..是否越界的条件：oldCap>=MAXIUM_CAPACITY(这个是1>>30)

if ((tab = table) == null || (n = tab.length) == 0)
	n = (tab = resize()).length;
if ((p = tab[i = (n - 1) & hash]) == null)
	tab[i] = newNode(hash, key, value, null);
。不涉及key重复的情况下。很简单。





B树,B+树,B*树

每层都有横向指针从左至右相连。。no，B+是叶子节点。B*是非root，B没有任何横向指针。
B，B+，叶子节点都在同一层？


插入数据时，分裂。


一棵m阶的B 树 (m叉树)的特性如下：
1.树中每个结点最多含有m个孩子（m>=2）；
2.除根结点和叶子结点外，其它每个结点至少有[ceil(m / 2)]个孩子（其中ceil(x)是一个取上限的函数）；
3.若根结点不是叶子结点，则至少有2个孩子（特殊情况：没有孩子的根结点，即根结点为叶子结点，整棵树只有一个根节点）；
4.所有叶子结点都出现在同一层，叶子结点不包含任何关键字信息(可以看做是外部接点或查询失败的接点，实际上这些结点不存在，指向这些结点的指针都为null)；（读者反馈@冷岳：这里有错，叶子节点只是没有孩子和指向孩子的指针，这些节点也存在，也有元素。@JULY：其实，关键是把什么当做叶子结点，因为如红黑树中，每一个NULL指针即当做叶子结点，只是没画出来而已）。
5.每个非终端结点中包含有n个关键字信息： (n，P0，K1，P1，K2，P2，......，Kn，Pn)。其中：
	   a)   Ki (i=1...n)为关键字，且关键字按顺序升序排序K(i-1)< Ki。 
	   b)   Pi为指向子树根的接点，且指针P(i-1)指向子树种所有结点的关键字均小于Ki，但都大于K(i-1)。 
	   c)   关键字的个数n必须满足： [ceil(m / 2)-1]<= n <= m-1



一棵m阶的B+树和m阶的B树的差异在于：

1.有n棵子树的结点中含有n个关键字； (而B 树是n棵子树有n-1个关键字)
。。B+树的第一个关键字是父节点的关键字。
。。所以value都是大于等于第一个关键字(也是父类的某个关键字)的，而B树，关键字不和父类的相等。所以value可能小于第一个关键字。
。。B+树的关键字表示value是属于本个key和后一个key之间的集合。如果本key是最后一个，那么是本key和父类的key的后一个之间的集合。

2.所有的叶子结点中包含了全部关键字的信息，及指向含有这些关键字记录的指针，且叶子结点本身依关键字的大小自小而大的顺序链接。 (而B 树的叶子节点并没有包括全部需要查找的信息)

3.所有的非终端结点可以看成是索引部分，结点中仅含有其子树根结点中最大（或最小）关键字。 (而B 树的非终节点也包含需要查找的有效信息)
。。2和3说的是，数据只在叶子节点上，非叶子节点只是索引。
，，所以1.子节点需要重复父节点的key。


B*-tree是B+-tree的变体，在B+ 树非根和非叶子结点再增加指向兄弟的指针；B*树定义了非叶子结点关键字个数至少为(2/3)*M，即块的最低使用率为2/3（代替B+树的1/2）
。。B树没有横向指针，B+叶子节点有横向指针。B*非根节点都有横向指针。


一棵含有N个总关键字数的m阶的B树的最大高度是多少?答曰：log_ceil（m/2）N（上面中关于m阶B树的第1点特性已经提到：树中每个结点含有最多含有m个孩子，即m满足：ceil(m/2)<=m<=m。而树中每个结点含孩子数越少，树的高度则越大，故如此）


B树insert
插入一个元素时，首先在B树中是否存在，如果不存在，即在叶子结点处结束，然后在叶子结点中插入该新的元素，注意：如果叶子结点空间足够，这里需要向右移动该叶子结点中大于新插入关键字的元素，
如果空间满了以致没有足够的空间去添加新的元素，则将该结点进行“分裂”，将一半数量的关键字元素分裂到新的其相邻右结点中，中间关键字元素上移到父结点中
（当然，如果父结点空间满了，也同样需要“分裂”操作），
而且当结点中关键元素向右移动了，相关的指针也需要向右移。
如果在根结点插入新元素，空间满了，则进行分裂操作，这样原来的根结点中的中间关键字元素向上移动到新的根结点中，因此导致树的高度增加一层。
。。树是向上长的。



B树删除
。。前驱，后继，必然在叶子节点。
若被删关键字K所在的结点非树叶，则用K的中序前趋(或后继)K'取代K，然后从叶子中删去K'。从叶子*x开始删去某关键字K的三种情形为：
　情形一：若x->keynum>Min，则只需删去K及其右指针(*x是叶子，K的右指针为空)即可使删除操作结束。
注意：
　 
　情形二：若x->keynum=Min，该叶子中的关键字个数已是最小值，删K及其右指针后会破坏B-树的性质(3)。
若*x的左(或右)邻兄弟结点*y中的关键字数目大于Min，则将*y中的最大(或最小)关键字上移至双亲结点*parent中，而将*parent中相应的关键字下移至x中。
显然这种移动使得双亲中关键字数目不变；*y被移出一个关键字，故其keynum减1，因它原大于Min，故减少1个关键字后keynum仍大于等于Min；而*x中已移入一个关键字，故删K后*x中仍有Min个关键字。涉及移动关键字的三个结点均满足B-树的性质(3)。 请读者验证，上述操作后仍满足B-树的性质(1)。移动完成后，删除过程亦结束。
　情形三：若*x及其相邻的左右兄弟(也可能只有一个兄弟)中的关键字数目均为最小值Min，则上述的移动操作就不奏效，
此时须*x和左或右兄弟合并。不妨设*x有右邻兄弟*y(对左邻兄弟的讨论与此类似)，在*x中删去K后，将双亲结点*parent中介于*x和*y之间的关键字K，作为中间关键字，与并x和*y中的关键字一起"合并"为一个新的结点取代*x和*y。因为*x和*y原各有Min个关键字，从双亲中移人的K'抵消了从*x中删除的K，故新结点中恰有2Min(即2「m/2」-2≤m-1)个关键字，没有破坏B-树的性质(3)。但由于K'从双亲中移到新结点后，相当于从*parent中删去了K'，若parent->keynum原大于Min，则删除操作到此结束；否则，同样要通过移动*parent的左右兄弟中的关键字或将*parent与其 左右兄弟合并的方法来维护B-树性质。最坏情况下，合并操作会向上传播至根，当根中只有一个关键字时，合并操作将会使根结点及其两个孩子合并成一个新的根，从而使整棵树的高度减少一层。

分析：
第1个被删的关键字h是在叶子中，且该叶子的keynum>Min(5阶B-树的Min=2)，故直接删去即可。
第2个删去的r不在叶子中，故用中序后继s取代r，即把s复制到r的位置上，然后从叶子中删去s。
第3个删去的p所在的叶子中的关键字数目是最小值Min，但其右兄弟的keynum>Min，故可以通过左移，将双亲中的s移到p所在的结点，而将右兄弟中最小(即最左边)的关键字t上移至双亲取代s。当删去d时，d所在的结点及其左右兄弟均无多余的关键字，故需将删去d后的结点与这两个兄弟中的一个(图中是选择左兄弟(ab))及其双亲中分隔这两个被合并结点的关键字c合并在一起形成一个新结点(abce)。但因为双亲中失去c后keynum<Min，故必须对该结点做调整操作，此时它只有一个右兄弟，且右兄弟无多余的关键字，不可能通过移动关键字来解决。因此引起再次合并，因根只有一个关键字，故合并后树高度减少一层，从而得到上图的最后一个图。



删除操作是指，根据key删除记录，如果B树中的记录中不存对应key的记录，则删除失败。

1）如果当前需要删除的key位于非叶子结点上，则用后继key（这里的后继key均指后继记录的意思）覆盖要删除的key，然后在后继key所在的子支中删除该后继key。此时后继key一定位于叶子结点上，这个过程和二叉搜索树删除结点的方式类似。删除这个记录后执行第2步

2）该结点key个数大于等于Math.ceil(m/2)-1，结束删除操作，否则执行第3步。

3）如果兄弟结点key个数大于Math.ceil(m/2)-1，则父结点中的key下移到该结点，兄弟结点中的一个key上移，删除操作结束。

否则，将父结点中的key下移与当前结点及它的兄弟结点中的key合并，形成一个新的结点。原父结点中的key的两个孩子指针就变成了一个孩子指针，指向这个新结点。然后当前结点的指针指向父结点，重复上第2步。

有些结点它可能即有左兄弟，又有右兄弟，那么我们任意选择一个兄弟结点进行操作即可。






B*树定义了非叶子结点关键字个数至少为(2/3)*M，即块的最低使用率为2/3（代替B+树的1/2）； 
B+树的分裂：当一个结点满时，分配一个新的结点，并将原结点中1/2的数据复制到新结点，最后在父结点中增加新结点的指针；B+树的分裂只影响原结点和父结点，而不会影响兄弟结点，所以它不需要指向兄弟的指针； 

B*树的分裂：当一个结点满时，如果它的下一个兄弟结点未满，那么将一部分数据移到兄弟结点中，再在原结点插入关键字，最后修改父结点中兄弟结点的关键字（因为兄弟结点的关键字范围改变了）；如果兄弟也满了，则在原结点与兄弟结点之间增加新结点，并各复制1/3的数据到新结点，最后在父结点增加新结点的指针； 

所以，B*树分配新结点的概率比B+树要低，空间使用率更高； 


B+树比B树更适合文件系统。



B+树由B树和索引顺序访问方法（ISAM，是不是很熟悉？对，这也是MyISAM引擎最初参考的数据结构）演化而来，但是在实际使用过程中几乎已经没有使用B树的情况了。

B+树是为磁盘或其他直接存取辅助设备而设计的一种平衡查找树，在B+树中，所有记录节点都是按键值的大小顺序存放在同一层的叶节点中，各叶节点指针进行连接。















布隆过滤器
它说没有就肯定没有。










































































