

Java性能，Java优化
JDK8            -- java 8 in action
Java并发编程实战
jdk静态代理。
偏向锁，轻量级锁，自旋锁，重量级锁



ctrl+e
ctrl+2,L
alt+shift+I
alt+shift+m
alt+方向键
ctrl+.  ctrl+1
F3
ctrl+q 最近一次编辑的地方
c+s+g workspace中搜索引用




《Java从入门到精通》

eclipse，babel：i18n。

透视图，多个视图的组合。
视图

文件
新建，shift+alt+N
关闭，ctrl+W
关闭所有编辑器，s+c+W
属性，alt+Enter

编辑
将选择范围扩展到，
查找下一个，c+K
查找上一个，s+c+K
添加书签
添加任务
灵活插入方式(切换插入方式，当禁用灵活插入方式时，将禁止自动缩进，添加右括号等辅助功能)，s+c+Insert
内容辅助
文字补全，c+a+/
快速修正，c+1

源代码
切换注释，c+/
添加块注释，s+c+/
去除块注释，s+c+\
更正缩进，c+I
组织导入，s+c+O
覆盖/实现方法
生成getter/setter.hashCode,equals,toString,构造函数
从超类中生成构造函数(对于当前选择的类型，按照超类中的定义来添加构造函数)
包围方式(用try..等.包围)，s+a+Z
外部化字符串(允许使用语句访问属性文件来替换代码中的所有字符串)

重构
重命名选择的java元素，s+a+R
移动选择的java元素，s+a+V
抽取方法(创建一个包含当前所选择的语句或表达式的新方法，并相关地引用)，s+a+M
抽取局部变量(创建为当前所选择的表达式指定的新变量，并将选择替换为对新变量的应用)，s+a+L
抽取常量(从所选表达式创建静态终态字段并替换字段引用，并且可以选择重写同一表达式的其他出现位置。)
内联(直接插入局部变量，方法或常量)，s+a+I
将匿名类转换为嵌套类(将匿名内部类转换为成员类)
将成员类型转换为顶级(为所选成员类型创建新的java编译单元，并根据需要更新所有引用)
将局部变量转换为字段(如果该变量是在创建时初始化的，则此操作将把初始化移动到新字段的声明或类的构造函数)
抽取超类(从一组同类型中抽取公共超类)
抽取接口(根据当前类的方法创建接口，并使该类实现这个接口)
包括字段(将对变量的所有引用替换为getXXX/setXXX方法)
历史记录(浏览工作空间重构历史记录，并提供用于从重构历史记录中删除重构的选项)

项目
全部构建(在工作空间中构建所有项目)，c+B
构建项目
构建工作集
清理
自动构建
生成javaDoc
属性

运行
运行上次启动，c+F11
调试上次启动，F11
运行历史记录
运行方式
运行
调试历史记录
调试历史
调试
切换行断点(添加或出去java编辑器中当前行的断点)，s+c+B
切换观察点(添加或删除当前java变量的观察点)
跳过所有断点
除去所有断点
添加java异常断点

窗口
打开透视图
显示视图
将透视图另存为
复位透视图
关闭透视图
关闭所有透视图
工作集
首选项


c+a+/自动补全java关键字，a+/启动eclipse代码辅助菜单。

syso,就可以直接alt+/;;;sys,alt+/是提示System。

c+a+/ 是直接补全，但是有问题。可能补全的不对，可能没办法补全(没反应)。

char存的是unicode字符，所以可以0x0000-0xffff.。2个字节。
。。但是char没办法用'\3333'来赋值，最大好像是'\377'...不知道为什么。
。。 '\377'是C语言中的一个转义字符,表示8进制的数377,对应的10进制为255
\ddd 1到3位八进制数所代表的任意字符 三位八进制
\xhh 1到2位十六进制所代表的任意字符 二位十六进制 
。。但是照网上写，\x不认啊。
。。有效的：'\67','\105','你','\333','\377','\u0045'

java是\123,8进制。\u0023，16进制
c/cpp，\123,8进制，\x22，16进制。
。。。网上的。

x=y=z=5;
。。这个不能在声明时就这样写。不，int e = a = b = 5;。。至多只能第一个未声明。

整型数值默认int，浮点型数值默认double。



&&，|| 短路
&,| 不短路
。。c,cpp里是 短路逻辑与，位与的区别。。没有不短路逻辑与。

java，&,|可以作为位与。


~,&,|,^,<<,>>,>>>
位反，位与，位或，异或，左移，右移，无符号右移，

<<补0
>>补符号位
>>>补0


a = a ^ b;
b = b ^ a;
a = a ^ b;
a,b互换



Arrays.fill(int[] a, int value)

Arrays.fill(int[] a, int fromIndex, int toIndex, int value)
包含fromIndex，不包含toIndex

Arrays.sort(Object)
copyOf(int[] arr, int newLength)
copyOfRange(int[] arr, int fromIndex, int toIndex)
包含from，不包含to


new String()
new String(char a[])
new String(char a[], int offset, int length)

indexOf(String subStr)
lastIndexOf(String subStr)
str.charAt(int index);
str.trim()

去除所有空格可以用StringTokenizer，replaceAll
StringTokenizer(String str, String delim)，这个是类。。hasMoreTokens(),nextToken().

public String replaceAll(String regex, String replacement) {
..正则！

replace方法的形参要么char，要么CharSequence
replaceFirst

equals
equalsIgnoreCase
startsWith
endsWith
toLowerCase
toUpperCase

public String[] split(String regex) {
	return split(regex, 0);
}
。。regex

Character.isDigit

public static String format(String format, Object... args) {

日期格式化转换符
%te		一个月中某天(1-31)
%tb		指定语言环境的月份简称
%tB		语言环境的月份全称
%tA		环境的星期几全称
%ta		环境的星期几简称
%tc		包括全部日期和时间信息
%tY		4位数的年份
%tj		一年中的第几天(1-366)
%tm		月份
%td		一个月中的第几天(01-31)
%ty		2位数的年份

时间格式化
%tH		2位数字的24时制的小时(00-23)
%tI		2位数字的12		(01-12)
%tk		2位数字的24		(0-23)
%tl		2位数字的12		(1-12)
%tM		2位数字的分钟	(00-59)
%tS		2位数字的秒数
%tL		3位数字的毫秒数
%tN		9位数字的微秒数
%tp		语言环境的上午或下午标记
%tz		相对于GMT RFC 82格式的数字时区偏移量
%tZ		时区缩写形式的字符串
%ts		1970-1-1至今的秒数
%tQ		1970-1-1至今的毫秒数

日期时间组合格式化
%tF		yyyy-MM-dd
%tD		MM/dd/yy
%tc		全部日期和时间信息
%tr		时:分:秒 PM/AM	12小时制
%tT		时:分:秒			24
%tR		时:分			24

常规类型格式化
%b,%B	结果被格式化为布尔类型
%h,%H	散列码
%s,%S	字符串
%c,%C	字符
%d		十进制整数
%o		8
%x,%X	16
%e		科学计数法表示的十进制
%a		带有效位数和指数的16进制浮点数
%n		特定于平台的行分隔符
%%		%


DecimalFormat。。。
NumberFormat。。

正则
String....matches(String regex)

\得用\\转义

正则表达式中的元字符
.			任意一个字符
\d			0-9数字
\D			非数字
\s			空白字符，如\t,\n
\S			非空白字符
\w			可用作标识符的字符，不包含$
\W			不可用作标志符的字符
\p{Lower}	小写a-z
\p{Upper}	大写A-Z
\p{ASCII}	ASCII字符
\p{Alpha}	字母字符
\p{Digit}	十进制数字，即0-9
\p{Alnum}	数字或字母
\p{Punct}	标点符号
\p{Graph}	可见字符
\p{Print}	可打印字符
\p{Bland}	空格或制表符
\p{Cntrl}	控制字符


限定符
?		0/1次
*		0或多次
+		1或多次
{n}		n次
{n,}	至少n次
{n,m}	n-m次

方括号中元字符的含义
[abc]			a或b或c
[^abc]			a,b,c之外的任何字符
[a-zA-Z]		a-z或A-Z
[a-d[m-p]]		a-d或m-p
[a-z&&[def]]	d或e或f
[a-z&&[^bc]]	a-z且不是b,c
[a-z&&[^m-p]]	a-z且不在m-p


StringBuilder
append(String)
append(StringBuffer)
insert(int offset, String str)
delete(int start, int end)
toString()


this()
super()
调用自己，父类的构造方法。

类中的
static {}		只执行一次
{}			每次new都会执行

不写访问权限修饰符是包访问。
protected是包或子类

protected finalize()。垃圾回收时，先调用该方法，下次垃圾回收时，才真正回收内存。

System.gc().


单例，能利用继承写个模板？


interface中可以声明+定义常量。
final float PI = 3.14159f;


无法继承private的属性。所以属性基本都不会被继承。
应该可以覆盖父类的非private的变量吧。实际父类变量还是存在的，可以super。

Comparable

抽象方法不能private，static修饰

包含抽象方法时，类必须是抽象类。


成员内部类
在一个类中使用内部类，可以在内部类中直接存取其所在类的私有成员变量。外部类访问内部类要按照访问权限来。
内部类的实例一定要绑在外部类的实例上。如果在外部类中初始化一个内部类对象，则这个内部类对象就会绑定在外部类对象上。

OuterClass out = new OuterClass();
OuterClass.InnerClass inn = out.new InnerClass();

public class O
{
	private int x;
	private class I
	{
		private int x = 9;
		public void doit(int x)
		{
			x++;			// 形参
			this.x++;		// 内部类x
			O.this.x++;		// 外部类x			// ！！！！
		}
	}
}


局部内部类
类的方法中定义的内部类。
这个内部类可以访问当前代码块的常量以及外部类的所有成员。
内部类的生命周期/作用范围是方法内，所以外部类无法访问到这个内部类。

public class O
{
	String n = "a";
	public void f1()
	{
		class I
		{
			int x = 1;
			public void f2() { sysout(x + a); }
		}
		I i = new I();
		i.f1();
	}
}


匿名内部类
不一定要给内部类取一个名字，可以直接以对象名来代替。匿名内部类的所有实现代码都要在大括号之间编写。

return new A() {...};
A表示对象名。

匿名内部类没有名称，所以匿名内部类使用默认构造器来生成对象。在匿名内部类定义结束后，需要加分号标识，这个分号并不代表定义内部类结束，而是代表创建匿名内部类的引用表达式的结束。


静态内部类
内部类前面加static。静态内部类可以声明静态成员，非静态内部类无法声明静态成员。但静态内部类无法访问外部类的非静态成员，所以很少见。
创建静态内部类的对象时，不需要外部类的对象。

内部类的继承
public class Clz1 extends A.B
{
	public Clz1(A a) { a.super(); }
}

class A
{
	class B {}
}

在某个类继承内部类时，必须硬性给予这个类一个带参数的构造方法，并且该参数是需要继承的内部类的外部类的引用，同时在构造器中使用a.super();

class Printer implements ActionListener
Toolkit.getDefaultToolkit().beep();
new Timer(delay, new Printer()).start();



Class与反射
getPackage()
getName
getSuperclass
getInterfaces
getConstructors(),getConstructors(Class<?>...parameterTypes),getDeclaerdConstructors(),getDeclaredConstructor(Class<?>...parameterTypes)
getMethods(),getMethod(String name, Class<?>,,,parameterTypes),getDeclaredMethods(),getDeclaredMethod(Stirng name, Class<?>,,,parameterTypes)
getFields(),getField(String name),getDeciaredFields(),getDeclaredField(String name, Class<?>,,,parameterTypes)

getClasses(),getDeclaredClasses(). 获得内部类。
getDeclaringClass(). 如果该类是内部类则返回它的成员类，否则返回null。


Constructor类方法
isVarAgrs()		是否允许带有可变数量的参数，true:允许。
getParameterTypes()		按声明顺序获得构造器的各个参数类型
getExceptionTypes()		获得可能抛出的异常
newInstance(Object...initargs)	用参数创建一个该类的对象。
setAccessible(boolean flag)		设置可见性
getModifiers()	获得可以解析出该构造器修饰符的整数。

Modifier类的常用静态方法
isPublic(int mod)
isProtected(int)
isPrivate(int)
isStatic(int)
isFinal(int)
toString(int)


Field类中方法
getName()
getType()
get(Object obj)
set(Object obj, Object value)
getInt(Object obj)		// 获得指定对象obj中类型为int的该成员变量的值
setInt(Object obj, int i)
getFloat
setFloat
getBoolean
setBoolean
setAccessible(boolean flag)
getModifiers()
。。getInt等方法的意义？可能存在多个吧。

int.class 是存在的。


Method方法
getName()
getParameterTypes()
getReturnType()			// ... void 返回什么？
getExceptionType()
invoke(Object obj, Object ... args)
isVarArgs()				// 是否有可变长参数列表
getModifiers()		// 获得可以解析出修饰符的整数



List接口方法
add(int index, Object obj)
addAll(int index, Collection col)
remove(int index)
get(int index)
indexOf(Object obj)
lastIndexOf(Object obj)
subList(int fromIndex, int toIndex)
set(int index, E element)
listIterator()


Set接口
add(Object obj)
addAll(Collection col)
remove(Object obj)
retainAll(Collection c)
removeAll(Collection c)
clear()
iterator()
size()
isEmpty()

retain，保留。retainAll，保留相同元素(求交集)


Map接口
put(Object key, Object value)
containkey(Object key)
containsValue(Object value)
get(Object key)
keySet()
values()


Iterator方法
hasNext
next
remove


Throwable方法
getLocalizedMessage()
getMessage()
printStackTrace()
toString()
..message.


try{} finally{}

访问修饰符 返回类型 方法名(形参) throws 异常1,异常2 {}

throw new Exception("");

方法被覆盖时，覆盖它的方法必须抛出相同的异常或子异常。
。。为了多态能正确使用，不然父类抛出RuntimeException，子类抛Throwable，原来的代码抓不住的。

public class NewException extends Exception
{
	public NewException(Double r)
	{
		sysout("" + r);
	}
}

Class.forName("com.mysql.jdbc.Driver");
DriverManager.getConnection()



InputStream是字节输入流的抽象类，是所有字节输入流的父类。类中所有方法遇到错误时都会抛出IOException
子类有：AudioInputStream,ByteArrayInputStream,StringBufferInputStream,FileInputStream,FilterInputStream,InputStream,ObjectInputStream,SequenceInputStream,PipedInputStream.

FilterInputStream的子类有：BufferedInputStream,DataInputStream,PushbackInputStream...等。

InputStream方法
read()			从输入流中读取下一个字节，返回[0,255]的int值，如果已经达到流末尾而没有可用字节，返回-1.
read(byte[] b)		从输入流读取一定长度的字节，并以int返回字节数。
mark(int readlimit)	在输入流的当前位置放置一个标记，readlimit参数告知此输入流在标记位置失效前允许读取的字节数
reset()	将输入指针返回到当前所做的标记处
skip(long n)	跳过输入流的n个字节并返回实际跳过的字节数。
markSupported()		如果当前流支持mark/reset就返回true
close()		关闭此输入流并释放与该流有关的所有系统资源。



Java的字符是Unicode编码，是双字节的。InputStream是用来处理字节的，在处理字符文本时很不方便。Java为字符文本的输入提供了专门的一套类Reader，Reader不是InputStream的替换者，只是在处理字符串时简化了编程。

Reader是字符输入流的抽象类。
子类有：CharArrayReader,BufferedReader(LineNumberReader),FilterReader(PushbackReader),InputStreamReader(FileReader),PipedReader,StringReader
..括号中为子类


输出流
OutputStream是字节输出流的抽象类。
子类：ByteArrayOutputStream,FileOutputStream,FilterOutputStream(BufferedOutputStream,DataOutputStream...等),ObjectOutputStream,OutputStream,PipedOutputStream

OutputStream所有方法都返回void，遇到错误会引发IOException
write(int b)			将制定字节写入输出流
write(byte[] b)		将b.length个字节从数组写入输出流
write(bytr[] b, int off, int len)	将数组中从编译了off开始的len个字节写入到输出流
flush()		彻底完成输出并清空缓存区
close()		关闭输出流


Writer是字符输出流的抽象类
子类：BufferedWriter,CharArrayWriter,FilterWriter,OutputStreamWriter(FileWriter),PipedWriter,PrintWriter,StringWriter.




File类
3种构造方法
File(String pathname)		// 路径
File(String parent, String child)	// 父路径，子路径
File(File f, String chile)	// 根据f的路径名和子路径名

new File("d:/1.txt")
new File("d:/myword", "word.txt")

如果目录里没有word.txt,File对象可以创建，如果存在，file对象可以删除。
File file = new File("D:/myword", "word.txt");
if (file.exists()) file.delete();
else try { file.createNewFile(); } catch() {}


File类方法
getName		文件名称
canRead		文件是否可读
canWrite		是否可写入
exists			是否存在
length			字节长度
getAbsolutePath	绝对路径
getParent		父路径
isFile			是否是文件
isDirectory		是否是目录
isHidden		是否隐藏
lastModified	最后修改时间



FileInputStream，继承自 InputStream
FileOutputStream		OutputStream

FileInputStream(String name)
FileInputStream(File file)

FileOutputStream的构造器参数和上面一样，创建一个FileOutputStream时，可以指定不存在的文件名，但是此文件不能是一个以被其他程序打开的文件。


FileReader，FileWriter

FileInputStream和FileOutputStream都是字节或字节数组读入，写出。由于汉字占多个字节，所以使用字节流，读取不好可能出现乱码情况。

FileReader，FileWrite是字符读入，写出。

FileReader顺序读取文件，只要不关闭流，每次read方法就顺序读取源中其余内容，直到源末尾或流被关闭。


带缓存的输入输出流
BufferedInputStream
BufferedOutputStream

BufferedInputStream(InputStream in)
BufferedInputStream(InputStream in, int size)

BufferedOutputStream 也是相同的参数。

size是缓冲区字节大小，默认32字节。


BufferedReader
BufferedWriter

。。。


DataInputStream
DataOutputStream

DataInputStream(InputStream in)
DataOutputStream(OutputStream out)

DataOutputStream，3中写入字符串的方法
writeBytes(String s)
wirteChars(String s)
writeUTF(String s)

DataInputStream.只有一个readUTF方法。这是因为在一个连续的字节流读入一个字符串，如果没有特殊的标记作为一个字符串的结尾，而且事先也不知道这个字符串的长度，也就无法知道读取到什么位置才是这个字符串的结束。DataOutputStream中只有writeUTF向目标设备中写入字符串的长度，所以能准确地读入字符串。


313
ZIP压缩输入输出流
java.util.zip包
ZipOutputStream，ZipInputStream

ZIP，所以需要知道读入或写出的文件在ZIP内部的路径。用ZipEntry表示。


ZipOutputStream(OutputStream out)

常用方法
putNextEntry(ZipEntry e)	开始写一个新的ZipEntry，并将流的位置移至此Entry所指数据的开头。
write(byte[] b, int off, int len)	将字节数组写入当前zip条目数据
finish()		完成写入zip输出流的内容，无须关闭OutputStream。
setComment(String comment)		zip文件的注释


ZipInputStream(InpoutStream in)

read(byte[] b, int off, int len)
available()		判断是否已读完目前entry所指定的数据，已读完返回0，否则返回1.
closeEntry()	关闭当前ZIP条目并定位流以读取下一个条目。
skip(long n)	跳过当前ZIP条目中指定的字节数
getNextEntry()	读取下一个ZipEntry，将流内的位置移至该entry所指数据的开头
createZipEntry(String name)	以指定的name参数新建一个ZipEntry对象。


Swing跳过
高级事件处理跳过



373
线程

继承java.lang.Thread
实现java.lang.Runnable

public Thread(String threadName)
public Thread()

线程的功能放在run方法中，start开启线程，会调用run方法。

Thread类实现了Runnable接口

实现Runnable接口的程序会创建一个Thread对象，并将Runnable对象和Thread对象相关联。
public Thread(Runnable r)
public Thread(Runnable r, String name)

使用Runnable接口启动新线程的步骤：
1.建立Runnable对象
2.Runnable对象作为形参构造Thread对象
3.调用start。

。。Runnable是因为单继承的缘故所以需要。

线程.wait()
线程.notify()

thread.getState()

Thread.currentThread().getThreadGroup();


线程状态：出生，就绪，运行，等待，休眠，阻塞，死亡。

调用start之前是出生，start之后是就绪，获得系统资源后是运行。

wait，等待
notify，唤醒
sleep，休眠

如果一个线程在运行状态下发出输入输出请求，该线程就会进入阻塞状态。

run执行完，就是死亡。

线程的加入
要求线程B先执行完，然后线程A执行。可以使用Thread类的join方法完成

class XX
{
	private Thread threadA, threadB;
	
	main()
	{
		threadA = new Thread(new Runnable()
		{
			public void run()
			{
				threadA.sleep(100);
				threadB.join();
			}
		});
		threadA.start();
		threadB = new Thread(new Runnable() { ... });
		threadB.start();
	}
}


以前使用stop方法停止线程。但当前版本jdk已经废除了stop方法。同时也不建议用stop来停止一个线程的运行。现在提倡在run方法中使用无限循环的形式，然后使用一个boolean控制循环的停止。

如果线程是因为使用了sleep或wait方法进入了就绪状态，这时可以使用Thread类中的interrupt方法使线程离开run方法，同时结束线程，但程序会抛出InterruptedException。


Thread提供了一种礼让方法，使用yield方法表示，它只是给当前正在运行状态的线程一个提醒，告知它可以将资源礼让给其他线程，但这只是一个暗示，不能保证当前线程会将资源礼让。
yield()使具有同样优先级的线程有进入可执行状态的机会，当当前线程放弃执行权时会再度回到就绪状态。对于支持多任务的os来说，不需要yield，因为os会自动为线程分配cpu时间片。

默认情况下，新建线程的优先级与创建该线程的线程的优先级相同。

垃圾回收线程的优先级较低。

Thread类中包含的成员变量代表了线程的某些优先级，Thread.MIN_PRIORITY(常数1),Thread.MAX_PRIORITY(常数10)，Thread.NORM_PRIORITY(常数5).每个线程的优先级都在1-10。默认情况下，优先级是NORM_PRIORITY。

setPriority().设置优先级，不在1-10会抛异常。


线程同步
同步块
synchronized(Object) { ... }
Object为任意一个对象，每个对象都存在一个标志位，并具有2个值，0，1.一个线程运行到同步块首先检查该对象的标志位，0说明有其他线程运行。这时该线程处于就绪状态，直到处于同步块中的线程执行完同步块中代码为止。这时该对象的标志位被置为1，该线程才能执行同步块中代码，并将Object对象的标志位置为0，防止其他线程运行同步块中代码。
。。。怎么保证查询，设置0，1是同步的呢？

同步方法
synchronized void f() {}


线程间通信
通过wait，notify，notifyAll实现。

sleep不释放锁，wait线程释放锁。


wait(time)
wait()


wait,notify,notifyAll只能在同步块或同步方法中使用。



网络通信

ping，IP
Process process = Runtime.getRuntime().exec("ping " + ip + " -w 280 -n 1");
InputStream is = process.getInputStream();
InputStreamReader isr = new InputStreamReader(is);
BufferedReader in = new BufferedReader(isr);
String line = in.readLine();

解析网页内容
URL url = new URL(utlString);
URLConnection conn = url.openConnection();
conn.connect();
InputStream is = conn.getInputStream();
InputStreamReader in = new InputStreamReader(is, "UTF-8");
BufferedReader br = new BufferedReader(in);
String nextLine = br.readLine();


TCP
服务端与客户端交互过程
1.服务器创建一个ServerSocket，调用accept方法等待客户端连接
2.客户端创建一个Socket，请求与服务器建立连接
3.服务器收到客户端请求，创建一个新的Socket与客户建立连接。


java.net.InetAdress类是与IP地址有关的类。利用该类可以获取IP地址，主机地址等信息。
常用方法：
InetAdress getByName(String host)	获取与host对应的InetAdress
String getHostAdress()	获取InetAdress对象中的IP地址
String getHostName()	获取主机名
InetAdress getLocalHost()	返回本地主机的InetAdress对象。

还有很多其他方法。看jdk

java.net.ServerSocket类用于表示服务器套接字。主要功能是等待来自网络上的请求。它可以通过指定的端口来等待连接的套接字。服务器套接字一次可以与一个套接字连接。如果多台客户机同时提出连接请求，服务器套接字会将请求连接的客户机存入队列中，然后从中取出一个套接字，与服务器新建的套接字连接起来。若请求连接数大于最大容纳数，则多出的请求会被拒绝。队列默认大小是50.

Scoket accept()		等待客户机的连接。若连接，则创建一套接字。
boolean isBound()	判断ServerSocket的绑定状态
InetAddress getInetAddress()	返回此服务器套接字的本地地址
boolean isClosed()
void close()
void bind(SocketAdress endpoint)	将ServerSocket绑定到特定地址(IP地址和端口号)
InetAddress getInetAddress() 返回ServerSocket的本地InetAdress

accept会阻线程直到收到客户机的请求。如果没有阻塞，问题通常是，其他程序占用了端口，导致ServerSocket绑定失败。


UDP

基于UDP通信的基本模式如下：
将数据打包(称为数据包)，然后将数据包发往目的地。
接收别人发过来的数据包，然后查看数据包。

发送数据包：
1.DatagramSocket()创建一个数据包套接字
2.使用DatagramPacket(byte[] buf, int offset, int length, InetAddress address, int port)创建要发送的数据包
3.使用DatagramSocket类的send方法发送数据包。

接收数据包：
1.DatagramSocket(int port)创建数据包套接字，绑定到指定的端口
2.DatagramPacket(byte[] buf, int length)方法创建字节数组来接受数据包。
3.使用receive方法来接收UDP包。


java.net.DatagramPacket类用来表示数据包。
DatagramPacket(byte[] buf, int length)
DatagramPacket(byte[] buf, int length, InetAddress address, int port)
第一种指定了数据包的内存空间和大小。第二种还额外指定了数据包的目标地址和端口。在发送数据时，必须指定接收方的Socket地址和端口。


java.net.DatagramSocket类用于表示发送和接受数据包的套接字。
DatagramSocket()
DatagramSocket(int port)
DatagramSocket(int port, InetAddress addr)
第一种创建DatagramSocket，构造数据包套接字并将其绑定到本地主机上任何可用的端口。
第二种创建DatagramSocket，构造数据包套接字并将其绑定到本地主机上指定端口。
第三种创建DatagramSocket，构造数据包套接字，将其绑定到指定的本地地址。适用于有多块网卡和多个IP的情况。










public class demo1 {
 /**
  * 使用jdbc实现查询数据库数据并显示在控制台中
  * @throws SQLException 
  */
 public static void main(String[] args) throws Exception {
  // 1.注册驱动，与数据库建立连接
   //不建议使用： DriverManager.registerDriver(new com.mysql.jdbc.Driver());
    //导致驱动被注册两次，强烈依赖数据库的驱动jar
  //1.加载驱动
   Class.forName("com.mysql.jdbc.Driver");  //反射机制加载驱动类
  // 2.获取连接Connection
    //主机:端口号/数据库名
  Connection conn=DriverManager.getConnection("jdbc:mysql://localhost:3306/cw","root","root");
  // 3.得到执行sql语句的对象Statement
  Statement stmt = conn.createStatement();
  // 4.执行sql语句，并返回结果
  ResultSet rs=stmt.executeQuery("select *from users");
  // 5.处理结果
  while(rs.next()){
   System.out.println(rs.getObject(1));
   System.out.println(rs.getObject(2));
   System.out.println(rs.getObject(3));
   System.out.println(rs.getObject(4));
   System.out.println(rs.getObject(5));
   System.out.println("---------------------");
  }
  // 6.关闭资源
  rs.close();
  stmt.close();
  conn.close();
 }
 @Test
 public void test2() throws Exception{
    //1.加载驱动
     Class.forName("com.mysql.jdbc.Driver");  //反射机制加载驱动类
    // 2.获取连接Connection
      //主机:端口号/数据库名
        //map集合
    Properties info=new Properties();
    info.setProperty("user", "root");
    info.setProperty("password", "root");
    Connection conn=DriverManager.getConnection("jdbc:mysql://localhost:3306/cw",info);
    // 3.得到执行sql语句的对象Statement
    Statement stmt = conn.createStatement();
    // 4.执行sql语句，并返回结果
    ResultSet rs=stmt.executeQuery("select *from users");
    // 5.处理结果
    while(rs.next()){
     System.out.println(rs.getObject(1));
     System.out.println(rs.getObject(2));
     System.out.println(rs.getObject(3));
     System.out.println(rs.getObject(4));
     System.out.println(rs.getObject(5));
     System.out.println("---------------------");
    }
    // 6.关闭资源
    rs.close();
    stmt.close();
    conn.close();
 }
 @Test
 public void test3() throws Exception{
  //1.加载驱动
   Class.forName("com.mysql.jdbc.Driver");  //反射机制加载驱动类
  // 2.获取连接Connection
    //主机:端口号/数据库名
      //map集合
  Connection conn=DriverManager.getConnection("jdbc:mysql://localhost:3306/cw?user=root&password=root");
  // 3.得到执行sql语句的对象Statement
  Statement stmt = conn.createStatement();
  // 4.执行sql语句，并返回结果
  ResultSet rs=stmt.executeQuery("select *from users");
  // 5.处理结果
  while(rs.next()){
   System.out.println(rs.getObject(1));
   System.out.println(rs.getObject(2));
   System.out.println(rs.getObject(3));
   System.out.println(rs.getObject(4));
   System.out.println(rs.getObject(5));
   System.out.println("---------------------");
  }
  // 6.关闭资源
  rs.close();
  stmt.close();
  conn.close();
}
}




jdbc制定了统一的访问各类关系数据库的标准接口。

DriverManager类用来管理数据库中的所有驱动程序。
getConnection(String url, String user, String password)
setLoginTimeout()
println(String msg)

Connection接口代表与特定数据库的连接。可以用过DriverManager的getConntection方法获取Conntection实例。
createStatement()
createStatement(int resultSetType, int resultSetConcurrency)	创建statement对象，该对象将生成具有给定类型，并发性和可保存性的ResultSet对象。
prepareStatement()
isReadOnly()
setReadOnly()
commit()
rollback()
close()

Statement接口用于创建向数据库中传递sql语句的对象。
execute(String sql)		执行静态select语句，可能返回多个结果集
executeQuery(String sql)	执行sql，返回单个ResultSet对象
clearBatch()
executeBatch()
executeUpdate()		执行给定sql语句，该语句可以是insert，update，delete语句
addBatch(String sql)	如果驱动程序不支持批量处理将抛出异常
close()

PreparedStatement继承Statement，用于执行动态sql语句，通过PreparedStatement实例执行的sql语句，将被预编译并保存到PreparementStatement实例中，从而可以反复地执行该sql。
execute()
executeQuery()
executeUpdate()
setByte(int pIndex, byte bt)
setDouble(int pIndex, double dou)
setInt(int pIndex, int x)
setObject(int pIndex, Object o)
setString(int pIndex, String str)
。。得需要占位符啊。


ResultSet接口类似一个临时表，用来暂存数据库查询操作所获得的结果集。
getInt(),getFloat,getDate,getBoolean,getString,getObject。
next
updateInt(),updateFloat(),...updateNull()


加载数据库驱动
Class.forName(String driverManager)

建立连接
Class.forName("com.mysql.jdbc.Driver");
String url = "jdbc:mysql://localhost:3306/db_database17";
String user = "root";
String pwd = "111";
Connection conn = DriverManager.getConnection(url, user, pwd);

添加数据
String sql = "insert into tb_users(username,password,sex,age) values ('张三','111','男','22')";
Statment stmt = conn.createStatement();
stmt.executeUpdate(sql);
conn.close();


String sql = "insert into tb_users (username, password, sex, age) values(?,?,?,?)";
PreparedStatement ps = conn.prepareStatement(sql);
ps.setString(1, "李四");
ps.setString(2, "aaa");
ps.setString(3, "男")
ps.setInt(4, 23);
ps.executeUpdate();
conn.close();


Statement接口的executeUpdate，executeQuery方法可以执行sql，executeUpdate用于执行数据的插入，修改，删除，返回受影响的数据库记录的条数。executeQuery()用于执行select语句，返回一个ResultSet结果集。
Statement stmt = conn.createStatement();
String sql = "select * from tb_users";
ResultSet rs = stmt.executeQuery(sql);
while (rs.next())
{
	id = rs.getInt("id");
	username = rs.getStrign(2);
	pwd = rs.getString("password");
	sex = rs.getString(4);
	age = rs.getInt("age");
}


更改数据库数据
String sql = "update tb_users set age=20 where id=1";
Statement stmt = conn.createStatement();
stmt.executeUpdate(sql);
conn.close();


String sql = "update tb_users set password = ? where sex = ?";
PreparedStatement ps = conn.preparedStatement(sql);
ps.setString(1, "admin");
ps.setString(2, "男");
int count = ps.executeUpdate();
sysout(count);
conn.close();



Swing高级组件
高级布局管理器
AWT绘图技术
酒店管理系统

Java从入门到精通。over。



Java性能，Java优化
1. 尽量在合适的场合使用单例
单例主要适用于以下三个方面：
第一，控制资源的使用，通过线程同步来控制资源的并发访问；
第二，控制实例的产生，以达到节约资源的目的；
第三，控制数据共享，在不建立直接关联的条件下，让多个不相关的进程或线程之间实现通信。

2. 尽量避免随意使用静态变量
当某个对象被定义为static变量所引用，那么GC通常是不会回收这个对象所占有的内存

3. 尽量避免过多过常地创建Java对象
在我们可以控制的范围内，最大限度地重用对象，最好能用基本的数据类型或数组来替代对象。

4. 尽量使用final修饰符
final类的所有方法都是final，final方法会尝试内联，getter/setter方法变成final。

5. 尽量使用局部变量
调用方法时传递的参数以及在调用中创建的临时变量都保存在栈（Stack）中，速度较快；其他变量，如静态变量、实例变量等，都在堆（Heap）中创建，速度较慢。

6. 尽量处理好包装类型和基本类型两者的使用场所
内存区域不同，基本类型在栈中，包装类型在堆中。
在集合类对象，有对象方面需要的处理适用包装类型，其他的处理提倡使用基本类型。

7. 慎用synchronized，尽量减小synchronize的方法
实现同步是要很大的系统开销作为代价的，甚至可能造成死锁，所以尽量避免无谓的同步控制。synchronize方法被调用时，直接会把当前对象锁了，在方法执行完之前其他线程无法调用当前对象的其他方法。所以，synchronize的方法尽量减小，并且应尽量使用方法同步代替代码块同步。
。。？synchronized不会导致无法调用当前对象的其他方法吧？难道syn在class上？

9. 尽量不要使用finalize方法

10. 尽量使用基本数据类型代替对象
String str = "hello";
上面这种方式会创建一个“hello”字符串，而且JVM的字符缓存池还会缓存这个字符串；
String str = new String("hello");
此时程序除创建字符串外，str所引用的String对象底层还包含一个char[]数组，这个char[]数组依次存放了h,e,l,l,o

11. 多线程在未发生线程安全前提下应尽量使用HashMap、ArrayList
HashTable、Vector等使用了同步机制，降低了性能。

12. 尽量合理的创建HashMap
当你要创建一个比较大的hashMap时，充分利用这个构造函数
public HashMap(int initialCapacity, float loadFactor);
避免HashMap多次进行了hash重构,扩容是一件很耗费性能的事，在默认中initialCapacity只有16，而loadFactor是 0.75，需要多大的容量，你最好能准确的估计你所需要的最佳大小，同样的Hashtable，Vectors也是一样的道理。

13. 尽量减少对变量的重复计算
for(int i=0;i<list.size();i++)
应该改为：
for(int i=0,len=list.size();i<len;i++)

14. 尽量避免不必要的创建
A a = new A();
if(i==1){
	list.add(a);
}
应该改为：
if(i==1){
	A a = new A();
	list.add(a);
}

15. 尽量在finally块中释放资源

16. 尽量使用移位来代替'a/b'的操作
"/"是一个代价很高的操作，使用移位的操作将会更快和更有效
int num = a / 4;
int num = a / 8;
应该改为：
int num = a >> 2;
int num = a >> 3;

17.尽量使用移位来代替'a*b'的操作
int num = a << 2;
int num = a << 3;

18. 尽量确定StringBuffer的容量
StringBuffer 的构造器会创建一个默认大小（通常是16）的字符数组。在使用中，如果超出这个大小，就会重新分配内存，创建一个更大的数组，并将原先的数组复制过来，再丢弃旧的数组。
StringBuffer buffer = new StringBuffer(1000);

19. 尽量早释放无用对象的引用
大部分时，方法局部引用变量所引用的对象会随着方法结束而变成垃圾，因此，大部分时候程序无需将局部，引用变量显式设为null。

Public void test(){
Object obj = new Object();
……
Obj=null;
}
上面这个就没必要了，随着方法test()的执行完成，程序中obj引用变量的作用域就结束了。但是如果是改成下面：
Public void test(){
Object obj = new Object();
……
Obj=null;
//执行耗时，耗内存操作；或调用耗时，耗内存的方法
……
}
这时候就有必要将obj赋值为null，可以尽早的释放对Object对象的引用。

20. 尽量避免使用二维数组
二维数据占用的内存空间比一维数组多得多，大概10倍以上。
。。？？？平方啊。

21. 尽量避免使用split
除非是必须的，否则应该避免使用split，split由于支持正则表达式，所以效率比较低，如果是频繁的几十，几百万的调用将会耗费大量资源，如果确实需要频繁的调用split，可以考虑使用apache的StringUtils.split(string,char)，频繁split的可以缓存结果。

22. ArrayList & LinkedList
一个是线性表，一个是链表，一句话，随机查询尽量使用ArrayList，ArrayList优于LinkedList，LinkedList还要移动指针，添加删除的操作LinkedList优于ArrayList，ArrayList还要移动数据，不过这是理论性分析，事实未必如此，重要的是理解好2者得数据结构，对症下药。

23. 尽量使用System.arraycopy ()代替通过来循环复制数组
System.arraycopy() 要比通过循环来复制数组快的多。

24. 尽量缓存经常使用的对象
尽可能将经常使用的对象进行缓存，可以使用数组，或HashMap的容器来进行缓存，但这种方式可能导致系统占用过多的缓存，性能下降，推荐可以使用一些第三方的开源工具，如EhCache，Oscache进行缓存，他们基本都实现了FIFO/FLU等缓存算法。

25. 尽量避免非常大的内存分配
有时候问题不是由当时的堆状态造成的，而是因为分配失败造成的。分配的内存块都必须是连续的，而随着堆越来越满，找到较大的连续块越来越困难。

26. 慎用异常
当创建一个异常时，需要收集一个栈跟踪(stack track)，这个栈跟踪用于描述异常是在何处创建的。构建这些栈跟踪时需要为运行时栈做一份快照，正是这一部分开销很大。
招致性能损失的并不是 throw 操作――尽管在没有预先创建异常的情况下就抛出异常是有点不寻常。真正要花代价的是创建异常，幸运的是，好的编程习惯已教会我们，不应该不管三七二十一就抛出异常。异常是为异常的情况而设计的，使用时也应该牢记这一原则。

27. 尽量重用对象
特别是String对象的使用中，出现字符串连接情况时应使用StringBuffer代替，由于系统不仅要花时间生成对象，以后可能还需要花时间对这些对象进行垃圾回收和处理。因此生成过多的对象将会给程序的性能带来很大的影响。

28. 不要重复初始化变量
默认情况下，调用类的构造函数时，java会把变量初始化成确定的值，所有的对象被设置成null，整数变量设置成0，float和double变量设置成0.0，逻辑值设置成false。当一个类从另一个类派生时，这一点尤其应该注意，因为用new关键字创建一个对象时，构造函数链中的所有构造函数都会被自动调用。
这里有个注意，给成员变量设置初始值但需要调用其他方法的时候，最好放在一个方法。比如initXXX()中，因为直接调用某方法赋值可能会因为类尚未初始化而抛空指针异常，如：public int state = this.getState()。

29. 在java+Oracle的应用系统开发中，java中内嵌的SQL语言应尽量使用大写形式，以减少Oracle解析器的解析负担。

30. 在java编程过程中，进行数据库连接，I/O流操作，在使用完毕后，及时关闭以释放资源。因为对这些大对象的操作会造成系统大的开销。

31. 过分的创建对象会消耗系统的大量内存，严重时，会导致内存泄漏，因此，保证过期的对象的及时回收具有重要意义。JVM的GC并非十分智能，因此建议在对象使用完毕后，手动设置成null。

32. 在使用同步机制时，应尽量使用方法同步代替代码块同步。

33. 不要在循环中使用Try/Catch语句，应把Try/Catch放在循环最外层
Error是获取系统错误的类，或者说是虚拟机错误的类。不是所有的错误Exception都能获取到的，虚拟机报错Exception就获取不到，必须用Error获取。

34. 通过StringBuffer的构造函数来设定它的初始化容量，可以明显提升性能
StringBuffer的默认容量为16，当StringBuffer的容量达到最大容量时，它会将自身容量增加到当前的2倍+2，也就是2*n+2。

35. 合理使用java.util.Vector
Vector与StringBuffer类似，每次扩展容量时，所有现有元素都要赋值到新的存储空间中。Vector的默认存储能力为10个元素，扩容加倍。
vector.add(index,obj) 这个方法可以将元素obj插入到index位置，但index以及之后的元素依次都要向下移动一个位置（将其索引加 1）。 除非必要，否则对性能不利。同样规则适用于remove(int index)方法，移除此向量中指定位置的元素。将所有后续元素左移（将其索引减 1）。返回此向量中移除的元素。所以删除vector最后一个元素要比删除第1个元素开销低很多。删除所有元素最好用removeAllElements()方法。
如果要删除vector里的一个元素可以使用 vector.remove(obj)；而不必自己检索元素位置，再删除，如int index = indexOf（obj）;vector.remove(index)。

36. 不用new关键字创建对象的实例
用new关键词创建类的实例时，构造函数链中的所有构造函数都会被自动调用。但如果一个对象实现了Cloneable接口，我们可以调用它的clone()方法。clone()方法不会调用任何类构造函数。

public static Credit getNewCredit()
{
return new Credit();
}
改进后的代码使用clone()方法：
private static Credit BaseCredit = new Credit();
public static Credit getNewCredit()
{
return (Credit)BaseCredit.clone();
}

9. 不要将数组声明为：public static final

37. HaspMap的遍历：
for( Entry<String, String[]> entry : paraMap.entrySet() )

39. 单线程应尽量使用 HashMap, ArrayList,除非必要，否则不推荐使用HashTable,Vector，它们使用了同步机制，而降低了性能。

40. StringBuffer,StringBuilder的区别在于
java.lang.StringBuffer 线程安全的可变字符序列。一个类似于String的字符串缓冲区，但不能修改。StringBuilder与该类相比，通常应该优先使用StringBuilder类，因为它支持所有相同的操作，但由于它不执行同步，所以速度更快。
为了获得更好的性能，在构造StringBuffer或StringBuilder时应尽量指定她的容量。当然如果不超过16个字符时就不用了。 相同情况下，使用StringBuilder比使用StringBuffer仅能获得10%~15%的性能提升，但却要冒多线程不安全的风险。综合考虑还是建议使用StringBuffer。

41. 尽量使用基本数据类型代替对象。

42. 使用具体类比使用接口效率高，但结构弹性降低了，但现代IDE都可以解决这个问题。

43. 考虑使用静态方法，如果你没有必要去访问对象的外部，那么就使你的方法成为静态方法。它会被更快地调用，因为它不需要一个虚拟函数导向表。这同时也是一个很好的实践，因为它告诉你如何区分方法的性质，调用这个方法不会改变对象的状态。

44. 应尽可能避免使用内在的GET,SET方法。

45.避免枚举，浮点数的使用。

字符串相加的时候，如果某个字符串只有一个字符的话，使用''。
















class1 = Class.forName("net.xsoftlab.baike.TestReflect");
class2 = new TestReflect().getClass();
class3 = TestReflect.class;


获取一个对象的父类与实现的接口
Class<?> parentClass = clazz.getSuperclass();
Class<?> intes[] = clazz.getInterfaces();


通过反射机制实例化一个类的对象
User user = (User) class1.newInstance();
user = (User) cons[1].newInstance(20, "Rollen");

Constructor<?> cons[] = class1.getConstructors();
Class<?> clazzs[] = cons[i].getParameterTypes();
。。Constructor.newInstance
。。newInstance的注释，如果是内部类的话，第一个参数是外部类实例。


获取某个类的全部属性
// 取得本类的全部属性
Field[] field = clazz.getDeclaredFields();
for (int i = 0; i < field.length; i++) {
	// 权限修饰符
	int mo = field[i].getModifiers();
	String priv = Modifier.toString(mo);
	// 属性类型
	Class<?> type = field[i].getType();
	System.out.println(priv + " " + type.getName() + " " + field[i].getName() + ";");
}

// 取得实现的接口或者父类的属性
Field[] filed1 = clazz.getFields();


获取某个类的全部方法
Class<?> clazz = Class.forName("net.xsoftlab.baike.TestReflect");
Method method[] = clazz.getMethods();
for (int i = 0; i < method.length; ++i) {
	Class<?> returnType = method[i].getReturnType();
	Class<?> para[] = method[i].getParameterTypes();
	int temp = method[i].getModifiers();
	Class<?> exce[] = method[i].getExceptionTypes();


通过反射机制调用某个类的方法
Class<?> clazz = Class.forName("net.xsoftlab.baike.TestReflect");
// 调用TestReflect类中的reflect1方法
Method method = clazz.getMethod("reflect1");
method.invoke(clazz.newInstance());
// Java 反射机制 - 调用某个类的方法1.
// 调用TestReflect的reflect2方法
method = clazz.getMethod("reflect2", int.class, String.class);
method.invoke(clazz.newInstance(), 20, "张三");

public void reflect1() {
public void reflect2(int age, String name) {


通过反射机制操作某个类的属性
Class<?> clazz = Class.forName("net.xsoftlab.baike.TestReflect");
Object obj = clazz.newInstance();
// 可以直接对 private 的属性赋值
Field field = clazz.getDeclaredField("proprety");
field.setAccessible(true);
field.set(obj, "Java反射机制");
System.out.println(field.get(obj));


反射机制的动态代理
// 获取类加载器的方法
TestReflect testReflect = new TestReflect();
System.out.println("类加载器  " + testReflect.getClass().getClassLoader().getClass().getName());


//定义项目接口
interface Subject {
    public String say(String name, int age);
}
// 定义真实项目
class RealSubject implements Subject {
    public String say(String name, int age) {
        return name + "  " + age;
    }
}
class MyInvocationHandler implements InvocationHandler {
    private Object obj = null;
    public Object bind(Object obj) {
        this.obj = obj;
        return Proxy.newProxyInstance(obj.getClass().getClassLoader(), obj.getClass().getInterfaces(), this);
    }
    public Object invoke(Object proxy, Method method, Object[] args) throws Throwable {
        Object temp = method.invoke(this.obj, args);
        return temp;
    }
}


MyInvocationHandler demo = new MyInvocationHandler();
Subject sub = (Subject) demo.bind(new RealSubject());
String info = sub.say("Rollen", 20);
System.out.println(info);


在泛型为Integer的ArrayList中存放一个String类型的对象。
ArrayList<Integer> list = new ArrayList<Integer>();
Method method = list.getClass().getMethod("add", Object.class);
method.invoke(list, "Java反射机制实例。");
System.out.println(list.get(0));

通过反射取得并修改数组的信息
int[] temp = { 1, 2, 3, 4, 5 };
Class<?> demo = temp.getClass().getComponentType();
System.out.println("数组类型： " + demo.getName());
System.out.println("数组长度  " + Array.getLength(temp));
System.out.println("数组的第一个元素: " + Array.get(temp, 0));
Array.set(temp, 0, 100);
System.out.println("修改之后数组第一个元素为： " + Array.get(temp, 0));



通过反射机制修改数组的大小
int[] temp = { 1, 2, 3, 4, 5, 6, 7, 8, 9 };
int[] newTemp = (int[]) arrayInc(temp, 15);

// 修改数组大小
public static Object arrayInc(Object obj, int len) {
	Class<?> arr = obj.getClass().getComponentType();
	Object newArr = Array.newInstance(arr, len);
	int co = Array.getLength(obj);
	System.arraycopy(obj, 0, newArr, 0, co);
	return newArr;
}


将反射机制应用于工厂模式
class Factory {
    public static fruit getInstance(String ClassName) {
        fruit f = null;
        try {
            f = (fruit) Class.forName(ClassName).newInstance();
        } catch (Exception e) {
            e.printStackTrace();
        }
        return f;
    }
}





1 	Vector
该类和ArrayList非常相似，但是该类是同步的，可以用在多线程的情况，该类允许设置默认的增长长度，默认扩容方式为原来的2倍。
2 	Stack
栈是Vector的一个子类，它实现了一个标准的后进先出的栈。
3 	Dictionary
Dictionary 类是一个抽象类，用来存储键/值对，作用和Map类相似。
4 	Hashtable
Hashtable 是 Dictionary(字典) 类的子类，位于 java.util 包中。
5 	Properties
Properties 继承于 Hashtable，表示一个持久的属性集，属性列表中每个键及其对应值都是一个字符串。
6 	BitSet
一个Bitset类创建一种特殊类型的数组来保存位值。BitSet中数组大小会随需要增加。




//第一种遍历方法使用foreach遍历List
//第二种遍历，把链表变为数组相关的内容进行遍历
String[] strArray=new String[list.size()];
list.toArray(strArray);
for(int i=0;i<strArray.length;i++) //这里也可以改写为  foreach(String str:strArray)这种形式
{
	System.out.println(strArray[i]);
}
//第三种遍历 使用迭代器进行相关遍历


实现序列化的两个原因：
1、将对象的状态保存在存储媒体中以便可以在以后重新创建出完全相同的副本；
2、按值将对象从一个应用程序域发送至另一个应用程序域。实现serializabel接口的作用是就是可以把对象存到字节流，然后可以恢复

有的时候并没有实现序列化，依然可以持久化到数据库。这个其实我们可以看看实体类中常用的数据类型，例如Date、String等等，它们已经实现了序列化，而一些基本类型，数据库里面有与之对应的数据结构，从我们的类声明来看，我们没有实现serializabel接口，其实是在声明的各个不同变量的时候，由具体的数据类型帮助我们实现了序列化操作。

在NoSql数据库中，并没有与我们java基本类型对应的数据结构，所以在往nosql数据库中存储时，我们就必须将对象进行序列化，同时在网络传输中我们要注意到两个应用中javabean的serialVersionUID要保持一致，不然就不能正常的进行反序列化。



从jvm的角度看，我们使用new的时候，这个要new的类可以没有加载；
但是使用newInstance时候，就必须保证：1、这个类已经加载；2、这个类已经连接了。而完成上面两个步骤的正是class的静态方法forName（）方法，这个静态方法调用了启动类加载器（就是加载javaAPI的那个加载器）。
有了上面jvm上的理解，那么我们可以这样说，newInstance实际上是把new这个方式分解为两步,即，首先调用class的加载方法加载某个类，然后实例化。
这样分步的好处是显而易见的。我们可以在调用class的静态加载方法forName时获得更好的灵活性，提供给了我们降耦的手段。

newInstance()是实现IOC、反射、依赖倒置 等技术方法的必然选择，new 只能实现具体类的实例化，不适合于接口编程。

factory = (AInterface)c.newInstance();

。。Class的newInstance是无参的，Constructor的newInstance是可变长参数


动态代理对象处理器
public class DynamicProxyHandler implements InvocationHandler {
    private Object proxyed;
    
    public DynamicProxyHandler(Object proxyed) {
        this.proxyed = proxyed;
    }
    
    @Override
    public Object invoke(Object proxy, Method method, Object[] args) throws IllegalAccessException, IllegalArgumentException, InvocationTargetException {
        System.out.println("代理工作了.");
        return method.invoke(proxyed, args);
    }
}

public class Main {
    public static void main(String[] args) {
        RealObject real = new RealObject();
        Interface proxy = (Interface) Proxy.newProxyInstance(
                Interface.class.getClassLoader(), new Class[] {Interface.class},
                new DynamicProxyHandler(real));
        
        proxy.doSomething();
        proxy.somethingElse("luoxn28");
    }
}


悲观锁，正如其名，它指的是对数据被外界（包括本系统当前的其他事务，以及来自外部系统的事务处理）修改持保守态度，因此，在整个数据处理过程中，将数据处于锁定状态。

悲观锁的实现，往往依靠数据库提供的锁机制（也只有数据库层提供的锁机制才能真正保证数据访问的排他性，否则，即使在本系统中实现了加锁机制，也无法保证外部系 统不会修改数据）。 


一个典型的倚赖数据库的悲观锁调用： 
select * from account where name=”Erica” for update
这条 sql 语句锁定了 account 表中所有符合检索条件（ name=”Erica” ）的记录。
本次事务提交之前（事务提交时会释放事务过程中的锁），外界无法修改这些记录。 

。。外界无法修改！能读吧

Hibernate 的悲观锁，也是基于数据库的锁机制实现。 
下面的代码实现了对查询记录的加锁：
String hqlStr ="from TUser as user where user.name='Erica'";
Query query = session.createQuery(hqlStr);
query.setLockMode("user",LockMode.UPGRADE); // 加锁
List userList = query.list();// 执行查询，获取数据
query.setLockMode 对查询语句中，特定别名所对应的记录进行加锁（我们为 TUser 类指定了一个别名 “user” ），这里也就是对返回的所有 user 记录进行加锁。

Hibernate 的加锁模式有： 
? LockMode.NONE ： 无锁机制。 
? LockMode.WRITE ： Hibernate 在 Insert 和 Update 记录的时候会自动获取
? LockMode.READ ： Hibernate 在读取记录的时候会自动获取。 
以上这三种锁机制一般由 Hibernate 内部使用，如 Hibernate 为了保证 Update
过程中对象不会被外界修改，会在save方法实现中自动为目标对象加上 WRITE 锁。 
? LockMode.UPGRADE ：利用数据库的 for update 子句加锁。 
? LockMode. UPGRADE_NOWAIT ： Oracle 的特定实现，利用 Oracle 的 for update nowait 子句实现加锁。 
上面这两种锁机制是我们在应用层较为常用的，加锁一般通过以下方法实现： 
Criteria.setLockMode
Query.setLockMode
Session.lock

乐观锁，大多是基于数据版本   Version ）记录机制实现。何谓数据版本？即为数据增加一个版本标识，在基于数据库表的版本解决方案中，一般是通过为数据库表增加一个 “version” 字段来 实现。 读取出数据时，将此版本号一同读出，之后更新时，对此版本号加一。此时，将提 交数据的版本数据与数据
库表对应记录的当前版本信息进行比对，如果提交的数据 版本号大于数据库表当前版本号，则予以更新，否则认为是过期数据。


hibernate中如何实现乐观锁：
在ormapping增加一属性optimistic-lock="version"即可，以下是样例片段
<class name="com.insigma.stock.ABC" optimistic-lock="version" table="T_Stock" schema="STOCK">
。。version是表的一个自定义的字段。


Java中获取键盘输入值的三种方法
char i = (char) System.in.read(); 

BufferedReader br = new BufferedReader(new InputStreamReader(System.in)); 
String str = br.readLine(); 

Scanner sc = new Scanner(System.in); 
String name = sc.nextLine(); 
int age = sc.nextInt(); 
float salary = sc.nextFloat(); 


在java中，next()方法是不接收空格的，在接收到有效数据前，所有的空格或者tab键等输入被忽略，若有有效数据，则遇到这些键退出。nextLine()可以接收空格或者tab键，其输入应该以enter键结束。


Class.forName(“”)返回的是类。Class.forName(“”).newInstance()返回的是object



List.listIterator(int index)
.set(int index, Object obj)
.subList(int fromIndex, int toIndex)...[from, to)


如果一个类要被声明为static的，只有一种情况，就是静态内部类。如果在外部类声明为static，程序会编译都不会过。在一番调查后个人总结出了3点关于内部类和静态内部类（俗称：内嵌类）

1.静态内部类跟静态方法一样，只能访问静态的成员变量和方法，不能访问非静态的方法和属性，但是普通内部类可以访问任意外部类的成员变量和方法

2.静态内部类可以声明普通成员变量和方法，而普通内部类不能声明static成员变量和方法。

3.静态内部类可以单独初始化: 
Inner i = new Outer.Inner();
普通内部类初始化：
Outer o = new Outer();
Inner i = o.new Inner();

静态内部类使用场景一般是当外部类需要使用内部类，而内部类无需外部类资源，并且内部类可以单独创建的时候会考虑采用静态内部类的设计，在知道如何初始化静态内部类，在《Effective Java》第二章所描述的静态内部类builder阐述了如何使用静态内部类：


1.如果类的构造器或静态工厂中有多个参数，设计这样类时，最好使用Builder模式，特别是当大多数参数都是可选的时候。
2.如果现在不能确定参数的个数，最好一开始就使用构建器即Builder模式。





enum。。。
public enum StringType {
    Space(1) {
        @Override
        public boolean isValid(char ch) {
            return ch == ' ';
        }
    },
。。觉得里面每一个枚举都是一个新类的实例，这个类继承StringType



多线程。ThreadLocal
java.lang.ThreadLocal<T>



EnumMap
EnumSet



isAssignableFrom
后面那个是子类或者相同类。




设置一个类不能被继承，两种方法：一是final，二就是构造方法私有；


enum有点。。
无法extends，implements Enum
Enum中的name，ordinal是固定的，无法修改的。因为enum中构造器无法调用父类Enum的构造器。反正一直说不可见。。。


注解上有Inherited才能被继承



switch+enum的时候，case 直接写 枚举名就可以了，不需要类名.



LinkedBlockingQueue
add，队列满则抛异常
put，队列满则阻塞等待
offer，队列满则返回false。


remove	队列空，抛出异常NoSuchElement
take	队列空，阻塞等待。
poll，队列空，返回null

offer，pool，还可以设定超时时间。




用来保存等待被执行的任务的阻塞队列，且任务必须实现Runable接口，在JDK中提供了如下阻塞队列：

1、ArrayBlockingQueue：基于数组结构的有界阻塞队列，按FIFO排序任务；

2、LinkedBlockingQuene：基于链表结构的阻塞队列，按FIFO排序任务，吞吐量通常要高于ArrayBlockingQuene；

3、SynchronousQuene：一个不存储元素的阻塞队列，每个插入操作必须等到另一个线程调用移除操作，否则插入操作一直处于阻塞状态，吞吐量通常要高于LinkedBlockingQuene；

4、priorityBlockingQuene：具有优先级的无界阻塞队列；







ThreadLocal用于保存某个线程共享变量：对于同一个static ThreadLocal，不同线程只能从中get，set，remove自己的变量，而不会影响其他线程的变量。

1、ThreadLocal.get: 获取ThreadLocal中当前线程共享变量的值。

2、ThreadLocal.set: 设置ThreadLocal中当前线程共享变量的值。

3、ThreadLocal.remove: 移除ThreadLocal中当前线程共享变量的值。

4、ThreadLocal.initialValue: ThreadLocal没有被当前线程赋值时或当前线程刚调用remove方法后调用get方法，返回此方法值。


ThreadLocal只能保存一个对象啊。如果要多个的话，得多个ThreadLocal
。。不，可以多个。

真正的数据还是保存在Thread中的，thread.threadLocals.

觉得threadLocal更像一个工具类啊。







Executors的ExecutorService的submit，对Runnable做了一层封装，封装成RunnableFuture，最终还是调用excute







在NIO中有几个比较关键的概念：Channel（通道），Buffer（缓冲区），Selector（选择器）。


首先从Channel说起吧，通道，顾名思义，就是通向什么的道路，为某个提供了渠道。在传统IO中，我们要读取一个文件中的内容，通常是像下面这样读取的：
public class Test {
    public static void main(String[] args) throws IOException  {
        File file = new File("data.txt");
        InputStream inputStream = new FileInputStream(file);
        byte[] bytes = new byte[1024];
        inputStream.read(bytes);
        inputStream.close();
    }  
}
这里的InputStream实际上就是为读取文件提供一个通道的。
因此可以将NIO 中的Channel同传统IO中的Stream来类比，但是要注意，传统IO中，Stream是单向的，比如InputStream只能进行读取操作，OutputStream只能进行写操作。而Channel是双向的，既可用来进行读操作，又可用来进行写操作。


Buffer（缓冲区），是NIO中非常重要的一个东西，在NIO中所有数据的读和写都离不开Buffer。比如上面的一段代码中，读取的数据时放在byte数组当中，而在NIO中，读取的数据只能放在Buffer中。同样地，写入数据也是先写入到Buffer中。

Selector。可以说它是NIO中最关键的一个部分，Selector的作用就是用来轮询每个注册的Channel，一旦发现Channel有注册的事件发生，便获取事件然后进行处理。


以下是常用的几种通道：
FileChannel
SocketChanel
ServerSocketChannel
DatagramChannel


通过使用FileChannel可以从文件读或者向文件写入数据；
通过SocketChannel，以TCP来向网络连接的两端读写数据；
通过ServerSocketChanel能够监听客户端发起的TCP连接，并为每个TCP连接创建一个新的SocketChannel来进行数据读写；
通过DatagramChannel，以UDP协议来向网络连接的两端读写数据。

下面给出通过FileChannel来向文件中写入数据的一个例子：

public class Test {
    public static void main(String[] args) throws IOException  {
        File file = new File("data.txt");
        FileOutputStream outputStream = new FileOutputStream(file);
        FileChannel channel = outputStream.getChannel();
        ByteBuffer buffer = ByteBuffer.allocate(1024);
        String string = "java nio";
        buffer.put(string.getBytes());
        buffer.flip();     //此处必须要调用buffer的flip方法
        channel.write(buffer);
        channel.close();
        outputStream.close();
    }  
}


在NIO中，Buffer是一个顶层父类，它是一个抽象类，常用的Buffer的子类有：
ByteBuffer
IntBuffer
CharBuffer
LongBuffer
DoubleBuffer
FloatBuffer
ShortBuffer

如果是对于文件读写，上面几种Buffer都可能会用到。但是对于网络读写来说，用的最多的是ByteBuffer。


Selector类是NIO的核心类，Selector能够检测多个注册的通道上是否有事件发生，如果有事件发生，便获取事件然后针对每个事件进行相应的响应处理。这样一来，只是用一个单线程就可以管理多个通道，也就是管理多个连接。这样使得只有在连接真正有读写事件发生时，才会调用函数来进行读写，就大大地减少了系统开销，并且不必为每个连接都创建一个线程，不用去维护多个线程，并且避免了多线程之间的上下文切换导致的开销。
与Selector有关的一个关键类是SelectionKey，一个SelectionKey表示一个到达的事件，这2个类构成了服务端处理业务的关键逻辑。








一个完整的IO读请求操作包括两个阶段：
　　1）查看数据是否就绪；
　　2）进行数据拷贝（内核将数据拷贝到用户线程）。

　　那么阻塞（blocking IO）和非阻塞（non-blocking IO）的区别就在于第一个阶段，如果数据没有就绪，在查看数据是否就绪的过程中是一直等待，还是直接返回一个标志信息。

　　Java中传统的IO都是阻塞IO，比如通过socket来读数据，调用read()方法之后，如果数据没有就绪，当前线程就会一直阻塞在read方法调用那里，直到有数据才返回；而如果是非阻塞IO的话，当数据没有就绪，read()方法应该返回一个标志信息，告知当前线程数据没有就绪，而不是一直在那里等待。



在《Unix网络编程》一书中对同步IO和异步IO的定义是这样的：

　　A synchronous I/O operation causes the requesting process to be blocked until that I/O operation completes.
　　An asynchronous I/O operation does not cause the requesting process to be blocked.

　　从字面的意思可以看出：同步IO即 如果一个线程请求进行IO操作，在IO操作完成之前，该线程会被阻塞；

　　而异步IO为 如果一个线程请求进行IO操作，IO操作不会导致请求线程被阻塞。


事实上，同步IO和异步IO模型是针对用户线程和内核的交互来说的：

　　对于同步IO：当用户发出IO请求操作之后，如果数据没有就绪，需要通过用户线程或者内核不断地去轮询数据是否就绪，当数据就绪时，再将数据从内核拷贝到用户线程；

　　而异步IO：只有IO请求操作的发出是由用户线程来进行的，IO操作的两个阶段都是由内核自动完成，然后发送通知告知用户线程IO操作已经完成。也就是说在异步IO中，不会对用户线程产生任何阻塞。

　　这是同步IO和异步IO关键区别所在，同步IO和异步IO的关键区别反映在数据拷贝阶段是由用户线程完成还是内核完成。所以说异步IO必须要有操作系统的底层支持。

注意同步IO和异步IO与阻塞IO和非阻塞IO是不同的两组概念。

　　阻塞IO和非阻塞IO是反映在当用户请求IO操作时，如果数据没有就绪，是用户线程一直等待数据就绪，还是会收到一个标志信息这一点上面的。也就是说，阻塞IO和非阻塞IO是反映在IO操作的第一个阶段，在查看数据是否就绪时是如何处理的。



在《Unix网络编程》一书中提到了五种IO模型，分别是：阻塞IO、非阻塞IO、多路复用IO、信号驱动IO以及异步IO。



多路复用IO模型是目前使用得比较多的模型。Java NIO实际上就是多路复用IO。

　　在多路复用IO模型中，会有一个线程不断去轮询多个socket的状态，只有当socket真正有读写事件时，才真正调用实际的IO读写操作。因为在多路复用IO模型中，只需要使用一个线程就可以管理多个socket，系统不需要建立新的进程或者线程，也不必维护这些线程和进程，并且只有在真正有socket读写事件进行时，才会使用IO资源，所以它大大减少了资源占用。

　　在Java NIO中，是通过selector.select()去查询每个通道是否有到达事件，如果没有事件，则一直阻塞在那里，因此这种方式会导致用户线程的阻塞。



异步IO模型才是最理想的IO模型，在异步IO模型中，当用户线程发起read操作之后，立刻就可以开始去做其它的事。而另一方面，从内核的角度，当它受到一个asynchronous read之后，它会立刻返回，说明read请求已经成功发起了，因此不会对用户线程产生任何block。然后，内核会等待数据准备完成，然后将数据拷贝到用户线程，当这一切都完成之后，内核会给用户线程发送一个信号，告诉它read操作完成了。也就说用户线程完全不需要实际的整个IO操作是如何进行的，只需要先发起一个请求，当接收内核返回的成功信号时表示IO操作已经完成，可以直接去使用数据了。

　　也就说在异步IO模型中，IO操作的两个阶段都不会阻塞用户线程，这两个阶段都是由内核自动完成，然后发送一个信号告知用户线程操作已完成。用户线程中不需要再次调用IO函数进行具体的读写。这点是和信号驱动模型有所不同的，在信号驱动模型中，当用户线程接收到信号表示数据已经就绪，然后需要用户线程调用IO函数进行实际的读写操作；而在异步IO模型中，收到信号表示IO操作已经完成，不需要再在用户线程中调用iO函数进行实际的读写操作。

　　注意，异步IO是需要操作系统的底层支持，在Java 7中，提供了Asynchronous IO。

　　前面四种IO模型实际上都属于同步IO，只有最后一种是真正的异步IO，因为无论是多路复用IO还是信号驱动模型，IO操作的第2个阶段都会引起用户线程阻塞，也就是内核进行数据拷贝的过程都会让用户线程阻塞。






java.util.concurrent.locks包

Lock接口方法，lock()、tryLock()、tryLock(long time, TimeUnit unit)和lockInterruptibly()是用来获取锁的。unLock()方法是用来释放锁的。newCondition()这个方法暂且不在此讲述，会在后面的线程协作一文中讲述。

lock()方法是平常使用得最多的一个方法，就是用来获取锁。如果锁已被其他线程获取，则进行等待。
如果采用Lock，必须主动去释放锁，并且在发生异常时，不会自动释放锁。因此一般来说，使用Lock必须在try{}catch{}块中进行，并且将释放锁的操作放在finally块中进行，以保证锁一定被被释放，防止死锁的发生。


tryLock()方法是有返回值的，它表示用来尝试获取锁，如果获取成功，则返回true，如果获取失败（即锁已被其他线程获取），则返回false，也就说这个方法无论如何都会立即返回。在拿不到锁时不会一直在那等待。
tryLock(long time, TimeUnit unit)方法和tryLock()方法是类似的，只不过区别在于这个方法在拿不到锁时会等待一定的时间，在时间期限之内如果还拿不到锁，就返回false。如果如果一开始拿到锁或者在等待期间内拿到了锁，则返回true。


lockInterruptibly()方法比较特殊，当通过这个方法去获取锁时，如果线程正在等待获取锁，则这个线程能够响应中断，即中断线程的等待状态。也就使说，当两个线程同时通过lock.lockInterruptibly()想获取某个锁时，假若此时线程A获取到了锁，而线程B只有在等待，那么对线程B调用threadB.interrupt()方法能够中断线程B的等待过程。

注意，当一个线程获取了锁之后，是不会被interrupt()方法中断的。因为本身在前面的文章中讲过单独调用interrupt()方法不能中断正在运行过程中的线程，只能中断阻塞过程中的线程。
因此当通过lockInterruptibly()方法获取某个锁时，如果不能获取到，只有进行等待的情况下，是可以响应中断的。
而用synchronized修饰的话，当一个线程处于等待某个锁的状态，是无法被中断的，只有一直等待下去。



ReentrantLock，意思是“可重入锁”，关于可重入锁的概念在下一节讲述。ReentrantLock是唯一实现了Lock接口的类，并且ReentrantLock提供了更多的方法。

private Lock lock = new ReentrantLock();

public void insert(Thread thread) {
	lock.lock();
	try {
		System.out.println(thread.getName()+"得到了锁");
		for(int i=0;i<5;i++) {
			arrayList.add(i);
		}
	} catch (Exception e) {
		// TODO: handle exception
	}finally {
		System.out.println(thread.getName()+"释放了锁");
		lock.unlock();
	}
}



ReadWriteLock也是一个接口，在它里面只定义了两个方法：Lock readLock(); 和 Lock writeLock();

一个用来获取读锁，一个用来获取写锁。也就是说将文件的读写操作分开，分成2个锁来分配给线程，从而使得多个线程可以同时进行读操作。下面的ReentrantReadWriteLock实现了ReadWriteLock接口。



ReentrantReadWriteLock里面提供了很多丰富的方法，不过最主要的有两个方法：readLock()和writeLock()用来获取读锁和写锁。



总结来说，Lock和synchronized有以下几点不同：
1）Lock是一个接口，而synchronized是Java中的关键字，synchronized是内置的语言实现；
2）synchronized在发生异常时，会自动释放线程占有的锁，因此不会导致死锁现象发生；而Lock在发生异常时，如果没有主动通过unLock()去释放锁，则很可能造成死锁现象，因此使用Lock时需要在finally块中释放锁；
3）Lock可以让等待锁的线程响应中断，而synchronized却不行，使用synchronized时，等待的线程会一直等待下去，不能够响应中断；
4）通过Lock可以知道有没有成功获取锁，而synchronized却无法办到。
5）Lock可以提高多个线程进行读操作的效率。
在性能上来说，如果竞争资源不激烈，两者的性能是差不多的，而当竞争资源非常激烈时（即有大量线程同时竞争），此时Lock的性能要远远优于synchronized。所以说，在具体使用时要根据适当情况选择。




与锁相关的几个概念。

1.可重入锁
如果锁具备可重入性，则称作为可重入锁。像synchronized和ReentrantLock都是可重入锁，可重入性在我看来实际上表明了锁的分配机制：基于线程的分配，而不是基于方法调用的分配。举个简单的例子，当一个线程执行到某个synchronized方法时，比如说method1，而在method1中会调用另外一个synchronized方法method2，此时线程不必重新去申请锁，而是可以直接执行方法method2。

上述代码中的两个方法method1和method2都用synchronized修饰了，假如某一时刻，线程A执行到了method1，此时线程A获取了这个对象的锁，而由于method2也是synchronized方法，假如synchronized不具备可重入性，此时线程A需要重新申请锁。但是这就会造成一个问题，因为线程A已经持有了该对象的锁，而又在申请获取该对象的锁，这样就会线程A一直等待永远不会获取到的锁。
而由于synchronized和Lock都具备可重入性，所以不会发生上述现象。


2.可中断锁
可中断锁：顾名思义，就是可以相应中断的锁。
在Java中，synchronized就不是可中断锁，而Lock是可中断锁。

如果某一线程A正在执行锁中的代码，另一线程B正在等待获取该锁，可能由于等待时间过长，线程B不想等待了，想先处理其他事情，我们可以让它中断自己或者在别的线程中中断它，这种就是可中断锁。

在前面演示lockInterruptibly()的用法时已经体现了Lock的可中断性。



3.公平锁
公平锁即尽量以请求锁的顺序来获取锁。比如同是有多个线程在等待一个锁，当这个锁被释放时，等待时间最久的线程（最先请求的线程）会获得该所，这种就是公平锁。
非公平锁即无法保证锁的获取是按照请求锁的顺序进行的。这样就可能导致某个或者一些线程永远获取不到锁。
在Java中，synchronized就是非公平锁，它无法保证等待的线程获取锁的顺序。
而对于ReentrantLock和ReentrantReadWriteLock，它默认情况下是非公平锁，但是可以设置为公平锁。


4.读写锁
读写锁将对一个资源（比如文件）的访问分成了2个锁，一个读锁和一个写锁。
正因为有了读写锁，才使得多个线程之间的读操作不会发生冲突。
ReadWriteLock就是读写锁，它是一个接口，ReentrantReadWriteLock实现了这个接口。
可以通过readLock()获取读锁，通过writeLock()获取写锁。








class NamedImpl implements Named, Serializable {
。。这个是guice的，Named是一个注解。。













JDK8


Runnable noarg = () -> System.out.println("111");
ActionListener listener = event -> System.out.println("222");
Runnable multi = () -> {
	System.out.println("333");
	System.out.println("444");
};
BinaryOperator<Long> add = (x, y) -> x + y;
BinaryOperator<Long> addExplicit = (Long x, Long y) -> x + y;

noarg.run();
listener.actionPerformed(null);
multi.run();
// need L, ,, int is error
System.out.println(add.apply(1L, 3L));
System.out.println(addExplicit.apply(1L, 5L));



如果你以前使用过匿名内部类，也许遇到过这样的问题。当你需要匿名内部类所在方法里的变量，必须把该变量声明为 final。如下例子所示：

final String name = getUserName();
button.addActionListener(new ActionListener() {
    public void actionPerformed(ActionEvent event) {
        System.out.println("hi " + name);
    }
});
。。name is final


Java 8放松了这一限制，可以不必再把变量声明为 final，但其实该变量实际上仍然是 final 的。虽然无需将变量声明为 final，但在 Lambda 表达式中，也无法用作非终态变量。如果坚持用作非终态变量（即改变变量的值），编译器就会报错。


String name = "AAA";

System.out.println(new Man() {
	@Override
	public String toString() {
		return name;
	}
});



函数式接口(Functional Interface)就是一个有且仅有一个抽象方法，但是可以有多个非抽象方法的接口。
函数式接口可以被隐式转换为 lambda 表达式。


JDK 8 中提供了一组常用的核心函数接口：
接口 			参数 	返回类型 	描述
Predicate<T> 	T 		boolean 	用于判别一个对象。比如求一个人是否为男性
Consumer<T> 	T 		void 	用于接收一个对象进行处理但没有返回，比如接收一个人并打印他的名字
Function<T, R> 	T 		R 		转换一个对象为不同类型的对象
Supplier<T> 	None 	T 		提供一个对象
UnaryOperator<T> 	T 	T 		接收对象并返回同类型的对象
BinaryOperator<T> 	(T, T) 	T 	接收两个同类型的对象，并返回一个原类型对象



Java 8 中，引入了流（Stream）的概念
所有继承自 Collection 的接口都可以转换为 Stream

假设我们有一个 List 包含一系列的 Person，Person 有姓名 name 和年龄 age 连个字段。现要求这个列表中年龄大于 50 的人数。

long count = list.stream().filter(ele -> ele.getAge() > 50).count();


Stream 的方法分为两类。一类叫惰性求值，一类叫及早求值。

判断一个操作是惰性求值还是及早求值很简单：只需看它的返回值。如果返回值是 Stream，那么是惰性求值。其实可以这么理解，如果调用惰性求值方法，Stream 只是记录下了这个惰性求值方法的过程，并没有去计算，等到调用及早求值方法后，就连同前面的一系列惰性求值方法顺序进行计算，返回结果。

通用形式为：

Stream.惰性求值.惰性求值. ... .惰性求值.及早求值

整个过程和建造者模式有共通之处。建造者模式使用一系列操作设置属性和配置，最后调 用一个 build 方法，这时，对象才被真正创建。


collect(toList())
collect(toList()) 方法由 Stream 里的值生成一个列表，是一个及早求值操作。可以理解为 Stream 向 Collection 的转换。
这边的 toList() 其实是 Collectors.toList()，因为采用了静态倒入，看起来显得简洁。

List<String> strList = Stream.of("A","b","C").collect(Collectors.toList());
。。static import,no import static
..import static java.lang.System.*;


map
如果有一个函数可以将一种类型的值转换成另外一种类型，map 操作就可以使用该函数，将一个流中的值转换成一个新的流。
map 方法就是接受的一个 Function 的匿名函数类，进行的转换。
strList = Stream.of("a", "b", "c").map(s2 -> s2 + "#").collect(Collectors.toList());


filter
遍历数据并检查其中的元素时，可尝试使用 Stream 中提供的新方法 filter。
filter 方法就是接受的一个 Predicate 的匿名函数类，判断对象是否符合条件，符合条件的才保留下来。
strList = Stream.of("aaaa", "bbb", "cc", "d").filter(q -> q.length() > 2).collect(Collectors.toList());


flatMap
flatMap 方法可用 Stream 替换值，然后将多个 Stream 连接成一个 Stream。
flatMap 最常用的操作就是合并多个 Collection。
List<Integer> iList1 = Arrays.asList(1,2,3,4);
List<Integer> iList2 = Arrays.asList(11,22,33);
iList1 = Stream.of(iList1, iList2).flatMap(z -> z.stream()).collect(Collectors.toList());


Stream 上常用的操作之一是求最大值和最小值。Stream API 中的 max 和 min 操作足以解决这一问题。

int max = iList1.stream().max(Integer::compareTo).get();
int min = iList1.stream().min(Integer::compareTo).get();

这里有 2 个要点需要注意：
max 和 min 方法返回的是一个 Optional 对象（对了，和 Google Guava 里的 Optional 对象是一样的）。Optional 对象封装的就是实际的值，可能为空，所以保险起见，可以先用 isPresent() 方法判断一下。Optional 的引入就是为了解决方法返回 null 的问题。
Integer::compareTo 也是属于 Java 8 引入的新特性，叫做 方法引用（Method References）。在这边，其实就是 (int1, int2) -> int1.compareTo(int2) 的简写，可以自己查阅了解，这里不再多做赘述。


reduce
reduce 操作可以实现从一组值中生成一个值。在上述例子中用到的 count、min 和 max 方法,因为常用而被纳入标准库中。事实上，这些方法都是 reduce 操作。

int i = Stream.of(1,2,3,4,5,6,7).reduce(0, (a, b) -> a + b);
。。0是初始值。

int i = Stream.of(1,2,3,4,5,6,7).reduce(1, (a, b) -> a * b);
。。阶乘，初始为0的话，返回0.

。。其余方法查看api。。。
看了下，节选部分Stream的方法，allMatch，anyMatch，concat,distinct,empty,filter,findAny,findFirst,forEach(Comsumer xx),forEachOrdered,iterate,limit,noneMatch,peek,skip,toArray.
..还有父类的方法，这里没有写。

Stream 的并行化也是 Java 8 的一大亮点。数据并行化是指将数据分成块，为每块数据分配单独的处理单元。这样可以充分利用多核 CPU 的优势。

并行化操作流只需改变一个方法调用。如果已经有一个 Stream 对象，调用它的 parallel() 方法就能让其拥有并行操作的能力。如果想从一个集合类创建一个流，调用 parallelStream() 就能立即获得一个拥有并行能力的流。



收集器
Stream 转换为 List 是很常用的操作，其他 Collectors 还有很多方法，可以将 Stream 转换为 Set, 或者将数据分组并转换为 Map，并对数据进行处理。也可以指定转换为具体类型，如 ArrayList, LinkedList 或者 HashMap。甚至可以自定义 Collectors，编写自己的收集器。
Collectors （收集器）的内容太多，有兴趣的可以自己研究。


元素顺序
另外一个尚未提及的关于集合类的内容是流中的元素以何种顺序排列。一些集合类型中的元素是按顺序排列的，比如 List；而另一些则是无序的，比如 HashSet。增加了流操作后，顺序问题变得更加复杂。
总之记住。如果集合本身就是无序的，由此生成的流也是无序的。一些中间操作会产生顺序，比如对值做映射时，映射后的值是有序的，这种顺序就会保留 下来。如果进来的流是无序的，出去的流也是无序的。
如果我们需要对流中的数据进行排序，可以调用 sorted 方法：

iList1 = Stream.of(4,3,5,2,7,1).parallel().sorted(Integer::compareTo).collect(Collectors.toList());
。。parallel，也可以，结果也是对的。


@FunctionalInterface

我们讨论过函数接口定义的标准，但未提及 @FunctionalInterface 注释。事实上，每个用作函数接口的接口都应该添加这个注释。

但 Java 中有一些接口，虽然只含一个方法，但并不是为了使用 Lambda 表达式来实现的。比如，有些对象内部可能保存着某种状态，使用带有一个方法的接口可能纯属巧合。

该注释会强制 javac 检查一个接口是否符合函数接口的标准。如果该注释添加给一个枚举类型、类或另一个注释，或者接口包含不止一个抽象方法，javac 就会报错。重构代码时，使用它能很容易发现问题。




Lambda
匿名
函数，有参数列表，函数主题，返回类型，可抛出异常列表
传递，lambda可以作为参数传递给方法或存储在变量中。
简洁

lambda由参数，箭头，主体 构成
(Apple a1, Apple a2) -> a1.getWeight().compareTo(a2.getWeight());



5个有效的例子。
(String s) -> s.length()
	具有一个String参数并返回一个int，Lambda没有return，因为已经隐含了return

(Apple a) -> a.getWeight() > 50
	Apple参数，返回一个boolean

(int x, int y) -> {
	Sysout("result");
	Sysout(x + y);
}
	2个int参数，没有返回值。

() -> 42
	没有参数，返回一个int

(Apple a1, Apple a2) -> a1.getWeight().compareTo(a2.getWeight())
	2个Apple参数，返回一个int。


(parameters) -> expression
(parameters) -> { statements; }


() -> {}
	无参，返回void
() -> "Raoul"
	无参，返回String
() -> { return "Mario"; }
	无参，利用显式返回语句返回String
(Integer i) -> return "Alan" + i;
	无效。需要return语句外面加{}才能有效
(String s) -> {"IronMan";}
	无效，"IronMan"是一个表达式，不是一个语句，删除{}和;变得有效。或者加个return也有效。


布尔表达式	(List<String> list) -> list.isEmpty()
创建对象		() -> new Apple(10)
消费一个对象	(Apple a) -> { sysout(a.getWeight()); }
从一个对象中选择/抽取	(String s) -> s.length()
组合两个值	(int a, int b) -> a * b
比较2个对象	(Apple a, Apple b) -> a1.compareTo(a2)


函数式接口，，使用lambda

函数式接口就是只定义一个抽象方法的接口。
Predicate。Comparator。Runnable。ActionListener。Callable。PrivilegedAction。
Consumer

Predicate<T>	1个参数，返回boolean
Consumer<T>	无参，返回void
Function<T, R>	接受一个T，返回一个R

Predicate<T>		T->boolean
Consumer<T>			T->void
Function<T, R>		T-R
Supplier<T>			()->T
UnaryOperator<T>	T->T
BinaryOperator<T>	(T,T)->T
BiPredicate<L,R>	(L,R)->boolean
BiConsumer<T,U>		(T,U)->void
BiFunction<T,U,R>	(T,U)->R

Comparator<T>	(T,T)->int


接口现在可以拥有默认方法。哪怕有很多默认方法，只要接口只定义了一个抽象方法，它仍然是一个函数式接口。
。。。这。。那么默认方法 算不算是抽象方法呢。。怎么做到很多默认方法，只有一个抽象方法？看样子不算？

lambda允许直接以内联的形式为函数式接口的抽象方法提供实现。并把整个表达式作为函数式接口的实例。


函数式接口的抽象方法的签名基本上就是lambda的签名
Runnable无参无返回，()->void代表了无参无返回。

(Apple, Apple)->int 代表2个参数，返回int。


@FunctionalInterface
如果用这个注解了一个接口，但是这个接口不是函数式接口的话，编译器会报错。
不是必须的，就像@Override。


任何函数式接口都不允许抛出受检异常，如果需要lambda抛出异常，2种办法，定义一个自己的函数式接口，并声明受检异常，或者把lambda包在一个try/catch中。


类型检查
根据方法的声明可以知道是Predicate还是Consumer或者其他，这样的话就知道lambda是否正确。


菱形运算符，Java7，利用泛型推断从上下文推断类型。
List<String> list = new ArrayList<>();

特殊的void兼容规则
如果lambda主体是一个语句表达式，它就和一个返回void的函数描述符兼容(当然需要参数列表也兼容)。以下2行都是合法的，虽然add方法返回一个boolean，并不是Consumer要求的void
Predicate<String> p = s -> list.add(s);
Consumer<String> c = s -> list.add(s);


Object obj = () -> {sysout("hi");};
是错误的。Object不是一个函数式接口。
Runnable r = () -> {sysout(hi);};	正确

java编译器会从上下文(目标类型)推断出用什么函数式接口来配合Lambda表达式。这意味着它也可以推断出适合Lambda的签名，因为函数描述符可以通过目标类型来得到。

List<Apple> greenApples = filter(inventory, a -> "green".equals(a.getColor()));
lambda仅有一个类型需要推导的参数时，参数名两边的括号也可以省略。
。。？那一个手动确定类名，另一个需要推导。这怎么可以省略括号？

Comparator<Apple> c = (Apple a1, Apple a2) -> a1.getWeight().compareTo(a2.getWeight());

Comparator<Apple> c = (a1, a2) -> ....;

52
Lambda表达式也允许使用自由变量(不是参数，是在外层作用域中定义的变量)，就像匿名类一样。它们被称为捕获Lambda。
下面的Lambda捕获了portNumber变量
int portNumber = 1337;
Runnable r = () -> sysout(portNumber);
。。外层是指 labmda的外面。。

lambda可以无限制地捕获(即在其主体中引用)实例变量和静态变量。但是局部变量必须显示声明为final或事实上是final。换句话说，lambda只能捕获指派给它们的局部变量一次(捕获实例变量可以被看作捕获最终局部变量this。)。
下面无法编译，因为portNumber被赋值2次。
int portNumber = 1337;
Runnable r = () -> sysout(portNumber);
portNumber = 31337;


为什么局部变量有这些限制。
1.实例变量和局部变量的实现有一个关键不同，实例变量在堆中，局部变量保存在栈上。如果lambda可以直接访问局部变量，而且lambda是在一个线程中使用的，则使用lambda的线程，可能会在分配该变量的线程将这个变量收回之后，去访问该变量。因此，java在访问自由局部变量时，实际上是访问它的副本。如果局部变量仅仅赋值一次那就没有什么区别了。
2.这一限制不鼓励你使用改变外部变量的典型命令式编程模式。(这种哦国内模式会阻碍很容易做到的并行处理。)

闭包(closure)
闭包是一个函数的实例，且它可以无限制地访问那个函数的非本地变量。例如，闭包可以作为参数传递给另一个函数。它也可以访问和修改其作用域之外的变量。
lambda和匿名类可以做类似的事情，它们可以作为参数传递给方法，并且可以访问其作用域之外的变量。但是有一个限制：它们不能修改定义lambda的方法的局部变量的内容。可以认为lambda是对值封闭，而不是对变量封闭。如果允许捕获可改变的局部变量，就会引发造成线程不安全的新的可能性。


53
方法引用，可以视为某些lambda的快捷写法。
方法引用可以让你重复使用现有的方法定义，并像lambda一样传递它们。

inventory.sort((Apple a1, Apple a2) -> a1.getWeight().compareTo(a2.getWeight()));

使用方法引用和java.util.Comparator.comparing之后：
inventory.sort(comparing(Apple::getWeight))
。。不需要Apple a1..

方法引用可以被看作仅仅调用特定方法的Lambda的一种快捷写法


Lambda 										等效的方法引用
(Apple a) -> a.getWeight()				 Apple::getWeight

() -> Thread.currentThread().dumpStack() Thread.currentThread()::dumpStack

(str, i) -> str.substring(i)				 String::substring

(String s) -> System.out.println(s) 		System.out::println


public static <T, U extends Comparable<? super U>> Comparator<T> comparing(
		Function<? super T, ? extends U> keyExtractor)
{
	Objects.requireNonNull(keyExtractor);
	return (Comparator<T> & Serializable)
		(c1, c2) -> keyExtractor.apply(c1).compareTo(keyExtractor.apply(c2));
}
。。lambda是一等公民，所以这里返回一个lambda。

。方法引用只是lambda中用到的方法，并不是lambda本身。方法应用(getWeight)+comparing == lambda。
。comparing会将getWeight组合成lambda并返回。

。。keyExtractor.apply(c1)。。keyExtractor就是Function(getWeight)，然后应用到某个对象。
。。但是Function本身就是一个lambda，所以Apple::getWeight就是一个lambda？？


方法引用主要有三类。
(1) 指向静态方法的方法引用（例如Integer的parseInt方法，写作Integer::parseInt）。
(2) 指向任意类型实例方法的方法引用（ 例如String 的length 方法， 写作
String::length）。
(3) 指向现有对象的实例方法的方法引用（假设你有一个局部变量expensiveTransaction
用于存放Transaction类型的对象，它支持实例方法getValue，那么你就可以写expensive-
Transaction::getValue）。

。。类名::方法。。。对象::方法。


还有针对构造函数、数组构造函数和父类调用（super-call）的一些特殊形式的方法引用


List<String> str = Arrays.asList("a","b","A","B");
str.sort((s1, s2) -> s1.compareToIgnoreCase(s2));
Lambda表达式的签名与Comparator的函数描述符兼容。利用前面所述的方法，这个例子可以用方法引用改写成下面的样子：
List<String> str = Arrays.asList("a","b","A","B");
str.sort(String::compareToIgnoreCase);

。。这里只有一步就是compareToIgnoreCase，而之前是getWeight然后compare。所以之前是comparing(getWeight)，这里直接就compareToIgnoreCase。


(1) Function<String, Integer> stringToInteger = (String s) -> Integer.parseInt(s);
Function<String, Integer> stringToInteger = Integer::parseInt;

(2) BiPredicate<List<String>, String> contains = (list, element) -> list.contains(element);
BiPredicate<List<String>, String> contains = List::contains;



对于一个现有构造函数，你可以利用它的名称和关键字new来创建它的一个引用：
ClassName::new。它的功能与指向静态方法的引用类似

假设有一个构造函数没有参数。它适合Supplier的签名() -> Apple。

Supplier<Apple> c1 = Apple::new;
Apple a1 = c1.get();
这就等价于：
Supplier<Apple> c1 = () -> new Apple();
Apple a1 = c1.get();


如果你的构造函数的签名是Apple(Integer weight)，那么它就适合Function接口的签名，于是你可以这样写：
Function<Integer, Apple> c2 = Apple::new;
Apple a2 = c2.apply(110);
这就等价于：
Function<Integer, Apple> c2 = (weight) -> new Apple(weight);
Apple a2 = c2.apply(110);


如果你有一个具有两个参数的构造函数Apple(String color, Integer weight)，那么它就适合BiFunction接口的签名，于是你可以这样写：
BiFunction<String, Integer, Apple> c3 = Apple::new;
Apple c3 = c3.apply("green", 110);
这就等价于：
BiFunction<String, Integer, Apple> c3 = (color, weight) -> new Apple(color, weight);
Apple c3 = c3.apply("green", 110);


static Map<String, Function<Integer, Fruit>> map = new HashMap<>();
static {
map.put("apple", Apple::new);
map.put("orange", Orange::new);
// etc...
}
public static Fruit giveMeFruit(String fruit, Integer weight){
return map.get(fruit.toLowerCase())
.apply(weight);
}




用不同的排序策略给一个Apple列表排序
这会用到书中迄今讲到的所有概念和功能：行为参数化、匿名类、Lambda表达式和方法引用。我们想要实现的最终解决方案是这样的（请注意，所有源代码均可见于本书网站）：
inventory.sort(comparing(Apple::getWeight));

第1 步：传递代码
Java 8的API已经为你提供了一个List可用的sort方法，你不用自己去实现它。
public class AppleComparator implements Comparator<Apple> {
	public int compare(Apple a1, Apple a2){
		return a1.getWeight().compareTo(a2.getWeight());
	}
}
inventory.sort(new AppleComparator());


第2 步：使用匿名类
你可以使用匿名类来改进解决方案，而不是实现一个Comparator却只实例化一次
inventory.sort(new Comparator<Apple>() {
	public int compare(Apple a1, Apple a2){
		return a1.getWeight().compareTo(a2.getWeight());
	}
});


第3 步：使用Lambda 表达式

Comparator代表了函数描述符(T, T) -> int。
因为你用的是苹果，所以它具体代表的就是(Apple, Apple) -> int

inventory.sort((Apple a1, Apple a2) -> a1.getWeight().compareTo(a2.getWeight())
);

Java编译器可以根据Lambda出现的上下文来推断Lambda表达式参数的
类型。那么你的解决方案就可以重写成这样：
inventory.sort((a1, a2) -> a1.getWeight().compareTo(a2.getWeight()));

Comparator具有一个叫作comparing的静态辅助方法，
它可以接受一个Function来提取Comparable键值，并生成一个Comparator对象

Comparator<Apple> c = Comparator.comparing((Apple a) -> a.getWeight());
现在你可以把代码再改得紧凑一点了：
import static java.util.Comparator.comparing;
inventory.sort(comparing((a) -> a.getWeight()));


第4 步：使用方法引用
你可以用方法引用让你的代码更简洁（假设你静态导入了java.util.Comparator.comparing）：
inventory.sort(comparing(Apple::getWeight));


许多函数式接口，比如用于传递Lambda表达式的Comparator、Function和Predicate都提供了允许你进行复合的方法。

在实践中，这意味着你可以把多个简单的Lambda复合成复杂的表达式。比如，你可以让两个谓词之间做一个or操作，组合成一个更大的谓词。而且，你还可以让一个函数的结果成为另一个函数的输入

你可能会想，函数式接口中怎么可能有更多的方法呢？（毕竟，这违背了函数式接口的定义啊！）窍门在于，我们即将介绍的方法都是默认方法，也就是说它们不是抽象方法
。。看来，函数式接口只能有一个接口方法，但可以有多个【同名】默认方法，并且，接口方法和默认方法都是可以被lambda使用的。。是不是？


1. 逆序
inventory.sort(comparing(Apple::getWeight).reversed());
。。直接lambda是没有这个方法的。。

2. 比较器链
如果发现有两个苹果一样重怎么办
inventory.sort(comparing(Apple::getWeight).reversed().thenComparing(Apple::getCountry));

。。还有，java.util.Comparator.nullsLast(Comparator)


谓词复合
谓词接口包括三个方法：negate、and和or，让你可以重用已有的Predicate来创建更复杂的谓词

and和or方法是按照在表达式链中的位置，从左向右确定优先级的。因此，a.or(b).and(c)可以看作(a || b) && c。



还可以把Function接口所代表的Lambda表达式复合起来。Function接口为此配了andThen和compose两个默认方法，它们都会返回Function的一个实例


Function<Integer, Integer> f = x -> x + 1;
Function<Integer, Integer> g = x -> x * 2;
Function<Integer, Integer> h = f.andThen(g);
int result = h.apply(1);
。。返回4

Function<Integer, Integer> f = x -> x + 1;
Function<Integer, Integer> g = x -> x * 2;
Function<Integer, Integer> h = f.compose(g);
int result = h.apply(1);
。。返回3



67
第二部分 函数式数据处理
新的Stream API

流是Java API的新成员，它允许你以声明性方式处理数据集合（通过查询语句来表达，而不是临时编写一个实现）。就现在来说，你可以把它们看成遍历数据集的高级迭代器。
此外，流还可以透明地并行处理，你无需写任何多线程代码了

下面两段代码都是用来返回低热量的菜肴名称的，
之前（Java 7）：
List<Dish> lowCaloricDishes = new ArrayList<>();
for(Dish d: menu){
	if(d.getCalories() < 400){
		lowCaloricDishes.add(d);
	}
}
Collections.sort(lowCaloricDishes, new Comparator<Dish>() {
	public int compare(Dish d1, Dish d2){
		return Integer.compare(d1.getCalories(), d2.getCalories());
	}
});
List<String> lowCaloricDishesName = new ArrayList<>();
for(Dish d: lowCaloricDishes){
	lowCaloricDishesName.add(d.getName());
}
。。400以下且有序。

在这段代码中，你用了一个“垃圾变量”lowCaloricDishes。它唯一的作用就是作为一次性的中间容器。在Java 8中，实现的细节被放在它本该归属的库里了。
之后（Java 8）：
import static java.util.Comparator.comparing;
import static java.util.stream.Collectors.toList;
List<String> lowCaloricDishesName =
	menu.stream()
		.filter(d -> d.getCalories() < 400)		// predicate
		.sorted(comparing(Dish::getCalories))	// 排序
		.map(Dish::getName)		// 提取名称
		.collect(toList());

为了利用多核架构并行执行这段代码，你只需要把stream()换成parallelStream()：
menu.parallelStream()


代码是以声明性方式写的：说明想要完成什么（筛选热量低的菜肴）而不是说明如何实现一个操作（利用循环和if条件等控制流语句）
这种方法加上行为参数化让你可以轻松应对变化的需求：你很容易再创建一个代码版本，利用Lambda表达式来筛选高卡路里的菜肴，而用不着去复制粘贴代码。

新的StreamAPI表达能力非常强。比如在读完本章以及第5章、第6章之后，你就可以写出像下面这样的代码：
Map<Dish.Type, List<Dish>> dishesByType = menu.stream().collect(groupingBy(Dish::getType));
按照Map里面的类别对菜肴进行分组



List<Dish> menu = Arrays.asList(
new Dish("pork", false, 800, Dish.Type.MEAT),
new Dish("beef", false, 700, Dish.Type.MEAT),
new Dish("chicken", false, 400, Dish.Type.MEAT),
new Dish("french fries", true, 530, Dish.Type.OTHER),
new Dish("rice", true, 350, Dish.Type.OTHER),
new Dish("season fruit", true, 120, Dish.Type.OTHER),
new Dish("pizza", true, 550, Dish.Type.OTHER),
new Dish("prawns", false, 300, Dish.Type.FISH),
new Dish("salmon", false, 450, Dish.Type.FISH) );

public Dish(String name, boolean vegetarian, int calories, Type type) {
	this.name = name;
	this.vegetarian = vegetarian;
	this.calories = calories;
	this.type = type;
}


要讨论流，我们先来谈谈集合，这是最容易上手的方式了。Java 8中的集合支持一个新的stream方法，它会返回一个流（接口定义在java.util.stream.Stream里）。你在后面会看到，还有很多其他的方法可以得到流，比如利用数值范围或从I/O资源生成流元素。

流到底是什么呢？简短的定义就是“从支持数据处理操作的源生成的元素序列”
元素序列――就像集合一样，流也提供了一个接口，可以访问特定元素类型的一组有序值。
源――流会使用一个提供数据的源，如集合、数组或输入/输出资源。
数据处理操作――流的数据处理功能支持类似于数据库的操作，以及函数式编程语言中的常用操作，如filter、map、reduce、find、match、sort等

流操作有两个重要的特点。
流水线――很多流操作本身会返回一个流，这样多个操作就可以链接起来，形成一个大的流水线。
内部迭代――与使用迭代器显式迭代的集合不同，流的迭代操作是在背后进行的

import static java.util.stream.Collectors.toList;
List<String> threeHighCaloricDishNames =
	menu.stream()		// 建立操作流水线。。也是一个流。
		.filter(d -> d.getCalories() > 300)		// 选热量
		.map(Dish::getName)		// 获得菜名
		.limit(3)			// 只选前3个。
		.collect(toList());		// 保存结果于另一个List
System.out.println(threeHighCaloricDishNames);


filter――接受Lambda，从流中排除某些元素。
map――接受一个Lambda，将元素转换成其他形式或提取信息。在本例中，通过传递方法引用Dish::getName，相当于Lambda d -> d.getName()，提取了每道菜的菜名。
limit――截断流，使其元素不超过给定数量
collect――将流转换为其他形式

Java现有的集合概念和新的流概念都提供了接口，来配合代表元素型有序值的数据接口

粗略地说，集合与流之间的差异就在于什么时候进行计算。集合是一个内存中的数据结构，它包含数据结构中目前所有的值――集合中的每个元素都得先算出来才能添加到集合中。
相比之下，流则是在概念上固定的数据结构（你不能添加或删除元素），其元素则是按需计算的
从另一个角度来说，流就像是一个延迟创建的集合：只有在消费者要求的时候才会计算值

。。集合和流都是数据，只不过集合必须先创建然后才能各种操作，流可以一边创建一边操作。

和迭代器类似，流只能遍历一次。遍历完之后，我们就说这个流已经被消费掉了。
你可以从原始数据源那里再获得一个新的流来重新遍历一遍，就像迭代器一样

List<String> title = Arrays.asList("Java8", "In", "Action");
Stream<String> s = title.stream();
s.forEach(System.out::println);
s.forEach(System.out::println);		// java.lang.IllegalStateException:流已被操作或关闭


集合和流的另一个关键区别在于它们遍历数据的方式。
。。外部迭代，内部迭代。。。就是是否需要自己写iterator。

Streams库的内部迭代可以自动选择一种适合你硬件的数据表示和并行实现。与此相反，一旦通过写for-each而选择了外部迭代，那你基本上就要自己管理所有的并行问题了


Stream接口定义了许多操作。它们可以分为两大类
filter、map和limit可以连成一条流水线；
collect触发流水线执行并关闭它。
可以连接起来的流操作称为中间操作，关闭流的操作称为终端操作。


78

诸如filter或sorted等中间操作会返回另一个流。这让多个操作可以连接起来形成一个查询。重要的是，除非流水线上触发一个终端操作，否则中间操作不会执行任何处理――它们很懒。这是因为中间操作一般都可以合并起来，在终端操作时一次性全部处理。
。。这样的话就是遍历一次直接得到结果，而不是遍历n次？是的，后面有个例子。

为了搞清楚流水线中到底发生了什么，我们把代码改一改，让每个Lambda都打印出当前处理的菜肴
List<String> names =
	menu.stream()
		.filter(d -> {
			System.out.println("filtering" + d.getName());
			return d.getCalories() > 300;
		})
		.map(d -> {
			System.out.println("mapping" + d.getName());
			return d.getName();
		})
		.limit(3)
		.collect(toList());
System.out.println(names);

将打印：
filtering pork
mapping pork
filtering beef
mapping beef
filtering chicken
mapping chicken
[pork, beef, chicken]

有好几种优化利用了流的延迟性质。
第一，尽管很多菜的热量都高于300卡路里，但只选出了前三个！这是因为limit操作和一种称为短路的技巧，我们会在下一章中解释。
第二，尽管filter和map是两个独立的操作，但它们合并到同一次遍历中了（我们把这种技术叫作循环合并）。


终端操作会从流的流水线生成结果。其结果是任何不是流的值，比如List、Integer，甚至void
。。返回结果不是流，而是其他，如list，integer，void等。

。。返回流的是中间操作，返回非流的是终端操作。


流的使用一般包括三件事：
一个数据源（如集合）来执行一个查询；
一个中间操作链，形成一条流的流水线；
一个终端操作，执行流水线，并能生成结果。


流的流水线背后的理念类似于构建器模式。在构建器模式中有一个调用链用来设置一套配置（对流来说这就是一个中间操作链），接着是调用built方法（对流来说就是终端操作）。


表4-1和表4-2总结了你前面在代码例子中看到的中间流操作和终端流操作。请注意这并不能涵盖Stream API提供的操作


操 作	类 型 	返回类型 	操作参数 		函数描述符
filter 	中间 	Stream<T> 	Predicate<T> 	T -> boolean
map 	中间 	Stream<R> 	Function<T, R> 	T -> R
limit 	中间 	Stream<T>
sorted 	中间 	Stream<T> 	Comparator<T> 	(T, T) -> int
distinct 中间 	Stream<T>

操 作	类 型 	目 的
forEach 终端 	消费流中的每个元素并对其应用Lambda。这一操作返回void
count 	终端 	返回流中元素的个数。这一操作返回long
collect 终端 	把流归约成一个集合，比如List、Map 甚至是Integer。


我们会看到很多模式，比如过滤、切片、查找、匹配、映射和归约，它们可以用来表达复杂的数据处理查询。


List<Dish> vegetarianDishes = new ArrayList<>();
	for(Dish d: menu){
	if(d.isVegetarian()){
		vegetarianDishes.add(d);
	}
}

import static java.util.stream.Collectors.toList;
List<Dish> vegetarianDishes =
	menu.stream()
		.filter(Dish::isVegetarian)
		.collect(toList());


筛选和切片
我们来看看如何选择流中的元素：用谓词筛选，筛选出各不相同的元素，忽略流中的头几个元素，或将流截短至指定长度。

Streams接口支持filter方法（你现在应该很熟悉了）。该操作会接受一个谓词（一个返回boolean的函数）作为参数，并返回一个包括所有符合谓词的元素的流


流还支持一个叫作distinct的方法，它会返回一个元素各异（根据流所生成元素的hashCode和equals方法实现）的流。例如，以下代码会筛选出列表中所有的偶数，并确保没有重复。
List<Integer> numbers = Arrays.asList(1, 2, 1, 3, 3, 2, 4);
numbers.stream()
	.filter(i -> i % 2 == 0)
	.distinct()
	.forEach(System.out::println);


流支持limit(n)方法，该方法会返回一个不超过给定长度的流。
如果流是有序的，则最多会返回前n个元素

请注意limit也可以用在无序流上，比如源是一个Set。这种情况下，limit的结果不会以任何顺序排列。

。。有序就是有序的前n个，无序就是随机n个。。觉得==没说。。
。。set多次运行的话，返回的应该是相同的吧。至少在某个线程中每次运行多次返回的应该都一样吧。。iterator是不是也是一样的。


流还支持skip(n)方法，返回一个扔掉了前n个元素的流。如果流中元素不足n个，则返回一个空流。请注意，limit(n)和skip(n)是互补的



一个非常常见的数据处理套路就是从某些对象中选择信息。比如在SQL里，你可以从表中选择一列。Stream API也通过map和flatMap方法提供了类似的工具。

流支持map方法，它会接受一个函数作为参数。这个函数会被应用到每个元素上，并将其映射成一个新的元素（使用映射一词，是因为它和转换类似，但其中的细微差别在于它是“创建一个新版本”而不是去“修改”）。

List<String> dishNames = menu.stream()
		.map(Dish::getName)
		.collect(toList());

因为getName方法返回一个String，所以map方法输出的流的类型就是Stream<String>

List<Integer> wordLengths = words.stream()
	.map(String::length)
	.collect(toList());

List<Integer> dishNameLengths = menu.stream()
	.map(Dish::getName)
	.map(String::length)
	.collect(toList());
。。每道菜名字有多长。


给定单词列表["Hello","World"]，你想要返回列表["H","e","l", "o","W","r","d"]。

words.stream()
	.map(word -> word.split(""))
	.distinct()
	.collect(toList());

这个方法的问题在于，传递给map方法的Lambda为每个单词返回了一个String[]
因此， map 返回的流实际上是Stream<String[]> 类型的。

幸好可以用flatMap来解决这个问题！


1. 尝试使用map和Arrays.stream()
首先，你需要一个字符流，而不是数组流。有一个叫作Arrays.stream()的方法可以接受一个数组并产生一个流

String[] arrayOfWords = {"Goodbye", "World"};
Stream<String> streamOfwords = Arrays.stream(arrayOfWords);

words.stream()
	.map(word -> word.split(""))
	.map(Arrays::stream)
	.distinct()
	.collect(toList());

当前的解决方案仍然搞不定！这是因为，你现在得到的是一个流的列表（更准确地说是Stream<String>）！的确，你先是把每个单词转换成一个字母数组，然后把每个数组变成了一个独立的流。

2. 使用flatMap
你可以像下面这样使用flatMap来解决这个问题：
List<String> uniqueCharacters =
	words.stream()
		.map(w -> w.split(""))
		.flatMap(Arrays::stream)
		.distinct()
		.collect(Collectors.toList());

使用flatMap方法的效果是，各个数组并不是分别映射成一个流，而是映射成流的内容。所有使用map(Arrays::stream)时生成的单个流都被合并起来，即扁平化为一个流

。。map后是stream<stream<String>>..flatmap是在之前的基础上，把stream<string>映射成了string...???..好像不是，上面写的是:所有使用map(Arrays::stream)时生成的单个流都被合并起来..下面也有说:flatmap方法让你把一个流中的每个值都换成另一个流，然后把所有的流连接起来成为一个流。


返回一个由每个数的平方构成的列表
List<Integer> numbers = Arrays.asList(1, 2, 3, 4, 5);
List<Integer> squares =
	numbers.stream()
		.map(n -> n * n)
		.collect(toList());

给定两个数字列表，如何返回所有的数对呢？例如，给定列表[1, 2, 3]和列表[3, 4]，应该返回[(1, 3), (1, 4), (2, 3), (2, 4), (3, 3), (3, 4)]

你可以使用两个map来迭代这两个列表，并生成数对。但这样会返回一个Stream-<Stream<Integer[]>>。你需要让生成的流扁平化，以得到一个Stream<Integer[]>。这正是flatMap所做的：
List<Integer> numbers1 = Arrays.asList(1, 2, 3);
List<Integer> numbers2 = Arrays.asList(3, 4);
List<int[]> pairs =
	numbers1.stream()
			.flatMap(i -> numbers2.stream()
						.map(j -> new int[]{i, j})
					)
			.collect(toList());

如何扩展前一个例子，只返回总和能被3整除的数对呢？例如(2, 4)和(3, 3)是可以的

你在前面看到了，filter可以配合谓词使用来筛选流中的元素。因为在flatMap操作后，你有了一个代表数对的int[]流，所以你只需要一个谓词来检查总和是否能被3整除就可以了：
List<Integer> numbers1 = Arrays.asList(1, 2, 3);
List<Integer> numbers2 = Arrays.asList(3, 4);
List<int[]> pairs =
	numbers1.stream()
		.flatMap(i ->
					numbers2.stream()
						.filter(j -> (i + j) % 3 == 0)
						.map(j -> new int[]{i, j})
				)
		.collect(toList());
..内部j调用了外部i。


查找和匹配
另一个常见的数据处理套路是看看数据集中的某些元素是否匹配一个给定的属性。Stream API通过allMatch、anyMatch、noneMatch、findFirst和findAny方法提供了这样的工具。



anyMatch方法可以回答“流中是否有一个元素能匹配给定的谓词”
if(menu.stream().anyMatch(Dish::isVegetarian)){
	System.out.println("The menu is (somewhat) vegetarian friendly!!");
}
anyMatch方法返回一个boolean，因此是一个终端操作。


allMatch方法的工作原理和anyMatch类似，但它会看看流中的元素是否都能匹配给定的谓词

菜品是否有利健康（即所有菜的热量都低于1000卡路里）：
boolean isHealthy = menu.stream()
		.allMatch(d -> d.getCalories() < 1000);


和allMatch相对的是noneMatch。它可以确保流中没有任何元素与给定的谓词匹配
用noneMatch重写前面的例子：
boolean isHealthy = menu.stream()
	.noneMatch(d -> d.getCalories() >= 1000);


anyMatch、allMatch和noneMatch这三个操作都用到了我们所谓的短路，这就是大家熟悉的Java中&&和||运算符短路在流中的版本。
。。只要有一个元素不满足，就退出。。


findAny方法将返回当前流中的任意元素。它可以与其他流操作结合使用。比如，你可能想找到一道素食菜肴
Optional<Dish> dish =
	menu.stream()
		.filter(Dish::isVegetarian)
		.findAny();

流水线将在后台进行优化使其只需走一遍，并在利用短路找到结果时立即结束


Optional<T>类（java.util.Optional）是一个容器类，代表一个值存在或不存在。在上面的代码中，findAny可能什么元素都没找到。Java 8的库设计人员引入了Optional<T>，这样就不用返回众所周知容易出问题的null了

Optional里面几种可以迫使你显式地检查值是否存在或处理值不存在的情形的方法也不错。
? isPresent()将在Optional包含值的时候返回true, 否则返回false。
? ifPresent(Consumer<T> block)会在值存在的时候执行给定的代码块。我们在第3章
介绍了Consumer函数式接口；它让你传递一个接收T类型参数，并返回void的Lambda
表达式。
? T get()会在值存在时返回值，否则抛出一个NoSuchElement异常。
? T orElse(T other)会在值存在时返回值，否则返回一个默认值。


在前面的代码中你需要显式地检查Optional对象中是否存在一道菜可以访问其名称：
menu.stream()
	.filter(Dish::isVegetarian)
	.findAny()
	.ifPresent(d -> System.out.println(d.getName());



能想要找到第一个元素。为此有一个findFirst方法，它的工作方式类似于findany。

List<Integer> someNumbers = Arrays.asList(1, 2, 3, 4, 5);
Optional<Integer> firstSquareDivisibleByThree =
	someNumbers.stream()
		.map(x -> x * x)
		.filter(x -> x % 3 == 0)
		.findFirst(); // 9


为什么会同时有findFirst和findAny呢？答案是并行。找到第一个元素在并行上限制更多。如果你不关心返回的元素是哪个，请使用findAny，因为它在使用并行流时限制较少。



把一个流中的元素组合起来，使用reduce操作来表达更复杂的查询
比如“计算菜单中的总卡路里”或“菜单中卡路里最高的菜是哪一个”
此类查询需要将流中所有元素反复结合起来，得到一个值，比如一个Integer
这样的查询可以被归类为归约操作（将流归约成一个值）。用函数式编程语言的术语来说，这称为折叠（fold），因为你可以将这个操作看成把一张长长的纸（你的流）反复折叠成一个小方块，而这就是折叠操作的结果。


对流中所有的元素求和：
int sum = numbers.stream().reduce(0, (a, b) -> a + b);

reduce接受两个参数：
一个初始值，这里是0；
一个BinaryOperator<T>来将两个元素结合起来产生一个新值，这里我们用的是lambda (a, b) -> a + b。



所有的元素相乘，只需要将另一个Lambda：(a, b) -> a * b传递给reduce操作就可以了：
int product = numbers.stream().reduce(1, (a, b) -> a * b);


在Java 8中，Integer类现在有了一个静态的sum方法来对两个数求和，这恰好是我们想要的，用不着反复用Lambda写同一段代码了：
int sum = numbers.stream().reduce(0, Integer::sum);

。。初始值+第一个元素进行sum操作，结果+第二个元素进行sum操作。。。

无初始值
reduce还有一个重载的变体，它不接受初始值，但是会返回一个Optional对象：
Optional<Integer> sum = numbers.stream().reduce((a, b) -> (a + b));
为什么它返回一个Optional<Integer>呢？考虑流中没有任何元素的情况。reduce操作无法返回其和，因为它没有初始值。这就是为什么结果被包裹在一个Optional对象里，以表明和可能不存在。

。。第一个元素+第二个元素进行reduce操作。。。结果和第三个元素进行。。


用归约就可以计算最大值和最小值
Optional<Integer> max = numbers.stream().reduce(Integer::max);

。。是流，所以无法得知number是否有值，有值的话应该可以reduce(nums[0], max); ?

Optional<Integer> min = numbers.stream().reduce(Integer::min);

当然也可以写成Lambda (x, y) -> x < y ? x : y而不是Integer::min，不过后者比较易读。


用map和reduce方法数一数流中有多少个菜
要解决这个问题，你可以把流中每个元素都映射成数字1，然后用reduce求和。这相当于按顺序数流中的元素个数。
int count = menu.stream()
		.map(d -> 1)
		.reduce(0, (a, b) -> a + b);

map和reduce的连接通常称为map-reduce模式，因Google用它来进行网络搜索而出名，因为它很容易并行化。请注意，在第4章中我们也看到了内置count方法可用来计算流中元素的个数：
long count = menu.stream().count();



诸如map或filter等操作会从输入流中获取每一个元素，并在输出流中得到0或1个结果。这些操作一般都是无状态的：它们没有内部状态（假设用户提供的Lambda或方法引用没有内部可变状态）。


诸如sort或distinct等操作一开始都和filter和map差不多――都是接受一个流，再生成一个流（中间操作），但有一个关键的区别。从流中排序和删除重复项时都需要知道先前的历史。例如，排序要求所有元素都放入缓冲区后才能给输出流加入一个项目，这一操作的存储要求是无界的。要是流比较大或是无限的，就可能会有问题（把质数流倒序会做什么呢？它应当返回最大的质数，但数学告诉我们它不存在）。我们把这些操作叫作有状态操作


迄今讲过的操作。

操 作 	类 型 	返回类型 	使用的类型/函数式接口 	函数描述符
filter 	中间 	Stream<T> 	Predicate<T> 			T -> boolean
distinct 中间	Stream<T>
		(有状态 无界)
skip 	中间	Stream<T> 	long
		(有状态 有界)
limit 	中间	Stream<T> 	long
		(有状态?有界)
map 	中间 	Stream<R> 	Function<T, R> 			T -> R
flatMap 中间 	Stream<R> 	Function<T, Stream<R>> 	T -> Stream<R>
sorted 	中间	Stream<T> 	Comparator<T> 			(T, T) -> int
		(有状态?无界)
anyMatch 终端 	boolean 	Predicate<T> 			T -> boolean
noneMatch 终端 	boolean 	Predicate<T> 			T -> boolean
allMatch 终端 	boolean 	Predicate<T> 			T -> boolean
findAny 终端 	Optional<T>
findFirst 终端 	Optional<T>
forEach 终端 	void 		Consumer<T> 			T -> void
collect 终端 	R 			Collector<T, A, R>
reduce 	终端	Optional<T> BinaryOperator<T> 		(T, T) -> T
		(有状态?有界)
count 	终端 	long


找出2011年的所有交易并按交易额排序（从低到高）
List<Transaction> tr2011 =
	transactions.stream()
		.filter(transaction -> transaction.getYear() == 2011)
		.sorted(comparing(Transaction::getValue))
		.collect(toList());

List<String> cities =
	transactions.stream()
		.map(transaction -> transaction.getTrader().getCity())
		.distinct()
		.collect(toList());

还有一个新招：你可以去掉distinct()，改用toSet()，这样就会把流转换为集合。


查找所有来自于剑桥的交易员，并按姓名排序
List<Trader> traders =
	transactions.stream()
		.map(Transaction::getTrader)
		.filter(trader -> trader.getCity().equals("Cambridge"))
		.distinct()
		.sorted(comparing(Trader::getName))
		.collect(toList());


返回所有交易员的姓名字符串，按字母顺序排序
String traderStr =
	transactions.stream()
		.map(transaction -> transaction.getTrader().getName())
		.distinct()
		.sorted()
		.reduce("", (n1, n2) -> n1 + n2);
此解决方案效率不高

更为高效的解决方案
String traderStr =
	transactions.stream()
		.map(transaction -> transaction.getTrader().getName())
		.distinct()
		.sorted()
		.collect(joining());


有没有交易员是在米兰工作的
boolean milanBased =
	transactions.stream()
		.anyMatch(
					transaction -> transaction.getTrader()
					.getCity()
					.equals("Milan")
				);		// )和anyMatch匹配。


打印生活在剑桥的交易员的所有交易额
transactions.stream()
	.filter(t -> "Cambridge".equals(t.getTrader().getCity()))
	.map(Transaction::getValue)
	.forEach(System.out::println);


最高的交易额
Optional<Integer> highestValue =
	transactions.stream()
		.map(Transaction::getValue)
		.reduce(Integer::max);

101

交易额最小的交易

Optional<Transaction> smallestTransaction =
	transactions.stream()
		.reduce((t1, t2) ->
				t1.getValue() < t2.getValue() ? t1 : t2);


流支持min和max方法，它们可以接受一个Comparator作为参数，指定计算最小或最大值时要比较哪个键值
Optional<Transaction> smallestTransaction =
	transactions.stream()
		.min(comparing(Transaction::getValue));


Java 8引入了三个原始类型特化流接口来解决这个问题：IntStream、DoubleStream和LongStream，分别将流中的元素特化为int、long和double，从而避免了暗含的装箱成本。

将流转换为特化版本的常用方法是mapToInt、mapToDouble和mapToLong
int calories = menu.stream()
	.mapToInt(Dish::getCalories)
	.sum();

如果流是空的，sum默认返回0。IntStream还支持其他的方便方法，如max、min、average等。


要把原始流转换成一般流（每个int都会装箱成一个Integer），可以使用boxed方法
IntStream intStream = menu.stream().mapToInt(Dish::getCalories);
Stream<Integer> stream = intStream.boxed();


对于三种原始流特化，也分别有一个Optional原始类型特化版本：OptionalInt、OptionalDouble和OptionalLong。
。。sum可以默认0，但是max之类无法默认。

OptionalInt maxCalories = menu.stream()
	.mapToInt(Dish::getCalories)
	.max();
	
int max = maxCalories.orElse(1);


Java 8引入了两个可以用于IntStream和LongStream的静态方法，帮助生成这种范围：
range和rangeClosed。这两个方法都是第一个参数接受起始值，第二个参数接受结束值。但range是不包含结束值的，而rangeClosed则包含结束值。

IntStream evenNumbers = IntStream.rangeClosed(1, 100).filter(n -> n % 2 == 0);
System.out.println(evenNumbers.count());


知道前2个整数，确认并生成勾股定理的第三个整数。
假设周围的代码给a提供了一个值，并且stream提供了b可能出现的值，filter将只选出那些可以与a组成勾股数的b。
stream.filter(b -> Math.sqrt(a*a + b*b) % 1 == 0)
	.map(b -> new int[]{a, b, (int) Math.sqrt(a * a + b * b)});


IntStream.rangeClosed(1, 100)
	.filter(b -> Math.sqrt(a*a + b*b) % 1 == 0)
	.boxed()
	.map(b -> new int[]{a, b, (int) Math.sqrt(a * a + b * b)});

IntStream中的map方法只能为流中的每个元素返回另一个int，所以需要boxed转换。

可以用IntStream的mapToObj方法改写它，这个方法会返回一个对象值流
IntStream.rangeClosed(1, 100)
	.filter(b -> Math.sqrt(a*a + b*b) % 1 == 0)
	.mapToObj(b -> new int[]{a, b, (int) Math.sqrt(a * a + b * b)});


Stream<int[]> pythagoreanTriples =
	IntStream.rangeClosed(1, 100).boxed()
		.flatMap(a ->
			IntStream.rangeClosed(a, 100)
				.filter(b -> Math.sqrt(a*a + b*b) % 1 == 0)
				.mapToObj(b ->
					new int[]{a, b, (int)Math.sqrt(a * a + b * b)})
			);

目前的解决办法并不是最优的，因为你要求两次平方根。让代码更为紧凑的一种可能的方法是，先生成所有的三元数(a*a, b*b, a*a+b*b)，然后再筛选符合条件的：

Stream<double[]> pythagoreanTriples2 =
	IntStream.rangeClosed(1, 100).boxed()
		.flatMap(a ->
			IntStream.rangeClosed(a, 100)
				.mapToObj(
					b -> new double[]{a, b, Math.sqrt(a*a + b*b)})
				.filter(t -> t[2] % 1 == 0));



从值序列、数组、文件来创建流，甚至由生成函数来创建无限流！


使用静态方法Arrays.stream从数组创建一个流。它接受一个数组作为参数
int[] numbers = {2, 3, 5, 7, 11, 13};
int sum = Arrays.stream(numbers).sum();


Java中用于处理文件等I/O操作的NIO API（非阻塞 I/O）已更新，以便利用Stream API。
java.nio.file.Files中的很多静态方法都会返回一个流。例如，一个很有用的方法是Files.lines，它会返回一个由指定文件中的各行构成的字符串流

一个文件中有多少各不相同的词
long uniqueWords = 0;
try(Stream<String> lines =
	Files.lines(Paths.get("data.txt"), Charset.defaultCharset()))
{		// try。。自动关闭的资源的那种写法。 java 7特性。
		uniqueWords = lines.flatMap(line -> Arrays.stream(line.split(" ")))
		.distinct()
		.count();
}
catch(IOException e){
}

。。(try-with-resources)，resource对象必须实现Autocloseable接口



Stream API提供了两个静态方法来从函数生成流：Stream.iterate和Stream.generate。
这两个操作可以创建所谓的无限流：不像从固定集合创建的流那样有固定大小的流
应该使用limit(n)来对这种流加以限制，以避免打印无穷多个值。

Stream.iterate(0, n -> n + 2)
	.limit(10)
	.forEach(System.out::println);

iterate方法接受一个初始值（在这里是0），还有一个依次应用在每个产生的新值上的Lambda（UnaryOperator<t>类型）。这里，我们使用Lambda n -> n + 2，返回的是前一个元素加上2。


fibonacci
Stream.iterate(new int[]{0, 1},
		t -> new int[]{t[1], t[0]+t[1]})			// new int..
	.limit(20)
	.forEach(t -> System.out.println("(" + t[0] + "," + t[1] +")"));

与iterate方法类似，generate方法也可让你按需生成一个无限流。但generate不是依次对每个新生成的值应用函数的。它接受一个Supplier<T>类型的Lambda提供新的值
。。？iterator也是lambda啊。不清楚。可能是：iterator是初始参数+方法体的lambda形式，，而这里直接就是lambda

public static<T> Stream<T> iterate(final T seed, final UnaryOperator<T> f) {

public static<T> Stream<T> generate(Supplier<T> s) {

。。都是lambda，一个有初始值，一个没有。
。。UnaryOperator 是 T -> T,接受一个T类型，返回一个T类型。
。。Supplier 是void -> T


Stream.generate(Math::random)
	.limit(5)
	.forEach(System.out::println);


我们使用的供应源（指向Math.random的方法引用）是无状态的：它不会在任何地方记录任何值，以备以后计算使用。但供应源不一定是无状态的。你可以创建存储状态的供应源，它可以修改状态，并在为流生成下一个值时使用

在并行代码中使用有状态的供应源是不安全的。因此下面的代码仅仅是为了内容完整，应尽量避免使用



使用IntStream说明避免装箱操作的代码。IntStream的generate方法会接受一个IntSupplier，而不是Supplier<t>。

可以这样来生成一个全是1的无限流：
IntStream ones = IntStream.generate(() -> 1);

Lambda允许你创建函数式接口的实例，只要直接内联提供方法的实现就可以。你也可以像下面这样，通过实现IntSupplier接口中定义的getAsInt方法显式传递一个对象（虽然这看起来是无缘无故地绕圈子，也请你耐心看）：
IntStream twos = IntStream.generate(new IntSupplier(){
		public int getAsInt(){
			return 2;
		}
	});
generate方法将使用给定的供应源，并反复调用getAsInt方法，而这个方法总是返回2。

这里使用的匿名类和Lambda的区别在于，匿名类可以通过字段定义状态，而状态又可以用getAsInt方法来修改。这是一个副作用的例子。你迄今见过的所有Lambda都是没有副作用的；它们没有改变任何状态。


创建一个在调用时返回下一个斐波纳契项的IntSupplier：

IntSupplier fib = new IntSupplier(){
		private int previous = 0;
		private int current = 1;
		public int getAsInt(){
			int oldPrevious = this.previous;
			int nextValue = this.previous + this.current;
			this.previous = this.current;
			this.current = nextValue;
			return oldPrevious;
		}
	};
IntStream.generate(fib).limit(10).forEach(System.out::println);

相比之下，使用iterate的方法则是纯粹不变的：它没有修改现有状态，
但在每次迭代时会创建新的元组。你将在第7章了解到，你应该始终采用不变的方法，以便并行处理流，并保持结果正确。请注意，因为你处理的是一个无限流，所以必须使用limit操作来显式限制它的大小；否则，终端操作（这里是forEach）将永远计算下去。同样，你不能对无限流做排序或归约，因为所有元素都需要处理，而这永远也完不成！




111
第6章	用流收集数据



用指令式风格对交易按照货币分组
Map<Currency, List<Transaction>> transactionsByCurrencies = new HashMap<>();
for (Transaction transaction : transactions) {
	Currency currency = transaction.getCurrency();
	List<Transaction> transactionsForCurrency = 
						transactionsByCurrencies.get(currency);
	if (transactionsForCurrency == null) {
		transactionsForCurrency = new ArrayList<>();
		transactionsByCurrencies
							.put(currency, transactionsForCurrency);
	}
	transactionsForCurrency.add(transaction);
}


用Stream中collect方法的一个更通用的Collector参数，你就可以用一句话实现完全相同的结果，而用不着使用上一章中那个toList的特殊情况了：
Map<Currency, List<Transaction>> transactionsByCurrencies =
transactions.stream().collect(groupingBy(Transaction::getCurrency));


函数式编程相对于指令式编程的一个主要优势：你只需指出希望的结果――“做什么”，而不用操心执行的步骤――“如何做”

toList只是说“按顺序给每个元素生成一个列表”；在本例中，groupingBy说的是“生成一个Map，它的键是（货币）桶，值则是桶中那些元素的列表”。

Collector会对元素应用一个转换函数（很多时候是不体现任何效果的恒等转换，例如toList），并将结果累积在一个数据结构中，从而产生这一过程的最终输出

Collectors实用类提供了很多静态工厂方法,最直接和最常用的收集器是toList
它会把流中所有的元素收集到一个List中：
List<Transaction> transactions =
		transactionStream.collect(Collectors.toList());


Collectors类提供的工厂方法（例如groupingBy）创建的收集器。它们主要提供了三大功能：
将流元素归约和汇总为一个值
元素分组
元素分区


菜单里有多少种菜：
long howManyDishes = menu.stream().collect(Collectors.counting());
这还可以写得更为直接：
long howManyDishes = menu.stream().count();

counting收集器在和其他收集器联合使用的时候特别有用

import static java.util.stream.Collectors.*;


菜单中热量最高的菜。你可以使用两个收集器，Collectors.maxBy和Collectors.minBy，来计算流中的最大或最小值。这两个收集器接收一个Comparator参数来比较流中的元素。

Comparator<Dish> dishCaloriesComparator =
	Comparator.comparingInt(Dish::getCalories);
Optional<Dish> mostCalorieDish =
	menu.stream()
		.collect(maxBy(dishCaloriesComparator));


Collectors类专门为汇总提供了一个工厂方法：Collectors.summingInt。它可接受一个把对象映射为求和所需int的函数，并返回一个收集器

求出菜单列表的总热量：
int totalCalories = menu.stream().collect(summingInt(Dish::getCalories));

该收集器在传递给普通的collect方法后即执行我们需要的汇总操作
..这句话意思是一个元素处理完就立刻sum，而不是等全部元素处理完？是的，下面。

在遍历流时，会把每一道菜都映射为其热量，然后把这个数字累加到一个累加器（这里的初始值0）。


汇总不仅仅是求和；还有Collectors.averagingInt，连同对应的averagingLong和averagingDouble可以计算数值的平均数：
double avgCalories =
	menu.stream().collect(averagingInt(Dish::getCalories));


一次获得max，min，avg，你可以使用summarizingInt工厂方法返回的收集器

通过一次summarizing操作你可以就数出菜单中元素的个数，并得到菜肴热量总和、平均值、最大值和最小值：
IntSummaryStatistics menuStatistics =
	menu.stream().collect(summarizingInt(Dish::getCalories));

打印menuStatisticobject会得到以下输出：
IntSummaryStatistics{count=9, sum=4300, min=120, average=477.777778, max=800}


相应的summarizingLong和summarizingDouble工厂方法有相关的LongSummaryStatistics和DoubleSummaryStatistics类型


连接字符串

116
joining工厂方法返回的收集器会把对流中每一个对象应用toString方法得到的所有字符串连接成一个字符串

菜单中所有菜肴的名称连接起来，如下所示：
String shortMenu = menu.stream().map(Dish::getName).collect(joining());

joining在内部使用了StringBuilder来把生成的字符串逐个追加起来。此外还要注意，如果Dish类有一个toString方法来返回菜肴的名称，那你无需用提取每一道菜名称的函数来对原流做映射就能够得到相同的结果：

String shortMenu = menu.stream().collect(joining());
。。joining里调用的是toString

joining工厂方法有一个重载版本可以接受元素之间的分界符，这样你就可以得到一个逗号分隔的菜肴名称列表：
String shortMenu = menu.stream().map(Dish::getName).collect(joining(", "));


所有这种形式的归约过程，其实都是Collectors.reducing工厂方法提供的更广义归约收集器的特殊情况。


可以用reducing方法创建的收集器来计算你菜单的总热量，如下所示：
int totalCalories = menu.stream().collect(reducing(0, Dish::getCalories, (i, j) -> i + j));

第一个参数是归约操作的起始值，也是流中没有元素时的返回值，所以很显然对于数值和而言0是一个合适的值。
第二个参数就是你在6.2.2节中使用的函数，将菜肴转换成一个表示其所含热量的int。
第三个参数是一个BinaryOperator，将两个项目累积成一个同类型的值。这里它就是对两个int求和。


单参数形式的reducing来找到热量最高的菜，如下所示：
Optional<Dish> mostCalorieDish =
	menu.stream().collect(reducing(
		(d1, d2) -> d1.getCalories() > d2.getCalories() ? d1 : d2));

可以把单参数reducing工厂方法创建的收集器看作三参数方法的特殊情况，它把流中的第一个项目作为起点，把恒等函数（即一个函数仅仅是返回其输入参数）作为一个转换函数


118
你可能想知道，Stream接口的collect和reduce方法有何不同，因为两种方法通常会获得相同的结果。例如，你可以像下面这样使用reduce方法来实现toListCollector所做的工作：
Stream<Integer> stream = Arrays.asList(1, 2, 3, 4, 5, 6).stream();
List<Integer> numbers = stream.reduce(
		new ArrayList<Integer>(),
		(List<Integer> l, Integer e) -> {
				l.add(e);
				return l; },
		(List<Integer> l1, List<Integer> l2) -> {
				l1.addAll(l2);
				return l1; });

有两个问题：一个语义问题和一个实际问题。语义问题在于，reduce方法旨在把两个值结合起来生成一个新值，它是一个不可变的归约。与此相反，collect方法的设计就是要改变容器，从而累积要输出的结果。这意味着，上面的代码片段是在滥用reduce方法，因为它在原地改变了作为累加器的List
以错误的语义使用reduce方法还会造成一个实际问题：这个归约过程不能并行工作，因为由多个线程并发修改同一个数据结构可能会破坏List本身。

。。这个reduce的输出是什么。。。就是stream。toList
。。不能这样吗：reduce(new List, e -> e.getValue(), (list, e)->{list.add(e); return list});。。应该可以吧。能直接e->e作为恒等函数吗？可以的，下面有e->1L.顺便找个工具类进行ListUtils::Add。。Add似乎必须static？
.。no，可以类.static方法，类.普通方法，对象.方法。。。
。。不行，reduce的参数类型不正确。


简化求和例子--使用Integer::sum
int totalCalories = menu.stream().collect(reducing(0,
				Dish::getCalories,
				Integer::sum));

从逻辑上说，归约操作的工作原理如图6-3所示：利用累积函数，把一个初始化为起始值的累加器，和把转换函数应用到流中每个元素上得到的结果不断迭代合并起来。


counting收集器也是类似地利用三参数reducing工厂方法实现的。它把流中的每个元素都转换成一个值为1的Long型对象，然后再把它们相加：
public static <T> Collector<T, ?, Long> counting() {
	return reducing(0L, e -> 1L, Long::sum);
}

?通配符，它用作counting工厂方法返回的收集器签名中的第二个泛型类型
在这里，它仅仅意味着收集器的累加器类型未知，换句话说，累加器本身可以是任何类型。


int totalCalories =
	menu.stream().map(Dish::getCalories).reduce(Integer::sum).get();

一般来说，使用允许提供默认值的方法，如orElse或orElseGet来解开Optional中包含的值更为安全


更简洁的方法是把流映射到一个IntStream，然后调用sum方法，你也可以得到相同的结果：
int totalCalories = menu.stream().mapToInt(Dish::getCalories).sum();


以下哪一种reducing收集器的用法能够合法地替代joining收集器
String shortMenu = menu.stream().map(Dish::getName).collect(joining());

(1) String shortMenu = menu.stream().map(Dish::getName)
		.collect( reducing ( (s1, s2) -> s1 + s2 ) ).get();

(2) String shortMenu = menu.stream()
		.collect( reducing( (d1, d2) -> d1.getName() + d2.getName() ) ).get();

(3) String shortMenu = menu.stream()
		.collect( reducing( "",Dish::getName, (s1, s2) -> s1 + s2 ) );

1，3可以，2不行。因为reducing接受的参数是一个BinaryOperator<t>，也就是一个BiFunction<T,T,T>。这就意味着它需要的函数必须能接受两个参数，然后返回一个相同类型的值。

实际应用而言，不管是从可读性还是性能方面考虑，我们始终建议使用joining收集器。


一个常见的数据库操作是根据一个或多个属性对集合中的项目进行分组。

用Collectors.groupingBy工厂方法返回的收集器就可以轻松地完成这项任务，如下所示：
Map<Dish.Type, List<Dish>> dishesByType =
			menu.stream().collect(groupingBy(Dish::getType));

给groupingBy方法传递了一个Function（以方法引用的形式），它提取了流中每一道Dish的Dish.Type。我们把这个Function叫作分类函数，因为它用来把流中的元素分成不同的组


把热量不到400卡路里的菜划分为“低热量”（diet），热量400到700卡路里的菜划为“普通”（normal），高于700卡路里的划为“高热量”（fat）。

public enum CaloricLevel { DIET, NORMAL, FAT }
Map<CaloricLevel, List<Dish>> dishesByCaloricLevel = menu.stream().collect(
groupingBy(dish -> {
	if (dish.getCalories() <= 400) return CaloricLevel.DIET;
	else if (dish.getCalories() <= 700) return CaloricLevel.NORMAL;
	else return CaloricLevel.FAT;
} ));


想同时按照这两个标准(卡路里，Type)分类怎么办呢？分组的强大之处就在于它可以有效地组合

要实现多级分组，我们可以使用一个由双参数版本的Collectors.groupingBy工厂方法创建的收集器，它除了普通的分类函数之外，还可以接受collector类型的第二个参数。
那么要进行二级分组的话，我们可以把一个内层groupingBy传递给外层groupingBy，并定义一个为流中项目分类的二级标准，

Map<Dish.Type, Map<CaloricLevel, List<Dish>>> dishesByTypeCaloricLevel =
menu.stream().collect(
	groupingBy(Dish::getType,
		groupingBy(dish -> {
			if (dish.getCalories() <= 400) return CaloricLevel.DIET;
			else if (dish.getCalories() <= 700) return CaloricLevel.NORMAL;
			else return CaloricLevel.FAT;
		} )
	)
);


传递给第一个groupingBy的第二个收集器可以是任何类型，而不一定是另一个groupingBy

要数一数菜单中每类菜有多少个，可以传递counting收集器作为groupingBy收集器的第二个参数：
Map<Dish.Type, Long> typesCount = menu.stream().collect(groupingBy(Dish::getType, counting()));


普通的单参数groupingBy(f)（其中f是分类函数）实际上是groupingBy(f,toList())的简便写法。
。。map的values是一个list。。

查找菜单中热量最高的菜肴的收集器改一改，按照菜的类型分类：
Map<Dish.Type, Optional<Dish>> mostCaloricByType =
	menu.stream()
		.collect(groupingBy(Dish::getType,
				maxBy(comparingInt(Dish::getCalories))));


因为分组操作的Map结果中的每个值上包装的Optional没什么用，所以你可能想要把它们去掉。要做到这一点，或者更一般地来说，把收集器返回的结果转换为另一种类型，你可以使用Collectors.collectingAndThen工厂方法返回的收集器

Map<Dish.Type, Dish> mostCaloricByType =
	menu.stream()
		.collect(groupingBy(Dish::getType,
			collectingAndThen(maxBy(comparingInt(Dish::getCalories)),
										Optional::get)));

这个工厂方法接受两个参数――要转换的收集器以及转换函数，并返回另一个收集器

注意以下几点。
收集器用虚线表示，因此groupingBy是最外层，根据菜肴的类型把菜单流分组，得到三个子流。
groupingBy收集器包裹着collectingAndThen收集器，因此分组操作得到的每个子流都用这第二个收集器做进一步归约。
collectingAndThen收集器又包裹着第三个收集器maxBy。
随后由归约收集器进行子流的归约操作，然后包含它的collectingAndThen收集器会对其结果应用Optional:get转换函数。
对三个子流分别执行这一过程并转换而得到的三个值，也就是各个类型中热量最高的Dish，将成为groupingBy收集器返回的Map中与各个分类键（Dish的类型）相关联的值。


通过groupingBy工厂方法的第二个参数传递的收集器将会对分到同一组中的所有流元素执行进一步归约操作

Map<Dish.Type, Integer> totalCaloriesByType =
	menu.stream().collect(groupingBy(Dish::getType,
						summingInt(Dish::getCalories)));


常常和groupingBy联合使用的另一个收集器是mapping方法生成的。这个方法接受两个参数：一个函数对流中的元素做变换，另一个则将变换的结果对象收集起来。其目的是在累加之前对每个输入元素应用一个映射函数，这样就可以让接受特定类型元素的收集器适应不同类型的对象


对于每种类型的Dish，菜单中都有哪些CaloricLevel。
Map<Dish.Type, Set<CaloricLevel>> caloricLevelsByType =
	menu.stream().collect(
		groupingBy(Dish::getType, mapping(
			dish -> { if (dish.getCalories() <= 400) return CaloricLevel.DIET;
			else if (dish.getCalories() <= 700) return CaloricLevel.NORMAL;
			else return CaloricLevel.FAT; },
		toSet() )));

传递给映射方法的转换函数将Dish映射成了它的CaloricLevel：生成的CaloricLevel流传递给一个toSet收集器，它和toList类似，不过是把流中的元素累积到一个Set而不是List中，以便仅保留各不相同的值。

返回的Set是什么类型并没有任何保证。但通过使用toCollection，你就可以有更多的控制。

给它传递一个构造函数引用来要求HashSet：

Map<Dish.Type, Set<CaloricLevel>> caloricLevelsByType =
menu.stream().collect(
groupingBy(Dish::getType, mapping(
dish -> { if (dish.getCalories() <= 400) return CaloricLevel.DIET;
else if (dish.getCalories() <= 700) return CaloricLevel.NORMAL;
else return CaloricLevel.FAT; },
			toCollection(HashSet::new) )));



分区是分组的特殊情况：由一个谓词（返回一个布尔值的函数）作为分类函数，它称分区函数。分区函数返回一个布尔值，这意味着得到的分组Map的键类型是Boolean，于是它最多可以分为两组――true是一组，false是一组


获取素菜
Map<Boolean, List<Dish>> partitionedMenu =
	menu.stream().collect(partitioningBy(Dish::isVegetarian));
List<Dish> vegetarianDishes = partitionedMenu.get(true);

用同样的分区谓词，对菜单List创建的流作筛选，然后把结果收集到另外一个List中也可以获得相同的结果：
List<Dish> vegetarianDishes =
	menu.stream().filter(Dish::isVegetarian).collect(toList());

分区的好处在于保留了分区函数返回true或false的两套流元素列表
。。应该能collect(groupby(::isVegetarian)) 吧。

partitioningBy工厂方法有一个重载版本，可以像下面这样传递第二个收集器：
Map<Boolean, Map<Dish.Type, List<Dish>>> vegetarianDishesByType =
	menu.stream().collect(
		partitioningBy(Dish::isVegetarian,
			groupingBy(Dish::getType)));

这将产生一个二级Map：
{false={FISH=[prawns, salmon], MEAT=[pork, beef, chicken]},
true={OTHER=[french fries, rice, season fruit, pizza]}}

重用前面的代码来找到素食和非素食中热量最高的菜：
Map<Boolean, Dish> mostCaloricPartitionedByVegetarian =
	menu.stream().collect(
		partitioningBy(Dish::isVegetarian,
			collectingAndThen(
				maxBy(comparingInt(Dish::getCalories)),
				Optional::get)));


128
测试某一个待测数字是否是质数的谓词
public boolean isPrime(int candidate) {
	return IntStream.range(2, candidate)
						.noneMatch(i -> candidate % i == 0);
}

public boolean isPrime(int candidate) {
	int candidateRoot = (int) Math.sqrt((double) candidate);
	return IntStream.rangeClosed(2, candidateRoot)
						.noneMatch(i -> candidate % i == 0);
}

前n个自然数分为质数和非质数
public Map<Boolean, List<Integer>> partitionPrimes(int n) {
	return IntStream.rangeClosed(2, n).boxed()
			.collect(
					partitioningBy(candidate -> isPrime(candidate)));
}


Collectors类的静态工厂方法
工厂方法 	返回类型 	用 于
toList 		List<T> 	把流中所有项目收集到一个List
使用示例：List<Dish> dishes = menuStream.collect(toList());

toSet 		Set<T> 		把流中所有项目收集到一个Set，删除重复项
使用示例：Set<Dish> dishes = menuStream.collect(toSet());

toCollection Collection<T> 把流中所有项目收集到给定的供应源创建的集合
使用示例：Collection<Dish> dishes = menuStream.collect(toCollection(),ArrayList::new);

counting 	Long 		计算流中元素的个数
使用示例：long howManyDishes = menuStream.collect(counting());

summingInt 	Integer 	对流中项目的一个整数属性求和
使用示例：int totalCalories = menuStream.collect(summingInt(Dish::getCalories));

averagingInt Double	 	计算流中项目Integer 属性的平均值
使用示例：double avgCalories =
menuStream.collect(averagingInt(Dish::getCalories));

summarizingInt IntSummaryStatistics
收集关于流中项目Integer 属性的统计值，例如最大、最小、总和与平均值
使用示例：IntSummaryStatistics menuStatistics =
menuStream.collect(summarizingInt(Dish::getCalories));

joining` String 	连接对流中每个项目调用toString 方法所生成的字符串
使用示例：String shortMenu =
menuStream.map(Dish::getName).collect(joining(", "));

maxBy 	Optional<T>
一个包裹了流中按照给定比较器选出的最大元素的Optional，或如果流为空则为Optional.empty()
使用示例：Optional<Dish> fattest =
menuStream.collect(maxBy(comparingInt(Dish::getCalories)));

minBy 	Optional<T>
一个包裹了流中按照给定比较器选出的最小元素的Optional，或如果流为空则为Optional.empty()
使用示例：Optional<Dish> lightest =
menuStream.collect(minBy(comparingInt(Dish::getCalories)));

reducing 归约操作产生的类型
从一个作为累加器的初始值开始，利用BinaryOperator 与流中的元素逐个结合，从而将流归约为单个值
使用示例：int totalCalories =
menuStream.collect(reducing(0, Dish::getCalories, Integer::sum));

collectingAndThen 转换函数返回的类型 包裹另一个收集器，对其结果应用转换函数
使用示例：int howManyDishes =
menuStream.collect(collectingAndThen(toList(), List::size));

groupingBy Map<K, List<T>>
根据项目的一个属性的值对流中的项目作问组，并将属性值作为结果Map 的键
使用示例：Map<Dish.Type,List<Dish>> dishesByType =
menuStream.collect(groupingBy(Dish::getType));

partitioningBy Map<Boolean,List<T>> 根据对流中每个项目应用谓词的结果来对项目进行分区
使用示例：Map<Boolean,List<Dish>> vegetarianDishes =
menuStream.collect(partitioningBy(Dish::isVegetarian));


Collector接口包含了一系列方法，为实现具体的归约操作（即收集器）提供了范本

public interface Collector<T, A, R> {
	Supplier<A> supplier();
	BiConsumer<A, T> accumulator();
	Function<A, R> finisher();
	BinaryOperator<A> combiner();
	Set<Characteristics> characteristics();
}

? T是流中要收集的项目的泛型。
? A是累加器的类型，累加器是在收集过程中用于累积部分结果的对象。
? R是收集操作得到的对象（通常但并不一定是集合）的类型。


1. 建立新的结果容器：supplier方法
supplier方法必须返回一个结果为空的Supplier，也就是一个无参数函数，在调用时它会创建一个空的累加器实例，供数据收集过程使用

在我们的ToListCollector中，supplier返回一个空的List
public Supplier<List<T>> supplier() {
	return () -> new ArrayList<T>();
}

public Supplier<List<T>> supplier() {
	return ArrayList::new;
}

2. 将元素添加到结果容器：accumulator方法
accumulator方法会返回执行归约操作的函数。两个参数：保存归约结果的累加器（已收集了流中的前n-1个项目），还有第n个元素本身。返回void，因为累加器是原位更新

public BiConsumer<List<T>, T> accumulator() {
	return (list, item) -> list.add(item);
}

public BiConsumer<List<T>, T> accumulator() {
	return List::add;
}

3. 对结果容器应用最终转换：finisher方法
在遍历完流后，finisher方法必须返回在累积过程的最后要调用的一个函数，以便将累加器对象转换为整个集合操作的最终结果。
通常，就像ToListCollector的情况一样，累加器对象恰好符合预期的最终结果，因此无需进行转换

public Function<List<T>, List<T>> finisher() {
	return Function.identity();
}
。。这个是恒等函数。

实践中的实现细节可能还要复杂一点，
一方面是因为流的延迟性质，可能在collect操作之前还需要完成其他中间操作的流水线，
另一方面则是理论上可能要进行并行归约。


4. 合并两个结果容器：combiner方法
combiner方法会返回一个供归约操作使用的函数，它定义了对流的各个子部分进行并行处理时，各个子部分归约所得的累加器要如何合并
对于toList而言，这个方法的实现非常简单

public BinaryOperator<List<T>> combiner() {
	return (list1, list2) -> {
		list1.addAll(list2);
		return list1; }
}

有了这第四个方法，就可以对流进行并行归约了。它会用到Java 7中引入的分支/合并框架和Spliterator抽象


5. characteristics方法
最后一个方法――characteristics会返回一个不可变的Characteristics集合，它定义了收集器的行为――尤其是关于流是否可以并行归约，以及可以使用哪些优化的提示。
Characteristics是一个包含三个项目的枚举。
UNORDERED――归约结果不受流中项目的遍历和累积顺序的影响。
CONCURRENT――accumulator函数可以从多个线程同时调用，且该收集器可以并行归约流。如果收集器没有标为UNORDERED，那它仅在用于无序数据源时才可以并行归约。
IDENTITY_FINISH――这表明完成器方法返回的函数是一个恒等函数，可以跳过。这种情况下，累加器对象将会直接用作归约过程的最终结果。这也意味着，将累加器A不加检查地转换为结果R是安全的。
public Set<Characteristics> characteristics() {
	return Collections.unmodifiableSet(EnumSet.of(
				IDENTITY_FINISH, CONCURRENT));
}
。。EnumSet.of


对于IDENTITY_FINISH的收集操作，还有一种方法可以得到同样的结果而无需从头实现新的Collectors接口。Stream有一个重载的collect方法可以接受另外三个函数――supplier、accumulator和combiner，其语义和Collector接口的相应方法返回的函数完全相同
List<Dish> dishes = menuStream.collect(
								ArrayList::new,
								List::add,
								List::addAll);

138
上面的前n个质数，可以通过自定义collector来优化。
public static boolean isPrime(List<Integer> primes, int candidate){
	int candidateRoot = (int) Math.sqrt((double) candidate);
	return takeWhile(primes, i -> i <= candidateRoot)
	.stream()
	.noneMatch(p -> candidate % p == 0);
}
.。只和质数比较。

public Supplier<Map<Boolean, List<Integer>>> supplier() {
	return () -> new HashMap<Boolean, List<Integer>>() {{
				put(true, new ArrayList<Integer>());
				put(false, new ArrayList<Integer>());
	}};
}

public BiConsumer<Map<Boolean, List<Integer>>, Integer> accumulator() {
	return (Map<Boolean, List<Integer>> acc, Integer candidate) -> {
			acc.get( isPrime( acc.get(true),candidate) )
				.add(candidate);
	};
}`

public BinaryOperator<Map<Boolean, List<Integer>>> combiner() {
	return (Map<Boolean, List<Integer>> map1,
				Map<Boolean, List<Integer>> map2) -> {
			map1.get(true).addAll(map2.get(true));
			map1.get(false).addAll(map2.get(false));
			return map1;
		};
}

public Function<Map<Boolean, List<Integer>>,
Map<Boolean, List<Integer>>> finisher() {
	return Function.identity();
}

public Set<Characteristics> characteristics() {
	return Collections.unmodifiableSet(EnumSet.of(IDENTITY_FINISH));
}
。。不是unordered，不是concurrent，因为质数是按顺序发现的。


比较性能
public class CollectorHarness {
	public static void main(String[] args) {
		long fastest = Long.MAX_VALUE;
		for (int i = 0; i < 10; i++) {
			long start = System.nanoTime();
			partitionPrimes(1_000_000);
			long duration = (System.nanoTime() - start) / 1_000_000;
			if (duration < fastest) 
				fastest = duration;
		}
		System.out.println("Fastest execution done in " + fastest + " msecs");
	}
}

更为科学的测试方法是用一个诸如JMH的框架

自定义收集器比partitioningBy
获得了大约32%的性能提升


public Map<Boolean, List<Integer>> partitionPrimesWithCustomCollector
(int n) {
	IntStream.rangeClosed(2, n).boxed()
		.collect(
			() -> new HashMap<Boolean, List<Integer>>() {{
				put(true, new ArrayList<Integer>());
				put(false, new ArrayList<Integer>());
			}},
			(acc, candidate) -> {
				acc.get( isPrime(acc.get(true), candidate) )
							.add(candidate);
			},
			(map1, map2) -> {
				map1.get(true).addAll(map2.get(true));
				map1.get(false).addAll(map2.get(false));
			});
}



141
第7章
并行数据处理与性能

在Java 7之前，并行处理数据集合非常麻烦。第一，你得明确地把包含数据的数据结构分成若干子部分。第二，你要给每个子部分分配一个独立的线程。第三，你需要在恰当的时候对它们进行同步来避免不希望出现的竞争条件，等待所有线程完成，最后把这些部分结果合并起来。Java 7引入了一个叫作分支/合并的框架，让这些操作更稳定、更不易出错。

流是如何在幕后应用Java 7引入的分支/合并框架的。

对收集源调用parallelStream方法来把集合转换为并行流。并行流就是一个把内容分成多个数据块，并用不同的线程分别处理每个数据块的流


需要写一个方法，接受数字n作为参数，并返回从1到给定参数的所有数字的和
生成一个无穷大的数字流，把它限制到给定的数目，然后用对两个数字求和的BinaryOperator来归约这个流，
public static long sequentialSum(long n) {
	return Stream.iterate(1L, i -> i + 1)
					.limit(n)
					.reduce(0L, Long::sum);
}

用更为传统的Java术语来说，这段代码与下面的迭代等价：
public static long iterativeSum(long n) {
	long result = 0;
	for (long i = 1L; i <= n; i++) {
		result += i;
	}
	return result;
}

将顺序流转换为并行流
public static long parallelSum(long n) {
	return Stream.iterate(1L, i -> i + 1)
		.limit(n)
		.parallel()					//........
		.reduce(0L, Long::sum);
}
。。图上是，1，2，3，4一个流，5，6，7，8一个流，然后2个流的结果相加。

对顺序流调用parallel方法并不意味着流本身有任何实际的变化。它在内部实际上就是设了一个boolean标志，表示你想让调用parallel之后进行的所有操作都并行执行

类似地，你只需要对并行流调用sequential方法就可以把它变成顺序流


请注意，你可能以为把这两个方法结合起来，就可以更细化地控制在遍历流时哪些操作要并行执行，哪些要顺序执行。例如，你可以这样做：
stream.parallel()
	.filter(...)
	.sequential()
	.map(...)
	.parallel()
	.reduce();
但最后一次parallel或sequential调用会影响整个流水线。在本例中，流水线会并行执行，因为最后调用的是它。

并行流内部使用了默认的ForkJoinPool（7.2节会进一步讲到分支/合并框架），它默认的线程数量就是你的处理器数量， 这个值是由Runtime.getRuntime().availableProcessors()得到的。
但是你可以通过系统属性java.util.concurrent.ForkJoinPool.common.parallelism来改变线程池大小，如下所示：
System.setProperty("java.util.concurrent.ForkJoinPool.common.parallelism","12");
这是一个全局设置，因此它将影响代码中所有的并行流。反过来说，目前还无法专为某个并行流指定这个值。一般而言，让ForkJoinPool的大小等于处理器数量是个不错的默认值，除非你有很好的理由，否则我们强烈建议你不要修改它。



测量对前n个自然数求和的函数的性能
public long measureSumPerf(Function<Long, Long> adder, long n) {
	long fastest = Long.MAX_VALUE;
	for (int i = 0; i < 10; i++) {
		long start = System.nanoTime();
		long sum = adder.apply(n);
		long duration = (System.nanoTime() - start) / 1_000_000;
		System.out.println("Result: " + sum);
		if (duration < fastest) fastest = duration;
	}
	return fastest;
}

System.out.println("Sequential sum done in:" + measureSumPerf(ParallelStreams::sequentialSum, 10_000_000) + " msecs");
。。2页前的方法。
97ms

System.out.println("Iterative sum done in:" + measureSumPerf(ParallelStreams::iterativeSum, 10_000_000) + " msecs");
2ms

System.out.println("Parallel sum done in: " + measureSumPerf(ParallelStreams::parallelSum, 10_000_000) + " msecs" );
164ms

这相当令人失望，求和方法的并行版本比顺序版本要慢很多。
这里实际上有两个问题：
? iterate生成的是装箱的对象，必须拆箱成数字才能求和；
? 我们很难把iterate分成多个独立块来并行执行。
。。所以iterativeSum，这个不需要装箱，拆箱的非常非常快。

第二个问题更有意思一点，因为你必须意识到某些流操作比其他操作更容易并行化
iterate很难分割成能够独立执行的小块，因为每次应用这个函数都要依赖前一次应用的结果
整张数字列表在归纳过程开始时没有准备好，因而无法有效地把流划分为小块来并行处理。把流标记成并行，你其实是给顺序处理增加了开销，它还要把每次求和操作分到一个不同的线程上。

。。归纳开始时，数据是否全部准备好。


那到底要怎么利用多核处理器，用流来高效地并行求和呢？我们在第5章中讨论了一个叫LongStream.rangeClosed的方法。这个方法与iterate相比有两个优点。
LongStream.rangeClosed直接产生原始类型的long数字，没有装箱拆箱的开销。
LongStream.rangeClosed会生成数字范围，很容易拆分为独立的小块。例如，范围1~20可分为1~5、6~10、11~15和16~20。

public static long rangedSum(long n) {
	return LongStream.rangeClosed(1, n)
		.reduce(0L, Long::sum);
}
17ms

public static long parallelRangedSum(long n) {
	return LongStream.rangeClosed(1, n)
				.parallel()
				.reduce(0L, Long::sum);
}
1ms


并行化并不是没有代价的。并行化过程本身需要对流做递归划分，把每个子流的归纳操作分配到不同的线程，然后把这些操作的结果合并成一个值。但在多个内核之间移动数据的代价也可能比你想的要大，所以很重要的一点是要保证在内核中并行执行工作的时间比在内核之间传输数据的时间长


错用并行流而产生错误的首要原因，就是使用的算法改变了某些共享状态
下面是另一种实现对前n个自然数求和的方法，但这会改变一个共享累加器：
public static long sideEffectSum(long n) {
	Accumulator accumulator = new Accumulator();
	LongStream.rangeClosed(1, n).forEach(accumulator::add);
	return accumulator.total;
}
public class Accumulator {
	public long total = 0;
	public void add(long value) { total += value; }
}


public static long sideEffectParallelSum(long n) {
	Accumulator accumulator = new Accumulator();
	LongStream.rangeClosed(1, n).parallel().forEach(accumulator::add);
	return accumulator.total;
}

结果是错误的。

这是由于多个线程在同时访问累加器，执行total += value，而这一句虽然看似简单，却不是一个原子操作

问题的根源在于，forEach中调用的方法有副作用，它会改变多个线程共享的对象的可变状态。

要避免共享可变状态，确保并行Stream得到正确的结果


并行与机器有关，无法量化问题(100万数据单线程快，101万数据并行快)。
我们至少可以提出一些定性意见，帮你决定某个特定情况下是否有必要使用并行流。
1. 如果有疑问，测量。把顺序流转成并行流轻而易举，但却不一定是好事。我们在本节中已经指出，并行流并不总是比顺序流快。
2. 留意装箱。自动装箱和拆箱操作会大大降低性能。Java8中有原始类型流（IntStream、LongStream、DoubleStream）来避免这种操作，但凡有可能都应该用这些流。
3. 有些操作本身在并行流上的性能就比顺序流差。特别是limit和findFirst等依赖于元素顺序的操作，它们在并行流上执行的代价非常大。例如，findAny会比findFirst性能好，因为它不一定要按顺序来执行。你总是可以调用unordered方法来把有序流变成无序流。那么，如果你需要流中的n个元素而不是专门要前n个的话，对无序并行流调用limit可能会比单个有序流（比如数据源是一个List）更高效。
。。unordered方法。

4. 还要考虑流的操作流水线的总计算成本。设N是要处理的元素的总数，Q是一个元素通过流水线的大致处理成本，则N*Q就是这个对成本的一个粗略的定性估计。Q值较高就意味着使用并行流时性能好的可能性比较大。
。。单个元素处理成本越高，越适合多线程。这是因为线程间通信，cpu数据转移都很费时间，所以N*Q一样的情况下，Q越大，说明元素越少，这样多线程的话，cpu间数据流动次数少，消耗小。。。和下面的重复了啊。。

5. 对于较小的数据量，选择并行流几乎从来都不是一个好的决定。并行处理少数几个元素的好处还抵不上并行化造成的额外开销。

6. 要考虑流背后的数据结构是否易于分解。例如，ArrayList的拆分效率比LinkedList高得多，因为前者用不着遍历就可以平均拆分，而后者则必须遍历。另外，用range工厂方法创建的原始类型流也可以快速分解。最后，你将在7.3节中学到，你可以自己实现Spliterator来完全掌控分解过程。
。。刚看到时，想的是ArrayList慢，毕竟LinkedList只要断开链接就行。。但是，断开连接后，依然需要new LinkedList(part_list)吧。

7. 流自身的特点，以及流水线中的中间操作修改流的方式，都可能会改变分解过程的性能。
例如，一个SIZED流可以分成大小相等的两部分，这样每个部分都可以比较高效地并行处理，但筛选操作可能丢弃的元素个数却无法预测，导致流本身的大小未知。

8. 还要考虑终端操作中合并步骤的代价是大是小（例如Collector中的combiner方法）。如果这一步代价很大，那么组合每个子流产生的部分结果所付出的代价就可能会超出通过并行流得到的性能提升。


源 				可分解性
ArrayList 		极佳
LinkedList 		差
IntStream.range 极佳
Stream.iterate 	差
HashSet 		好
TreeSet 		好


7.2
分支/合并框架的目的是以递归方式将可以并行的任务拆分成更小的任务，然后将每个子任务的结果合并起来生成整体结果。它是ExecutorService接口的一个实现，它把子任务分配给线程池（称为ForkJoinPool）中的工作线程。首先来看看如何定义任务和子任务。

要把任务提交到这个池，必须创建RecursiveTask<R>的一个子类，其中R是并行化任务（以及所有子任务）产生的结果类型，或者如果任务不返回结果，则是RecursiveAction类型（当然它可能会更新其他非局部机构）

要定义RecursiveTask，只需实现它唯一的抽象方法compute：

protected abstract R compute();
这个方法同时定义了将任务拆分成子任务的逻辑，以及无法再拆分或不方便再拆分时，生成单个子任务结果的逻辑

if (任务足够小或不可分) {
	顺序计算该任务
} else {
	将任务分成两个子任务
	递归调用本方法，拆分每个子任务，等待所有子任务完成
	合并每个子任务的结果
}

fork，分叉，分支
join，归并，合并


用分支/合并框架执行并行求和

public class ForkJoinSumCalculator
				extends java.util.concurrent.RecursiveTask<Long> {

	private final long[] numbers;	// 要求和的数组
	private final int start;		// 子任务处理的数组的起始
	private final int end;			//					终止

	// 小于这个，不再分解
	public static final long THRESHOLD = 10_000;

	// 用于创建主任务
	public ForkJoinSumCalculator(long[] numbers) {
		this(numbers, 0, numbers.length);
	}

	// 以递归方式创建子任务
	private ForkJoinSumCalculator(long[] numbers, int start, int end) {
		this.numbers = numbers;
		this.start = start;
		this.end = end;
	}

	@Override
	protected Long compute() {
		int length = end - start;
		if (length <= THRESHOLD) {	// 小于阈值，不再分治。
			return computeSequentially();
		}
		ForkJoinSumCalculator leftTask = new ForkJoinSumCalculator(numbers, start, start + length/2);
		
		// 利用另一个ForkJoinPool线程异步执行新创建的子任务
		leftTask.fork();
		ForkJoinSumCalculator rightTask = new ForkJoinSumCalculator(numbers, start + length/2, end);
		
		// 同步执行后半部分任务，可能会进一步分治。
		// 。。本线程执行这个就可以了，不需要像left一样再来一个新线程
		Long rightResult = rightTask.compute();
		
		// 读取第一个子任务的结果，如果未完成，则等待。
		Long leftResult = leftTask.join();
		return leftResult + rightResult;
	}

	private long computeSequentially() {
		long sum = 0;
		for (int i = start; i < end; i++) {{
			sum += numbers[i];
		}
		return sum;
	}
}

public static long forkJoinSum(long n) {
	long[] numbers = LongStream.rangeClosed(1, n).toArray();
	ForkJoinTask<Long> task = new ForkJoinSumCalculator(numbers);
	return new ForkJoinPool().invoke(task);
}

ForkJoinTask（RecursiveTask的父类）

在实际应用时，使用多个ForkJoinPool是没有什么意义的。正是出于这个原因，一般来说把它实例化一次，然后把实例保存在静态字段中，使之成为单例
这里创建时用了其默认的无参数构造函数，这意味着想让线程池使用JVM能够使用的所有处理器。更确切地说，该构造函数将使用Runtime.availableProcessors的返回值来决定线程池使用的线程数。请注意availableProcessors方法虽然看起来是处理器，但它实际上返回的是可用内核的数量，包括超线程生成的虚拟内核。
。。虚拟内核。。


当把ForkJoinSumCalculator任务传给ForkJoinPool时，这个任务就由池中的一个线程执行，这个线程会调用任务的compute方法。该方法会检查任务是否小到足以顺序执行，如果不够小则会把要求和的数组分成两半，分给两个新的ForkJoinSumCalculator，而它们也由ForkJoinPool安排执行。

41ms
这个性能看起来比用并行流的版本要差，但这只是因为必须先要把整个数字流都放进一个long[]，之后才能在ForkJoinSumCalculator任务中使用它。


以下是几个有效使用它的最佳做法。
1. 对一个任务调用join方法会阻塞调用方，直到该任务做出结果。因此，有必要在两个子任务的计算都开始之后再调用它。否则，你得到的版本会比原始的顺序算法更慢更复杂，因为每个子任务都必须等待另一个子任务完成才能启动。
。。fork，compute后才join。。尽量1/2划分。或者前半个小一点点。

2. 不应该在RecursiveTask内部使用ForkJoinPool的invoke方法。相反，你应该始终直接调用compute或fork方法，只有顺序代码才应该用invoke来启动并行计算。

3. 对子任务调用fork方法可以把它排进ForkJoinPool。同时对左边和右边的子任务调用它似乎很自然，但这样做的效率要比直接对其中一个调用compute低。这样做你可以为其中一个子任务重用同一线程，从而避免在线程池中多分配一个任务造成的开销。
。。2边都fork不如fork+compute

4. 调试使用分支/合并框架的并行计算可能有点棘手。特别是你平常都在你喜欢的IDE里面看栈跟踪（stack trace）来找问题，但放在分支?合并计算上就不行了，因为调用compute的线程并不是概念上的调用方，后者是调用fork的那个。

5. 和并行流一样，你不应理所当然地认为在多核处理器上使用分支/合并框架就比顺序计算快。我们已经说过，一个任务可以分解成多个独立的子任务，才能让性能在并行化时有所提升。所有这些子任务的运行时间都应该比分出新任务所花的时间长；一个惯用方法是把输入/输出放在一个子任务里，计算放在另一个里，这样计算就可以和输入/输出同时进行。此外，在比较同一算法的顺序和并行版本的性能时还有别的因素要考虑。就像任何其他Java代码一样，分支/合并框架需要“预热”或者说要执行几遍才会被JIT编译器优化。这就是为什么在测量性能之前跑几遍程序很重要，我们的测试框架就是这么做的。同时还要知道，编译器内置的优化可能会为顺序版本带来一些优势（例如执行死码分析――删去从未被使用的计算）。

。。JIT优化。

对于分支/合并拆分策略还有最后一点补充：你必须选择一个标准，来决定任务是要进一步拆分还是已小到可以顺序求值

分出大量的小任务一般来说都是一个好的选择。这是因为，理想情况下，划分并行任务时，应该让每个任务都用完全相同的时间完成，让所有的CPU内核都同样繁忙。不幸的是，实际中，每个子任务所花的时间可能天差地别，要么是因为划分策略效率低，要么是有不可预知的原因，比如磁盘访问慢，或是需要和外部服务协调执行。
。。最理想，几核就几个任务，但是由于各种原因，这种情况执行时间并不平均。所以需要多个任务来平均执行时间。

分支/合并框架工程用一种称为工作窃取（work stealing）的技术来解决这个问题。在实际应用中，这意味着这些任务差不多被平均分配到ForkJoinPool中的所有线程上

每个线程都为分配给它的任务保存一个双向链式队列，每完成一个任务，就会从队列头上取出下一个任务开始执行。

某个线程可能早早完成了分配给它的所有任务，也就是它的队列已经空了，而其他的线程还很忙。这时，这个线程并没有闲下来，而是随机选了一个别的线程，从队列的尾巴上“偷走”一个任务。
。。偷一半是不是更快？不过这样的话，需要保存任务队列中任务数量。并且需要向前遍历。

这就是为什么要划成许多小任务而不是少数几个大任务，这有助于更好地在工作线程之间平衡负载。


本节中我们分析了一个例子，你明确地指定了将数字数组拆分成多个任务的逻辑。但是，使用本章前面讲的并行流时就用不着这么做了，这就意味着，肯定有一种自动机制来为你拆分流。这种新的自动机制称为Spliterator

Spliterator是Java 8中加入的另一个新接口；这个名字代表“可分迭代器”（splitableiterator）。

Spliterator也用于遍历数据源中的元素，但它是为了并行执行而设计的。

Java 8已经为集合框架中包含的所有数据结构提供了一个默认的Spliterator实现。集合实现了Spliterator接口，接口提供了一个spliterator方法。

public interface Spliterator<T> {
	boolean tryAdvance(Consumer<? super T> action);
	Spliterator<T> trySplit();
	long estimateSize();
	int characteristics();
}

T是Spliterator遍历的元素的类型

tryAdvance方法的行为类似于普通的Iterator，因为它会按顺序一个一个使用Spliterator中的元素，并且如果还有其他元素要遍历就返回true。

trySplit是专为Spliterator接口设计的，因为它可以把一些元素划出去分给第二个Spliterator（由该方法返回），让它们两个并行处理

estimateSize方法估计还剩下多少元素要遍历，因为即使不那么确切，能快速算出来是一个值也有助于让拆分均匀一点。

将Stream拆分成多个部分的算法是一个递归过程

第一步是对第一个Spliterator调用trySplit，生成第二个Spliterator。
第二步对这两个Spliterator调用trysplit，这样总共就有了四个Spliterator。
这个框架不断对Spliterator调用trySplit直到它返回null，表明它处理的数据结构不能再分割，如第三步所示。
最后，这个递归拆分过程到第四步就终止了，这时所有的Spliterator在调用trySplit时都返回了null。

。。是所有的Spliterator，不一定是一分二的。反正一直调用trySplit直到null。

这个拆分过程也受Spliterator本身的特性影响，而特性是通过characteristics方法声明的。


Spliterator接口声明的最后一个抽象方法是characteristics，它将返回一个int，代表Spliterator本身特性集的编码

ORDERED 元素有既定的顺序（例如List），因此Spliterator在遍历和划分时也会遵循这一顺序

DISTINCT 对于任意一对遍历过的元素x和y，x.equals(y)返回false

SORTED 遍历的元素按照一个预定义的顺序排序

SIZED 该Spliterator由一个已知大小的源建立（例如Set），因此estimatedSize()返回的是准确值

NONNULL 保证遍历的元素不会为null

IMMUTABLE
Spliterator的数据源不能修改。这意味着在遍历时不能添加、删除或修改任何元素

CONCURRENT
该Spliterator的数据源可以被其他线程同时修改而无需同步

SUBSIZED 该Spliterator和所有从它拆分出来的Spliterator都是SIZED


157
一个计算string中多少个单词的例子。

public int countWordsIteratively(String s) {
	int counter = 0;
	boolean lastSpace = true;
	for (char c : s.toCharArray()) {
		if (Character.isWhitespace(c)) {
			lastSpace = true;
		} else {
		if (lastSpace) counter++;
			lastSpace = false;
		}
	}
	return counter;
}


Stream<Character> stream = IntStream.range(0, SENTENCE.length())
						.mapToObj(SENTENCE::charAt);

class WordCounter {
	private final int counter;
	private final boolean lastSpace;
	public WordCounter(int counter, boolean lastSpace) {
		this.counter = counter;
		this.lastSpace = lastSpace;
	}
	public WordCounter accumulate(Character c) {
		if (Character.isWhitespace(c)) {
			return lastSpace ? this : new WordCounter(counter, true);
		} else {
			return lastSpace ?
						new WordCounter(counter + 1, false) : this;
		}
	}
	public WordCounter combine(WordCounter wordCounter) {
		return new WordCounter(counter + wordCounter.counter,
											wordCounter.lastSpace);
	}
	public int getCounter() {
		return counter;
	}
}

private int countWords(Stream<Character> stream) {
	WordCounter wordCounter = stream.reduce(new WordCounter(0, true),
							WordCounter::accumulate,
							WordCounter::combine);
	return wordCounter.getCounter();
}


Stream<Character> stream = IntStream.range(0, SENTENCE.length())
										.mapToObj(SENTENCE::charAt);
System.out.println("Found " + countWords(stream) + " words");


System.out.println("Found " + countWords(stream.parallel()) + " words");
parallel的结果有问题。
问题的根源并不难找。因为原始的String在任意位置拆分，所以有时一个词会被分为两个词，然后数了两次。这就说明，拆分流会影响结果，而把顺序流换成并行流就可能使结果出错。

如何解决这个问题呢？解决方案就是要确保String不是在随机位置拆开的，而只能在词尾拆开。要做到这一点，你必须为Character实现一个Spliterator，


class WordCounterSpliterator implements Spliterator<Character> {
	private final String string;
	private int currentChar = 0;
	public WordCounterSpliterator(String string) {
		this.string = string;
	}
	@Override
	public boolean tryAdvance(Consumer<? super Character> action) {
		action.accept(string.charAt(currentChar++));
		return currentChar < string.length();
	}
	@Override
	public Spliterator<Character> trySplit() {
		int currentSize = string.length() - currentChar;
		if (currentSize < 10) {
		return null;
		}
		
		// 从中间开始，找到第一个空白，然后拆分。
		for (int splitPos = currentSize / 2 + currentChar;
							splitPos < string.length(); splitPos++) {
			if (Character.isWhitespace(string.charAt(splitPos))) {
				Spliterator<Character> spliterator = new WordCounterSpliterator(string.substring(currentChar, splitPos));
				currentChar = splitPos;
				return spliterator;
			}
		}
		return null;
	}
	@Override
	public long estimateSize() {
		return string.length() - currentChar;
	}
	@Override
	public int characteristics() {
		return ORDERED + SIZED + SUBSIZED + NONNULL + IMMUTABLE;
	}
}

Spliterator<Character> spliterator = new WordCounterSpliterator(SENTENCE);
Stream<Character> stream = StreamSupport.stream(spliterator, true);
System.out.println("Found " + countWords(stream) + " words");

Spliterator还有最后一个值得注意的功能，就是可以在第一次遍历、第一次拆分或第一次查询估计大小时绑定元素的数据源，而不是在创建时就绑定。这种情况下，它称为延迟绑定（late-binding）的Spliterator。
我们专门用附录C来展示如何开发一个工具类来利用这个功能在同一个流上执行多个操作。



164
chapter 8
重构、测试和调试

Java 8的新特性也可以帮助提升代码的可读性：
? 使用Java 8，你可以减少冗长的代码，让代码更易于理解
? 通过方法引用和Stream API，你的代码会变得更直观

这里我们会介绍三种简单的重构，利用Lambda表达式、方法引用以及Stream改善程序代码的可读性：
? 重构代码，用Lambda表达式取代匿名类
? 用方法引用重构Lambda表达式
? 用Stream API重构命令式的数据处理


从匿名类到Lambda 表达式的转换
将实现单一抽象方法的匿名类转换为Lambda表达式。
Runnable r1 = new Runnable(){
	public void run(){
		System.out.println("Hello");
	}
};

Runnable r2 = () -> System.out.println("Hello");

某些情况下，将匿名类转换为Lambda表达式可能是一个比较复杂的过程。 
首先，匿名类和Lambda表达式中的this和super的含义是不同的。在匿名类中，this代表的是类自身，但是在Lambda中，它代表的是包含类。

其次，匿名类可以屏蔽包含类的变量，而Lambda表达式不能（它们会导致编译错误）
int a = 10;
Runnable r1 = () -> {
	int a = 2;			// compiler error
	System.out.println(a);
};

最后，在涉及重载的上下文里，将匿名类转换为Lambda表达式可能导致最终的代码更加晦涩。
实际上，匿名类的类型是在初始化时确定的，而Lambda的类型取决于它的上下文。
假设你用与Runnable同样的签名声明了一个函数接口，我们称之为Task

interface Task{
	public void execute();
}
public static void doSomething(Runnable r){ r.run(); }
public static void doSomething(Task a){ a.execute(); }
。。就是2个方法，一个调用Runnable，一个调Task。

传递一个匿名类实现的Task，不会碰到任何问题：
doSomething(new Task() {
	public void execute() {
		System.out.println("Danger danger!!");
	}
});

但是将这种匿名类转换为Lambda表达式时，就导致了一种晦涩的方法调用，因为Runnable和Task都是合法的目标类型：
doSomething(() -> System.out.println("Danger danger!!"));

你可以对Task尝试使用显式的类型转换来解决这种模棱两可的情况：
doSomething((Task)() -> System.out.println("Danger danger!!"));


166
Lambda表达式非常适用于需要传递代码片段的场景。不过，为了改善代码的可读性，也请尽量使用方法引用。因为方法名往往能更直观地表达代码的意图
Map<CaloricLevel, List<Dish>> dishesByCaloricLevel =
	menu.stream()
		.collect(
		groupingBy(dish -> {
			if (dish.getCalories() <= 400) return CaloricLevel.DIET;
			else if (dish.getCalories() <= 700) return CaloricLevel.NORMAL;
			else return CaloricLevel.FAT;
		}));
		
可以将Lambda抽取成一个方法。
Map<CaloricLevel, List<Dish>> dishesByCaloricLevel = menu.stream().collect(groupingBy(Dish::getCaloricLevel));

public class Dish{
	…
	public CaloricLevel getCaloricLevel(){
		if (this.getCalories() <= 400) return CaloricLevel.DIET;
		else if (this.getCalories() <= 700) return CaloricLevel.NORMAL;
		else return CaloricLevel.FAT;
	}
}

除此之外，我们还应该尽量考虑使用静态辅助方法，比如comparing、maxBy。
inventory.sort((Apple a1, Apple a2) -> a1.getWeight().compareTo(a2.getWeight()));

inventory.sort(comparing(Apple::getWeight));
。。上面的需要自己写lambda，下面的更加清晰。

此外，很多通用的归约操作，比如sum、maximum，都有内建的辅助方法可以和方法引用结合使用。

int totalCalories = menu.stream().map(Dish::getCalories).reduce(0, (c1, c2) -> c1 + c2);

int totalCalories = menu.stream().collect(summingInt(Dish::getCalories));


我们建议你将所有使用迭代器这种数据处理模式处理集合的代码都转换成Stream API的方式。为什么呢？Stream API能更清晰地表达数据处理管道的意图。除此之外，通过短路和延迟载入以及利用第7章介绍的现代计算机的多核架构，我们可以对Stream进行优化。


你可以依照这两种模式重构代码，利用Lambda表达式带来的灵活性，它们分别是：有条件的延迟执行和环绕执行

有条件的延迟执行
我们经常看到这样的代码，控制语句被混杂在业务逻辑代码之中。典型的情况包括进行安全性检查以及日志输出。比如，下面的这段代码，它使用了Java语言内置的Logger类：
if (logger.isLoggable(Log.FINER)){
	logger.finer("Problem: " + generateDiagnostic());
}

存在的问题：
日志器的状态（它支持哪些日志等级）通过isLoggable方法暴露给了客户端代码。
为什么要在每次输出一条日志之前都去查询日志器对象的状态？这只能搞砸你的代码。

更好的方案是使用log方法，该方法在输出日志消息之前，会在内部检查日志对象是否已经设置为恰当的日志等级：

logger.log(Level.FINER, "Problem: " + generateDiagnostic());
不再需要在代码中插入那些条件判断，与此同时日志器的状态也不再被暴露出去

依旧存在一个问题。日志消息的输出与否每次都需要判断，即使你已经传递了参数，不开启日志。

这就是Lambda表达式可以施展拳脚的地方。你需要做的仅仅是延迟消息构造，如此一来，日志就只会在某些特定的情况下才开启

public void log(Level level, Supplier<String> msgSupplier){
	if(logger.isLoggable(level)){
		log(level, msgSupplier.get());
	}
}

logger.log(Level.FINER, () -> "Problem: " + generateDiagnostic());

如果你发现你需要频繁地从客户端代码去查询一个对象的状态（比如前文例子中的日志器的状态），只是为了传递参数、调用该对象的一个方法（比如输出一条日志），那么可以考虑实现一个新的方法，以Lambda或者方法表达式作为参数，新方法在检查完该对象的状态之后才调用原来的方法。你的代码会因此而变得更易读（结构更清晰），封装性更好（对象的状态也不会暴露给客户端代码了）。

。。lambda。变成Supplier是在编译时，所以运行时。也不是。不管怎么弄，运行时new出来的对象吧。这不会更慢吗？


环绕执行
如果你发现虽然你的业务代码千差万别，但是它们拥有同样的准备和清理阶段，这时，你完全可以将这部分代码用Lambda实现。这种方式的好处是可以重用准备和清理阶段的逻辑，减少重复冗余的代码

String oneLine = processFile((BufferedReader b) -> b.readLine());
String twoLines = processFile((BufferedReader b) -> b.readLine() + b.readLine());

public static String processFile(BufferedReaderProcessor p) throws IOException {
	try(BufferedReader br = new BufferedReader(new FileReader("java8inaction/
	chap8/data.txt"))){
		return p.process(br);
	}
}

public interface BufferedReaderProcessor{
	String process(BufferedReader b) throws IOException;
}

。。这是把逻辑代码提取出来，只剩下固定的资源读取，资源关闭。逻辑代码用lambda实现。
。。以前应该是把固定的资源读取和关闭提取出来变成一个方法，然后每个逻辑代码之前之后调用一次。(没有try-with-resources的时候。)


8.2 使用Lambda 重构面向对象的设计模式

策略模式代表了解决一类算法的通用解决方案，你可以在运行时选择使用哪种方案

策略模式包含三部分内容
一个代表某个算法的接口（它是策略模式的接口）。
一个或多个该接口的具体实现，它们代表了算法的多种实现（比如，实体类ConcreteStrategyA或者ConcreteStrategyB）。
一个或多个使用策略对象的客户。

验证输入的内容是否根据标准进行了恰当的格式化（比如只包含小写字母或数字）

定义接口
public interface ValidationStrategy {
	boolean execute(String s);
}

定义实现
public class IsAllLowerCase implements ValidationStrategy {
	public boolean execute(String s){
		return s.matches("[a-z]+");
	}
}
public class IsNumeric implements ValidationStrategy {
	public boolean execute(String s){
		return s.matches("\\d+");
	}
}

public class Validator{
	private final ValidationStrategy strategy;
	public Validator(ValidationStrategy v){
		this.strategy = v;
	}
	public boolean validate(String s){
		return strategy.execute(s);
	}
}

Validator numericValidator = new Validator(new IsNumeric());
boolean b1 = numericValidator.validate("aaaa");
Validator lowerCaseValidator = new Validator(new IsAllLowerCase ());
boolean b2 = lowerCaseValidator.validate("bbbb");

意识到ValidationStrategy是一个函数接口

Validator numericValidator = new Validator((String s) -> s.matches("[a-z]+"));
boolean b1 = numericValidator.validate("aaaa");
Validator lowerCaseValidator = new Validator((String s) -> s.matches("\\d+"));
boolean b2 = lowerCaseValidator.validate("bbbb");

Lambda表达式避免了采用策略设计模式时僵化的模板代码


模板方法
希望使用这个算法，但是需要对其中的某些行进行改进，才能达到希望的效果

abstract class OnlineBanking {
	public void processCustomer(int id){
		Customer c = Database.getCustomerWithId(id);
		makeCustomerHappy(c);
	}
	abstract void makeCustomerHappy(Customer c);
}

processCustomer方法搭建了在线银行算法的框架：获取客户提供的ID，然后提供服务让用户满意。不同的支行可以通过继承OnlineBanking类，对该方法提供差异化的实现。

。。策略模式是用户-策略-实现接口。策略和实现没有父子类关系。策略包含了实现。
。。模板方法是用户-方法接口。


向processCustomer方法引入了第二个参数，它是一个Consumer<Customer>类型的参数，与前文定义的makeCustomerHappy的特征保持一致：
public void processCustomer(int id, Consumer<Customer> makeCustomerHappy){
	Customer c = Database.getCustomerWithId(id);
	makeCustomerHappy.accept(c);
}

new OnlineBankingLambda().processCustomer(1337, (Customer c) -> System.out.println("Hello " + c.getName());

。。就是把方法换成lambda，这样就不需要继承重写方法，而是直接把lambda发送进去。


观察者模式是一种比较常见的方案，某些事件发生时（比如状态转变），如果一个对象（通常我们称之为主题）需要自动地通知其他多个对象（称为观察者），就会采用该方案。

当接收的新闻中包含他们感兴趣的关键字时，能得到特别通知。

首先，你需要一个观察者接口，它将不同的观察者聚合在一起。它仅有一个名为notify的方法，一旦接收到一条新的新闻，该方法就会被调用：
interface Observer {
	void notify(String tweet);
}

现在，你可以声明不同的观察者（比如，这里是三家不同的报纸机构），依据新闻中不同的关键字分别定义不同的行为：
class NYTimes implements Observer{
	public void notify(String tweet) {
		if(tweet != null && tweet.contains("money")){
			System.out.println("Breaking news in NY! " + tweet);
		}
	}
}
class Guardian implements Observer{
	public void notify(String tweet) {
		if(tweet != null && tweet.contains("queen")){
			System.out.println("Yet another news in London... " + tweet);
		}
	}
}
class LeMonde implements Observer{
	public void notify(String tweet) {
		if(tweet != null && tweet.contains("wine")){
			System.out.println("Today cheese, wine and news! " + tweet);
		}
	}
}

最重要的部分：Subject！让我们为它定义一个接口：
interface Subject{
	void registerObserver(Observer o);
	void notifyObservers(String tweet);
}

class Feed implements Subject{
	private final List<Observer> observers = new ArrayList<>();
	public void registerObserver(Observer o) {
		this.observers.add(o);
	}
	public void notifyObservers(String tweet) {
		observers.forEach(o -> o.notify(tweet));
	}
}

Feed f = new Feed();
f.registerObserver(new NYTimes());
f.registerObserver(new Guardian());
f.registerObserver(new LeMonde());
f.notifyObservers("The queen said her favourite book is Java 8 in Action!");

。。观察者注册中心接收信息，然后每个已注册的观察者都会处理这条信息。

Observer接口的所有实现类都提供了一个方法：notify

f.registerObserver((String tweet) -> {
	if(tweet != null && tweet.contains("money")){
		System.out.println("Breaking news in NY! " + tweet);
	}
});
f.registerObserver((String tweet) -> {
	if(tweet != null && tweet.contains("queen")){
		System.out.println("Yet another news in London... " + tweet);
	}
});

观察者的逻辑有可能十分复杂，它们可能还持有状态，抑或定义了多个方法，诸如此类。在这些情形下，你还是应该继续使用类的方式。


责任链模式是一种创建处理对象序列（比如操作序列）的通用方案。一个处理对象可能需要在完成一些工作之后，将结果传递给另一个对象，这个对象接着做一些工作，再转交给下一个处理对象，以此类推。

这种模式是通过定义一个代表处理对象的抽象类来实现的，在抽象类中会定义一个字段来记录后续对象。一旦对象完成它的工作，处理对象就会将它的工作转交给它的后继

public abstract class ProcessingObject<T> {
	protected ProcessingObject<T> successor;
	public void setSuccessor(ProcessingObject<T> successor){
		this.successor = successor;
	}
	public T handle(T input){
		T r = handleWork(input);
		if(successor != null){
			return successor.handle(r);
		}
		return r;
	}
	abstract protected T handleWork(T input);
}


public class HeaderTextProcessing extends ProcessingObject<String> {
	public String handleWork(String text){
		return "From Raoul, Mario and Alan: " + text;
	}
}
public class SpellCheckerProcessing extends ProcessingObject<String> {
	public String handleWork(String text){
		return text.replaceAll("labda", "lambda");
	}
}

ProcessingObject<String> p1 = new HeaderTextProcessing();
ProcessingObject<String> p2 = new SpellCheckerProcessing();
p1.setSuccessor(p2);
String result = p1.handle("Aren't labdas really sexy?!!");
System.out.println(result);


UnaryOperator<String> headerProcessing = (String text) -> "From Raoul, Mario and Alan: " + text;
UnaryOperator<String> spellCheckerProcessing = (String text) -> text.replaceAll("labda", "lambda");
Function<String, String> pipeline = headerProcessing.andThen(spellCheckerProcessing);
String result = pipeline.apply("Aren't labdas really sexy?!!");

。。直接全部lambda。。andThen



使用工厂模式，你无需向客户暴露实例化的逻辑就能完成对象的创建

public class ProductFactory {
	public static Product createProduct(String name){
		switch(name){
			case "loan": return new Loan();
			case "stock": return new Stock();
			case "bond": return new Bond();
			default: throw new RuntimeException("No such product " + name);
		}
	}
}

贷款（Loan）、股票（Stock）和债券（Bond）都是产品（Product）的子类。

final static Map<String, Supplier<Product>> map = new HashMap<>();
static {
	map.put("loan", Loan::new);
	map.put("stock", Stock::new);
	map.put("bond", Bond::new);
}

public static Product createProduct(String name){
	Supplier<Product> p = map.get(name);
	if(p != null) return p.get();
	throw new IllegalArgumentException("No such product " + name);
}


但是，如果工厂方法createProduct需要接收多个传递给产品构造方法的参数，这种方式的扩展性不是很好。你不得不提供不同的函数接口，

public interface TriFunction<T, U, V, R>{
	R apply(T t, U u, V v);
}

Map<String, TriFunction<Integer, Integer, String, Product>> map = new HashMap<>();



Lambda并无函数名（毕竟它们都是匿名函数），因此要对你代码中的Lambda函数进行测试实际上比较困难，因为你无法通过函数名的方式调用它们。

有些时候，你可以借助某个字段访问Lambda函数，这种情况，你可以利用这些字段，通过它们对封装在Lambda函数内的逻辑进行测试

比如，我们假设你在Point类中添加了静态字段compareByXAndThenY，通过该字段，使用方法引用你可以访问Comparator对象：
public class Point{
	public final static Comparator<Point> compareByXAndThenY = 
		comparing(Point::getX).thenComparing(Point::getY);
		
	…
}

@Test
public void testComparingTwoPoints() throws Exception {
	Point p1 = new Point(10, 15);
	Point p2 = new Point(10, 20);
	int result = Point.compareByXAndThenY.compare(p1 , p2);
	assertEquals(-1, result);
}

但是Lambda的初衷是将一部分逻辑封装起来给另一个方法使用。从这个角度出发，你不应该将Lambda表达式声明为public，它们仅是具体的实现细节。相反，我们需要对使用Lambda表达式的方法进行测试。比如下面这个方法moveAllPointsRightBy：

public static List<Point> moveAllPointsRightBy(List<Point> points, int x){
	return points.stream()
			.map(p -> new Point(p.getX() + x, p.getY()))
			.collect(toList());
}

我们没必要对Lambda表达式p -> new Point(p.getX() + x,p.getY())进行测试，它只是moveAllPointsRightBy内部的实现细节。我们更应该关注的是方法moveAllPointsRightBy的行为：

@Test
public void testMoveAllPointsRightBy() throws Exception{
	List<Point> points = Arrays.asList(new Point(5, 5), new Point(10, 5));
	List<Point> expectedPoints = Arrays.asList(new Point(15, 5), new Point(20, 5));
	List<Point> newPoints = Point.moveAllPointsRightBy(points, 10);
	assertEquals(expectedPoints, newPoints);
}

上面的单元测试中，Point类恰当地实现equals方法非常重要，否则该测试的结果就取决于Object类的默认实现。


接受函数作为参数的方法或者返回一个函数的方法（所谓的“高阶函数”，higher-order function，我们在第14章会深入展开介绍）更难测试。如果一个方法接受Lambda表达式作为参数，你可以采用的一个方案是使用不同的Lambda表达式对它进行测试。比如，你可以使用不同的谓词对第2章中创建的filter方法进行测试。

@Test
public void testFilter() throws Exception{
	List<Integer> numbers = Arrays.asList(1, 2, 3, 4);
	List<Integer> even = filter(numbers, i -> i % 2 == 0);
	List<Integer> smallerThanThree = filter(numbers, i -> i < 3);
	assertEquals(Arrays.asList(2, 4), even);
	assertEquals(Arrays.asList(1, 2), smallerThanThree);
}

如果被测试方法的返回值是另一个方法，该如何处理呢？你可以仿照我们之前处理Comparator的方法，把它当成一个函数接口，对它的功能进行测试。


两大老式武器，分别是：
? 查看栈跟踪
? 输出日志

不幸的是，由于Lambda表达式没有名字，它的栈跟踪可能很难分析

我们刻意地引入了一些错误：
import java.util.*;
public class Debugging{
	public static void main(String[] args) {
		List<Point> points = Arrays.asList(new Point(12, 2), null);
		points.stream().map(p -> p.getX()).forEach(System.out::println);
	}
}

会产生下面的栈跟踪：
Exception in thread "main" java.lang.NullPointerException
	at Debugging.lambda$main$0(Debugging.java:6)
	at Debugging$$Lambda$5/284720968.apply(Unknown Source)
	at java.util.stream.ReferencePipeline$3$1.accept(ReferencePipeline
	.java:193)
	at java.util.Spliterators$ArraySpliterator.forEachRemaining(Spliterators
	.java:948)

n$0(D。。$0的含义是什么。

因为Points列表的第二个元素是空（null）。这时你的程序实际是在试图处理一个空引用。由于Stream流水线发生了错误，构成Stream流水线的整个方法调用序列都暴露在你面前了

at Debugging.lambda$main$0(Debugging.java:6)
at Debugging$$Lambda$5/284720968.apply(Unknown Source)
这些表示错误发生在Lambda表达式内部。由于Lambda表达式没有名字，所以编译器只能为它们指定一个名字。这个例子中，它的名字是lambda$main$0，看起来非常不直观。如果你使用了大量的类，其中又包含多个Lambda表达式，这就成了一个非常头痛的问题。

即使你使用了方法引用，还是有可能出现栈无法显示你使用的方法名的情况。将之前的Lambda表达式p-> p.getX()替换为方法引用reference Point::getX也会产生难于分析的栈跟踪：

points.stream().map(Point::getX).forEach(System.out::println);

Exception in thread "main" java.lang.NullPointerException
	at Debugging$$Lambda$5/284720968.apply(Unknown Source)
	at java.util.stream.ReferencePipeline$3$1.accept(ReferencePipeline
	.java:193)


如果方法引用指向的是同一个类中声明的方法，那么它的名称是可以在栈跟踪中显示的。比如，下面这个例子：
import java.util.*;
public class Debugging{
	public static void main(String[] args) {
		List<Integer> numbers = Arrays.asList(1, 2, 3);
		numbers.stream()
				.map(Debugging::divideByZero)
				.forEach(System.out::println);
	}
	public static int divideByZero(int n){
		return n / 0;
	}
}

方法divideByZero在栈跟踪中就正确地显示了：
Exception in thread "main" java.lang.ArithmeticException: / by zero
	at Debugging.divideByZero(Debugging.java:10)
	at Debugging$$Lambda$1/999966131.apply(Unknown Source)
	at java.util.stream.ReferencePipeline$3$1.accept(ReferencePipeline
	.java:193)


涉及Lambda表达式的栈跟踪可能非常难理解。这是Java编译器未来版本可以改进的一个方面。


假设你试图对流操作中的流水线进行调试，该从何入手呢？你可以像下面的例子那样，使用forEach将流操作的结果日志输出到屏幕上或者记录到日志文件中：
List<Integer> numbers = Arrays.asList(2, 3, 4, 5);

numbers.stream()
	.map(x -> x + 17)
	.filter(x -> x % 2 == 0)
	.limit(3)
	.forEach(System.out::println);
	
这段代码的输出如下：
20
22

一旦调用forEach，整个流就会恢复运行。到底哪种方式能更有效地帮助我们理解Stream流水线中的每个操作（比如map、filter、limit）产生的输出？

这就是流操作方法peek大显身手的时候。peek的设计初衷就是在流的每个元素恢复运行之前，插入执行一个动作。但是它不像forEach那样恢复整个流的运行，而是在一个元素上完成操作之后，它只会将操作顺承到流水线中的下一个操作。

List<Integer> result =
numbers.stream()
	.peek(x -> System.out.println("from stream: " + x))
	.map(x -> x + 17)
	.peek(x -> System.out.println("after map: " + x))
	.filter(x -> x % 2 == 0)
	.peek(x -> System.out.println("after filter: " + x))
	.limit(3)
	.peek(x -> System.out.println("after limit: " + x))
	.collect(toList());

通过peek操作我们能清楚地了解流水线操作中每一步的输出结果：
from stream: 2
after map: 19

from stream: 3
after map: 20
after filter: 20
after limit: 20

from stream: 4
after map: 21

from stream: 5
after map: 22
after filter: 22
after limit: 22


。。流究竟是一组元素的某个动作全部执行完后，执行下一个动作，还是一个元素的动作顺序执行？
。。应该是一个元素吧。不然limit的短路无法实现的。
。。而且peek也是这样的输出。
。。不过在数据合并(终端操作)的时候会等待数据吧。
。。anyMatch、allMatch和noneMatch这三个操作都用到了我们所谓的短路



185
chapter 9
default function

一旦类库的设计者需要更新接口，向其中加入新的方法，这种方式就会出现问题。现实情况是，现存的实体类往往不在接口设计者的控制范围之内，这些实体类为了适配新的接口约定也需要进行修改。

List接口上的sort方法，像Guava和Apache Commons这样的框架现在都需要修改实现了List接口的所有类，为其添加sort方法的实现。

Java 8为了解决这一问题引入了一种新的机制。Java 8中的接口现在支持在声明方法的同时提供实现
通过两种方式可以完成这种操作。
其一，Java 8允许在接口内声明静态方法。
其二，Java8引入了一个新功能，叫默认方法，通过默认方法你可以指定接口方法的默认实现。

List接口中的sort，以及Collection接口中的stream。是默认方法

List接口中的sort方法
default void sort(Comparator<? super E> c){
	Collections.sort(this, c);
}

List<Integer> numbers = Arrays.asList(3, 5, 1, 2, 6);
numbers.sort(Comparator.naturalOrder());

Comparator.naturalOrder方法Comparator接口的一个全新的静态方法


Collection中的stream方法的定义
default Stream<E> stream() {
	return StreamSupport.stream(spliterator(), false);
}

。。实际上接口-抽象类-实体类。这种结构也能解决接口增加方法问题。但是接口和抽象类有什么区别，划分出接口的意义是什么。
。。。下面有，多继承，，，，一个抽象类可以通过实例变量（字段）保存一个通用状态，而接口是不能有实例变量的。。。。？？？


同时定义接口以及工具辅助类（companion class）是Java语言常用的一种模式。

Collections就是处理Collection对象的辅助类。由于静态方法可以存在于接口内部，你代码中的这些辅助类就没有了存在的必要，你可以把这些静态方法转移到接口内部。

。。之前的更新，更多的是放在工具类中，来变相扩展对象功能。

函数式接口只包含一个抽象方法，默认方法是种非抽象方法

抽象类和抽象接口之间的区别
首先，一个类只能继承一个抽象类，但是一个类可以实现多个接口。
其次，一个抽象类可以通过实例变量（字段）保存一个通用状态，而接口是不能有实例变量的。
。。第二点是什么意思。。抽象类也不能new啊。


这段在190，txt里copy的时候，有些错位了。
不同类型的兼容性：二进制、源代码和函数行为
变更对Java程序的影响大体可以分成三种类型的兼容性，分别是：二进制级的兼容、源代
码级的兼容，以及函数行为的兼容。①刚才我们看到，向接口添加新方法是二进制级的兼容，
但最终编译实现接口的类时却会发生编译错误。了解不同类型兼容性的特性是非常有益的，下
面我们会深入介绍这部分的内容。

二进制级的兼容性表示现有的二进制执行文件能无缝持续链接（包括验证、准备和解析）
和运行。比如，为接口添加一个方法就是二进制级的兼容，这种方式下，如果新添加的方法不
被调用，接口已经实现的方法可以继续运行，不会出现错误。

简单地说，源代码级的兼容性表示引入变化之后，现有的程序依然能成功编译通过。比如，
向接口添加新的方法就不是源码级的兼容，因为遗留代码并没有实现新引入的方法，所以它们
无法顺利通过编译。

最后，函数行为的兼容性表示变更发生之后，程序接受同样的输入能得到同样的结果。比
如，为接口添加新的方法就是函数行为兼容的，因为新添加的方法在程序中并未被调用（抑或
该接口在实现中被覆盖了）。

。。接口+default方法后，实现类不需要重新编译吧。
。。在更新接口的情况下，这3种兼容应该是，二进制兼容==实现类不需要重新编译就能运行。源代码兼容==需要重新编译。函数行为兼容==需要重新写代码。。？？？不是。
。。default应该是二进制兼容。

。。二进制兼容：接口增加一个方法，实现类不增加实现。只要不调用新增加的方法，就不会报错。。。这里只是替换class文件。
。。源代码兼容：做出修改以后，能整个工程编译通过。
。。函数行为兼容：这个就是程序员的能力了。是一种代码优化。



192
使用默认方法的两种用例：可选方法和行为的多继承。

Iterator接口定义了hasNext、next，还定义了remove方法，remove方法常被忽略。因此，实现Interator接口的类通常会为remove方法放置一个空的实现，这些都是些毫无用处的模板代码。
为remove提供一个默认的实现，这样实体类就无需在自己的实现中显式地提供一个空方法
interface Iterator<T> {
	boolean hasNext();
	T next();
	default void remove() {
		throw new UnsupportedOperationException();
	}
}

通过这种方式，你可以减少无效的模板代码。


行为的多继承。这是一种让类从多个来源重用代码的能力，
。。接口可以继承多个，每个接口可以通过default存在行为。变相的多继承。。
。。这。。违背了当初单继承啊。。。


继承不应该成为你一谈到代码复用就试图倚靠的万精油。比如，从一个拥有100个方法及字段的类进行继承就不是个好主意，因为这其实会引入不必要的复杂性
你完全可以使用代理有效地规避这种窘境，即创建一个方法通过该类的成员变量直接调用该类的方法
。。新建一个类封装巨大类作为属性，然后新类只开放需要的接口。

这就是为什么有的时候我们发现有些类被刻意地声明为final类型：声明为final的类不能被其他的类继承，避免发生这样的反模式，防止核心代码的功能被污染。
有的时候声明为final的类都会有其不同的原因，比如，String类被声明为final，因为我们不希望有人对这样的核心功能产生干扰。
。。string的原因不是和上面一样吗，都是为了防止核心代码被污染/干扰。

这种思想同样也适用于使用默认方法的接口。通过精简的接口，你能获得最有效的组合，因为你可以只选择你需要的实现。
。。但是接口无法把巨大类保存成属性啊。。。


菱形继承
public interface A {
	default void hello() {
		System.out.println("Hello from A");
	}
}
public interface B extends A {
	default void hello() {
		System.out.println("Hello from B");
	}
}
public class C implements B, A {
	public static void main(String... args) {
		new C().hello();
	}
}

如果一个类使用相同的函数签名从多个地方（比如另一个类或接口）继承了方法，通过三条规则可以进行判断。
(1) 类中的方法优先级最高。类或父类中声明的方法的优先级高于任何声明为默认方法的优先级。
。。类中方法优先于default。必须是类中override的，类继承而来的不算。继承来的算是父类/接口的。如果还是继承来的，那么继续向上。
(2) 如果无法依据第一条进行判断，那么子接口的优先级更高：函数签名相同时，优先选择拥有最具体实现的默认方法的接口，即如果B继承了A，那么B就比A更加具体。
。。提供相同default的多个接口中最底层/最子类/最具体实现的优先。。。而且得先确认，所有的方法都是在一棵树上的，如果有2棵继承树，那么这里肯定没有办法的。只能3.
(3) 最后，如果还是无法判断，继承了多个接口的类必须通过显式覆盖和调用期望的方法，显式地选择使用哪一个默认方法的实现。
。。程序员必须自己选择。

public class D implements A{ }

public class C extends D implements B, A {
	public static void main(String... args) {
		new C().hello();
	}
}
D没有override，所以还是A中的default，A和B中选择B中的实现。B的更具体。

如果D是
public abstract class D implements A {
	public abstract void hello();
}
那么C必须自己实现hello。


public interface A {
	void hello() {
		System.out.println("Hello from A");
	}
}
public interface B {
	void hello() {
		System.out.println("Hello from B");
	}
}
public class C implements B, A { }
此时，compiler无法得知哪个接口是最具体实现，所以compile error。Error: class C inherits unrelated defaults for hello() from types B and A.

只能显式地决定你希望在C中使用哪一个方法

Java8中引入了一种新的语法X.super.m(…)，其中X是你希望调用的m方法所在的父接口。

希望C使用来自于B的默认方法
public class C implements B, A {
	void hello(){
		B.super.hello();
	}
}
。。B.hello不行吗。。


public interface A{
default void hello(){
	System.out.println("Hello from A");
}
}
public interface B extends A { }
public interface C extends A { }
public class D implements B, C {
	public static void main(String... args) {
		new D().hello();
	}
}
输出“Hello from A”。

如果B中也提供了一个默认的hello方法，根据规则(2)，会选择B中声明的默认方法

在C接口中添加一个抽象的hello方法（这次添加的不是一个默认方法）
public interface C extends A {
	void hello();
}
这个新添加到C接口中的抽象方法hello比由接口A继承而来的hello方法拥有更高的优先级，因为C接口更加具体。因此，类D现在需要为hello显式地添加实现，否则该程序无法通过编译。


202
chapter 10
用Optional取代null

使用null会带来理论和实际操作上的种种问题。

? 它是错误之源。
NullPointerException是目前Java程序开发中最典型的异常。

? 它会使你的代码膨胀。
它让你的代码充斥着深度嵌套的null检查，代码的可读性糟糕透顶。

? 它自身是毫无意义的。
null自身没有任何的语义，尤其是，它代表的是在静态类型语言中以一种错误的方式对缺失变量值的建模。

? 它破坏了Java的哲学。
Java一直试图避免让程序员意识到指针的存在，唯一的例外是：null指针。

? 它在Java的类型系统上开了个口子。
null并不属于任何类型，这意味着它可以被赋值给任意引用类型的变量。这会导致问题，原因是当这个变量被传递到系统中的另一个部分后，你将无法获知这个null变量最初的赋值到底是什么类型。


java.util.Optional<T>

变量存在时，Optional类只是对类简单封装。变量不存在时，缺失的值会被建模成一个“空”的Optional对象，由方法Optional.empty()返回。Optional.empty()方法是一个静态工厂方法，它返回Optional类的特定单一实例

Optional<T> 代表变量可能有可能没有
T 代表变量必然有。

在你的代码中始终如一地使用Optional，能非常清晰地界定出变量值的缺失是结构上的问题，还是你算法上的缺陷，抑或是你数据中的问题。
。。出现空指针，那么就要确定，这个属性确实可以null的话，就说明结构上问题，需要转为Optional。。。如果这个属性不可能是null，那么说明数据出现问题。

引入Optional类的意图并非要消除每一个null引用。与此相反，它的目标是帮助你更好地设计出普适的API，让程序员看到方法签名，就能了解它是否接受一个Optional的值。



1. 声明一个空的Optional
通过静态工厂方法Optional.empty，创建一个空的Optional对象：
Optional<Car> optCar = Optional.empty();

2. 依据一个非空值创建Optional
静态工厂方法Optional.of，依据一个非空值创建一个Optional对象：
Optional<Car> optCar = Optional.of(car);
如果car是一个null，这段代码会立即抛出一个NullPointerException

3. 可接受null的Optional
静态工厂方法Optional.ofNullable，你可以创建一个允许null值的Optional对象：
Optional<Car> optCar = Optional.ofNullable(car);
如果car是null，那么得到的Optional对象就是个空对象。


使用map 从Optional 对象中提取和转换值
Optional<Insurance> optInsurance = Optional.ofNullable(insurance);
Optional<String> name = optInsurance.map(Insurance::getName);

从概念上，这与我们在第4章和第5章中看到的流的map方法相差无几。map操作会将提供的函数应用于流的每个元素。你可以把Optional对象看成一种特殊的集合数据，它至多包含一个元素。如果Optional包含一个值，那函数就将该值作为参数传递给map，对该值进行转换。如果Optional为空，就什么也不做

使用flatMap 链接Optional 对象

Optional<Person> optPerson = Optional.of(person);
Optional<String> name =
		optPerson.map(Person::getCar)
		.map(Car::getInsurance)
		.map(Insurance::getName);
		
不幸的是，这段代码无法通过编译。为什么呢？optPerson是Optional<Person>类型的变量，调用map方法应该没有问题。但getCar返回的是一个Optional<Car>类型的对象，这意味着map操作的结果是一个Optional<Optional<Car>>类型的对象

使用流时，flatMap方法接受一个函数作为参数，这个函数的返回值是另一个流。这个方法会应用到流中的每一个元素，最终形成一个新的流的流

类似地，传递给optional的flatMap方法的函数会将原始包含正方形的optional对象转换为包含三角形的optional对象。如果将该方法传递给map方法，结果会是一个Optional对象，而这个Optional对象中包含了三角形；但flatMap方法会将这种两层的Optional对象转换为包含三角形的单一Optional对象。

public String getCarInsuranceName(Optional<Person> person) {
	return person.flatMap(Person::getCar)
			.flatMap(Car::getInsurance)
			.map(Insurance::getName)
			.orElse("Unknown");		// Optional空，默认值
}


由于Optional类设计时就没特别考虑将其作为类的字段使用，所以它也并未实现Serializable接口。由于这个原因，如果你的应用使用了某些要求序列化的库或者框架，在域模型中使用Optional，有可能引发应用程序故障
如果你一定要实现序列化的域模型，作为替代方案，我们建议你像下面这个例子那样，提供一个能访问声明为Optional、变量值可能缺失的接口，

public class Person {
	private Car car;
	public Optional<Car> getCarAsOptional() {
		return Optional.ofNullable(car);
	}
}

。。修改get方法，而不是属性。


Optional类提供了多种方法读取Optional实例中的变量值。

get()是这些方法中最简单但又最不安全的方法。如果变量存在，它直接返回封装的变量值，否则就抛出一个NoSuchElementException异常

orElse(T other)
			它允许你在Optional对象不包含值时提供一个默认值。

orElseGet(Supplier<? extends T> other)
是orElse方法的延迟调用版，Supplier方法只有在Optional对象不含值时才执行调用。如果创建默认值是件耗时费力的工作，你应该考虑采用这种方式（借此提升程序的性能），或者你需要非常确定某个方法仅在Optional为空时才进行调用，也可以考虑该方式（这种情况有严格的限制条件）。

orElseThrow(Supplier<? extends X> exceptionSupplier)
和get方法非常类似，它们遭遇Optional对象为空时都会抛出一个异常，但是使用orElseThrow你可以定制希望抛出的异常类型。

ifPresent(Consumer<? super T>)
让你能在变量值存在时执行一个作为参数传入的方法，否则就不进行任何操作。


假设有这样一个方法，它接受一个Person和一个Car对象，并以此为条件对外部提供的服务进行查询，通过一些复杂的业务逻辑，试图找到满足该组合的最便宜的保险公司：
public Insurance findCheapestInsurance(Person person, Car car) {
	// 不同的保险公司提供的查询服务
	// 对比所有数据
	return cheapestCompany;
}

想要该方法的一个null-安全的版本，它接受两个Optional对象作为参数，返回值是一个Optional<Insurance>对象，如果传入的任何一个参数值为空，它的返回值亦为空。Optional类还提供了一个isPresent方法，如果Optional对象包含值，该方法就返回true
第一想法可能是通过下面这种方式实现该方法：
public Optional<Insurance> nullSafeFindCheapestInsurance(Optional<Person> person, Optional<Car> car) {
	if (person.isPresent() && car.isPresent()) {
		return Optional.of(findCheapestInsurance(person.get(), car.get()));
	} else {
		return Optional.empty();
	}
}

不幸的是，该方法的具体实现和你之前曾经实现的null检查太相似了：方法接受一个Person和一个Car对象作为参数，而二者都有可能为null

可以像使用三元操作符那样，无需任何条件判断的结构，以一行语句实现该方法，
public Optional<Insurance> nullSafeFindCheapestInsurance(Optional<Person> person, Optional<Car> car) {

	return person.flatMap(p -> car.map(c -> findCheapestInsurance(p, c)));
	
}


需要检查保险公司的名称是否为“Cambridge-Insurance”。为了以一种安全的方式进行这些操作，你首先需要确定引用指向的Insurance对象是否为null，之后再调用它的getName方法
Insurance insurance = ...;
if(insurance != null && "CambridgeInsurance".equals(insurance.getName())){
	System.out.println("ok");
}

使用Optional对象的filter方法，这段代码可以重构如下：
Optional<Insurance> optInsurance = ...;
optInsurance.filter(insurance -> "CambridgeInsurance".equals(insurance.getName())).ifPresent(x -> System.out.println("ok"));

filter方法接受一个谓词作为参数。如果Optional对象的值存在，并且它符合谓词的条件，filter方法就返回其值；否则它就返回一个空的Optional对象


对Optional类中的方法进行了分类和概括。
方 法 	描 述
empty
返回一个空的Optional 实例

filter
如果值存在并且满足提供的谓词，就返回包含该值的Optional 对象；否则返回一个空的Optional 对象

flatMap
如果值存在，就对该值执行提供的mapping 函数调用，返回一个Optional 类型的值，否则就返回一个空的Optional 对象

get 
如果该值存在，将该值用Optional 封装返回，否则抛出一个NoSuchElementException 异常

ifPresent 如果值存在，就执行使用该值的方法调用，否则什么也不做

isPresent 如果值存在就返回true，否则返回false

map 
如果值存在，就对该值执行提供的mapping 函数调用

of
将指定值用Optional 封装之后返回，如果该值为null，则抛出一个NullPointerException异常

ofNullable 
将指定值用Optional 封装之后返回，如果该值为null，则返回一个空的Optional 对象

orElse 如果有值则将其返回，否则返回一个默认值

orElseGet 如果有值则将其返回，否则返回一个由指定的Supplier 接口生成的值

orElseThrow 
如果有值则将其返回，否则抛出一个由指定的Supplier 接口生成的异常



Object value = map.get("key");

Optional<Object> value = Optional.ofNullable(map.get("key"));


由于某种原因，函数无法返回某个值，这时除了返回null，Java API比较常见的替代做法是抛出一个异常
你也可以用空的Optional对象，对遭遇无法转换的String时返回的非法值进行建模，这时你期望parseInt的返回值是一个optional
我们无法修改最初的Java方法，但是这无碍我们进行需要的改进，你可以实现一个工具方法
public static Optional<Integer> stringToInt(String s) {
	try {
		return Optional.of(Integer.parseInt(s));
	} catch (NumberFormatException e) {
		return Optional.empty();
	}
}
我们的建议是，你可以将多个类似的方法封装到一个工具类中，让我们称之为OptionalUtility。通过这种方式，你以后就能直接调用OptionalUtility.stringToInt方法，将String转换为一个Optional<Integer>对象，而不再需要记得你在其中封装了笨拙的try/catch的逻辑了。


与Stream 对象一样， Optional 也提供了类似的基础类型――OptionalInt、OptionalLong以及OptionalDouble
我们不推荐大家使用基础类型的Optional，因为基础类型的Optional不支持map、flatMap以及filter方法，而这些却是Optional类最有用的方法


Properties props = new Properties();
props.setProperty("a", "5");
props.setProperty("b", "true");
props.setProperty("c", "-3");

程序需要从这些属性中读取一个值，该值是以秒为单位计量的一段时间。由于一段时间必须是正数，你想要该方法符合下面的签名：
public int readDuration(Properties props, String name)
如果给定属性对应的值是一个代表正整数的字符串，就返回该整数值，任何其他的情况都返回0

assertEquals(5, readDuration(param, "a"));
assertEquals(0, readDuration(param, "b"));
assertEquals(0, readDuration(param, "c"));
assertEquals(0, readDuration(param, "d"));

public int readDuration(Properties props, String name) {
	String value = props.getProperty(name);
	if (value != null) {
	try {
		int i = Integer.parseInt(value);
			if (i > 0) {
				return i;
			}
		} catch (NumberFormatException nfe) { }
	}
	return 0;
}

public int readDuration(Properties props, String name) {
	return Optional.ofNullable(props.getProperty(name))
			.flatMap(OptionalUtility::stringToInt)
			.filter(i -> i > 0)
			.orElse(0);
}


220
chapter 11
CompletableFuture:组合式异步编程

并行：多个cpu，同时工作。
并发：单个cpu，不停切换执行不同任务。

第7章中介绍的分支/合并框架以及并行流是实现并行处理的宝贵工具；它们将一个操作切分为多个子操作，在多个不同的核、CPU甚至是机器上并行地执行这些子操作。

如果你的意图是实现并发，而非并行，或者你的主要目标是在同一个CPU上执行几个松耦合的任务，充分利用CPU的核，让其足够忙碌，从而最大化程序的吞吐量，那么你其实真正想做的是避免因为等待远程服务的返回，或者对数据库的查询，而阻塞线程的执行，浪费宝贵的计算资源，因为这种等待的时间很可能相当长。通过本章中你会了解，Future接口，尤其是它的新版实现CompletableFuture，是处理这种情况的利器。

Future接口在Java5中被引入，设计初衷是对将来某个时刻会发生的结果进行建模

它建模了一种异步计算，返回一个执行运算结果的引用，当运算结束后，这个引用被返回给调用方。

在Future中触发那些潜在耗时的操作，把调用线程解放出来，让它能继续执行其他有价值的工作，不再需要呆呆等待耗时的操作完成。

Future的另一个优点是它比更底层的Thread更易用。要使用Future，通常你只需要将耗时的操作封装在一个Callable对象中，再将它提交给ExecutorService，就万事大吉了

使用Future以异步的方式执行一个耗时的操作
ExecutorService executor = Executors.newCachedThreadPool();
	Future<Double> future = executor.submit(new Callable<Double>() {
	public Double call() {
		return doSomeLongComputation();
	}});
	
doSomethingElse();

try {
	Double result = future.get(1, TimeUnit.SECONDS);
} catch (ExecutionException ee) {
	// 计算抛出一个异常
} catch (InterruptedException ie) {
	// 当前线程在等待过程中被中断
} catch (TimeoutException te) {
	// 在Future对象完成之前超过已过期
}

虽然Future提供了一个无需任何参数的get方法，我们还是推荐大家使用重载版本的get方法，它接受一个超时的参数


Future接口提供了方法来检测异步计算是否已经结束（使用isDone方法），等待异步操作结束，以及获取计算的结果。但是这些特性还不足以让你编写简洁的并发代码

无法完成下面的需求
将两个异步计算合并为一个――这两个异步计算之间相互独立，同时第二个又依赖于第一个的结果。
等待Future集合中的所有任务都完成。
仅等待Future集合中最快结束的任务完成（有可能因为它们试图通过不同的方式计算同一个值），并返回它的结果。
通过编程方式完成一个Future任务的执行（即以手工设定异步操作结果的方式）。
应对Future的完成事件（即当Future的完成事件发生时会收到通知，并能使用Future计算的结果进行下一步的操作，不只是简单地阻塞等待操作的结果）。

新的CompletableFuture类（它实现了Future接口）如何利用Java8的新特性以更直观的方式将上述需求都变为可能。Stream和CompletableFuture的设计都遵循了类似的模式：它们都使用了Lambda表达式以及流水线的思想


创建一个名为“最佳价格查询器”（best-price-finder）的应用，它会查询多个在线商店，依据给定的产品或服务找出最低的价格

你会学到几个重要的技能。

首先，你会学到如何为你的客户提供异步API（如果你拥有一间在线商店的话，这是非常有帮助的）。

其次，你会掌握如何让你使用了同步API的代码变为非阻塞代码。你会了解如何使用流水线将两个接续的异步操作合并为一个异步计算操作。这种情况肯定会出现，比如，在线商店返回了你想要购买商品的原始价格，并附带着一个折扣代码――最终，要计算出该商品的实际价格，你不得不访问第二个远程折扣服务，查询该折扣代码对应的折扣比率。

你还会学到如何以响应式的方式处理异步操作的完成事件，以及随着各个商店返回它的商品价格，最佳价格查询器如何持续地更新每种商品的最佳推荐，而不是等待所有的商店都返回他们各自的价格（这种方式存在着一定的风险，一旦某家商店的服务中断，用户可能遭遇白屏）。


同步API其实只是对传统方法调用的另一种称呼：你调用了某个方法，调用方在被调用方运行的过程中会等待，被调用方运行结束返回，调用方取得被调用方的返回值并继续运行。
异步API会直接返回，或者至少在被调用方计算完成之前，将它剩余的计算任务交给另一个线程去做，该线程和调用方是异步的――这就是非阻塞式调用的由来


商店应该声明依据指定产品名称返回价格的方法：
public class Shop {
	public double getPrice(String product) {
		// 待实现
	}
}

该方法的内部实现会查询商店的数据库，但也有可能执行一些其他耗时的任务，比如联系其他外部服务（比如，商店的供应商，或者跟制造商相关的推广折扣）。
我们在本章剩下的内容中，采用delay方法模拟这些长期运行的方法的执行，它会人为地引入1秒钟的延迟
public static void delay() {
	try {
		Thread.sleep(1000L);
	} catch (InterruptedException e) {
		throw new RuntimeException(e);
	}
}

getPrice方法会调用delay方法，并返回一个随机计算的值
public double getPrice(String product) {
	return calculatePrice(product);
}
private double calculatePrice(String product) {
	delay();
	return random.nextDouble() * product.charAt(0) + product.charAt(1);
}


将同步方法转换为异步方法

将getPrice转换为getPriceAsync方法，并修改它的返回值：
public Future<Double> getPriceAsync(String product) { ... }

public Future<Double> getPriceAsync(String product) {
	CompletableFuture<Double> futurePrice = new CompletableFuture<>();
	new Thread( () -> {
			double price = calculatePrice(product);
			futurePrice.complete(price);
	}).start();
	return futurePrice;
}

创建了一个代表异步计算的CompletableFuture对象实例，它在计算完成时会包含计算的结果
调用fork创建了另一个线程去执行实际的价格计算工作，不等该耗时计算任务结束，直接返回一个Future实例
当请求的产品价格最终计算得出时，你可以使用它的complete方法，结束completableFuture对象的运行，并设置变量的值
。。Future自己并不会多线程。只是进行线程间通讯。
。。自己new Thread，，ExecutorService.submit(Callable..),才是多线程。


Shop shop = new Shop("BestShop");
long start = System.nanoTime();
Future<Double> futurePrice = shop.getPriceAsync("my favorite product");
long invocationTime = ((System.nanoTime() - start) / 1_000_000);
System.out.println("Invocation returned after " + invocationTime + " msecs");
// 执行更多任务，比如查询其他商店
doSomethingElse();
// 在计算商品价格的同时
try {
	// 价格未知时，阻塞
	double price = futurePrice.get();
	System.out.printf("Price is %.2f%n", price);
} catch (Exception e) {
	throw new RuntimeException(e);
}
long retrievalTime = ((System.nanoTime() - start) / 1_000_000);
System.out.println("Price returned after " + retrievalTime + " msecs");


227

为了让客户端能了解商店无法提供请求商品价格的原因，你需要使用CompletableFuture的completeExceptionally方法将导致CompletableFuture内发生问题的异常抛出。

public Future<Double> getPriceAsync(String product) {
	CompletableFuture<Double> futurePrice = new CompletableFuture<>();
	new Thread( () -> {
		try {
			double price = calculatePrice(product);
			futurePrice.complete(price);
		} catch (Exception ex) {
			futurePrice.completeExceptionally(ex);
		}
	}).start();
	return futurePrice;
}

CompletableFuture类自身提供了大量精巧的工厂方法，使用这些方法能更容易地完成整个流程，还不用担心实现的细节。

采用supplyAsync方法后，你可以用一行语句重写代码
public Future<Double> getPriceAsync(String product) {
	return CompletableFuture.supplyAsync(() -> calculatePrice(product));
}
supplyAsync方法接受一个生产者（Supplier）作为参数，返回一个CompletableFuture对象，该对象完成异步执行后会读取调用生产者方法的返回值。生产者方法会交由ForkJoinPool池中的某个执行线程（Executor）运行，但是你也可以使用supplyAsync方法的重载版本，传递第二个参数指定不同的执行线程执行生产者方法。


228
让你的代码免受阻塞之苦

有一个商家的列表
List<Shop> shops = Arrays.asList(new Shop("BestPrice"),
			new Shop("LetsSaveBig"),
			new Shop("MyFavoriteShop"),
			new Shop("BuyItAll"));

需要使用下面这样的签名实现一个方法，它接受产品名作为参数，返回一个字符串列表，这个字符串列表中包括商店的名称、该商店中指定商品的价格
public List<String> findPrices(String product);

顺序查询所有商店的方式实现的findPrices方法
public List<String> findPrices(String product) {
	return shops.stream()
		.map(shop -> String.format("%s price is %.2f", shop.getName(), shop.getPrice(product)))
		.collect(toList());
}

需要4s多一点点。因为每个getPrice中都会Thread.sleep(1000)

采用并行流
public List<String> findPrices(String product) {
	return shops.parallelStream()
		.map(shop -> String.format("%s price is %.2f",shop.getName(), shop.getPrice(product)))
		.collect(toList());
}
1s多一点点。

使用CompletableFuture 发起异步请求
List<CompletableFuture<String>> priceFutures =
	shops.stream()
		.map(shop -> CompletableFuture.supplyAsync(
			() -> String.format("%s price is %.2f",
			shop.getName(), shop.getPrice(product))))
		.collect(toList());

。。懒加载。。

但是，由于你用CompletableFutures实现的findPrices方法要求返回一个List<String>，你需要等待所有的future执行完毕，将其包含的值抽取出来，填充到列表中才能返回。
。。不是吧，这个也是4s？..应该是1s，是因为方法的返回值是List<String>,现在只是List<CompletableFuture<String>>，还需要转为List<String>，这里用到了supplyAsync，所以应该是1s。。。如果是单核cpu，应该还是4s，双核就2s？。。不是，Thread.sleep的时候又不是os停止。。单核就是单cpu并发。
。。好像不是，下面的例子，5个商店的时候就直接增加1s，而不是继续总共1s。。

向最初的List<CompletableFuture<String>>施加第二个map操作，对List中的所有future对象执行join操作，一个接一个地等待它们运行结束。
public List<String> findPrices(String product) {
	List<CompletableFuture<String>> priceFutures =
		shops.stream()
			.map(shop -> CompletableFuture.supplyAsync(
				() -> shop.getName() + " price is " +
						shop.getPrice(product)))
			.collect(Collectors.toList());
	return priceFutures.stream()
		.map(CompletableFuture::join)
		.collect(toList());
}

CompletableFuture类中的join方法和Future接口中的get有相同的含义，并且也声明在Future接口中，它们唯一的不同是join不会抛出任何检测到的异常。
。。内置try，外面就不需要再捕获了。

如果你在单一流水线中处理流，发向不同商家的请求只能以同步、顺序执行的方式才会成功。因此，每个创建CompletableFuture对象只能在前一个操作结束之后执行查询指定商家的动作、通知join方法返回计算结果

上面的代码2s。


增加第5个商店时，
顺序流是5s。
并行流版本是2s。
CompletableFuture是2s。

9个商店时，
并行流3s。
CompletableFuture，3s。

它们看起来不相伯仲，究其原因都一样：它们内部采用的是同样的通用线程池，默认都使用固定数目的线程，具体线程数取决于Runtime.getRuntime().availableProcessors()的返回值。
然而，CompletableFuture具有一定的优势，因为它允许你对执行器（Executor）进行配置，尤其是线程池的大小，让它以更适合应用需求的方式进行配置，满足程序的要求，而这是并行流API无法提供的。


如何选择合适的线程数目
Brian Goetz建议，线程池大小与处理器的利用率之比可以使用下面的公式进行估算：

Nthreads = NCPU * UCPU * (1 + W/C)
NCPU是处理器的核的数目，可以通过Runtime.getRuntime().availableProcessors()得到
UCPU是期望的CPU利用率（该值应该介于0和1之间）
W/C是等待时间与计算时间的比率

你的应用99%的时间都在等待商店的响应，所以估算出的W/C比率为100。这意味着如果你期望的CPU利用率是100%，你需要创建一个拥有400个线程的线程池

。。看来parallelStream的cpu/线程数量是Runtime.get.available的值，固定的。所以有5个商店的时候，就是4个执行，然后再1个执行。
。。自己改变线程池大小后，就可以一次性执行任意个。


定制的执行器
实际操作中，如果你创建的线程数比商店的数目更多，反而是一种浪费，因为这样做之后，你线程池中的有些线程根本没有机会被使用。
出于这种考虑，我们建议你将执行器使用的线程数，与你需要查询的商店数目设定为同一个值，这样每个商店都应该对应一个服务线程。
不过，为了避免发生由于商店的数目过多导致服务器超负荷而崩溃，你还是需要设置一个上限，比如100个线程

private final Executor executor = Executors.newFixedThreadPool(Math.min(shops.size(), 100),
				new ThreadFactory() {
					public Thread newThread(Runnable r) {
					Thread t = new Thread(r);
		// 使用守护线程――这种方式不会阻止程序的关停
					t.setDaemon(true);
					return t;
				}
});

。。ThreadFactory，

Java程序无法终止或者退出一个正在运行中的线程，所以最后剩下的那个线程会由于一直等待无法发生的事件而引发问题。与此相反，如果将线程标记为守护进程，意味着程序退出时它也会被回收。这二者之间没有性能上的差异

将执行器作为第二个参数传递给supplyAsync工厂方法
CompletableFuture.supplyAsync(() -> shop.getName() + " price is " + shop.getPrice(product), executor);

改进之后，使用CompletableFuture方案的程序处理5个商店仅耗时1021秒，处理9个商店时耗时1022秒。
一般而言，这种状态会一直持续，直到商店的数目达到我们之前计算的阈值400。
。。400？不是100？线程池中数量最多100啊。


目前为止，你已经知道对集合进行并行计算有两种方式：
1.要么将其转化为并行流，利用map这样的操作开展工作，
2.要么枚举出集合中的每一个元素，创建新的线程，在CompletableFuture内对其进行操作。
后者提供了更多的灵活性，你可以调整线程池的大小，而这能帮助你确保整体的计算不会因为线程都在等待I/O而发生阻塞。

我们对使用这些API的建议如下。
?如果你进行的是计算密集型的操作，并且没有I/O，那么推荐使用Stream接口，因为实现简单，同时效率也可能是最高的（如果所有的线程都是计算密集型的，那就没有必要创建比处理器核数更多的线程）。
?反之，如果你并行的工作单元还涉及等待I/O的操作（包括网络连接等待），那么使用CompletableFuture灵活性更好，你可以像前文讨论的那样，依据等待/计算，或者W/C的比率设定需要使用的线程数。这种情况不使用并行流的另一个原因是，处理流的流水线中如果发生I/O等待，流的延迟特性会让我们很难判断到底什么时候触发了等待。


236
11.4
对多个异步任务进行流水线操作

public List<String> findPrices(String product) {
	List<CompletableFuture<String>> priceFutures = 
		shops.stream()
			.map(shop -> CompletableFuture.supplyAsync(
				() -> shop.getPrice(product), executor))
			.map(future -> future.thenApply(Quote::parse))
			.map(future -> future.thenCompose(quote ->
				CompletableFuture.supplyAsync(
					() -> Discount.applyDiscount(quote), executor)))
			.collect(toList());
	return priceFutures.stream()
			.map(CompletableFuture::join)
			.collect(toList());
}


合并两个独立的CompletableFuture对象
Future<Double> futurePriceInUSD =
	CompletableFuture.supplyAsync(() -> shop.getPrice(product))
	.thenCombine(
		CompletableFuture.supplyAsync(
			() -> exchangeService.getRate(Money.EUR, Money.USD)),
		(price, rate) -> price * rate
	);
这里整合的操作只是简单的乘法操作，用另一个单独的任务对其进行操作有些浪费资源，所以你只要使用thenCombine方法，无需特别求助于异步版本的thenCombineAsync方法


利用Java 7的方法合并两个Future对象
ExecutorService executor = Executors.newCachedThreadPool();
final Future<Double> futureRate = executor.submit(new Callable<Double>() {
	public Double call() {
		return exchangeService.getRate(Money.EUR, Money.USD);
	}});
Future<Double> futurePriceInUSD = executor.submit(new Callable<Double>() {
	public Double call() {
		double priceInEUR = shop.getPrice(product);
		return priceInEUR * futureRate.get();
	}});

通过向执行器提交一个Callable对象的方式创建了第一个Future对象，向外部服务查询欧元和美元之间的转换汇率。紧接着，你创建了第二个Future对象，查询指定商店中特定商品的欧元价格，在同一个Future中通过查询商店得到的欧元商品价格乘以汇率得到了最终的价格


11.5 响应CompletableFuture 的completion 事件

对最佳价格查询器应用的优化
要避免的首要问题是，等待创建一个包含了所有价格的List创建完成。你应该做的是直接处理CompletableFuture流，这样每个CompletableFuture都在为某个商店执行必要的操作
public Stream<CompletableFuture<String>> findPricesStream(String product) {
	return shops.stream()
		.map(shop -> CompletableFuture.supplyAsync(
			() -> shop.getPrice(product), executor))
		.map(future -> future.thenApply(Quote::parse))
		.map(future -> future.thenCompose(quote ->
			CompletableFuture.supplyAsync(
				() -> Discount.applyDiscount(quote), executor)));
}

新添加的操作其实很简单，只是在每个CompletableFuture上注册一个操作，该操作会在CompletableFuture完成执行后使用它的返回值。
Java8的CompletableFuture通过thenAccept方法提供了这一功能，它接收CompletableFuture执行完毕后的返回值做参数。

findPricesStream("myPhone").map(f -> f.thenAccept(System.out::println));

和你之前看到的thenCompose和thenCombine方法一样，thenAccept方法也提供了一个异步版本，名为thenAcceptAsync。异步版本的方法会对处理结果的消费者进行调度，从线程池中选择一个新的线程继续执行，不再由同一个线程完成CompletableFuture的所有任务。因为你想要避免不必要的上下文切换，更重要的是你希望避免在等待线程上浪费时间，尽快响应CompletableFuture的completion事件，所以这里没有采用异步版本。
由于thenAccept 方法已经定义了如何处理CompletableFuture 返回的结果，一旦CompletableFuture计算得到结果，它就返回一个CompletableFuture<Void>。
对这个<CompletableFuture<Void>>对象，你能做的事非常有限，只能等待其运行结束，不过这也是你所期望的。你还希望能给最慢的商店一些机会，让它有机会打印输出返回的价格。为了实现这一目的，你可以把构成Stream的所有CompletableFuture<Void>对象放到一个数组中，等待所有的任务执行完成，
CompletableFuture[] futures = findPricesStream("myPhone")
	.map(f -> f.thenAccept(System.out::println))
	.toArray(size -> new CompletableFuture[size]);
CompletableFuture.allOf(futures).join();

allOf工厂方法接收一个由CompletableFuture构成的数组，数组中的所有CompletableFuture对象执行完成之后，它返回一个CompletableFuture<Void>对象

另一些场景中，你可能希望只要CompletableFuture对象数组中有任何一个执行完毕就不再等待，比如，你正在查询两个汇率服务器，任何一个返回了结果都能满足你的需求。在这种情况下，你可以使用一个类似的工厂方法anyOf。该方法接收一个CompletableFuture对象构成的数组，返回由第一个执行完毕的CompletableFuture对象的返回值构成的CompletableFuture<Object>。


现在你可以通过代码清单11-19中的randomDelay方法模拟
远程方法调用，产生一个介于0.5秒到2.5秒的随机延迟，不再使用恒定1秒的延迟值。代码清单
11-21应用了这一改变，执行这段代码你会看到不同商店的价格不再像之前那样总是在一个时刻
返回，而是随着商店折扣价格返回的顺序逐一地打印输出。为了让这一改变的效果更加明显，我
们对代码进行了微调，在输出中打印每个价格计算所消耗的时间：
long start = System.nanoTime();
CompletableFuture[] futures = findPricesStream("myPhone27S")
	.map(f -> f.thenAccept(
		s -> System.out.println(s + " (done in " +
			((System.nanoTime() - start) / 1_000_000) + " msecs)")))
	.toArray(size -> new CompletableFuture[size]);
CompletableFuture.allOf(futures).join();
System.out.println("All shops have now responded in " + ((System.nanoTime() - start) / 1_000_000) + " msecs");


246
chapter12
新的日期和时间API

在Java 1.0中，对日期和时间的支持只能依赖java.util.Date类
在Java1.1中，Date类中的很多方法被废弃了，取而代之的是java.util.Calendar类。

DateFormat方法也有它自己的问题。比如，它不是线程安全的。这意味着两个线程如果尝试使用同一个formatter解析日期，你可能会得到无法预期的结果。

缺陷和不一致导致用户们转投第三方的日期和时间库，比如Joda-Time
Java 8在java.time包中整合了很多Joda-Time的特性。


从探索如何创建简单的日期和时间间隔入手。java.time包中提供了很多新的类可以帮你解决问题，它们是LocalDate、LocalTime、Instant、Duration和Period。

最先碰到的可能是LocalDate类。该类的实例是一个不可变对象，它只提供了简单的日期，并不含当天的时间信息。另外，它也不附带任何与时区相关的信息。
通过静态工厂方法of创建一个LocalDate实例。LocalDate实例提供了多种方法来读取常用的值，比如年份、月份、星期几等，

LocalDate date = LocalDate.of(2014, 3, 18);
int year = date.getYear();
Month month = date.getMonth();		// March
int day = date.getDayOfMonth();		// 18
DayOfWeek dow = date.getDayOfWeek();	// Tuesday
int len = date.lengthOfMonth();		// 31 (days in March)
boolean leap = date.isLeapYear();	// false

使用工厂方法从系统时钟中获取当前的日期：
LocalDate today = LocalDate.now();


还可以通过传递一个TemporalField参数给get方法拿到同样的信息。TemporalField是一个接口，它定义了如何访问temporal对象某个字段的值。ChronoField枚举实现了这一接口，所以你可以很方便地使用get方法得到枚举元素的值

int year = date.get(ChronoField.YEAR);
int month = date.get(ChronoField.MONTH_OF_YEAR);
int day = date.get(ChronoField.DAY_OF_MONTH);


一天中的时间，比如13:45:20，可以使用LocalTime类表示。你可以使用of重载的两个工厂方法创建LocalTime的实例。第一个重载函数接收小时和分钟，第二个重载函数同时还接收秒

LocalTime time = LocalTime.of(13, 45, 20);
int hour = time.getHour();
int minute = time.getMinute();
int second = time.getSecond();


LocalDate和LocalTime都可以通过解析代表它们的字符串创建。使用静态方法parse
LocalDate date = LocalDate.parse("2014-03-18");
LocalTime time = LocalTime.parse("13:45:20");

可以向parse方法传递一个DateTimeFormatter。该类的实例定义了如何格式化一个日期或者时间对象。正如我们之前所介绍的，它是替换老版java.util.DateFormat的推荐替代品。

一旦传递的字符串参数无法被解析为合法的LocalDate或LocalTime对象，这两个parse方法都会抛出一个继承自RuntimeException的DateTimeParseException异常。


LocalDateTime，是LocalDate和LocalTime的合体。它同时表示了日期和时间，但不带有时区信息，你可以直接创建，也可以通过合并日期和时间对象构造
LocalDateTime dt1 = LocalDateTime.of(2014, Month.MARCH, 18, 13, 45, 20);
LocalDateTime dt2 = LocalDateTime.of(date, time);
LocalDateTime dt3 = date.atTime(13, 45, 20);
LocalDateTime dt4 = date.atTime(time);
LocalDateTime dt5 = time.atDate(date);

通过它们各自的atTime或者atDate方法，向LocalDate传递一个时间对象，或者向LocalTime传递一个日期对象的方式，你可以创建一个LocalDateTime对象。
。。date.at(time) -> datetime

也可以使用toLocalDate或者toLocalTime方法，从LocalDateTime中提取LocalDate或者LocalTime组件
LocalDate date1 = dt1.toLocalDate();
LocalTime time1 = dt1.toLocalTime();


从计算机的角度来看，建模时间最自然的格式是表示一个持续时间段上某个点的单一大整型数。这也是新的java.time.Instant类对时间建模的方式，基本上它是以Unix元年时间（传统的设定为UTC时区1970年1月1日午夜时分）开始所经历的秒数进行计算。

向静态工厂方法ofEpochSecond传递一个代表秒数的值创建一个该类的实例。静态工厂方法ofEpochSecond还有一个增强的重载版本，它接收第二个以纳秒为单位的参数值，对传入作为秒数的参数进行调整。重载的版本会调整纳秒参数，确保保存的纳秒分片在0到999999999之间。
这意味着下面这些对ofEpochSecond工厂方法的调用会返回几乎同样的Instant对象：
Instant.ofEpochSecond(3);
Instant.ofEpochSecond(3, 0);
Instant.ofEpochSecond(2, 1_000_000_000);
Instant.ofEpochSecond(4, -1_000_000_000);

Instant类也支持静态工厂方法now，它能够帮你获取当前时刻的时间戳。
我们想要特别强调一点，Instant的设计初衷是为了便于机器使用。它包含的是由秒及纳秒所构成的数字。所以，它无法处理那些我们非常容易理解的时间单位

int day = Instant.now().get(ChronoField.DAY_OF_MONTH);
它会抛出下面这样的异常：
java.time.temporal.UnsupportedTemporalTypeException: Unsupported field:
	DayOfMonth

但是你可以通过Duration和Period类使用Instant


目前为止，你看到的所有类都实现了Temporal接口，Temporal接口定义了如何读取和操纵为时间建模的对象的值

我们需要创建两个Temporal对象之间的duration。Duration类的静态工厂方法between就是为这个目的而设计的
。你可以创建两个LocalTimes对象、两个LocalDateTimes对象，或者两个Instant对象之间的duration

Duration d1 = Duration.between(time1, time2);
Duration d1 = Duration.between(dateTime1, dateTime2);
Duration d2 = Duration.between(instant1, instant2);

由于LocalDateTime和Instant是为不同的目的而设计的，一个是为了便于人阅读使用，另一个是为了便于机器处理，所以你不能将二者混用。如果你试图在这两类对象之间创建duration，会触发一个DateTimeException异常
由于Duration类主要用于以秒和纳秒衡量时间的长短，你不能仅向between方法传递一个LocalDate对象做参数。

如果你需要以年、月或者日的方式对多个时间单位建模，可以使用Period类。使用该类的工厂方法between，你可以使用得到两个LocalDate之间的时长
Period tenDays = Period.between(LocalDate.of(2014, 3, 8),
LocalDate.of(2014, 3, 18));


Duration和Period类都提供了很多非常方便的工厂类，直接创建对应的实例，不再是只能以两个temporal对象的差值的方式来定义它们的对象。
Duration threeMinutes = Duration.ofMinutes(3);
Duration threeMinutes = Duration.of(3, ChronoUnit.MINUTES);
Period tenDays = Period.ofDays(10);
Period threeWeeks = Period.ofWeeks(3);
Period twoYearsSixMonthsOneDay = Period.of(2, 6, 1);

Duration类和Period类共享了很多相似的方法
方 法 名 	是否是静态方法 	方法描述
between 	是 				创建两个时间点之间的interval
from 		是 				由一个临时时间点创建interval
of 			是 				由它的组成部分创建interval 的实例
parse 		是 				由字符串创建interval 的实例
addTo 		否 				创建该interval的副本，并将其叠加到某个指定的temporal 对象
get 		否 				读取该interval 的状态
isNegative 	否 				检查该interval 是否为负值，不包含零
isZero 		否 			检查该interval 的时长是否为零
minus 		否 		通过减去一定的时间创建该interval 的副本
multipliedBy 否 		将interval 的值乘以某个标量创建该interval 的副本
negated 	否 		以忽略某个时长的方式创建该interval 的副本
plus 		否 以增加某个指定的时长的方式创建该interval 的副本
subtractFrom 否 		从指定的temporal 对象中减去该interval


如果你已经有一个LocalDate对象，想要创建它的一个修改版，最直接也最简单的方法是使用withAttribute方法。withAttribute方法会创建对象的一个副本，并按照需要修改它的属性。
注意，下面的这段代码中所有的方法都返回一个修改了属性的对象。它们都不会修改原来的对象！

LocalDate date1 = LocalDate.of(2014, 3, 18);
LocalDate date2 = date1.withYear(2011);
LocalDate date3 = date2.withDayOfMonth(25);
LocalDate date4 = date3.with(ChronoField.MONTH_OF_YEAR, 9);

采用更通用的with方法能达到同样的目的，它接受的第一个参数是一个TemporalField对象

最后这一行中使用的with方法和代码清单12-2中的get方法有些类似。它们都声明于Temporal接口，所有的日期和时间API类都实现这两个方法，它们定义了单点的时间，比如LocalDate、LocalTime、LocalDateTime以及Instant。更确切地说，使用get和with方法，我们可以将Temporal对象值的读取和修改区分开。如果Temporal对象不支持请求访问的字段，它会抛出一个UnsupportedTemporalTypeException异常，比如试图访问Instant对象的ChronoField.MONTH_OF_YEAR字段，或者LocalDate对象的ChronoField.NANO_OF_SECOND字段时都会抛出这样的异常。


它甚至能以声明的方式操纵LocalDate对象。比如，你可以像下面这段代码那样加上或者减去一段时间。
LocalDate date1 = LocalDate.of(2014, 3, 18);
LocalDate date2 = date1.plusWeeks(1);
LocalDate date3 = date2.minusYears(3);
LocalDate date4 = date3.plus(6, ChronoUnit.MONTHS);

与我们刚才介绍的get和with方法类似，代码清单12-7中最后一行使用的plus方法也是通用方法，它和minus方法都声明于Temporal接口中。

通过这些方法，对TemporalUnit对象加上或者减去一个数字，我们能非常方便地将Temporal对象前溯或者回滚至某个时间段，通过ChronoUnit枚举我们可以非常方便地实现TemporalUnit接口。


像LocalDate、LocalTime、LocalDateTime以及Instant这样表示时间点的日期?时间类提供了大量通用的方法

方 法 名 	是否是静态方法	描 述
from 		是 	依据传入的Temporal 对象创建对象实例
now 		是 依据系统时钟创建Temporal 对象
of 			是 由Temporal 对象的某个部分创建该对象的实例
parse 		是 由字符串创建Temporal 对象的实例
atOffset 	否 将Temporal 对象和某个时区偏移相结合
atZone 		否 将Temporal 对象和某个时区相结合
format 		否 使用某个指定的格式器将Temporal 对象转换为字符串（Instant 类不提供该方法）
get 		否 读取Temporal 对象的某一部分的值
minus 		否
创建Temporal 对象的一个副本，通过将当前Temporal 对象的值减去一定的时长创建该副本
plus 		否
创建Temporal 对象的一个副本，通过将当前Temporal 对象的值加上一定的时长创建该副本
with 		否 以该Temporal 对象为模板，对某些状态进行修改创建该对象的副本


date = date.plusYears(2).minusDays(10);
。。链式。


截至目前，你所看到的所有日期操作都是相对比较直接的。有的时候，你需要进行一些更加复杂的操作，比如，将日期调整到下个周日、下个工作日，或者是本月的最后一天。这时，你可以使用重载版本的with方法，向其传递一个提供了更多定制化选择的TemporalAdjuster对象，更加灵活地处理日期。
对于最常见的用例， 日期和时间API已经提供了大量预定义的
TemporalAdjuster。你可以通过TemporalAdjuster类的静态工厂方法访问它们

import static java.time.temporal.TemporalAdjusters.*;
LocalDate date1 = LocalDate.of(2014, 3, 18);
LocalDate date2 = date1.with(nextOrSame(DayOfWeek.SUNDAY));
LocalDate date3 = date2.with(lastDayOfMonth());

TemporalAdjuster类中的工厂方法
dayOfWeekInMonth 创建一个新的日期，它的值为同一个月中每一周的第几天

firstDayOfMonth 创建一个新的日期，它的值为当月的第一天

firstDayOfNextMonth 创建一个新的日期，它的值为下月的第一天

firstDayOfNextYear 创建一个新的日期，它的值为明年的第一天

firstDayOfYear 创建一个新的日期，它的值为当年的第一天

firstInMonth 创建一个新的日期，它的值为同一个月中，第一个符合星期几要求的值

lastDayOfMonth 创建一个新的日期，它的值为当月的最后一天

lastDayOfNextMonth 创建一个新的日期，它的值为下月的最后一天

lastDayOfNextYear 创建一个新的日期，它的值为明年的最后一天

lastDayOfYear 创建一个新的日期，它的值为今年的最后一天

lastInMonth 创建一个新的日期，它的值为同一个月中，最后一个符合星期几要求的值

next/previous
创建一个新的日期，并将其值设定为日期调整后或者调整前，第一个符合指定星期几要求的日期

nextOrSame/previousOrSame
创建一个新的日期，并将其值设定为日期调整后或者调整前，第一个符合指定星期几要求的日期，如果该日期已经符合要求，直接返回该对象


创建你自己的TemporalAdjuster也并非难事。实际上，TemporalAdjuster接口只声明了单一的一个方法（这使得它成为了一个函数式接口）

@FunctionalInterface
public interface TemporalAdjuster {
	Temporal adjustInto(Temporal temporal);
}
这意味着TemporalAdjuster接口的实现需要定义如何将一个Temporal对象转换为另一个Temporal对象。你可以把它看成一个UnaryOperator<Temporal>。


实现一个定制的TemporalAdjuster
计算明天的日期，同时过滤掉周六和周日这些节假日。
public class NextWorkingDay implements TemporalAdjuster {
	@Override
	public Temporal adjustInto(Temporal temporal) {
		DayOfWeek dow = DayOfWeek.of(temporal.get(ChronoField.DAY_OF_WEEK));
		int dayToAdd = 1;
		if (dow == DayOfWeek.FRIDAY) dayToAdd = 3;
		else if (dow == DayOfWeek.SATURDAY) dayToAdd = 2;
		return temporal.plus(dayToAdd, ChronoUnit.DAYS);
	}
}

date = date.with(temporal -> {
	DayOfWeek dow = DayOfWeek.of(temporal.get(ChronoField.DAY_OF_WEEK));
	int dayToAdd = 1;
	if (dow == DayOfWeek.FRIDAY) dayToAdd = 3;
	else if (dow == DayOfWeek.SATURDAY) dayToAdd = 2;
	return temporal.plus(dayToAdd, ChronoUnit.DAYS);
});

使用Lambda表达式定义TemporalAdjuster对象，推荐使用TemporalAdjusters类的静态工厂方法ofDateAdjuster，它接受一个UnaryOperator<LocalDate>类型的参数

TemporalAdjuster nextWorkingDay = TemporalAdjusters.ofDateAdjuster(
	temporal -> {
		DayOfWeek dow =
		DayOfWeek.of(temporal.get(ChronoField.DAY_OF_WEEK));
		int dayToAdd = 1;
		if (dow == DayOfWeek.FRIDAY) dayToAdd = 3;
		if (dow == DayOfWeek.SATURDAY) dayToAdd = 2;
		return temporal.plus(dayToAdd, ChronoUnit.DAYS);
	});
date = date.with(nextWorkingDay);


格式化以及解析日期?时间对象是另一个非常重要的功能。新的java.time.format包就是特别为这个目的而设计的
这个包中，最重要的类是DateTimeFormatter
创建格式器最简单的方法是通过它的静态工厂方法以及常量。像BASIC_ISO_DATE和ISO_LOCAL_DATE 这样的常量是DateTimeFormatter 类的预定义实例。

LocalDate date = LocalDate.of(2014, 3, 18);
// 20140318
String s1 = date.format(DateTimeFormatter.BASIC_ISO_DATE);
// 2014-03-18
String s2 = date.format(DateTimeFormatter.ISO_LOCAL_DATE);


LocalDate date1 = LocalDate.parse("20140318",
		DateTimeFormatter.BASIC_ISO_DATE);
LocalDate date2 = LocalDate.parse("2014-03-18",
		DateTimeFormatter.ISO_LOCAL_DATE);

和老的java.util.DateFormat相比较，所有的DateTimeFormatter实例都是线程安全的

DateTimeFormatter类还支持一个静态工厂方法，它可以按照某个特定的模式创建格式器
DateTimeFormatter formatter = DateTimeFormatter.ofPattern("dd/MM/yyyy");

LocalDate date1 = LocalDate.of(2014, 3, 18);
String formattedDate = date1.format(formatter);
LocalDate date2 = LocalDate.parse(formattedDate, formatter);


ofPattern方法也提供了一个重载的版本，使用它你可以创建某个Locale的格式器

DateTimeFormatter italianFormatter = DateTimeFormatter.ofPattern("d. MMMM yyyy", Locale.ITALIAN);
LocalDate date1 = LocalDate.of(2014, 3, 18);
String formattedDate = date.format(italianFormatter); // 18. marzo 2014
LocalDate date2 = LocalDate.parse(formattedDate, italianFormatter);

如果你还需要更加细粒度的控制，DateTimeFormatterBuilder类还提供了更复杂的格式器，你可以选择恰当的方法，一步一步地构造自己的格式器。
它还提供了非常强大的解析功能，比如区分大小写的解析、柔性解析（允许解析器使用启发式的机制去解析输入，不精确地匹配指定的模式）、填充， 以及在格式器中指定可选节

可以通过DateTimeFormatterBuilder自己编程实现我们在代码清单12-11中使用的italianFormatter
DateTimeFormatter italianFormatter = new DateTimeFormatterBuilder()
	.appendText(ChronoField.DAY_OF_MONTH)
	.appendLiteral(". ")
	.appendText(ChronoField.MONTH_OF_YEAR)
	.appendLiteral(" ")
	.appendText(ChronoField.YEAR)
	.parseCaseInsensitive()
	.toFormatter(Locale.ITALIAN);


新的java.time.ZoneId类是老版java.util.TimeZone的替代品

它的设计目标就是要让你无需为时区处理的复杂和繁琐而操心，比如处理日光时（Daylight Saving Time，DST）这种问题。跟其他日期和时间类一样，ZoneId类也是无法修改的。

时区是按照一定的规则将区域划分成的标准时间相同的区间。在ZoneRules这个类中包含了40个这样的实例。你可以简单地通过调用ZoneId的getRules()得到指定时区的规则。每个特定的ZoneId对象都由一个地区ID标识
ZoneId romeZone = ZoneId.of("Europe/Rome");
地区ID都为“{区域}/{城市}”的格式，这些地区集合的设定都由英特网编号分配机构（IANA）的时区数据库提供。
你可以通过Java 8的新方法toZoneId将一个老的时区对象转换为ZoneId：
ZoneId zoneId = TimeZone.getDefault().toZoneId();

一旦得到一个ZoneId对象，你就可以将它与LocalDate、LocalDateTime或者是Instant对象整合起来，构造为一个ZonedDateTime实例，它代表了相对于指定时区的时间点

LocalDate date = LocalDate.of(2014, Month.MARCH, 18);
ZonedDateTime zdt1 = date.atStartOfDay(romeZone);
LocalDateTime dateTime = LocalDateTime.of(2014, Month.MARCH, 18, 13, 45);
ZonedDateTime zdt2 = dateTime.atZone(romeZone);
Instant instant = Instant.now();
ZonedDateTime zdt3 = instant.atZone(romeZone);

通过ZoneId，你还可以将LocalDateTime转换为Instant：
LocalDateTime dateTime = LocalDateTime.of(2014, Month.MARCH, 18, 13, 45);
Instant instantFromDateTime = dateTime.toInstant(romeZone);
你也可以通过反向的方式得到LocalDateTime对象：
Instant instant = Instant.now();
LocalDateTime timeFromInstant = LocalDateTime.ofInstant(instant, romeZone);

。。datetime转instant，需要时区？那么unix的1970.1.1是哪个时区的？


另一种比较通用的表达时区的方式是利用当前时区和UTC/格林尼治的固定偏差，你可以说“纽约落后于伦敦5小时”。
这种情况下，你可以使用ZoneOffset类，它是ZoneId的一个子类，表示的是当前时间和伦敦格林尼治子午线时间的差异：

ZoneOffset newYorkOffset = ZoneOffset.of("-05:00");
“-05:00”的偏差实际上对应的是美国东部标准时间。注意，使用这种方式定义的ZoneOffset并未考虑任何日光时的影响，所以在大多数情况下，不推荐使用。
ZoneOffset也是ZoneId

甚至还可以创建这样的OffsetDateTime，它使用ISO-8601的历法系统，以相对于UTC/格林尼治时间的偏差方式表示日期时间。
LocalDateTime dateTime = LocalDateTime.of(2014, Month.MARCH, 18, 13, 45);
OffsetDateTime dateTimeInNewYork = OffsetDateTime.of(date, newYorkOffset);

新版的日期和时间API还提供了另一个高级特性，即对非ISO历法系统（non-ISO calendaring）的支持。

ISO-8601日历系统是世界文明日历系统的事实标准
Java 8中另外还提供了4种其他的
日历系统。这些日历系统中的每一个都有一个对应的日志类，分别是ThaiBuddhistDate、MinguoDate 、JapaneseDate 以及HijrahDate
所有这些类以及LocalDate都实现了ChronoLocalDate接口，能够对公历的日期进行建模
使用它们提供的静态工厂方法，你可以创建任何一个Temporal对象的实例
LocalDate date = LocalDate.of(2014, Month.MARCH, 18);
JapaneseDate japaneseDate = JapaneseDate.from(date);

还可以为某个Locale显式地创建日历系统，接着创建该Locale对应的日期的实例。新的日期和时间API中，Chronology接口建模了一个日历系统，使用它的静态工厂方法ofLocale，
Chronology japaneseChronology = Chronology.ofLocale(Locale.JAPAN);
ChronoLocalDate now = japaneseChronology.dateNow();

日期及时间API的设计者建议我们使用LocalDate，尽量避免使用ChronoLocalDate，原因是开发者在他们的代码中可能会做一些假设，而这些假设在不同的日历系统中，有可能不成立。
比如，有人可能会做这样的假设，即一个月天数不会超过31天，一年包括12个月，或者一年中包含的月份数目是固定的。由于这些原因，我们建议你尽量在你的应用中使用LocalDate，包括存储、操作、业务规则的解读；不过如果你需要将程序的输入或者输出本地化，这时你应该使用ChronoLocalDate类。


261
超越Java

假设你被要求对一个大型的遗留软件系统进行升级，而且这个系统你之前并不是非常了解
稍有理智的外包Java程序员只会依赖如下这种言不由衷的格言做决定，“搜索一下代码中有没有使用synchronized关键字，如果有就直接拒绝（由此我们可以了解修复并发导致的缺陷有多困难），否则进一步看看系统结构的复杂程度”。

如果你喜欢无状态的行为（即你处理Stream的流水线中的函数不会由于需要等待从另一个方法中读取变量，或者由于需要写入的变量同时有另一个方法正在写而发生中断），
Java8中新增的Stream提供了强大的技术支撑，让我们无需担心锁引起的各种问题，充分发掘系统的并发能力。


无法预知的变量修改问题，都源于共享的数据结构被你所维护的代码
中的多个方法读取和更新。假设几个类同时都保存了指向某个列表的引用。
那么到底谁对这个列表拥有所属权呢？
如果一个类对它进行了修改，会发生什么情况？
其他的类预期会发生这种变化吗？
其他的类又如何得知列表发生了修改呢？
我们需要通知使用该列表的所有类这一变化吗？
抑或是不是每个类都应该为自己准备一份防御式的数据备份以备不时之需呢？

由于使用了可变的共享数据结构，我们很难追踪你程序的各个组成部分所发生的变化。

假设有这样一个系统，它不修改任何数据。维护这样的一个系统将是一个无以伦比的美梦，因为你不再会收到任何由于某些对象在某些地方修改了某个数据结构而导致的意外报告。如果一个方法既不修改它内嵌类的状态，也不修改其他对象的状态，使用return返回所有的计算结果，那么我们称其为纯粹的或者无副作用的。

哪些因素会造成副作用,副作用就是函数的效果已经超出了函数自身的范畴
1除了构造器内的初始化操作，对类中数据结构的任何修改，包括字段的赋值操作（一个典型的例子是setter方法）。
2抛出一个异常。
3进行输入/输出操作，比如向一个文件写数据。

从另一个角度来看“无副作用”的话，我们就应该考虑不可变对象。不可变对象是这样一种对象，它们一旦完成初始化就不会被任何方法修改状态。这意味着一旦一个不可变对象初始化完毕，它永远不会进入到一个无法预期的状态。你可以放心地共享它，无需保留任何副本，并且由于它们不会被修改，还是线程安全的。

“无副作用”这个想法的限制看起来很严苛，你甚至可能会质疑是否有真正的生产系统能够以这种方式构建。我们希望结束本章的学习之后，你能够确信这一点。一个好消息是，如果构成系统的各个组件都能遵守这一原则，该系统就能在完全无锁的情况下，使用多核的并发机制，因为任何一个方法都不会对其他的方法造成干扰。此外，这还是一个让你了解你的程序中哪些部分是相互独立的非常棒的机会。
这些思想都源于函数式编程，我们在下一节会进行介绍。但是在开始之前，让我们先看看函数式编程的基石声明式编程吧。


一般通过编程实现一个系统，有两种思考方式。
一种专注于如何实现，比如：“首先做这个，紧接着更新那个，然后……“
这种“如何做”风格的编程非常适合经典的面向对象编程，有些时候我们也称之为“命令式”编程，因为它的特点是它的指令和计算机底层的词汇非常相近，比如赋值、条件分支以及循环，

另一种方式则更加关注要做什么
使用StreamAPI你可以指定下面这样的查询这个查询把最终如何实现的细节留给了函数库。我们把这种思想称之为内部迭代。它的巨大优势在于你的查询语句现在读起来就像是问题陈述，由于采用了这种方式，我们马上就能理解它的功能，比理解一系列的命令要简洁得多。

。。有什么用/区别？把查询封装成一个方法，不就可以了。。streamAPI内部实现更难以理解吧。。官方api和自己的api的区别吧。自己的不算api，无法通用。
。。无副作用！。。

我们很容易想象这样一个方法，它接受一个整型和一个浮点型参数，返回一个浮点型的结果――它也有副作用，随着调用次数的增加，它会不断地更新共享变量
。。更新共享变量，有副作用。

在函数式编程的上下文中，一个“函数”对应于一个数学函数：它接受零个或多个参数，生成一个或多个结果，并且不会有任何副作用。

无法用Java语言以纯粹的函数式来完成一个程序的。比如，Java的I/O模型就包含了带副作用的方法（调用Scanner.nextLine就有副作用，它会从一个文件中读取一行，通常情况两次调用的结果完全不同）。
。。这。。

不过，你还是有可能为你系统的核心组件编写接近纯粹函数式的实现。在Java语言中，如果你希望编写函数式的程序，首先需要做的是确保没有人能觉察到你代码的副作用，这也是函数式的含义

假设这样一个函数或者方法，它没有副作用，进入方法体执行时会对一个字段的值加一，退出方法体之前会对该字段减一。对一个单线程的程序而言，这个方法是没有副作用的，可以看作函数式的实现
如果另一个线程可以查看该字段的值――或者更糟糕的情况，该方法会同时被多个线程并发调用――那么这个方法就不能称之为函数式的实现了
当然，你可以用加锁的方式对方法的方法体进行封装，掩盖这一问题，你甚至可以再次声称该方法符合函数式的约定。但是，这样做之后，你就失去了在你的多核处理器的两个核上并发执行两个方法调用的能力。它的副作用对程序可能是不可见的，不过对于程序员你而言是可见的，因为程序运行的速度变慢了！


我们的准则是，被称为“函数式”的函数或方法都只能修改本地变量。除此之外，它引用的对象都应该是不可修改的对象。
通过这种规定，我们期望所有的字段都为final类型，所有的引用类型字段都指向不可变对象。后续的内容中，你会看到我们实际也允许对方法中全新创建的对象中的字段进行更新，不过这些字段对于其他对象都是不可见的，也不会因为保存对后续调用结果造成影响。

要成为真正的函数式程序还有一个附加条件，不过它在最初时不太为大家所重视。要被称为函数式，函数或者方法不应该抛出任何异常

如果不使用异常，你该如何对除法这样的函数进行建模呢？答案是请使用Optional<T>类型
。。但是异常可以中断程序，但是Optional，还得自己写错误处理。

从实际操作的角度出发，你可以选择在本地局部地使用异常，避免通过接口将结果暴露给其他方法，这种方式既取得了函数式的优点，又不会过度膨胀代码。

作为函数式的程序，你的函数或方法调用的库函数如果有副作用，你必须设法隐藏它们的非函数式行为，否则就不能调用这些方法
换句话说，你需要确保它们对数据结构的任何修改对于调用者都是不可见的，你可以通过首次复制，或者捕获任何可能抛出的异常实现这一目的


“没有可感知的副作用”（不改变对调用者可见的变量、不进行I/O、不抛出异常）的这些限制都隐含着引用透明性。如果一个函数只要传递同样的参数值，总是返回同样的结果，那这个函数就是引用透明的

String.replace方法就是引用透明的，因为像"raoul".replace('r','R')这样的调用总是返回同样的结果（replace方法返回一个新的字符串，用小写的r替换掉所有大写的R），而不是更新它的this对象，所以它可以被看成函数式的。
。。就是内部copy，然后对副本进行操作，然后return副本。
。。cpp还特意弄了个&，来让操作直接作用到原对象。。
。。java的形参必然是&。。。

换句话说，函数无论在何处、何时调用，如果使用同样的输入总能持续地得到相同的结果，就具备了函数式的特征。。这也解释了我们为什么不把Random.nextInt看成函数式的方法

268
Java语言中，关于引用透明性还有一个比较复杂的问题。假设你对一个返回列表的方法调用了两次。这两次调用会返回内存中的两个不同列表，不过它们包含了相同的元素。如果这些列表被当作可变的对象值（因此是不相同的），那么该方法就不是引用透明的。如果你计划将这些列表作为单纯的值（不可修改），那么把这些值看成相同的是合理的，这种情况下该方法是引用透明的。通常情况下，在函数式编程中，你应该选择使用引用透明的函数。


让我们从解决一个示例函数式的编程练习题入手：给定一个列表List<value>，比如{1, 4, 9}，构造一个List<List<Integer>>，它的成员都是类表{1, 4, 9}的子集――我们暂时不考虑元素的顺序。{1, 4, 9}的子集是{1, 4, 9}、{1, 4}、{1, 9}、{4, 9}、{1}、{4}、{9}以及{}。

static List<List<Integer>> subsets(List<Integer> list) {
	if (list.isEmpty()) {
		List<List<Integer>> ans = new ArrayList<>();
		ans.add(Collections.emptyList());
		return ans;
	}
	Integer first = list.get(0);
	List<Integer> rest = list.subList(1,list.size());
	List<List<Integer>> subans = subsets(rest);
	List<List<Integer>> subans2 = insertAll(first, subans);
	return concat(subans, subans2);
}
。。分成2部分，包含first，不包含first，然后不包含的部分递归，递归完成后这部分每个list都加入first
。。注释中有一种解法，利用二进制来表示数字（Java解决方案的代码分别对应于000,001,010,011,100,101,110,111）。
。。0 - (2^n-1),就是所有解的二进制。
。。不知道这种解法比以前的递归，和现在这里的递归，哪种快。或者结合？

static List<List<Integer>> insertAll(Integer first,
							List<List<Integer>> lists) {
	List<List<Integer>> result = new ArrayList<>();
	for (List<Integer> list : lists) {
		List<Integer> copyList = new ArrayList<>();
		copyList.add(first);
		copyList.addAll(list);
		result.add(copyList);
	}
	return result;
}
。。不能直接修改形参。

提供了一个简单的实现，但是我们希望你不要这样使用（我们展示这段代码的目的只是为了便于你比较不同的编程风格）。
static List<List<Integer>> concat(List<List<Integer>> a,
							List<List<Integer>> b) {
	a.addAll(b);
	return a;
}
我们真正建议你采用的是下面这种方式：
static List<List<Integer>> concat(List<List<Integer>> a,
							List<List<Integer>> b) {
	List<List<Integer>> r = new ArrayList<>(a);
	r.addAll(b);
	return r;
}
。。但是第一种更快吧。

第二个版本的concat是纯粹的函数式。虽然它在内部会对对象进行修改（向列表r添加元素），但是它返回的结果基于参数却没有修改任何一个传入的参数。与此相反，第一个版本基于这样的事实，执行完concat(subans, subans2)方法调用后，没人需要再次使用subans的值。

。。确实，需要没有人再使用subans，这样便于扩展。。不过可以在concat之前就使用subans，使用时，必须没有副作用，不然subans一改，结果就改了。
。。确实，后续的改进才是大头。慢不了多少，但是可以让改进更快且不容易出错。

请牢记：考虑编程问题时，采用函数式的方法，关注函数的输入参数以及输出结果（即你希望做什么），通常比设计阶段的早期就考虑如何做、修改哪些东西要卓有成效得多。


纯粹的函数式编程语言通常不包含像while或者for这样的迭代构造器。为什么呢？因为这种类型的构造器经常隐藏着陷阱，诱使你修改对象
很多情况下循环还是非常有用的。我们在前面的介绍中已经声明过，如果没有人能感知的话，函数式也允许进行变更，这意味着我们可以修改局部变量。
Iterator<Apple> it = apples.iterator();
while (it.hasNext()) {
	Apple apple = it.next();
	// ...
}
这并不是问题，因为改变发生时，这些变化（包括使用next方法对迭代器状态的改变以及在while循环内部对apple变量的赋值）对于方法的调用方是不可见的。

但是，如果使用for-each循环，比如像下面这个搜索算法就会带来问题，因为循环体会对调用方共享的数据结构进行修改：
public void searchForGold(List<String> l, Stats stats){
	for(String s: l){
		if("gold".equals(s)){
			stats.incrementFor("gold");
		}
	}
}

对函数式而言，循环体带有一个无法避免的副作用：它会修改stats对象的状态，而这和程序的其他部分是共享的

由于这个原因，纯函数式编程语言，比如Haskell直接去除了这样的带有副作用的操作！之后你该如何编写程序呢？比较理论的答案是每个程序都能使用无需修改的递归重写，通过这种方式避免使用迭代

使用递归，你可以消除每步都需更新的迭代变量。一个经典的教学问题是用迭代的方式或者递归的方式（假设输入值大于1）编写一个计算阶乘的函数（参数为正数），

// 迭代式
static int factorialIterative(int n) {
	int r = 1;
	for (int i = 1; i <= n; i++) {
		r *= i;
	}
	return r;
}

// 递归式
static long factorialRecursive(long n) {
	return n == 1 ? 1 : n * factorialRecursive(n-1);
}

// stream
static long factorialStreams(long n){
	return LongStream.rangeClosed(1, n)
				.reduce(1, (long a, long b) -> a * b);
}

通常而言，执行一次递归式方法调用的开销要比迭代执行单一机器级的分支指令大不少
还容易遇到StackOverflowError

函数式语言提供了一种方法解决这一问题：尾调优化（tail-call optimization）。基本的思想是你可以编写阶乘的一个迭代定义，不过迭代调用发生在函数的最后（所以我们说调用发生在尾部）。这种新型的迭代调用经过优化后执行的速度快很多。
static long factorialTailRecursive(long n) {
	return factorialHelper(1, n);
}
static long factorialHelper(long acc, long n) {
	return n == 1 ? acc : factorialHelper(acc * n, n-1);
}
方法factorialHelper属于“尾?递”类型的函数，原因是递归调用发生在方法的最后。对比我们前文中factorialRecursive方法的定义，这个方法的最后一个操作是乘以n，从而得到递归调用的结果。
这种形式的递归是非常有意义的，现在我们不需要在不同的栈帧上保存每次递归计算的中间值，编译器能够自行决定复用某个栈帧进行计算。实际上，在factorialHelper的定义中，立即数（阶乘计算的中间结果）直接作为参数传递给了该方法。再也不用为每个递归调用分配单独的栈帧用于跟踪每次递归调用的中间值――通过方法的参数能够直接访问这些值。

图272页
之前的递归是每次递归一个栈帧，后面那个是在一个栈帧中多次递归。
。。有可能，因为前面的还需要把递归后的结果*n,而后面那个是直接返回递归结果。。也不一定是一个栈帧中多次递归，应该可能是递归return时栈帧删除，然后新建下一个递归的栈帧。这样系统中就只存在一个栈帧。不会stackoverflow。

坏消息是，目前Java还不支持这种优化。但是使用相对于传统的递归，“尾递”可能是更好的一种方式，因为它为最终实现编译器优化开启了一扇门。
。。。。。。。。。。。。。。。。

很多的现代JVM语言，比如Scala和Groovy都已经支持对这种形式的递归的优化，最终实现的效果和迭代不相上下。


使用Java8进行编程时，我们有一个建议，你应该尽量使用Stream取代迭代操作，从而避免变化带来的影响。
此外，如果递归能让你以更精炼，并且不带任何副作用的方式实现算法，你就应该用递归替换迭代。
实际上，我们看到使用递归实现的例子更加易于阅读，同时又易于实现和理解（比如，我们在前文中展示的子集的例子），大多数时候编程的效率要比细微的执行时间差异重要得多。
。。递归易于理解。。。我。。。


275
chatper 14
函数式编程的技巧

高阶函数、科里化、持久化数据结构、延迟列表、模式匹配、具备引用透明性的缓存，以及结合器。


能够像普通变量一样使用的函数称为一等函数（first-class function）。这是Java8补充的全新内容：通过::操作符，你可以创建一个方法引用，像使用函数值一样使用方法，也能使用Lambda表达式（比如，(int x) -> x + 1）直接表示方法的值。Java8中使用下面这样的方法引用将一个方法引用保存到一个变量是合理合法的：
Function<String, Integer> strToInt = Integer::parseInt;

静态方法Comparator.comparing的使用
Comparator<Apple> c = comparing(Apple::getWeight);
comparing方法接受一个函数作为参数，同时返回另一个函数


能满足下面任一要求就可以被称为高阶函数（higher-order function）：
? 接受至少一个函数作为参数
? 返回的结果是一个函数
。。处理/输出函数的函数,高阶函数。

接受一个函数作为参数（比如，(Double x) -> x \* x），又返回一个函数作为结果（这个例子中返回值是(Double x) -> 2 * x），你可以用不同的方式实现类型定义，如下所示：
Function<Function<Double,Double>, Function<Double,Double>>

我们把它定义成Function类型（最左边的Function），目的是想显式地向你确认可以将这个函数传递给另一个函数。但是，最好使用差异化的类型定义，函数签名如下：
Function<Double,Double> differentiate(Function<Double,Double> func)

其实二者说的是同一件事。


第7章中我们了解到传递给流操作的函数应该是无副作用的，否则会发生各种各样的问题（比如错误的结果，有时由于竞争条件甚至会产生我们无法预期的结果）。
这一原则在你使用高阶函数时也同样适用。编写高阶函数或者方法时，你无法预知会接收什么样的参数――一旦传入的参数有某些副作用，我们将会一筹莫展
一旦发生问题，你将很难理解程序中发生了什么
将所有你愿意接收的作为参数的函数可能带来的副作用以文档的方式记录下来是一个不错的设计原则，最理想的情况下你接收的函数参数应该没有任何副作用！

277
科里化：它是一种可以帮助你模块化函数、提高代码重用性的技术。

应用程序通常都会有国际化的需求，将一套单位转换到另一套单位是经常碰到的问题。

单位转换通常都会涉及转换因子以及基线调整因子的问题

将摄氏度转换到华氏度的公式是CtoF(x) = x*9/5 + 32。

所有的单位转换几乎都遵守下面这种模式：
(1) 乘以转换因子
(2) 如果需要，进行基线调整

可以使用下面这段通用代码表达这一模式：
static double converter(double x, double f, double b) {
	return x * f + b;
}
这里x是你希望转换的数量，f是转换因子，b是基线值。
转换因子和基线值并不是每种转换都必须的。(公里-英里不需要基线值)
converter方法时都使用3个参数，但是每次都提供转换因子和基准比较繁琐，并且你还极有可能输入错误。

也可以为每一个应用编写一个新方法，不过这样就无法对底层的逻辑进行复用。


这里我们提供一种简单的解法，它既能充分利用已有的逻辑，又能让converter针对每个应用进行定制。你可以定义一个“工厂”方法，它生产带一个参数的转换方法，我们希望借此来说明科里化
static DoubleUnaryOperator curriedConverter(double f, double b){
	return (double x) -> x * f + b;
}
你要做的只是向它传递转换因子和基准值（f和b），它会不辞辛劳地按照你的要求返回一个方法（使用参数x）

DoubleUnaryOperator convertCtoF = curriedConverter(9.0/5, 32);
DoubleUnaryOperator convertUSDtoGBP=curriedConverter(0.6, 0);
DoubleUnaryOperator convertKmtoMi=curriedConverter(0.6214, 0);

由于DoubleUnaryOperator定义了方法applyAsDouble，你可以像下面这样使用你的converter：
double gbp = convertUSDtoGBP.applyAsDouble(1000);

科里化的理论定义
科里化是一种将具备2个参数（比如，x和y）的函数f转化为使用一个参数的函数g，并且这个函数的返回值也是一个函数，它会作为新函数的一个参数。后者的返回值和初始函数的返回值相同，即f(x,y) = (g(x))(y)。

。。科里化似乎只适合于：既可以写成所有参数都从形参获得的方法，有可以写成只有少部分参数从形参获得的方法。
。。部分参数是固定的，至少在一种假设(华氏转摄氏)下，部分参数是固定的。多种假设下，可以不通用。
。。不不不，现在的例子是科里化的一种。大部分科里化都是简单的抽取吧。毕竟抽取出新方法，是符合f(x,y) = (g(x))(y)的。
。。对，温度转换分为2部分，加法(乘法(x),y)。不过似乎不对。。科里化是返回函数的。。。
。。科里化是返回函数的。。科里化是返回函数的。。科里化是返回函数的
。。将流程/公式抽取出来。以便复用。


现在我们转而讨论函数式编程的另一个方面。如果你不能修改数据结构，还能用它们编程吗？
我们会探讨函数式编程中如何使用数据结构。这一主题有各种名称，比如函数式数据结构、不可变数据结构，不过最常见的可能还要算持久化数据结构（不幸的是，这一术语和数据库中的持久化概念有一定的冲突，数据库中它代表的是“生命周期比程序的执行周期更长的数据”）。

函数式方法不允许修改任何全局数据结构或者任何作为参数传入的参数。为什么呢？因为一旦对这些数据进行修改，两次相同的调用就很可能产生不同的结构――这违背了引用透明性原则，我们也就无法将方法简单地看作由参数到结果的映射。

例子是一个链表的node，连接两个链表时(A链的尾巴指向B链的头)，会导致链表原有信息的丢失。比如，长度，最后一个节点，这些信息都被修改了。
例子是火车旅行，这样丢失了原有的旅行信息。
class TrainJourney {
	public int price;
	public TrainJourney onward;
	public TrainJourney(int p, TrainJourney t) {
		price = p;
		onward = t;
	}
}

static TrainJourney link(TrainJourney a, TrainJourney b){
	if (a==null) return b;
	TrainJourney t = a;
	while(t.onward != null){
		t = t.onward;
	}
	t.onward = b;
	return a;
}

函数式编程解决这一问题的方法是禁止使用带有副作用的方法。如果你需要使用表示计算结果的数据结果，那么请
创建它的一个副本而不要直接修改现存的数据结构。
这一最佳实践也适用于标准的面向对象程序设计。

也存在着一些异议，比较常见的是认为这样做会导致过度的对象复制，有些程序员会说“我会记住那些有副作用的方法”或者“我会将这些写入文档”。但这些都不能解决问题，这些坑都留给了接受代码维护工作的程序员。

static TrainJourney append(TrainJourney a, TrainJourney b){
	return a==null ? b : new TrainJourney(a.price, append(a.onward, b));
}
。。。cooooooooool。。。
它返回的是一个由n+m个元素组成的序列，这个序列的前n个元素是新创建的，而后m个元素和TrainJourney对象b是共享的
用户需要确保不对append操作的结果进行修改，因为一旦这样做了，作为参数传入的TrainJourney对象序列b就可能被破坏。
..确实，只需要复制前半段。.即使以后再append也没有问题的。

281
另一个使用Tree的例子
二叉查找树，通过key来做分叉。
。。书上说的是，保存名字和年龄。

class Tree {
	private String key;
	private int val;
	private Tree left, right;
	public Tree(String k, int v, Tree l, Tree r) {
		key = k; val = v; left = l; right = r;
	}
}

class TreeProcessor {
	public static int lookup(String k, int defaultval, Tree t) {
		if (t == null) return defaultval;
		if (k.equals(t.key)) return t.val;
		return lookup(k, defaultval,
				k.compareTo(t.key) < 0 ? t.left : t.right);
	}
	// 处理Tree的其他方法
}

更新与某个键对应的值，简化起见，我们假设键已经存在于这个树中了
public static void update(String k, int newval, Tree t) {
	if (t == null) { /* 应增加一个新的节点 */ }
	else if (k.equals(t.key)) t.val = newval;
	else update(k, newval, k.compareTo(t.key) < 0 ? t.left : t.right);
}

增加一个新的节点会复杂很多；最简单的方法是让update直接返回它刚遍历的树（除非你需要加入一个新的节点，否则返回的树结构是不变的）
public static Tree update(String k, int newval, Tree t) {
	if (t == null)
		t = new Tree(k, newval, null, null);
	else if (k.equals(t.key))
		t.val = newval;
	else if (k.compareTo(t.key) < 0)
		t.left = update(k, newval, t.left);
	else
		t.right = update(k, newval, t.right);
	return t;
}
这两个版本的update都会对现有的树进行修改，这意味着使用树存放映射关系的所有用户都会感知到这些修改。


采用函数式的方法
你需要为新的键?值对创建一个新的节点，除此之外你还需要创建从树的根节点到新节点的路径上的所有节点。通常，代价并不大，平衡树深度为d，只需要新建d个节点就能满足。
。。只需要root到新节点。新节点子节点还是用原来的。

public static Tree fupdate(String k, int newval, Tree t) {
	return (t == null) ?
		new Tree(k, newval, null, null) :
		
		k.equals(t.key) ?
			new Tree(k, newval, t.left, t.right) :
			
			k.compareTo(t.key) < 0 ?
				new Tree(t.key, t.val, fupdate(k,newval, t.left), t.right) :
				new Tree(t.key, t.val, t.left, fupdate(k,newval, t.right));
}
。。t是原树的节点。
。。还有最后2行。fupdate返回作为left，right。


通过一行语句进行的条件判断，没有采用if-then-else这种方式，目的是希望强调一个思想，那就是该函数体仅包含一条语句，没有任何副作用
。。一行 != 没有副作用吧。。。

你也可以按照自己的习惯，使用if-then-else这种方式，在每一个判断结束处使用return返回。

方法update有这样一种假设，即每一个update的用户都希望共享同一份数据结构，也希望能了解程序任何部分所做的更新。
因此，无论任何时候，只要你使用非函数式代码向树中添加某种形式的数据结构，请立刻创建它的一份副本，因为谁也不知道将来的某一天，某个人会突然对它进行修改，这一点非常重要（不过也经常被忽视）
。。意思应该是，任何用户都可以更新树，所以需要自己保存下新增/修改的数据，免得被别人覆盖掉而丢失数据。。。不过只要保证原子操作，并且也说了是所有用户都希望共享一份数据，那么不需要保存自己的数据吧。

fupdate是纯函数式的。它会创建一个新的树，并将其作为结果返回，通过参数的方式实现共享
。。指共享需要通过参数传递把root传过去，而不是只有一棵树，不需要传递。


这种函数式数据结构通常被称为持久化的――数据结构的值始终保持一致，不受其他部分变化的影响

我们了解到fupdate可能有更加高效的方式：基于“不对现存结构进行修改”规则，对仅有细微差别的数据结构（比如，用户A看到的树结构与用户B看到的就相差不多），我们可以考虑对这些通用数据结构使用共享存储。
可以凭借编译器，将Tree类的字段key、val、left以及right声明为final执行。
。。话说，final TreeNode x; 那x只能在构造器里初始化了啊。
。。final的指针不变，但是指向的对象中的内容是可变的，当然这里对象中的内容也被final了。

你可能会说：“我希望对树结构的更新对某些用户可见（当然，这句话的潜台词是其他人看不到这些更新）。
两种方式：
第一种是典型的Java解决方案（对对象进行更新时，你需要特别小心，慎重地考虑是否需要在改动之前保存对象的一份副本）
另一种是函数式的解决方案：逻辑上，你在做任何改动之前都会创建一份新的数据结构（这样一来就不会有任何的对象发生变更），只要确保按照用户的需求传递给他正确版本的数据结构就好了。这一想法甚至还可以通过API直接强制实施


Stream 的延迟计算

由于各种各样的原因，包括实现时的效率考量，Java 8的设计者们在将Stream引入时采取了比较特殊的方式。其中一个比较显著的局限是，你无法声明一个递归的Stream，因为Stream仅能使用一次

可以用下面这种方式计算得出由质数构成的Stream：
public static Stream<Integer> primes(int n) {
	return Stream.iterate(2, i -> i + 1)
		.filter(MyMathUtils::isPrime)
		.limit(n);
}
public static boolean isPrime(int candidate) {
	int candidateRoot = (int) Math.sqrt((double) candidate);
	return IntStream.rangeClosed(2, candidateRoot)
		.noneMatch(i -> candidate % i == 0);
}
不过这一方案看起来有些笨拙：你每次都需要遍历每个数字，查看它能否被候选数字整除（实际上，你只需要测试那些已经被判定为质数的数字）。

284
。。。中间有个例子。。

一旦你对Stream执行一次终端操作调用，它就永久地终止了！


Java 8的Stream以其延迟性而著称。
当你向一个Stream发起一系列的操作请求时，这些请求只是被一一保存起来。只有当你向Stream发起一个终端操作时，才会实际地进行计算。
这种设计具有显著的优点，特别是你需要对Stream进行多个操作时（你有可能先要进行filter操作，紧接着做一个map，最后进行一次终端操作reduce）；这种方式下Stream只需要遍历一次，不需要为每个操作遍历一次所有的元素。

利用Supplier暂时阻止对象出现在内存中。

class LazyList<T> implements MyList<T>{
	final T head;
	final Supplier<MyList<T>> tail;
	public LazyList(T head, Supplier<MyList<T>> tail) {
		this.head = head;
		this.tail = tail;
	}
	public T head() {
		return head;
	}
	public MyList<T> tail() {
		return tail.get();
	}
	public boolean isEmpty() {
		return false;
	}
}

public static LazyList<Integer> from(int n) {
	return new LazyList<Integer>(n, () -> from(n+1));
}

LazyList<Integer> numbers = from(2);
int two = numbers.head();
int three = numbers.tail().head();
int four = numbers.tail().tail().head();
System.out.println(two + " " + three + " " + four);


能否利用我们目前已经做的去生成一个自定义的质数延迟列表
将之前使用StreamAPI的代码转换成使用我们新版的LazyList，它看起来会像下面这段代码：
public static MyList<Integer> primes(MyList<Integer> numbers) {
	return new LazyList<>(
		numbers.head(),
		() -> primes(
				numbers.tail()
					.filter(n -> n % numbers.head() != 0)
			)
	);
}

public MyList<T> filter(Predicate<T> p) {
	return isEmpty() ?
		this :
		p.test(head()) ?
			new LazyList<>(head(), () -> tail().filter(p)) :
			tail().filter(p);
}

头三个质数：
LazyList<Integer> numbers = from(2);
int two = primes(numbers).head();
int three = primes(numbers).tail().head();
int five = primes(numbers).tail().tail().head();
System.out.println(two + " " + three + " " + five);

。。每次都要从头开始tail的，
。。无法理解。
。。2，3。3之后filter，只能保证下一个不能被3整除，没办法保证不被2整除吧。


还有一个问题就是性能。
我们很容易得出结论，延迟操作的性能会比提前操作要好――仅在程序需要时才计算值和数据结构当然比传统方式下一次性地创建所有的值（有时甚至比实际需求更多的值）要好。
不过，实际情况并非如此简单。完成延迟操作的开销，比如 LazyList中每个元素之间执行额外Suppliers调用的开销，有可能超过你猜测会带来的好处，除非你仅仅只访问整个数据结构的10%，甚至更少。
最后，还有一种微妙的方式会导致你的LazyList并非真正的延迟计算。如果你遍历LazyList中的值，比如from(2)，可能直到第10个元素，这种方式下，它会创建每个节点两次，最终创建20个节点，而不是10个。这几乎不能被称为延迟计算。问题在于每次实时访问LazyList的元素时，tail中的Supplier都会被重复调用；你可以设定tail中的Supplier方法仅在第一次实时访问时才执行调用，从而修复这一问题――计算的结果会缓存起来――效果上对列表进行了增强。要实现这一目标，你可以在LazyList的定义中添加一个私有的Optional<LazyList<T>>类型字段alreadyComputed，tail方法会依据情况查询及更新该字段的值。纯函数式语言Haskell就是以这种方式确保它所有的数据结构都恰当地进行了延迟。


我们推荐的原则是将延迟数据结构作为你编程兵器库中的强力武器。如果它们能让程序设计更简单，就尽量使用它们。如果它们会带来无法接受的性能损失，就尝试以更加传统的方式重新实现它们。



函数式编程中还有另一个重要的方面，那就是（结构式）模式匹配。不要将这个概念和正则表达式中的模式匹配相混淆。

数学公式可以通过下面的方式进行定义：
f(0) = 1
f(n) = n*f(n-1) otherwise
不过在Java语言中，你只能通过if-then-else语句或者switch语句实现。随着数据类型变得愈加复杂，需要处理的代码（以及代码块）的数量也在迅速攀升。

为了说明，我们先看一个树结构，你希望能够遍历这一整棵树。我们假设使用一种简单的数学语言，它包含数字和二进制操作符：
class Expr { ... }
class Number extends Expr { int val; ... }
class BinOp extends Expr { String opname; Expr left, right; ... }

假设你需要编写方法简化一些表达式。比如，5 + 0可以简化为5。使用我们的域语言，new BinOp("+", new Number(5), new Number(0))可以简化为Number(5)。

你可以像下面这样遍历Expr结构：
Expr simplifyExpression(Expr expr) {
		if (expr instanceof BinOp
				&& ((BinOp)expr).opname.equals("+"))
				&& ((BinOp)expr).right instanceof Number
				&& ... // 变得非常笨拙
				&& ... ) {
			return (Binop)expr.left;
	}
...
}
你可以预期这种方式下代码会迅速地变得异常丑陋，难于维护。

Java语言中还有另一种方式可以解包数据类型，那就是使用访问者（Visitor）设计模式
本质上，使用这种方法你需要创建一个单独的类，这个类封装了一个算法，可以“访问”某种数据类型
访问者类接受某种数据类型的实例作为输入。它可以访问该实例的所有成员

通过这个例子我们能了解这一方法是如何工作的。首先，你需要向BinOp添加一个accept方法，它接受一个SimplifyExprVisitor作为参数，并将自身传递给它（你还需要为Number添加一个类似的方法）：

class BinOp extends Expr{
...
	public Expr accept(SimplifyExprVisitor v){
		return v.visit(this);
	}
}

SimplifyExprVisitor现在就可以访问BinOp对象并解包其中的内容了：
public class SimplifyExprVisitor {
	...
	public Expr visit(BinOp e){
	if("+".equals(e.opname) && e.right instanceof Number && …){
		return e.left;
	}
		return e;
	}
}
。。靠Visitor的名字来区分动作。class add implements Visitor.
..class sub implements Visitor.
。。并且访问者只有一个public方法。毕竟visit是写死在代码里的。

。。这种和再写一个util，单独处理，似乎没什么区别啊。
。。可能访问者更私有。

通过一个名为模式匹配的特性，我们能以更简单的方案解决问题。这种特性目前在Java语言中暂时还不提供

。。。好难。。。。

在Scala程序设计语言中（我们采用Scala的原因是它的语法与Java非常接近），你可以利用下面的这段代码解析表达式：
def simplifyExpression(expr: Expr): Expr = expr match {
	case BinOp("+", e, Number(0)) => e // 加0
	case BinOp("*", e, Number(1)) => e // 乘以1
	case BinOp("/", e, Number(1)) => e // 除以1
	case _ => expr // 不能简化expr
}
。。是指一个公式的形参满足，+，e，0，就直接简化为e?，BinOp都简化掉。？

Scala的语法
Expression match { case Pattern => Expression ... }
和Java的语法非常相似：
switch (Expression) { case Constant : Statement ... }

Scala的通配符判断和Java中的default:扮演这同样的角色。这二者之间主要的语法区别在于Scala是面向表达式的，而Java则更多地面向语句，不过，对程序员而言，它们主要的区别是Java中模式的判断标签被限制在了某些基础类型、枚举类型、封装基础类型的类以及String类型。
。。果然函数是第一公民，能直接简化。。

让我们看看Scala的模式匹配特性提供的匹配表达式有多么丰富
def simplifyExpression(expr: Expr): Expr = expr match {
	case BinOp("+", e, Number(0)) => e
	...

意思是：“检查expr是否为BinOp，抽取它的三个组成部分（opname、left、right），紧接着对这些组成部分分别进行模式匹配――第一个部分匹配String+，第二个部分匹配变量e（它总是匹配），第三个部分匹配模式Number(0)。

换句话说，Scala（以及很多其他的函数式语言）中的模式匹配是多层次的。我们使用Java8的Lambda表达式进行的模式匹配模拟只会提供一层的模式匹配；以前面的这个例子而言，这意味着它只能覆盖BinOp(op, l, r)或者Number(n)这种用例，无法顾及BinOp("+", e, Number(0))。

由于你选择使用Lambda，原则上你的代码里不应该使用if-then-else。你可以使用方法调用
myIf(condition, () -> e1, () -> e2);
取代condition ? e1 : e2这样的代码。

static <T> T myIf(boolean b, Supplier<T> truecase, Supplier<T> falsecase) {
	return b ? truecase.get() : falsecase.get();
}

正常情况下用这种方式会增加代码的复杂度，让它变得愈加晦涩难懂，因为用if-then-else就已经能非常顺畅地完成这一任务，这么做似乎有些杀鸡用牛刀的嫌疑。不过，我们也注意到，Java的switch和if-then-else无法完全实现模式匹配的思想，而Lambda表达式能以简单的方式实现单层的模式匹配――对照使用if-then-else链的解决方案，这种方式要简洁得多。

Expr类有两个子类，分别为BinOp和Number，你可以定义一个方法patternMatchExpr（同样，我们在这里会使用泛型T，用它表示模式匹配的结果类型）：
interface TriFunction<S, T, U, R>{
	R apply(S s, T t, U u);
}
static <T> T patternMatchExpr(
			Expr e,
			TriFunction<String, Expr, Expr, T> binopcase,
			Function<Integer, T> numcase,
			Supplier<T> defaultcase) {
	return
	(e instanceof BinOp) ?
		binopcase.apply(((BinOp)e).opname, ((BinOp)e).left,
									((BinOp)e).right) :
	(e instanceof Number) ?
			numcase.apply(((Number)e).val) :
			defaultcase.get();
}
最终的结果是，方法调用
patternMatchExpr(e, (op, l, r) -> {return binopcode;},
			(n) -> {return numcode;},
			() -> {return defaultcode;});

会判断e是否为BinOp类型（如果是，会执行binopcode方法，它能够通过标识符op、l和r访问BinOp的字段），是否为Number类型（如果是，会执行numcode方法，它可以访问n的值）。这个方法还可以返回defaultcode，如果有人在将来某个时刻创建了一个树节点，它既不是BinOp类型，也不是Number类型，那就会执行这部分代码。

下面这段代码通过简化的加法和乘法表达式展示了如何使用patternMatchExpr。

public static Expr simplify(Expr e) {
	TriFunction<String, Expr, Expr, Expr> binopcase =
	(opname, left, right) -> {
		if ("+".equals(opname)) {
			if (left instanceof Number && ((Number) left).val == 0) {
				return right;
			}
			if (right instanceof Number && ((Number) right).val == 0) {
				return left;
			}
		}
		if ("*".equals(opname)) {
			if (left instanceof Number && ((Number) left).val == 1) {
				return right;
			}
			if (right instanceof Number && ((Number) right).val == 1) {
				return left;
			}
		}
		return new BinOp(opname, left, right);
	};
	Function<Integer, Expr> numcase = val -> new Number(val);
	Supplier<Expr> defaultcase = () -> new Number(0);
	return patternMatchExpr(e, binopcase, numcase, defaultcase);
}

你可以通过下面的方式调用简化的方法：
Expr e = new BinOp("+", new Number(5), new Number(0));
Expr match = simplify(e);
System.out.println(match);

缓存或记忆表
computeNumberOfNodes方法计算树形网络中给定区间内的节点数目，网络不会变化。

解决这一问题的一种比较标准的解决方案是使用记忆表（memoization）――为方法添加一个封装器，在其中加入一块缓存（比如，利用一个HashMap）――封装器被调用时，首先查看缓存，看请求的“（参数，结果）对”是否已经存在于缓存，如果已经存在，那么方法直接返回缓存的结果；否则，你会执行computeNumberOfNodes调用，不过从封装器返回之前，你会将新计算出的“（参数，结果）对”保存到缓存中

final Map<Range,Integer> numberOfNodes = new HashMap<>();
Integer computeNumberOfNodesUsingCache(Range range) {
	Integer result = numberOfNodes.get(range);
	if (result != null){
		return result;
	}
	result = computeNumberOfNodes(range);
	numberOfNodes.put(range, result);
	return result;
}

Java8改进了Map接口，提供了一个名为computeIfAbsent的方法处理这样的情况。
Integer computeNumberOfNodesUsingCache(Range range) {
	return numberOfNodes.computeIfAbsent(range,
						this::computeNumberOfNodes);
}

方法computeNumberOfNodesUsingCache是引用透明的（我们假设computeNumberOfNodes也是引用透明的）。
。。引用透明：相同的形参，总返回相同的结果。不修改形参。结果的内存地址一样。。反正就是外部不可见到修改。外部看不到副作用。

不过，事实上，numberOfNodes处于可变共享状态，并且HashMap也没有同步，这意味这该段代码不是线程安全的。如果多个核对numberOfNodes执行并发调用，即便不用HashMap，而是用（由锁保护的）Hashtable或者（并发无锁的）ConcurrentHashMap，可能都无法达到预期的性能，因为这中间又存在由于发现某个值不在Map中，需要将对应的“（参数，结果）对”插回到Map而引起的条件竞争。这意味着多个核上的进程可能算出的结果相同，又都需要将其加入到Map中。

我们能得到的最大收获可能是，一旦并发和可变状态的对象揉到一起，它们引起的复杂度要远超我们的想象，而函数式编程能从根本上解决这一问题。
当然，这也有一些例外，比如出于底层性能的优化，可能会使用缓存，而这可能会有一些影响。另一方面，如果不使用缓存这样的技巧，如果你以函数式的方式进行程序设计，那就完全不必担心你的方法是否使用了正确的同步方式，因为你清楚地知道它没有任何共享的可变状态。

使用不会改动的持久化数据结构时，t2和t3在逻辑上并没有差别。 对于这一点我们已经辩论了很长时间，不过最简单的概括可能是函数式编程通常不使用==（引用相等），而是使用equal对数据结构值进行比较，由于数据没有发生变更，所以这种模式下fupdate是引用透明的。
。。t2.t3就是一个方法返回的2个equals的对象。


函数式编程时编写高阶函数是非常普通而且非常自然的事。高阶函数接受两个或多个函数，并返回另一个函数，实现的效果在某种程度上类似于将这些函数进行了结合
术语结合器通常用于描述这一思想。Java8中的很多API都受益于这一思想，比如CompletableFuture类中的thenCombine方法。该方法接受两个CompletableFuture方法和一个BiFunction方法，返回另一个CompletableFuture方法。

下面这个方法就体现了函数组合（function composition）的思想：
static <A,B,C> Function<A,C> compose(Function<B,C> g, Function<A,B> f) {
	return x -> g.apply(f.apply(x));
}
它接受函数f和g作为参数，并返回一个函数，实现的效果是先做f，接着做g

你希望接受一个参数，并使用函数f连续地对它进行操作（比如n次），类似循环的效果。我们将你的操作命名为repeat，它接受一个参数f，f代表了一次迭代中进行的操作，它返回的也是一个函数，返回的函数会在n次迭代中执行。像下面这样一个方法调用
repeat(3, (Integer x) -> 2*x);
形成的效果是x ->(2*(2*(2*x)))或者x -> 8*x。

System.out.println(repeat(3, (Integer x) -> 2*x).apply(10));
输出的结果是80。

static <A> Function<A,A> repeat(int n, Function<A,A> f) {
	return n==0 ? x -> x
					: compose(f, repeat(n-1, f));
}


Scale&&Java

你希望在屏幕上打印输出下面这些内容：
Hello 2 bottles of beer
Hello 3 bottles of beer
Hello 4 bottles of beer
Hello 5 bottles of beer
Hello 6 bottles of beer

1. 命令式Scala
object Beer {
	def main(args: Array[String]){
		var n : Int = 2
		while( n <= 6 ){
			println(s"Hello ${n} bottles of beer")
			n += 1
		}
	}
}

通常而言，在Scala中声明非递归的方法时，不需要显式地返回类型，因为Scala会自动地替你推断生成一个。
你可以将对象声明中的方法看成静态的，这也是main方法的方法签名中并未显式地声明为静态的原因。

2. 函数式Scala
Java：
public class Foo {
	public static void main(String[] args) {
		IntStream.rangeClosed(2, 6)
			.forEach(n -> System.out.println("Hello " + n +
								" bottles of beer"));
	}
}

object Beer {
	def main(args: Array[String]){
		2 to 6 foreach { n => println(s"Hello ${n} bottles of beer") }
	}
}

2在这里并非原始数据类型，在Scala中它是一个类型为Int的对象。Scala语言里，任何事物都是对象

Scala语言中Int对象支持名为to的方法，它接受另一个Int对象，返回一个区间。所以，你还可以通过另一种方式实现这一语句，即2.to(6)。

这里Lambda表达式的语法和Java8也非常类似，区别是箭头的表示用=>替换了->

基础数据结构：List、Set、Map、Tuple、Stream 以及Option

在Scala中创建集合是非常简单的，这主要归功于它对简洁性的一贯坚持。比如，创建一个Map，你可以用下面的方式：
val authorsToAge = Map("Raoul" -> 23, "Mario" -> 40, "Alan" -> 53)

你可以编写val authorsToAge : Map[String, Int]这样的代码，显式地声明变量类型，不过Scala可以替你推断变量的类型（请注意，即便如此，代码依旧是静态检查的！所有的变量在编译时都具有确定的类型）。

关键字val表明变量是只读的，并由此不能被赋值（就像Java中声明为final的变量一样）。而关键字var表明变量是可以读写的。

你可以用同样的方式轻松地创建List（一种单向链表）或者Set（不带冗余数据的集合），如下所示：
val authors = List("Raoul", "Mario", "Alan")
val numbers = Set(1, 1, 2, 3, 5, 8)
这里的变量authors包含3个元素，而变量numbers包含5个元素。

Scala的集合有一个重要的特质我们应该牢记在心，那就是我们之前创建的集合在默认情况下都是只读的。这意味着它们从创建开始就不能修改。这是一种非常有用的特性，因为有了它，你知道任何时候访问程序中的集合都会返回包含相同元素的集合。

Scala中的这些集合都是持久化的：更新一个Scala集合会生成一个新的集合，这个新的集合和之前版本的集合共享大部分的内容，最终的结果是数据尽可能地实现了持久化

val numbers = Set(2, 5, 3);
val newNumbers = numbers + 8
println(newNumbers)		// (2, 5, 3, 8)
println(numbers)		// (2, 5, 3)

原始Set对象中的数字没有发生变更。实际的效果是该操作创建了一个新的Set，并向其中加入了一个新的元素。

.........skip...a lot of ....

闭包是一个函数实例，它可以不受限制地访问该函数的非本地变量。
不过Java8中的Lambda表达式自身带有一定的限制：它们不能修改定义Lambda表达式的函数中的本地变量值。这些变量必须隐式地声明为final。这些背景知识有助于我们理解“Lambda避免了对变量值的修改，而不是对变量的访问”。
与此相反，Scala中的匿名函数可以取得自身的变量，但并非变量当前指向的变量值
def main(args: Array[String]) {
	var count = 0
	val inc = () => count+=1
	inc()
	println(count)			// 1
	inc()
	println(count)			// 2
}
。。匿名函数可以取得自身的变量，自身是指匿名函数的调用者。而不是匿名函数，。。。

不过在Java中，下面的这段代码会遭遇编译错误，因为count隐式地被强制定义为final：
public static void main(String[] args) {
	int count = 0;
	Runnable inc = () -> count+=1;
	inc.run();
	System.out.println(count);
	inc.run();
}


科里化的技术：带有两个参数（比如x和y）的函数f可以看成一个仅接受一个参数的函数g，函数g的返回值也是一个仅带一个参数的函数。这一定义可以归纳为接受多个参数的函数可以转换为多个接受一个参数的函数。换句话说，你可以将一个接受多个参数的函数切分为一系列接受该参数列表子集的函数。Scala为此特别提供了一个构造器，帮助你更加轻松地科里化一个现存的方法。

Java一个简单的函数对两个正整数做乘法运算
static int multiply(int x, int y) {
	return x * y;
}
int r = multiply(2, 10);

static Function<Integer, Integer> multiplyCurry(int x) {
	return (Integer y) -> x * y;
}
由multiplyCurry返回的函数会捕获x的值，并将其与它的参数y相乘，然后返回一个整型结果。这意味着你可以像下面这样在一个map中使用multiplyCurry，对每一个元素值乘以2
Stream.of(1, 3, 5, 7)
	.map(multiplyCurry(2))
	.forEach(System.out::println);
这种方式工作的原因是map期望的参数为一个函数，而multiplyCurry的返回结果就是一个函数。


现在的Java语言中，为了构造科里化的形式需要你手工地切分函数（尤其是函数有非常多的参数时），这是极其枯燥的事情。Scala提供了一种特殊的语法可以自动完成这部分工作。

def multiply(x : Int, y: Int) = x * y
val r = multiply(2, 10);
该函数的科里化版本如下：
def multiplyCurry(x :Int)(y : Int) = x * y
val r = multiplyCurry(2)(10)

使用语法(x: Int)(y: Int)，
方法multiplyCurry接受两个由一个Int参数构成的参数列表。
与此相反，multiply接受一个由两个Int参数构成的参数列表。

可以将对multiplyCurry的第一次调用保存到一个变量中，进行复用：
val multiplyByTwo : Int => Int = multiplyCurry(2)
val r = multiplyByTwo(10)

Scala语言中构造器、getter方法以及setter方法都能隐式地生成，从而大大降低你代码中的冗余：
class Student(var name: String, var id: Int)
val s = new Student("Raoul", 1)
println(s.name)
s.id = 1337
println(s.id)

Scala还提供了另一个非常有助于抽象对象的特性，名称叫trait。它是Scala为实现Java中的接口而设计的替代品。trait中既可以定义抽象方法，也可以定义带有默认实现的方法。trait同时还支持Java中接口那样的多继承

trait中还可以包含像抽象类这样的字段，而Java8的接口不支持这样的特性。

trait Sized{
	var size : Int = 0
	def isEmpty() = size == 0
}

class Empty extends Sized
println(new Empty().isEmpty())

trait和Java的接口类似，也是在对象实例化时被创建

可以创建一个Box类，动态地决定到底选择哪一个实例支持由trait Sized定义的操作：
class Box
val b1 = new Box() with Sized
println(b1.isEmpty())
val b2 = new Box()
b2.isEmpty()

如果一个类继承了多个trait，各trait中声明的方法又使用了相同的签名或者相同的字段，这时会发生什么情况？为了解决这些问题，Scala中定义了一系列限制，这些限制和我们之前在第9章介绍默认方法时的限制极其类似。




chapter last

行为参数化（Lambda 以及方法引用）
流
CompletableFuture
Optional
默认方法

下面这段代码合法的原因：
List<? extends Number> numbers = new ArrayList<Integer>();
不过下面的这段赋值（省略了? extends）会产生一个编译错误：
List<Number> numbers = new ArrayList<Integer>();


我们有必要提醒你，即使是传统的面向对象设计也已经不推荐使用switch了，现在大家更推荐的方式是采用一些设计模式，比如访问者模式
使用访问者模式时，程序利用dispatch方法，依据数据类型来选择相应的控制流，不再使用传统的switch方式。这并非另一种编程语言中的事――函数式编程语言中使用基于数据类型的模式匹配通常也是设计程序最便捷的方式。


Java 8只支持三种类型的值，分别为：
? 简单类型值
? 指向对象的引用
? 指向函数的引用



326
附录A

重复注解（repeated annotation）、类型注解（type annotation）和通用目标类型推断（generalized target-type inference）。

我们不会谈及Nashorn或者是精简运行时（Compact Profiles），因为它们属于JVM的新特性


Java 8在两个方面对注解机制进行了改进，分别为：
? 你现在可以定义重复注解
? 使用新版Java，你可以为任何类型添加注解

在Java 8之前，只有声明可以被注解

Java中的注解是一种对程序元素进行配置，提供附加信息的机制

注解尤其适用于下面这些场景。
在JUnit的上下文中，使用注解能帮助区分哪些方法用于单元测试，哪些用于做环境搭建工作。
注解可以用于文档编制。比如，@Deprecated注解被广泛应用于说明某个方法不再推荐使用。
Java编译器还可以依据注解检查错误，禁止报警输出，甚至还能生成代码。
注解在Java企业版中尤其流行，它们经常用于配置企业应用程序。


之前版本的Java禁止对同样的注解类型声明多次。由于这个原因，下面的第二句代码是无效的：
@interface Author { String name(); }
@Author(name="Raoul") @Author(name="Mario") @Author(name="Alan")
class Book{ }

Java企业版的程序员经常通过一些惯用法绕过这一限制。你可以声明一个新的注解，它包含了你希望重复的注解数组。这种方法的形式如下：
@interface Author { String name(); }
@interface Authors {
	Author[] value();
}
@Authors(
	{ @Author(name="Raoul"), @Author(name="Mario") , @Author(name="Alan")}
)
class Book{}

。。想起来，更多的是@interface Author { String[] names();} 这种吧。
。。这种就是下面说的:一个注解在设计之初就是可重复的


现在，如果你的配置允许重复注解，你可以毫无顾虑地一次声明多个同一种类型的注解。它目前还不是默认行为，你需要显式地要求进行重复注解。

创建一个重复注解
如果一个注解在设计之初就是可重复的，你可以直接使用它。但是，如果你提供的注解是为用户提供的，那么就需要做一些工作，说明该注解可以重复。下面是你需要执行的两个步骤：
(1) 将注解标记为@Repeatable
(2) 提供一个注解的容器

下面的例子展示了如何将@Author注解修改为可重复注解：
@Repeatable(Authors.class)
@interface Author { String name(); }

@interface Authors {
	Author[] value();
}

完成了这样的定义之后，Book类可以通过多个@Author注解进行注释，如下所示：
@Author(name="Raoul") @Author(name="Mario") @Author(name="Alan")
class Book{ }

编译时，Book会被认为使用了
@Authors({@Author(name="Raoul"), @Author(name
=”Mario”), @Author(name=”Alan”)}) 这样的形式进行了注解

。自动转换。

Java API中的getAnnotation(Class<T>
annotationClass)方法会为注解元素返回类型为T的注解。如果实际情况有多个类型为T的注解，该方法的返回到底是哪一个呢？
我们不希望一下子就陷入细节的魔咒，类Class提供了一个新的getAnnotationsByType方法，它可以帮助我们更好地使用重复注解

public static void main(String[] args) {
	Author[] authors = Book.class.getAnnotationsByType(Author.class);
	Arrays.asList(authors).forEach(a -> { System.out.println(a.name()); });
}


从Java8开始，注解已经能应用于任何类型。这其中包括new操作符、类型转换、instanceof检查、泛型类型参数，以及implements和throws子句。

类型为String的变量name不能为空，所以我们使用了@NonNull对其进行注解：
@NonNull String name = person.getName();
类似地，你可以对列表中的元素类型进行注解：
List<@NonNull Car> cars = new ArrayList<>();

Java8并未提供官方的注解或者一种工具能以开箱即用的方式使用它们。它仅仅提供了一种功能，你使用它可以对不同的类型添加注解

一个名为Checker的框架，它定义了多种类型注解，使用它们你可以增强类型检查。如果对此感兴趣，我们建议你看看它的教程


通用目标类型推断
Java 8对泛型参数的推断进行了增强。

Java中的方法emptyList方法定义如下：
static <T> List<T> emptyList();

List<Car> cars = Collections.<Car>emptyList();
不过Java也可以推断泛型参数的类型。上面的代码和下面这段代码是等价的：
List<Car> cars = Collections.emptyList();

Java8出现之前，这种推断机制依赖于程序的上下文（即目标类型），具有一定的局限性。比如，下面这种情况就不大可能完成推断：
static void cleanCars(List<Car> cars) {
}
cleanCars(Collections.emptyList());
你会遭遇下面的错误：
cleanCars (java.util.List<Car>)cannot be applied to
	(java.util.List<java.lang.Object>)
为了修复这一问题，你只能像我们之前展示的那样提供一个显式的类型参数。

Java8中，目标类型包括向方法传递的参数，因此你不再需要提供显式的泛型参数：
List<Car> cleanCars = dirtyCars.stream()
			.filter(Car::isClean)
			.collect(Collectors.toList());

正是伴随Java8而来的改进让你只需要一句Collectors.toList()就能完成期望的工作，不再需要编写Collectors.<Car>toList()



JavaAPI的设计者们充分利用默认方法，为集合接口和类新增了多个新的方法。
Map
getOrDefault，forEach，compute，computeIfAbsent，computeIfPresent，merge，putIfAbsent，remove(key,value)，replace，replaceAll

Iterable 
forEach，spliterator

Iterator 
forEachRemaining

Collection 
removeIf，stream，parallelStream

List 
replaceAll，sort

BitSet 
stream

一个特别有用的方法是computeIfAbsent，这个方法在第14章解释记忆表时曾经简要地提到过。它能帮助你非常方便地使用缓存模式
我们假设你需要从不同的网站抓取和处理数据。这种场景下，如果能够缓存数据是非常有帮助的，这样你就不需要每次都执行（代价极高的）数据抓取操作了：
public String getData(String url){
	String data = cache.get(url);
	if(data == null){
		data = getData(url);
		cache.put(url, data);
	}
	return data;
}

这段代码，你现在可以通过computeIfAbsent用更加精炼的方式实现，代码如下所示：
public String getData(String url){
	return cache.computeIfAbsent(url, this::getData);
}

removeIf方法可以移除集合中满足某个谓词的所有元素
StreamAPI中的filter方法会产生一个新的流，不会对当前作为数据源的流做任何变更。

replaceAll方法会对列表中的每一个元素执行特定的操作，并用处理的结果替换该元素。
它的功能和Stream中的map方法非常相似，不过replaceAll会修改列表中的元素。与此相反，map方法会生成新的元素。

List<Integer> numbers = Arrays.asList(1, 2, 3, 4, 5);
numbers.replaceAll(x -> x * 2);
System.out.println(numbers);	// 2，4，6，8，10


Collections类已经存在了很长的时间，它的主要功能是操作或者返回集合。Java8中它又新增了一个方法，该方法可以返回不可修改的、同步的、受检查的或者是空的NavigableMap或NavigableSet。除此之外，它还引入了checkedQueue方法，该方法返回一个队列视图，可以扩展进行动态类型检查。


Comparator接口现在同时包含了默认方法和静态方法。你可以使用第3章中介绍的静态方法Comparator.comparing返回一个Comparator对象，该对象提供了一个函数可以提取排序关键字。

新的实例方法包含了下面这些。
reversed――对当前的Comparator 对象进行逆序排序， 并返回排序之后新的Comparator对象。

thenComparing――当两个对象相同时，返回使用另一个Comparator进行比较的Comparator对象。

thenComparingInt、thenComparingDouble、thenComparingLong――这些方法的工作方式和thenComparing方法类似，不过它们的处理函数是特别针对某些基本数据类型（分别对应于ToIntFunction、ToDoubleFunction和ToLongFunction）的。

新的静态方法包括下面这些。
comparingInt、comparingDouble、comparingLong――它们的工作方式和comparing类似，但接受的函数特别针对某些基本数据类型（分别对应于ToIntFunction、ToDoubleFunction和ToLongFunction）。

naturalOrder――对Comparable对象进行自然排序，返回一个Comparator对象。

nullsFirst、nullsLast――对空对象和非空对象进行比较，你可以指定空对象（null）比非空对象（non-null）小或者比非空对象大，返回值是一个Comparator对象。

reverseOrder――和naturalOrder().reversed()方法类似。


java.util.concurrent.atomic包提供了多个对数字类型进行操作的类，比如AtomicInteger和AtomicLong，它们支持对单一变量的原子操作。

getAndUpdate――以原子方式用给定的方法更新当前值，并返回变更之前的值。
updateAndGet――以原子方式用给定的方法更新当前值，并返回变更之后的值。
getAndAccumulate――以原子方式用给定的方法对当前及给定的值进行更新，并返回变更之前的值。
accumulateAndGet――以原子方式用给定的方法对当前及给定的值进行更新，并返回变更之后的值。


展示了如何以原子方式比较一个现存的原子整型值和一个给定的观测值（比如10），并将变量设定为二者中较小的一个。
int min = atomicInteger.accumulateAndGet(10, Integer::min);


Adder和Accumulator
多线程的环境中，如果多个线程需要频繁地进行更新操作，且很少有读取的动作（比如，在统计计算的上下文中），JavaAPI文档中推荐大家使用新的类LongAdder、LongAccumulator、DoubleAdder以及DoubleAccumulator，尽量避免使用它们对应的原子类型。这些新的类在设计之初就考虑了动态增长的需求，可以有效地减少线程间的竞争。

LongAdder adder = new LongAdder();
adder.add(10);
// …
long sum = adder.sum();

LongAccumulator acc = new LongAccumulator(Long::sum, 0);
acc.accumulate(10);
// …
long result = acc.get();



ConcurrentHashMap支持三种新的操作，这些操作和你之前在流中所见的很像：
forEach――对每个键值对进行特定的操作
reduce――使用给定的精简函数（reduction function），将所有的键值对整合出一个结果
search――对每一个键值对执行一个函数，直到函数的返回值为一个非空值

以上每一种操作都支持四种形式，接受使用键、值、Map.Entry以及键值对的函数：
使用键和值的操作（forEach、reduce、search）
使用键的操作（forEachKey、reduceKeys、searchKeys）
使用值的操作 （forEachValue、reduceValues、searchValues）
使用Map.Entry对象的操作（forEachEntry、reduceEntries、searchEntries）

这些操作不会对ConcurrentHashMap的状态上锁。它们只会在运行过程中对元素进行操作。应用到这些操作上的函数不应该对任何的顺序，或者其他对象，抑或在计算过程发生变化的值，有依赖。

除此之外，你需要为这些操作指定一个并发阈值。如果经过预估当前map的大小小于设定的阈值，操作会顺序执行。使用值1开启基于通用线程池的最大并行。使用值Long.MAX_VALUE设定程序以单线程执行操作。
。。数据量少的时候，开启线程的消耗，数据分割，结果合并等操作占比太大，反而总体更慢。

使用reduceValues试图找出map中的最大值：
ConcurrentHashMap<String, Integer> map = new ConcurrentHashMap<>();
Optional<Integer> maxValue = Optional.of(map.reduceValues(1, Integer::max));

对int、long和double，它们的reduce操作各有不同（比如reduceValuesToInt、reduceKeysToLong等）。


ConcurrentHashMap类提供了一个新的方法，名叫mappingCount，它以长整型long返回map中映射的数目。我们应该尽量使用这个新方法，而不是老的size方法，size方法返回的类型为int。这是因为映射的数量可能是int无法表示的。


ConcurrentHashMap类还提供了一个名为KeySet的新方法，该方法以Set的形式返回ConcurrentHashMap的一个视图（对map的修改会反映在该Set中，反之亦然）。你也可以使用新的静态方法newKeySet，由ConcurrentHashMap创建一个Set。



Arrays类提供了不同的静态方法对数组进行操作。现在，它又包括了四个新的方法（它们都有特别重载的变量）。

parallelSort方法会以并发的方式对指定的数组进行排序，你可以使用自然顺序，也可以为数组对象定义特别的Comparator。

setAll和parallelSetAll方法可以以顺序的方式也可以用并发的方式，使用提供的函数计算每一个元素的值，对指定数组中的所有元素进行设置
该函数接受元素的索引，返回该索引元素对应的值
由于parallelSetAll需要并发执行，所以提供的函数必须没有任何副作用

int[] evenNumbers = new int[10];
Arrays.setAll(evenNumbers, i -> i * 2);


parallelPrefix方法以并发的方式，用用户提供的二进制操作符对给定数组中的每个元素进行累积计算
int[] ones = new int[10];
Arrays.fill(ones, 1);
Arrays.parallelPrefix(ones, (a, b) -> a + b);


Java 8 API对Number和Math也做了改进，为它们增加了新的方法。

Number类中新增的方法如下。

Short、Integer、Long、Float和Double类提供了静态方法sum、min和max。

Integer和Long类提供了compareUnsigned、divideUnsigned、remainderUnsigned和toUnsignedLong方法来处理无符号数。

Integer和Long类也分别提供了静态方法parseUnsignedInt和parseUnsignedLong将字符解析为无符号int或者long类型。

Byte和Short类提供了toUnsignedInt和toUnsignedLong方法通过无符号转换将参数转化为int 或者long 类型。类似地， Integer 类现在也提供了静态方法toUnsignedLong。

Double和Float类提供了静态方法isFinite，可以检查参数是否为有限浮点数。

Boolean类现在提供了静态方法logicalAnd、logicalOr和logicalXor，可以在两个boolean之间执行and、or和xor操作。

BigInteger 类提供了byteValueExact 、shortValueExact 、intValueExact 和longValueExact，可以将BigInteger类型的值转换为对应的基础类型。不过，如果在转换过程中有信息的丢失，方法会抛出算术异常。


如果Math中的方法在操作中出现溢出，Math类提供了新的方法可以抛出算术异常。支持这一异常的方法包括
使用int和long参数的addExact、subtractExact、multipleExact、incrementExact、decrementExact和negateExact。
此外，Math类还新增了一个静态方法toIntExact，可以将long值转换为int值。
其他的新增内容包括静态方法floorMod、floorDiv和nextDown。



Files类最引人注目的改变是，你现在可以用文件直接产生流。第5章中提到过新的静态方法Files.lines，通过该方法你可以以延迟方式读取文件的内容，并将其作为一个流。此外，还有一些非常有用的静态方法可以返回流。

Files.list――生成由指定目录中所有条目构成的Stream<Path>。这个列表不是递归包含的。由于流是延迟消费的，处理包含内容非常庞大的目录时，这个方法非常有用。

Files.walk――和Files.list有些类似，它也生成包含给定目录中所有条目的Stream<Path>。不过这个列表是递归的，你可以设定递归的深度。注意，该遍历是依照深度优先进行的。

Files.find――通过递归地遍历一个目录找到符合条件的条目， 并生成一个
Stream<Path>对象。



Relection接口的另一个变化是新增了可以查询方法参数信息的API，比如，你现在可以使用新增的java.lang.reflect.Parameter类查询方法参数的名称和修饰符，这个类被新的java.lang.reflect.Executable类所引用，而java.lang.reflect.Executable通用函数和构造函数共享的父类。



String类也新增了一个静态方法，名叫join。你大概已经猜出它的功能了，它可以用一个分隔符将多个字符串连接起来
String authors = String.join(", ", "Raoul", "Mario", "Alan");
System.out.println(authors);		// Raoul, Mario,Alan


附录C 如何以并发方式在同一个流上执行多种操作
。。一个很大很大的例子。。。


附录D Lambda表达式和JVM字节码

如果你认为Lambda表达式就是简单地被转换为匿名类，那就太天真了

由于Lambda表达式提供了函数式接口中抽象方法的实现，这让人有一种感觉，似乎在编译过程中让Java编译器直接将Lambda表达式转换为匿名类更直观。不过，匿名类有着种种不尽如人意的特性，会对应用程序的性能带来负面影响。

编译器会为每个匿名类生成一个新的.class文件。这些新生成的类文件的文件名通常以ClassName$1这种形式呈现，其中ClassName是匿名类出现的类的名字，紧跟着一个美元符号和一个数字。生成大量的类文件是不利的，因为每个类文件在使用之前都需要加载和验证，这会直接影响应用的启动性能。如果将Lambda表达式转换为匿名类，每个Lambda表达式都会产生一个新的类文件，这是我们不期望发生的。

每个新的匿名类都会为类或者接口产生一个新的子类型。如果你为了实现一个比较器，使用了一百多个不同的Lambda表达式，这意味着该比较器会有一百多个不同的子类型。这种情况下，JVM的运行时性能调优会变得更加困难。



创建额外的类现在被invokedynamic指令替代了。

invokedynamic添加了更高层的抽象，使得一部分逻辑可以依据动态语言的特征来决定调用目标。这一指令的典型使用场景如下：
def add(a, b) { a + b }
这里a和b的类型在编译时都未知，有可能随着运行时发生变化。由于这个原因，JVM首次执行invokedynamic调用时，它会查询一个bootstrap方法，该方法实现了依赖语言的逻辑，可以决定选择哪一个方法进行调用。bootstrap方法返回一个链接调用点（linked call site）。很多情况下，如果add方法使用两个int类型的变量，紧接下来的调用也会使用两个int类型的值。所以，每次调用也没有必要都重新选择调用的方法。调用点自身就包含了一定的逻辑，可以判断在什么情况下需要进行重新链接。


使用invokedynamic指令的目的略微有别于我们最初介绍的那一种。这个例子中，它被用于延迟Lambda表达式到字节码的转换，最终这一操作被推迟到了运行时。换句话说，以这种方式使用invokedynamic，可以将实现Lambda表达式的这部分代码的字节码生成推迟到运行时。这种设计选择带来了一系列好结果。

Lambda表达式的代码块到字节码的转换由高层的策略变成了纯粹的实现细节。它现在可以动态地改变，或者在未来版本中得到优化、修改，并且保持了字节码的后向兼容性。

没有带来额外的开销，没有额外的字段，也不需要进行静态初始化，而这些如果不使用Lambda，就不会实现。

对无状态非捕获型Lambda，我们可以创建一个Lambda对象的实例，对其进行缓存，之后对同一对象的访问都返回同样的内容。这是一种常见的用例，也是人们在Java 8之前就惯用的方式；比如，以static final变量的方式声明某个比较器实例。

没有额外的性能开销，因为这些转换都是必须的，并且结果也进行了链接，仅在Lambda首次被调用时需要转换。其后所有的调用都能直接跳过这一步，直接调用之前链接的实现。


349
将Lambda表达式的代码体填入到运行时动态创建的静态方法，就完成了Lambda表达式的字节码转换。无状态Lambda在它涵盖的范围内不保持任何状态信息

。。over。。。












Java并发编程实战

早期计算机没有os，它们从头至尾只执行一个程序。

os的出现，使得计算机每次能运行多个程序，不同的程序都在单独的进程中执行。
不同进程间可以通过一些粗粒度的通信机制来交换数据，包括：套接字，信号处理器，共享内存，信号量及文件等。

线程允许在同一个进程中同时存在多个程序控制流。同一个程序中的多个线程也可以被同时调度到多个cpu上运行。

线程也被称为轻量级进程。在大多数现代os中，都是以线程为基本的调度单位。如果没有明确的协同机制，那么线程将彼此独立执行。由于同一个进程中的所有线程都将共享进程的内存地址空间，因此这些线程都能访问相同的变量并在同一个堆上分配对象，这就需要实现一种比在进程间共享数据粒度更细的数据共享机制。如果没有明确的同步机制来协同对共享数据的访问，那么当一个线程正在使用某个变量时，另一个线程可能同时访问这个变量，这将造成不可预知的后果。


线程的优势

发挥多处理器的强大功能

建模的简单性
一个任务从头至尾，不需要考虑是否和其他任务有冲突，和其他任务的优先级，执行时间，不同任务间的切换。

异步事件的简化处理
服务器如果是单线程处理请求，防止一个请求卡住全部，那么需要非阻塞IO，这种IO复杂性远远高于同步IO。如果每个请求都有自己的线程，那么就不需要考虑请求的IO是否卡住。

响应更灵敏的用户界面
传统GUI应用程序通常是单线程的，从而在代码的各个位置都需要调用poll方法来获得输入事件，或者通过一个主事件循环来间接地执行应用程序的所有代码。如果主事件循环中调用代码需要很长时间才能完成，那么用户界面就会被冻结，直到代码执行完成。
现在GUI框架，如AWT，Swing等。都采用一个时间分发线程来替代主事件循环。当某个用户界面事件发生时，在事件线程中将调用应用程序的事件处理器，由于大多数GUI框架都是单线程子程序，应此到目前为止仍然存在主事件循环，但它现在处于GUI工具的控制下并在其自己的线程中运行，而不是在应用程序的控制下。
。。。what？？？


线程带来的风险

安全性问题。
没有充足同步的情况下，多个线程中的操作执行顺序是不可预知的，甚至会产生奇怪的结果。
@NotThreadSafe是本书中使用的自定义注解之一。
线程安全性注解在许多方面都是有用的。如果用@ThreadSafe来注解某个类，那么开发人员可以放心地在多线程环境下使用这个类。

活跃性问题
安全性的含义是：永远不发生糟糕的事情。
活跃性：某件正确的事情最终会发生。
死锁，饥饿，活锁。

性能问题
和活跃性问题密切相关的是性能问题。
活跃性意味着某件正确的事情最终会发生，但却不一定够好，够快。
性能问题包含：服务时间过长，响应不灵敏，吞吐率过低，资源消耗过高，可伸缩性较低。
在多线程程序中，当线程调度器临时挂起活跃线程并转而运行另一个线程时，就会频繁地出现上下文切换操作，这种操作消耗极大的开销。
当线程共享数据时，必须使用同步机制，这些机制往往会抑制某些编译器优化，使内存缓存区中的数据无效，以及增加共享内存总数的同步流量。这些操作都将带来额外的性能开销。


下面的模块都将在应用程序之外的线程中调用应用程序的代码。
Timer，TimerTask
Servlet，JSP(Java Server Page)
RMI(remote method invocation)
Swing，AWT


25
chapter 2 线程安全性

要编出线程安全的代码，其核心在于要对状态访问操作进行管理，特别是对共享的和可变的状态的访问。
从非正式的意义上说，对象的状态是指存储在状态变量(例如实例或静态域)中的数据。对象的状态可能包含其他以来对象的域，例如某个hashmap的状态不仅存储在hashmap对象本身，还存储在许多Map.Entry对象中。在对象的状态中包含了任何可能影响其外部可见行为的数据。

当多个线程访问某个状态变量并且其中有一个线程执行写入操作时，必须采用同步机制来协同这些线程对变量的访问。
java中主要同步机制是关键字synchronized，它提供了一种独占的加锁方式。但"同步"这个术语还包括volatile类型的变量，显示锁和原子变量。

多线程访问一个可变的状态变量时，没有合适的同步就会出现错误，修补办法：
1.不在线程间贡献该状态变量
2.将该状态变量修改为不可变
3.访问状态变量时使用同步。

当多个线程访问某个类时，这个类始终能表现出正确的行为，那么这个类就是线程安全的。

无状态：不包含任何域，任何对其他类中域的引用。计算过程中的临时状态仅存在于线程栈上的局部变量中，并且只能由正在执行的线程访问。2个线程不会互相影响，因为2个线程间没有共享状态。

无状态对象一定是线程安全的。

大多数Servlet都是无状态的。


原子操作
方法内部count++；count是类属性。

count++并非原子操作，而是一个操作序列：读取-修改-写入，其结果状态依赖于之前的状态。

在并发编程中，这种由于不恰当的执行时序而出现的不正确的结果是一种非常重要的情况，它有一个正式的名字：竞态条件。

大多数竞态条件的本质：基于一种可能失效的观察结果来做出判断或者执行某个计算。

简单的懒初始化，if (a == null) a = new XX();  包含了竞态条件

32
尽量使用现有的线程安全对象(如AtomicLong)来管理类的状态。与非线程安全的对象相比，判断线程安全对象的可能状态及其状态转换情况要更为容易，从而也更容易维护和验证线程安全性。


@NotThreadSafe
public class Unsafe implements Servlet
{
	private final AtomicReference<BigInteger> lastNumber = new AtomicReference<BigInteger>();
	private final AtomicReference<BigInteger[]> lastFactors = new ..
	
	public void service(ServletRequest req, ServletResponse resp)
	{
		BigInteger i = extractFromRequest(req);
		if (i.equals(lastNumber.get()))
			ancodeIntoResponse(resp, lastFactors.get());	
		else
		{
			BigInteger[] factors = factor(i);
			lastNumber.set(i);
			lastFactors.set(factors);
			encodeIntoResponse(resp, factors);
		}
	}
}
这个方法并不正确。虽然这些原子引用本身是线程安全的，但是在类中存在竞态条件，会导致错误的结果。

lastNumber和lastFactors的更新操作并不是原子操作的。


内置锁
Java提供一种内置的锁机制来支持原子性。
synchronized同步代码块包含2个部分：一个作为锁的对象引用，一个作为由这个锁保护的代码块。

静态的synchronized以Class对象作为锁。


每个java对象都可以用做一个实现同步的锁，这些锁被称为内置锁或监视器锁。
进入同步代码块之前自动获得锁，在推出同步代码块时自动释放锁。
可以正常的控制路径退出，或者从代码块抛出异常退出。获得内置锁的唯一途径就是进入由这个锁保护的同步代码块或方法。

java内置锁相当于一种互斥体(或互斥锁)，这意味着至多只有一个线程能持有这种锁。


重入
当一个线程请求一个由其他线程持有的锁时，发出请求的线程会阻塞。

由于内置锁是可重入的，因此如果某个线程试图获得一个已经由它自己持有的锁，那么这个请求就会成功。

重入意味着获取锁的操作的粒度是线程，而不是调用(方法)。

重入的一种实现方式，为每个锁关联一个获取计数值和一个所有者线程。计数值为0时，这个锁没有被任何线程持有，当线程请求一个未被持有的锁时，jvm记录下锁的持有者，并将获取计数值设置为1，当同一个线程再次获取这个锁，计数值++，当线程退出同步代码块时，计数值--，当计数值==0时，这个锁被释放。

pthread(POSIX线程)互斥体的默认加锁行为是以调用为粒度的。

不可重入的话，子类sync方法中调用父类的sync方法就会死锁。因为无法再获得锁。


仅仅将复合操作封装到一个同步代码块中是不够的。
如果用同步来协调对某个变量的访问，那么访问这个变量的所有位置上都需要使用同步。而且当使用锁来协调对某个变量的访问时，在访问变量的所有位置上都要使用同一个锁。
。。1.任何用到变量的地方都要同步。2.使用同一个锁。

一种常见的错误是认为只有在写入共享变量时才需要使用同步。并非如此，对于可能被多个线程同时访问的可变状态变量，在访问它时都需要持有同一个锁。(3.1中会解释)

对象的内置锁和其状态之间没有内在的关联，虽然大多数类都将内置锁用做一种有效的加锁机制，但对象的域并不一定要通过内置锁来保护。当获取与对象关联的锁时，并不能阻止其他线程访问该对象，某个线程在获得对象的锁之后，只能阻止其他线程获得同一个锁。

一种常见的加锁约定是，将所有可变状态都封装在对象内部，并通过对象的内置锁对所有访问可变状态的代码路径进行同步。

当类的不变性条件涉及多个状态变量时，那么还有另外一个要求：在不变性条件中的每个变量都必须由同一个锁来保护。因此可以在单个原子操作中访问或更新这些变量，从而确保不变性条件不被破坏。
。。不变性条件？。。看意思似乎是，如果多个属性是相互关联的，那么这些属性的修改必须在一个同步块中。。不知道对不对。
。。看网上，大约是指：不同属性之间的逻辑关系不能被破坏。就像提到的数和因子，这2个属性的关系不能被破坏成数和其他数的因子。
。。某个属性由其他属性计算而来，那么这2个属性就需要确保(逻辑/关系)不变性。
。。不变性条件，就是字面意思，这个属性的有些条件/约束是不变的，计数永远是非负的，某个属性永远是和另一个属性相关联的。


即使每个方法都加上sync，也不能保证复合操作都是原子的。
if (!vector.contains(element))
	vector.add(element);
contains,add是原子的，但是复合起来就不是原子的了。。

每个方法都sync可能会导致活跃性问题或性能问题

活跃性与性能

sync的范围需要小而全，小就能低等待，高并发，全就能保证原子。
尽量将不影响共享状态且执行时间较长的操作从同步代码块中分离出去，从而在这些操作执行的过程中，其他线程可以访问共享状态。

性能和简单性之间存在相互制约。当实现某个同步策略时，一定不要盲目地为了性能而牺牲简单性(这可能会破坏安全性)。

执行较长时间的计算或者可能无法快速完成的操作时(网络IO，控制台IO)，一定不要持有锁。



41
chapter 3 对象的共享

第二章介绍了如何通过同步来避免多个线程在同一时刻访问相同的数据。
本章将介绍如何共享和发布对象，使它们能安全地由多个线程同时访问。

我们已经知道同步代码块和同步方法可以确保以原子的方式执行操作，但一种常见的误解是，认为synchronized只能用于实现原子性或确定"临界区"。
同步还有另一个重要的东西：内存可见性。我们不仅希望防止某个线程正在使用对象状态而另一个线程在同时修改该状态，而且希望确保当一个线程修改对象状态后，其他线程能看到发生的变化。

public class NoVisibility
{
	private static boolean ready;
	private static int number;
	private static class ReaderThread extends Thread
	{
		public void run()
		{
			while (!ready)
				Thread.yield();
			sysout(number);
		}
	}
	public static void main(String[] args)
	{
		new ReaderThread().start();
		number = 42;
		ready = true;
	}
}

NoVisibility可能会持续循环下去，因为读线程可能永远都看不到ready的值。更奇怪的情况是，NoVisibility可能输出0，因为读线程可能看到了写入的ready的值，但没有看到之后写入的number的值，这种现象是"重排序"。
。。什么情况下会永远看不到？最多延迟段时间吧，只能说数据延迟刷新啊。难道编译器优化，把ready = true 优化没了？

在没有同步的情况下，编译器，处理器，运行时，都可能对操作的执行顺序进行调整。在缺乏足够同步的多线程程序中，要想对内存操作的执行顺序进行判断，几乎无法得到正确的结论。

一种简单方法来避免这些问题：只要有数据在多个线程之间共享，就使用正确的同步。


上面例子展现了在缺乏同步的程序汇总可能产生错误结果的一种情况：失效数据。线程查看变量时，获得了一个已经失效的值。
失效值可能不会同时出现：一个线程可能获得某个变量的最新值，另一个变量的失效值。


在没有同步的情况下，线程读取变量，可能获得一个失效值，但至少这个值是由之前某个线程设置的，而不是一个随机值。这种安全性称为最低安全性。

最低安全性适合于绝大多数变量，但存在一个例外，非volatile类型的64位数值变量(double，long)。Java内存模型要求，变量的读取和写入操作都必须是原子操作，但对于非volatile的long和double，JVM允许将64位的读或写操作分解为两个32位的操作。


内置锁可以用于确保某个线程以一种可预测的方式来查看另一个线程的执行结果。
线程A执行某个同步代码块时，线程B随后进入由同一个锁保护的同步代码块，这种情况下，可以保证，在A中锁被释放之前的变量值，在B获得锁后可以由B看到。换句话说，当B执行由锁保护的同步代码块时，可以看到线程A之前在同一个同步代码块中的所有操作结果。
。。同一个代码块。能相同锁的不同的同步代码块中吗？应该可以。

访问某个共享且可变的变量时，所有的线程都在同一个锁上同步，就是为了保证某个线程写入该变量的值能被其他线程看到。


Java提供了一种稍弱的同步机制，volatile变量，用来确保将变量的更新操作通知到其他线程。
当变量声明为volatile后，编译器与运行时都会注意到这个变量是共享的，因此不会把这个变量上的操作与其他内存操作一起重排序。volatile变量不会被缓存在寄存器或者对其他处理器不可见的地方，因此在读取volatile时总返回最新写入的值。
volatile不会加锁，是一种比sync更轻量级的同步机制。

volatile变量对可见性的影响比volatile变量本身更为重要。在线程A写入一个volatile并且B读取该变量时，在A写入volatile之前对A可见的所有变量的值，在B读取volatile之后，对B也可见。
。。volatile不会重排序，所以能保证A在volatile之前的所有设置，在B读取volatile的时候，对B是可见的。
。。但是如果是缓存呢，A和B各有寄存器缓存，A之前设置的值，只能保证写到内存里吧，没有办法影响到B的寄存器中缓存的值吧？

因此，从内存可见性的角度来看，写入volatile相当于退出同步代码块，读取volatile相当于进入同步代码块。
我们并不建议过度依赖volatile提供的可见性。如果在代码中依赖volatile变量来控制状态的可见性，通常比使用锁的代码更脆弱，更难以理解。

volatile正确的使用方式包括：确保它们自身状态的可见性，确保它们所引用对象的状态的可见性，以及标识一些重要的程序生命周期时间的发生(如，初始化或关闭)

volatile的典型用法：检查某个状态标记以判断是否退出循环。

volatile boolean asleep;
...
	while (!asleep)
		countSomeSheep();
多线程运行。没有volatile时，如果asleep被另一个线程修改，判断执行的线程却发现不了。

对于服务器应用程序，无论在开发阶段开始测试阶段，启动jvm时，一定要指定-server。server模式比client模式的jvm进行更多的优化，例如将循环中未被修改的变量提升到循环外部。例如，如果上面asleep不是volatile，那么server模式会把asleep的判断条件提升到循环体外部(这将导致一个无限循环)，但client模式不会这么做。
。。asleep怎么提升到循环体外部。。。p45_

volatile不能保证原子性，i++...

当前仅当满足下面所有条件时，才使用volatile变量：
1.对变量的写入操作不依赖变量的当前值，或者你能确保只有单个线程更新变量。
2.该变量不会与其他状态变量一起纳入不变性条件中。
3.在访问变量时不需要加锁。


46
"发布(Publish)"一个对象的意思是指，使对象能够在当前作用域之外的代码中使用。
例如，将一个指向该对象的引用保存到其他代码可以访问的地方，或者在一个非私有的方法中返回该引用，或者将引用传递到其他类的方法中。
许多情况下，我们需要保证对象及其内部状态不被发布。
某些情况下，我们需要发布某个对象，但如果在发布时需要确保线程安全性，则可能需要同步。
发布内部状态可能会破坏封装性，并使得程序难以维持不变性条件。例如，如果在对象构造完成之前就发布该对象，就会破坏线程安全性。
当某个不应该发布的对象被发布时，这种情况称为逸出。

发布对象最简单的方法是将对象的引用保存到一个公有的静态变量中，以便任何类和线程都能看见该对象。

当发布某个对象时，可能会间接地发布其他对象。如就一个Secret对象添加到List<Secret>对象中，那么发布list的时候会同时发布Secret对象。因为任何代码都可以遍历这个集合，并获得对这个Secret对象的引用。
如果从非私有方法中返回一个引用，同样会发布返回的对象。

发布一个对象时，该对象的非私有域中引用的所有对象同样也会被发布。

无论其他线程对已发布的引用执行何种操作，其实都不重要，因为误用该引用的风险始终存在。当某个对象逸出后，你必须假设某个类or线程可能会误用该对象。这正是需要使用封装的最主要原因：封装能使得对程序的正确性进行分析变得可能，并使得无意中破坏设计约束条件变得更难。

最后一种发布对象或其内部状态的机制就是发布一个内部的类实例。
public class ThisEscape
{
	public ThisEscape(EventSource source)
	{
		source.registerListener(
			new EventListener()
			{
				public void onEvent(Event e)
				{
					doSth(e);
				}
			}
		)
	}
}
当ThisEscape发布EventListener时，也隐含地发布了ThisEscape本身，因为在这个内部类的实例中包含了对ThisEscape实例的隐含引用
。。内部类可以访问外部类。这不是内部类。是内部类。

48
安全的对象构造过程
ThisScape给出了一个逸出的特殊示例，即this引用在构造函数中逸出。当内部EventListener实例发布时，在外部封装的ThisEscape实例也逸出了。当且仅当对象的构造函数返回时，对象才处于可预测的和一致的状态。因此，当从对象的构造函数中发布对象时，只是发布了一个尚未构造完成的对象。如果this引用在构造过程中逸出，则这种对象就被认为是不正确构造。
。。？？。。。
具体来说，只有当构造函数返回时，this引用才应该从线程中逸出。

在构造过程中使用this引用逸出的一个常见错误是，在构造函数中启动一个线程。当对象在某个构造函数中创建一个线程时，无论是显示创建(通过将它传递给构造函数)还是隐式创建(由于Thread或Runnable是该对象的一个内部类)，this引用都会被新建的线程共享。在对象未完去构造之前，新的线程就可以看见它。
在构造函数中创建线程并没有错误，但最好不要立刻启动它，而是通过一个start或initialize方法来启动。在构造函数中调用一个可改写的实例方法时(既不是私有方法，也不是终结方法)，同样会导致this引用在构造过程中逸出。

如果想在构造函数中注册一个事件监听器或启动线程，那么可以使用一个私有的构造函数和一个公有的工程方法，从而避免不正确的构造过程。
public class SafeListener
{
	private final EventListener listener;
	private SafaListener()
	{
		listener = new EventListener()
		{
			public void onEvent(Event e)
			{
				doSth(e);
			}
		};
	}
	
	public static SafeListener newInstance(EventSource source)
	{
		SafeListener safe = new SateListener();
		source.registerListener(sate.listener);
		return safe;
	}
}


线程封闭
当访问共享的可变数据时，通常需要使用同步，一种避免使用同步的方法就是不共享数据。如果仅在单线程内访问数据，就不需要同步。这种技术被称为线程封闭(Thread Confinement)，它是实现线程安全性的最简单方法之一。
当某个对象封闭在一个线程中时，这种用法将自动实现线程安全性，即使被封闭的对象本身不是线程安全的。

Swing中大量使用线程封闭技术。Swing的可视化组件和数据模型对象都不是线程安全的，Swing通过将它们封闭到Swing的事件分发线程中来实现线程安全性。
要正确地使用Swing，那么在除了事件线程之外的其他线程就不能访问这些对象(为了进一步简化对Swing的使用，Swing还提供了invokeLater机制，用于将一个Runnable实例调度到事件线程中执行)。Swing应用程序的许多并发错误都是由于错误地在另一个线程中使用了这些被封闭的对象。

线程封闭技术的另一种常见应用是JDBC的Connection对象。JDBC规范并不要求Connection对象必须是线程安全的。
在典型的服务器应用程序中，线程从线程池中获得一个Connection对象，并且用该对象来处理请求，用完后再将对象返还给连接池。由于大多数请求(例如Servlet请求或EJB调用等)都是有单个线程采用同步的方式来处理，并且在Connection对象返回之前，连接池不会再将它分配给其他线程，因此，这种连接管理模式在处理请求时隐含地将Connection对象封闭在线程中。

Java语言中并没有强制规定某个变量必须由锁来保护，同样在java中也无法强制将对象封闭在某个线程中。线程封闭是在程序设计中的一个考虑因素，必须在程序中实现。java语言及核心库提供了一些机制来帮助维持线程封闭性，例如局部变量和ThreadLocal类，但即便如此，程序员依然需要负责确保封闭在线程中的对象不会从线程中逸出。

49_

Ad-hoc线程封闭
是指，维护线程封闭性的职责完全有程序实现来承担。它是非常脆弱的，因为没有任何一种语言特性，例如可见性修饰符或局部变量，能将对象封闭到目标线程上。事实上，对线程封闭对象的引用通常保存在公有变量中。

当决定使用线程封闭技术时，通常是因为要将某个特定的子系统实现为一个单线程子系统。某些情况下，单线程子系统提供的简便性要胜过Ad-hoc线程封闭技术的脆弱性。(单线程子系统的另一个优势是防止死锁，这也是大多数GUI框架都是单线程的原因)

在volatile变量上存在一种特殊的线程封闭。只有你能确保只有单个线程对共享的volatile变量执行写入操作，那么就可以安全地在这些共享的volatile变量上执行"读取-修改-写入"操作。这种情况下，相当于将修改操作封闭到单个线程中以防止发生竞态条件，并且volatile变量的可见性保证还确保了其他线程能看到最新的值。

由于Ad-hoc线程封闭技术的脆弱性，因此在程序中尽量少用。在可能的情况下，应该使用更强的线程封闭技术(例如，栈封闭；ThreadLocal类)。

。。大约就是，程序员自己编码完成线程封闭，以及注意线程封闭。。？


50
栈封闭
是线程封闭的一种特例，在栈封闭中，只能通过局部变量才能访问对象。正如封装能使得代码更容易维护不变性条件那样，同步变量也能使对象更易于封闭在线程中。
局部变量固有的属性之一就是封闭在执行线程中，它们位于执行线程的栈中，其他线程无法访问这个栈。
栈封闭(亦被称为线程内部使用或线程局部使用，不要与核心库中的ThreadLocal混淆)比Ad-hoc线程封闭更易于维护，也更健壮。
。。似乎只是为了单纯的封闭，完全不为多线程考虑。

对于基本类型的局部变量，无论如何都不会破坏栈封闭性。由于任何方法都无法获得对基本类型的引用，所以java语言的这种语义就保证了基本类型的局部变量始终封闭在线程中。
。。对，得确保这个方法不会自己new一个线程，不过new出来的线程，赋予它一个方法局部变量，这种传输是引用还是复制？
。test。。上面说的是，其他线程无法访问，那我主动给呢？应该是引用。
。。对，return一个引用导致逸出

在线程内部上下文中使用非线程安全的对象，那么该对象依然是线程安全的。然而，只有开发人员才知道哪些对象需要被封闭到执行线程中，以及被封闭的对象是否线程安全。后续的维护人员很容易错误地使对象逸出。


ThreadLocal
这是更规范的方法，这个类使线程中某个值与保存值的对象关联起来。
ThreadLocal提供了get，set等访问接口或方法，这些方法为每个使用该变量的线程都存有一份独立的副本，因此get总是返回由当前执行线程在调用set时设置的最新值。

ThreadLocal对象通常用于防止对可变的单实例对象(Singleton)或全局变量进行共享。

例如，在单线程应用程序中可能会维持一个全局的数据库连接，并在程序启动时初始化这个连接对象，从而避免在调用每个方法是都要传递一个Connection对象。由于JDBC的连接不一定是线程安全的，因此，当多线程应用程序在没有协同的情况下使用全局变量时，就不是线程安全的。通过将JDBC的连接保存到ThreadLocal对象中，每个线程都会拥有属于自己的连接。

private static ThreadLocal<Connection> connectionHolder = new ThreadLocal<Connection>()
	{
		public Connection initialValue() {return DriverManager.getConnection(DB_URL);}
	}

public static Connection getConnection() {return connectionHolder.get();}

。。ThreadLocal的get是通过Thread.currentThread作为key的，所以get能保证线程安全。

当某个频繁执行的操作需要一个临时对象，例如一个缓冲区，而同时又希望避免在每次执行时都重新分配该临时对象，就可以使用这项技术。
例如，java5.0之前，Integer.toString()方法是用ThreadLocal来保存一个12字节大小的缓冲区，用于对结果进行格式化，而不是使用共享的静态缓冲区(这需要锁机制)或在每次调用时都分配一个新的缓冲区。
当然，除非这个操作的执行频率非常高，或者分配操作的开销非常高，否则这项技术不可能带来性能提升。在java5中，这项技术被一种更直接的方式替代，即在每次调用时分配一个新的缓冲区，对于像临时缓冲区这种简单的对象，该技术并没有什么性能优势。

当某个线程首次调用ThreadLocal.get时，就会调用initialValue来获得初始值。
从概念上，你可以将ThreadLocal<T>视为包含了Map<Thread,T>对象，其中保存了特定于该线程的值，但ThreadLocal的实现并非如此。这些特定于线程的值保存在Thread对象中，当线程终止后，这些值会作为垃圾回收。

假设你需要将一个单线程应用程序移植到多线程环境中，通过将共享的全局变量转换为ThreadLocal对象(如果全局变量的语义允许)，可以维持线程安全性。然而，如果将应用程序范围内的缓存转换为线程局部的缓存，就不会有太大作用。

在实现应用程序框架时大量使用了ThreadLocal，例如，在EJB调用期间，J2EE容器需要将一个事务上下文与某个执行中的线程关联起来。通过将事务上下文保存在静态的ThreadLocal中，可以很容易地实现这个功能：当框架代码需要判断当前运行的是哪个事务时，只需从这个ThreadLocal对象中读取事务上下文。这种机制很方便，因为它避免了在调用每个方法时都传递执行上下文信息，然而这也将使用该机制的代码与框架耦合在一起。

经常会滥用ThreadLocal，例如，将所有全局变量都作为ThreadLocal对象，或者作为一种"隐藏"方法参数的手段。
ThreadLocal变量类似于全局变量，它能降低代码的可重用性，并在类间引入隐含的耦合性，因此在使用时要格外小心。


满足同步需求的另一种方法是使用不可变对象。
至今，介绍了许多与原子性和可见性相关的问题，例如得到失效数据，丢失更新操作或者观察到某个对象处于不一致的状态等等，都与多线程试图同时访问同一个可变的状态有关。如果对象的状态不会改变，那么这些问题与复杂性也就自然消失了。

不可变对象：被创建后其状态就不能被修改。
线程安全性是不可变对象的固有属性之一，它们的不可变条件是由构造函数创建的，只要它们的状态不改变，那么这些不变性条件就能得以维持。

在程序设计中，一个困难的地方就是判断复杂对象的可能状态，然而，判断不可变对象的状态却很简单。

java语言规范和java内存模型都没有给出不可变性的正式定义，但不可变性并不等于将对象中所有的域都声明为final类型，即使对象中所有的域都是final类型的，这个对象也仍然是可变的，因为final类型的域中可以保存对可变对象的引用。

满足以下条件时，对象才是不可变的：
对象创建后其状态就不能修改。
对象所有域都是final类型(从技术上来说，不可变对象不要求所有域都是final，例如String就是，这需要对类的良性数据竞争情况作精确分析，因此需要深入理解java内存模型(String会将散列值的计算推迟到第一次调用hashCode时进行，并将计算得到的散列值缓存到非final类型的域中，但这种方式之所以可行，是因为这个域有一个非默认的值，并在每次计算中都得到相同的结果(因为基于一个不可变的状态)。自己在编码时不要这么做。))
对象是正确创建的(在对象的创建期间，this引用没有逸出)


在不可变对象的内部仍可以使用可变对象来管理它们的状态。
Set是可变的，但是Set构造完以后无法再修改。stooges是一个final类型的引用变量，因此所有的对象状态都通过一个final域来访问。最后一个要求是"正确地构造对象"，这个要求很容易满足，因为构造函数能使该引用由除了构造函数及其调用者之外的代码来访问。
@Immutable
public final class ThreeStooges
{
	private findl Set<String> stooges = new HashSet<String>();
	public ThreeStooges()
	{
		stooges.add("Moe");
		stooges.add("Larry");
		stooges.add("Curly");
	}
	public boolean isStooges(String name) {return stooges.contains(name);}
}


final关键字可以视为C++中const机制的一种受限版本，用于构造不可变对象。final类型的域是不能修改的。final类型所引用的对象是可以修改的。

在java内存模型中，final域还有着特殊的语义，final域能确保初始化过程的安全性，从而可以不受限制地访问不可变对象，并在共享这些对象是无须同步。

即使对象是可变的，通过将某些域声明为final，仍然可以简化对状态的判断，因此，限制对象的可变性也就相当于限制了该对象可能的状态集合。

除非需要更高的可见性，否则应将所有的域都声明为私有域。
除非需要某个域是可变的，否则应该其声明为final。
2个良好的编程习惯。


使用volatile类型来发布不可变对象
@Immutable
class OneValueCache
{
	private final BigInteger lastNumber;
	private final BigInteger[] lastFactors;
	
	public OneValueCache(BigInteger i, BigInteger[] factors)
	{
		lastNumber = i;
		lastFactors = Arrays.copyOf(factors, factors.length);
	}
	public BigInteger[] getFactors(BigInteger i)
	{
		if (lastNumber == null || !lastNumber.equals())
			return null;
		else
			return Arrays.copyOf(lastFactors, lastFactors.length);
	}
}
。如果没有好似用copyOf，那么OneValueCache就不是不可变的，同样还可以使用clone。

每当需要对一组相关数据以原子方式执行某个操作时，就可以考虑创建一个不可变的类来包含这些数据。例如上面。

对于访问和更新多个相关变量时出现的竞争条件问题，可以通过将这些变量全部保存在一个不可变对象中来消除。如果是一个可变的对象，那么就必须使用所来保证原子性。如果是一个不可变对象，那么当线程获得对该对象的引用后，就不必担心另一个线程会修改对象的状态。如果要更新这些变量，那么可以创建一个新的容器对象，但其他使用原有对象的线程仍会看到对象处于一致的状态。

下面的代码汇中，当一个线程将volatile类型的cache设置为引用一个新的OneValueCache时，其他线程就会立即看到新缓存的数据。

@ThreadSafe
public class VolatileCachedFactorizer implements Servlet
{
	private volatile OneValueCache cache = new OneValueCache(null, null);
	public void service(ServletRequest req, ServletResponse, resp)
	{
		BigInteger i = extractFromRequest(req);
		BigInteger[] factors = cache.get(Factors(i));
		if (factors == null)
		{
			factors = factor(i);
			cache = new OneValueCache(i, factors);
		}
		encodeIntoRequest(resp, factors);
	}
}
与cache相关的操作不会相互干扰，因为OneValueCache是不可变的，并且在每条相应的代码路径中只访问它一次。通过使用包含多个状态变量的容器对象来维持不变性条件，并使用一个volatile引用来确保可见性。使得上述代码在没有显示使用锁的情况下仍是线程安全的。


我们之前讨论的重点是如何确保对象不被发布，例如将对象封闭在线程或另一个对象的内部。
在某些情况下，我们希望在多个线程间共享对象，此时必须确保安全地进行共享。

像下面那样将对象引用保存到公有域中，还不足以安全地发布这个对象。
public Holder holder;
public void initializer() {holder = new Holder(42);}

由于可见性问题，其他线程看到的Holder对象将处于不一致的状态，即便在该对象的构造函数中已经正确地构造了不变性条件。这种不正确的发布将导致其他线程看到尚未创建完成的对象。


不能指望一个尚未被完全创建的对象拥有完整性。某个观察该对象的线程将看到对象处于不一致的状态，然后看到对象的状态突然发生变化，即使线程在对象发布后还没有修改过它。

如果使用了上面的不安全发布，另一个线程在调用assertSanity时会派出异常。
public class Holder
{
	private int n;
	public Holder(int n) {this.n = n;}
	public void assertSanity()
	{
		if (n != n)
			throw new AssertionError("error");
	}
}

没有使用同步来确保Holder对象对其他线程可见，因此将Holder称为"未被正确发布"。在未被正确发布的对象中存在2个问题。首先，除了发布对象的线程外，其他线程可以看到的Holder域是一个失效值，因此将看到一个空引用或者之前的旧值。然而，更糟糕的情况是，线程看到的Holder引用的值是最新的，但Holder状态的值却是失效的(Object的构造器会在子类构造函数之前先将默认值写入所有的域，因此，某个域的默认值可能被视为失效值)。情况变得更加不可预测的是，某个线程在第一次读取域时得到失效值，而再次读取这个域时会获得一个更新值，这就是抛出异常的原因。

57
安全发布的常用模式
可变对象必须通过安全的方式来发布，这通常意味着发布和使用该对象的线程都必须使用同步。

要安全地发布一个对象，对象的引用以及对象的状态必须同时对其他线程可见。一个正确构造的对象可以通过以下方式来安全地发布：
在静态初始化函数中初始化一个对象引用
将对象的引用保存到volatile类型的域或者AtomicReference对象中。
将对象的引用保存到某个正确构造对象的final类型域中。
将对象的引用保存到一个由锁保护的域中。

在线程安全容器内部的同步意味着，在将对象放入到某个容器，如Vector或SynchronizedList时，将满足上述要求的最后一个。
如果线程A将对象X放入一个线程安全的容器，随后线程B读取这个对象，那么可以确保B看到A设置的X状态，即便在这段读/写X的应用程序代码中没有显式的同步，尽管Javadoc在这个主题上没有给出很清晰的说明，但线程安全库中的容器提供了以下的安全发布保证：
1. 通过将一个键或值放入Hashtable，SynchronizedMap，ConcurrentMap中，可以安全地将它发布给任何从这些容器中访问它的线程(无论是直接访问还是通过迭代器访问)。
2. 通过将某个元素放入Vecotr，CopyOnWriteArrayList，CopyOnWriteArraySet，SynchronizedList，SynchronizedSet中，可以将该元素安全地发布到任何从这些元素中访问该元素的线程。
。。访问 == 读+写？
3. 通过将某个元素放入BlockingQueue，ConcurrentLinkedQueue中，可以将该元素安全地发布到任何从这些队列中访问该元素的线程。

类库中的其他数据传递机制(Future，Exchanger)同样能实现安全发布。

通常，要发布一个静态构造的对象，最简单和最安全的方式是使用静态的初始化器：
public static Holder holder = new Holder(42);

静态初始化器由JVM在类的初始化阶段执行，由于在JVM内部存在同步机制，因此，通过这种方式初始化的任何对象都可以被安全地发布。


如果对象在发布后不会被修改，那么对于其他在没有额外同步的情况下安全地访问这些对象的线程来说，安全发布是足够的。
所有的安全发布机制都能确保，当对象的引用对所有访问该对象的线程可见时，对象发布时的状态对于所有线程也将是可见的，并且如果对象状态不会再改变，那么就足以确保任何访问都是安全的。

事实不可变对象：从技术上来看是可变的，但其状态在发布后不会再改变。

在没有额外的同步的情况下，任何线程都可以安全地使用被安全发布的事实不可变对象。

public Map<String, Date> lastLogin = Collections.synchronizedMap(new HashMap<String, Date>);
如果Date对象的值在被放入Map后就不会改变，那么synchronizedMap中的同步机制就足以是Date值被安全发布，并且在访问这些Date值时不需要额外的同步。
。。synchronizedMap如果保存事实可变对象，需要额外的同步？


如果对象在构造后可以修改，那么安全发布只能确保"发布当时"状态的可见性。
对于可变对象，不仅在发布对象时需要使用同步，而且在每次对象访问时同样需要使用同步来确保后续修改操作的可见性。
要安全地共享可变对象，这些对象就必须被安全地发布，并且必须是线程安全的或者由某个锁保护起来。

对象的发布需求取决于它的可变性：
不可变对象可以通过任意机制来发布
事实不可变对象必须通过安全方式来发布
可变对象必须通过安全方式来发布，并且必须是线程安全的或由某个锁保护起来。

安全地共享对象
在并发程序中使用和共享对象时，可以使用一些实用的策略：
线程封闭。线程封闭的对象只能由一个线程拥有，对象被封闭在该线程中，并且只能有这个线程修改。
只读共享。在没有额外同步的情况下，共享的只读对象可以由多个线程并发访问，但任何线程都不能修改它。共享的只读对象包括不可变对象和事实不可变对象。
线程安全共享。线程安全的对象在其内部实现同步，因此多个线程可以通过对象的公有接口来访问而不需要进一步同步。
保护对象。被保护的对象只能通过持有特定的锁来访问，保护对象包括封装在其他线程安全对象中的对象，以及已发布的并且有某个特定锁保护的对象。


60
chapter 4
对象的组合

我们并不希望每次内存访问都进行分析以确保程序是线程安全的，而是希望将一些现有的线程安全组件组合为更大规模的组件或程序。

在设计线程安全类的过程中，需要包含以下3个基本要素
1. 找出构成对象状态的所有变量。
2. 找出约束对象状态的所有变量
3. 建立对象状态的并发访问管理策略。

要分析对象的状态，首先从对象的域开始。如果对象中所有的域都是基本类型变量，那么这些域就构成了对象的全部状态。如果在对象的域中引用了其他对象，那么该对象的状态将包含被引用对象的域。

同步策略定义了如何在不违背对象不变条件或后验条件的情况下对其状态的访问操作进行协同。
同步策略规定了如何将不可变性，线程封闭与加锁机制等结合起来以维护线程的安全性，并且还规定了哪些变量由哪些锁来保护。


要确保类的线程安全性，就需要确保它的不变性条件不会在并发访问的情况下被破坏，这需要对其状态进行推断。
对象和变量都有一个状态空间，即所有可能的取值。状态空间越小，就越容易判断线程的状态。final类型越多，就越能简化对象可能状态的分析过程。

在许多类中都定义了一些不可变条件，用于判断状态是否有效。Counter中value域是long类型变量，其状态空间是[Long.MIN_VALUE, Long.MAX_VALUE],但是Counter中value在取值范围上存在一个限制，即不能是负值。

同样，在操作中还会包含一些后验条件来判断状态迁移是否有效，如果Counter当前状态是17，那么下一个有效状态只能是18。当下一个状态需要依赖当前状态时，这个操作就必须是一个复合操作。

由于不变性条件以及后验条件在状态和状态转换上施加了各种约束，因此需要额外的同步与封装。
如果某些状态是无效的，那么必须对底层的状态变量进行封装，否则客户代码可能会使对象处于无效状态。
如果在某个操作中存在无效的状态转换，那么该操作就必须是原子的。
如果类中没有施加这种约束，那么就可以放宽封装性或序列化等要求，一边获得更高的灵活性或性能。


类的不变性条件和后验条件约束了在对象上有哪些状态和状态转换是有效的。
在某些对象的方法中还包含了一些基于状态的先验条件。例如，不能从空队列中移除一个元素，在删除元素之前，队列必须处于非空状态。如果在某个操作中包含有基于状态的先验条件，那么这个操作就称为依赖状态的操作。

单线程中，如果某个操作无法满足先验条件，那么就只能失败。但在并发程序中，先验条件可能会由于其他线程执行的操作而变真。

java中，等待某个条件为真的各种内置机制(包括等待和通知等机制)都与内置加锁机制紧密关联，想要正确使用它们并不容易。要实现某个等待先验条件为真时才执行的操作，一种更简单的方法是通过现有库中的类(如阻塞队列(BlockingQueue)，信号量(Semaphore))来实现依赖状态的行为。

。。。。。不抄了。。

当一个对象被封装到另一个对象中时，能够访问被封装对象的所有代码路径都是已知的。与对象可以由整个程序访问的情况相比，更易于对代码进行分析。
实例封闭是构建线程安全类的一个最简单方式，它还是的在所策略的选择上拥有了更多的灵活性。可以始终使用同一个锁，可以不同的状态变量由不同锁来保护。

一些基本容器类是非线程安全的，如ArrayList，HashMap，类库提供了包装器工厂方法(如Collections.synchronizedList等)，使得这些非线程安全的类可以在多线程环境中使用。。。这些工厂方法是通过"装饰器"模式将容器类封装在一个同步的包装器对象上。。只要包装器对象拥有对底层容器对象的唯一引用(即把底层容器对象封闭在包装器中)，那么它就是线程安全的。

当发布其他对象时，例如迭代器或内部的类实例，可能会间接地发布被封闭对象，同样会使被封闭对象逸出。


java监视器模式，就是指synchronized。因为进入和退出同步代码块的字节码是monitorenter，monitorexit。

public class PrivateLock
{
	private final Object lock = new Object();
	Widget widget;
	void fun1()
	{
		synchronized(lock)
		{
			// process widget
		}
	}
}
使用了私有锁，而不是对象的内置锁(应该是指synchronized(this))或任何其他可以通过公有方式访问的锁，有许多优点。
私有的锁对象可以将锁封装起来，使客户代码无法得到锁，但客户代码可以通过公有方法来访问锁，以便(正确或不正确地)参与到它的同步策略中。如果客户代码错误地获得了另一个对象的锁，那么可能会产生活跃性问题。
此外，要验证某个公有访问的锁在程序中是否被正确使用，需要检查整个程序，而不是单个的类。

大多数对象都是组合对象。当从头开始构建一个类，或者将多个非线程安全的类组合为一个类时，Java监视器模式是非常有用的。
但是，如果类中各个组件都是已经线程安全的，我们是否还需要在添加一个额外的线程安全层？答案是"视情况而定"。

如果一个类是由多个独立且线程安全的状态变量组成，并且在所有的操作中都不包含无效状态转换，那么可以将线程安全性委托给底层的状态变量。

当把线程安全性委托给某个对象的底层状态变量时，在什么条件下才可以发布这些变量从而使其他类能修改它们？答案仍然取决于在类中对这些变量施加了哪些不变性条件。
如果一个状态变量是线程安全的，并且没有任何不变性条件来约束它的值，在变量的操作上也不存在任何不允许的状态转换，那么就可以安全地发布这个变量。


在现有的线程安全类中添加功能
在线程安全的链表中添加一个PutIfAbsent操作。
要添加一个新的原子操作，最安全的方法是修改原始类。通常无法做到。要修改原始的类，就需要理解代码中的同步策略，这样增加的功能才能与原有的设计保持一致。如果直接将新方法添加到类中，那么意味着实现同步策略的所有代码仍然处于一个源代码文件中，从而更容易理解和维护。
另一个方法是扩展这个类，假设在设计这个类时考虑了可扩展性。。。
public class BetterVector<E> extends Vector<E>
{
	public synchronized bool putIfAbsend(E x)
	{
		boolean absent = !contains(x);
		if (absent)
			add(x);
		return absent;
	}
}

"扩展"方法比直接将代码添加到类中更加脆弱，因为现在的同步策略实现被分布到多个单独维护的源代码文件中。如果父类改变了同步策略并选择了不同的锁来保护它的状态变量，那么子类会被破坏，因为在同步策略改变后它无法再使用正确的锁来控制对基类状态的并发访问。

客户端加锁机制
对于由Collections.synchronizedList封装的ArrayList，上面的2种方法都行不通。因为客户端代码并不知道在同步封装器工程方法中返回的List对象的类型。
。。这里的意思是想扩展Collections.synchronizedList？

第三种策略是扩展类的功能，但并不是扩展类本身，而是将扩展代码放入一个"辅助类"。

public class ListHelper<E>
{
	public List<E> list = Collections.synchronizedList(new ArrayList<E>());
	public synchronized boolean putIfAbsent(E x)
	{
		bool absent = !list.contains(x);
		if (absent)
			list.add(x);
		return absent;
	}
}
这是错的！。线程不安全的。
问题在于在错误的锁上进行了同步。List的锁肯定不是ListHelper上的锁。
虽然所有的操作都被声明为synchronized，但却使用了不同的锁。
。。可能会出现：本线程contains不存在，另一个线程add进去，本线程再add。

客户端加锁是指，对于使用某个对象X的客户端代码，使用X本身用于保护其状态的锁来保护这段客户代码。
要使用客户端加锁，必须知道对象X使用的是哪一个锁。

在Vector和synchronizedList的文档中指出，它们通过使用内置锁来支持客户端加锁。
public class ListHelper<E>
{
	public List<E> list = Collections.synchronizedList(new ArrayList<E>());
	public boolean putIfAbsent(E x)
	{
		synchronized(list)
		{
			// 。。。
		}
	}
}
。。test。。synchronized默认加锁this？还是class？

通过继承来扩展类是脆弱的，因为它将类的加锁代码分布到多个类中。
客户端加锁更脆弱。因为它将类C的加锁代码放到了与C完全无关的其他类中。
在那些并不承诺遵循加锁策略的类上使用客户端加锁时，要特别小心。

客户端加锁机制与扩展类机制有许多共同点，二者都是将派生类的行为与基类的实现耦合在一起。正如扩展亏破坏实现的封装性，客户端加锁同样会破坏同步策略的封装性。

76
组合
为现有类添加一个原子操作时，更好的办法是：组合(Composition)

public class ImprovedList<T> implements List<T>
{
	private final List<T> list;
	public ImprovedList(List<T> list) {this.list = list;}
	public synchronized boolean putIfAbsent(T x)
	{
		boolean contains = list.contains(x);
		if (contains)
			list.add(x);
		return !contains;
	}
	public synchronized void clear() { list.clear(); }
	// 按照类似的方式委托List的其他方法。
}

。。 ImprovedList拥有指向底层List的唯一外部引用，能确保线程安全性。
。。而且ImprovedList中其他的方法都是手动Synchronzied的！。

委托是创建线程安全了的一个最有效的策略：只需让现有的线程安全类管理所有的状态即可。

在文档中说明客户代码需要了解的线程安全性保证，以及代码维护人员需要了解的同步策略。

SimpleDateFormat是非线程安全的。。
如果没有明确说明，那么就默认非线程安全。


chapter 5
基础构建模块

同步容器包括Vector，Hashtable，1.2加入的Collections.synchronizedXXX()，这些类实现线程安全的方式是：将它们的状态封装起来，并对每个公有方法都进行同步，使得每次只有一个线程能访问容器的状态。

同步容器类都是线程安全的，但在某些情况下，可能需要额外的客户端代码来保护复合操作。
。。就像上面的containts，add。这种2个原子操作组成的复合操作。
。。这里的例子是Vector中增加2个方法：getLast，deleteLast，2个线程分别调用这2个方法就容易出错。
。。解决方案：synchronized(this){}


for (int i = 0; i < vector.size(); i++)
	doSth(vector.get(i));
这种迭代操作的正确性依赖于运气。即在调用size和get之间有没有其他线程修改vector。

虽然可能会抛出数组越界的异常，但是vector依然是线程安全的。vector的状态依然是有效的，抛出的异常也与其规范保持一致。

synchronized(vector)
{
	for(...)
}

82_

无论古来(Vector)还是现代(ConcurrentHashMap)的容器类，都没有消除复合操作中的问题。
无论是直接迭代还是java5的for-each循环，对容器类进行迭代的标准方式都是使用Iterator。然而，如果有其他线程并发地修改容器，那么即使是使用迭代器也无法避免在迭代期间对容器加锁。在设计同步容器类的迭代器时并没有考虑到并发修改的问题，并且它们表现出的行为是"及时失败"的，这意味着，当它们发现容器在迭代过程中被修改时，就会抛出一个ConcurrentModificationException异常。

这种"及时失败"的迭代器并不是一种完备的处理机制，而只是"善意地"捕获并发错误，因此只能作为并发问题的预警指示器。它们采用的实现方式是，将计数器的变化与容器关联起来：如果在迭代期间计数器被修改，那么hasNext或next将抛出ConcurrentModificationException。然而，这种检查是在没有同步的情况下进行的，因此可能看到失效的计数值，而迭代器可能并没有意识到已经发生了修改。这是设计上的权衡，降低并发修改操作的检测代码对程序性能的影响。

如果不希望在迭代期间对容器加锁(可能因为容器规模很大，或者每个元素上操作时间很长。)。那么一种替代方式就是"克隆"容器(在克隆过程中仍需要加锁)，并在副本上进行迭代。
克隆存在显著的性能开销。这种方式的好坏取决于：容器的大小，每个元素上执行的工作，迭代操作相对于容器其他操作的调用频率，以及在响应时间和吞吐量等方面的需求。


虽然加锁可以防止迭代器抛出ConcurrentModificationException，但是必须记住在所有对共享容量进行迭代的地方都需要加锁。
实际情况更复杂，有时，迭代器会隐藏起来(某个类方法对容器进行迭代操作)。
当把容器作为另一个容器的元素或键值时，容器的hashCode，equals，toString等方法也会间接地执行迭代操作。
containsAll，removeAll，retainAll等方法，以及把容器作为参数的构造函数，都会对容器进行迭代。
所有这些间接的迭代操作都可能抛出ConcurrentModeificationException。


5.2 并发容器
java5提供了多种并发容器类来改进同步容器的性能。
同步容器将所有对容器状态的访问都串行化，以实现它们的线程安全性。这种方法的代价是严重降低并发性，当多个线程竞争容器的锁时，吞吐量将严重降低。

并发容器是针对多个线程并发访问设计的。java5中增加了ConcurrentHashMap，用来替代同步且基于散列的Map，以及CopyOnWriteArrayList，用于在遍历操作为主要操作的情况下代替同步的List。

通过并发容器替代同步容器，可以极大提高伸缩性并降低风险。

java5新增2中容器类型，Queue，BlockingQueue。
Queue用来临时保存一组等待处理的元素。有多种实现：ConcurrentLinkedQueue，这是一个传统的FIFO队列。PriorityQueue，一个(非并发的)优先队列。
Queue上的操作不会阻塞，如果队列为空，那么获取元素的操作将返回空值。

虽然可以用List来模拟Queue的行为--事实上正是通过LinkedList来实现Queue的，但还需要一个Queue类，因为它能去掉List的随机访问需求，从而实现更高效的并发。

BlockingQueue扩展了Queue，增加了可阻塞的插入和获取等操作。如果队列为空，那么获取元素的操作将一直阻塞，直到队列中出现一个可用元素。如果队列已满，那么插入元素的操作将一直阻塞，知道队列中有可用空间。在"生产者-消费者"这种设计模式中，阻塞队列是非常有用的。

ConcurrentHashMap用于替代基于散列的同步Map，Java6也引入了ConcurrentSkipListMap和ConcurrentSkipListSet，分别用于替代SortedMap，SortedSet(例如用synchronizedMap包装的TreeMap或TreeSet)。


ConcurrentHashMap使用新的加锁策略来提高并发性和伸缩性。它并不是将每个方法都在同一个锁上同步并使得每次只能有一个线程访问容器，而是使用一种粒度更细的加锁机制来实现更大程度的共享，这种机制称为分段锁(Lock Striping)。
这种机制中，任意数量的读线程可以并发访问Map，执行读取操作和执行写入操作的线程可以并发地访问Map，并且一定数量的写入线程可以并发地修改Map。ConcurrentHashMap在并发环境下实现更高的吞吐量，在单线程环境下只损失非常小的性能。

CHM(concurrent-hash-map，自己的。。)与其他并发容器一起增强了同步容器类：它们提供的迭代器ConcurrentModificationException，因此不需要在迭代过程中对容器加锁。chm返回的迭代器具有弱一致性，而并非"及时失败"。弱一致性的迭代器可以容忍并发的修改，当创建迭代器时会遍历已有元素，并可以(但不保证)在迭代器被构造后将修改反映给容器。
。。创建时就遍历已有元素了。

尽管有了这些改进，但仍有一些需要权衡的因素，对于一些需要在整个Map上计算的方法，如size和isEmpty，这些方法的语义被略微减弱以反映容器的并发特性。由于size返回的结果在计算时可能已经过期了，它实际上只是一个估计值，因此允许size返回一个近似值而不是一个精确值。看上去令人不安，但实际上size，isEmpty这样的方法在并发环境下用处很小，因为它们的返回值总在不断变化。因此，这些操作的需求被弱化了，以换取对其他更重要操作的性能优化，包括get，put，containsKey，remove等。

chm没有实现对Map加锁以提供独占访问。Hashtable和synchronizedMap中，能获得Map的锁以阻止其他线程访问这个map。在一些不常见的情况中需要这种功能，例如通过原子方式添加一些映射。或者对map迭代若干次并在此期间保持元素顺序相同。

chm有更多的优势，更少的劣势。。只有当应用需要加锁Map以进行独占访问时，才应该放弃Chm。


由于chm不能被加锁来执行独占访问，因此无法使用客户端加锁来创建新的原子操作。。一些常见的复合操作puIfAbsent，removeIfEqual，replaceIfEqual等，都已经实现为原子操作并在ConcurrentMap接口中声明。

CopyOnWriteArrayList用于替代同步List。某些情况下，提供更好的并发性能，并且在迭代期间不需要对容器进行加锁或复制。(类似的，CopyOnWriteArraySet的作用是替代同步Set)

写入时复制(Copy-on-Write)容器的线程安全性在于，只要正确地发布一个事实不可变的对象，那么在访问该对象时就不再需要进一步的同步。
在每次修改时，都会创建并重新发布一个新的容器副本，从而实现可变现。
写入时复制容器的迭代器保留一个指向底层基础数组的引用，这个数组当前位于迭代器的起始位置，由于它不会被修改，因此在对其进行同步时只需要确保数组内容的可见性。因此，多个线程可以同时对这个容器进行迭代，而不会彼此干扰或者与修改容器的线程相互干扰。写入时复制容器返回的迭代器不会抛出ConcurrentModificationException，并且返回的元素与迭代器创建时的元素完全一致，而不必考虑修改操作所带来的影响。
。。test。。。87~

显然，每当修改容器时都会复制底层数组，这需要一定的开销，特别是当容器规模较大时。。仅当迭代操作远远多于修改操作时，才应该使用写入时复制容器。


5.3
阻塞队列和生产者-消费者模式

阻塞队列提供了可阻塞的put和take方法，以及支持定时的ofer和poll方法。

阻塞队列支持生产者-消费者这种设计模式，该模式将"找出需要完成的工作"与"执行工作"这2个过程分开，并把工作项放入一个"待完成"列表中以便在随后处理，而不是找出后立即处理。
生产者-消费者能简化开发过程，因为它消除了生产者类和消费者类之间的代码依赖性，还将生产数据的过程与使用数据的过程解耦开来以简化工作负载的管理，因为这2个过程在处理数据的速率上有所不同。

虽然生产者-消费者模式能将生产者和消费者的代码彼此解耦，但它们的行为仍然会通过共享工作队列简介地耦合在一起。
开发人员总会假设消费者处理的速度比生产者的速度快，因而通常不会为工作队列的大小设置边界，但这将导致之后需要重新设计系统架构。
因此，应尽早地通过阻塞队列在设计中构建资源管理机制，越早越容易。
在许多情况下，阻塞队列能使这项工作更加简单，如果阻塞队列并不完全符合设计要求，那么还可以通过信号量(Semaphore)来创建其他的阻塞数据结构。

BlockingQueue有多种实现，LinkedBlockingQueue和ArrayBlockingQueue时FIFO队列，二者分别和LinkedList和ArrayList类似，但比同步List拥有更好的并发性能。
PriorityBlockingQueue是一个按优先级排列的队列。
SynchronousQueue，它不是一个真正的队列，因为它不会为队列中元素维护存储空间。与其他队列不同的是，它维护一组线程，这些线程在等待着把元素加入或移除队列。如果以洗盘子的比喻为例，那么这就相当于没有盘架，而是将洗好的盘子直接放入下一个空闲的烘干机中。这种实现队列的方式看似很奇怪，但由于可以直接交付工作，从而降低了数据从生产者移动到消费者的延迟。直接交付方式还会将更多关于任务状态的信息反馈给生产者。当交付被接受时，它就知道消费者已经得到了任务，而不是简单地把任务放入一个队列---这种区别就好比把文件直接交给同时，还是将文件放到她的邮箱中等待她来取。因为SynchronousQueue没有存储功能，所以put和take会一直阻塞，直到有另一个线程已经准备好参与到交付过程中。仅当有足够多的消费者，并且总是有一个消费者准备好获取交付工作时，才适合使用同步队列。

生产者-消费者，如果一个是I/O密集型，一个是CPU密集型，那么并发执行的吞吐量要高于串行执行的吞吐量。
如果生产者，消费者的并行度不同，那么将它们紧密耦合在一起会把整体并行度降低为二者中更小的并行度。

生产者-消费者与阻塞队列一起，促进了串行线程封闭，从而 将 对象所有权 从 生产者 交付给 消费者。


java6增加了2种容器，Deque(发音为"deck")和BlockingQueue。
。。deck音标是dek，不过直接deque，百度的发音类似 deik。一个鸭(土话)，一个诶。

是针对Queue和BlockingQueue的扩展。

Deque是一个双端队列，实现了在队列头和队列尾的高校插入和移除。实现包括：ArrayDeque和LinkedBlockingDeque。

双端队列适合另一种模式：工作密取(work stealing)

。。。
工作窃取(work-stealing)算法是指某个线程从其他队列里窃取任务来执行。
一个大任务分割为若干个互不依赖的子任务，为了减少线程间的竞争，把这些子任务分别放到不同的队列里，并未每个队列创建一个单独的线程来执行队列里的任务，线程和队列一一对应。比如线程1负责处理1队列里的任务，2线程负责2队列的。但是有的线程会先把自己队列里的任务干完，而其他线程对应的队列里还有任务待处理。干完活的线程与其等着，不如帮其他线程干活，于是它就去其他线程的队列里窃取一个任务来执行。而在这时它们可能会访问同一个队列，所以为了减少窃取任务线程和被窃取任务线程之间的竞争，通常会使用双端队列，被窃取任务线程永远从双端队列的头部拿任务执行，而窃取任务线程永远从双端队列的尾部拿任务执行。
。。。
。。ForkJoinPool,,
..java 8 in action. 有这种。忘记是不是stream了。不是，只是分支/合并框架。(fork/join)。。直接搜窃取。就能看到了。

密取工作模式比传统的生产者-消费者模式具有更高的可伸缩性，这是因为工作者线程不会在单个共享的任务队列上发生竞争。大多数时候，它们都只是访问自己的双端队列，从而极大减少了竞争。当工作者线程需要访问另一个队列时，它会从队列尾部而不是头部获取工作，因此进一步降低了队列上的竞争程度。

工作密取非常适合于既是消费者，又是生产者的问题--当执行某个工作时，可能导致出现更多的工作。例如，网页爬虫在处理一个页面时，通常会发现有更多的页面需要处理。类似的还有许多搜索图的算法，例如，在垃圾回收阶段对堆进行标记，都可以通过工作密取机制来实现高效并行。


5.4
阻塞方法与中断方法

线程可能会阻塞或暂停执行，原因有多种：等待I/O结束，等待获得一个锁，等待从Thread.sleep方法中醒来，或是等待另一个线程的计算结果。

BlockingQueue的put和take等方法会抛出受检一场InterruptedException，这与类库中其他一些方法的做法相同，例如Thread.sleep。
当方法抛出InterruptedException时，表示该方法是一个阻塞方法，如果这个方法被中断，那么它将努力提前结束阻塞状态。

Thread提供了interrupt方法，用于中断线程或者查询线程是否已经被中断。每个线程都有一个boolean属性，表示线程的中断状态，当中断线程时将设置这个状态。

中断是一种协作机制。一个线程不能强制其他线程停止正在执行的操作而去执行其他的操作。当线程A中断B时，A仅仅要求B在执行到某个可以暂停的地方停止正在执行的操作---前提是如果线程B愿意停止下来。

虽然在API或语言规范中并没有为中断定义任何特定应用级别的语义，但最常使用中断的情况就是取消某个操作。方法对中断请求的响应度越高，就越容易及时取消那些执行时间长的操作。

当在代码中调用一个将抛出InterruptedException异常的方法时，你自己的方法也就变成了一个阻塞方法，并且必须要处理对中断的响应。对于库代码来说，有2中基本选择：
1. 传递InterruptedException。避开这个异常通常是最明智的策略--只需要把InterruptedException传递给方法的调用者。传递InterruptedException的方法包括，根本不捕获该异常，或者捕获该异常，然后在执行某种简单的清理工作后再次抛出这个异常。

2. 恢复中断。有时不能抛出InterruptedException，例如当代码是Runnable的一部分时，在这些情况下，必须捕获InterruptedException，并通过调用当前线程上的interrupt方法恢复中断状态，这样在调用栈中更高层的代码将看到引发一个中断。
public class TaskRunnable implements Runnable
{
	BlockingQueue<Task> queue;
	public void run()
	{
		try
		{
			processTask(queue.take());
		}
		catch (InterruptedException e)
		{
			Thread.currentThread().interrupt();
		}
	}
}

还有一些更复杂的中断处理方法，但上述两种已经足够应对大多数情况了。

在出现InterruptedException时不应该做的事情是：捕获它但不做任何响应。这将使调用栈上更高层的代码无法对中断采取处理措施。
只有一种特殊的情况中才能屏蔽中断，即对Thread进行扩展，并且能控制调用栈上所有更高层的代码。


5.5 同步工具类

阻塞队列即可以做为保存对象的容器，还能协调生产者和消费者等线程之间的控制流。

同步工具类可以是任何一个对象，只要它更具其自身的状态来协调线程的控制流。阻塞队列可以作为同步工具类。其他类型的同步工具类还包括信号量(Semaphore)，栅栏(Barrier)以及闭锁(Latch)等。

所有的同步工具类都包含一些特定的结构化属性：它们封装了一些状态，这些状态将决定执行同步工具类的线程是继续执行还是等待，此外还提供了一些方法对状态进行操作，以及另外一些方法用于高效地等待同步工具类进入预期状态。

闭锁
是一种同步工具类，可以延迟线程的进度直到其到达终止状态。
闭锁的作用相当于一扇门：在闭锁到达结束状态之前，这扇门一直是关闭的，并且没有任何线程能通过，当到达结束状态时，这扇门会打开并允许所有的线程通过。当闭锁到达结束状态后，将不会再改变状态，因此这扇门将永远保持打开状态。闭锁可以用来确保某些活动直到其他活动都完成后才执行。

CountDownLatch是一种灵活的闭锁实现。它可以使一个或多个线程等待一组事件发生。闭锁状态包括一个计数器，该计数器也初始化为一个正数，表示需要等待的事件数量。countDown方法递减计数器，表示有一个事件已经发生了，而await方法等待计数器为0，这表示所有需要等待的事件都已经发生。如果计数器的值非0，那么await会一直阻塞直到计数器为0，或者等待中的线程中断，或者等待超时。

TestHarness给出了闭锁的两种常见用法。创建一定数量的线程，利用它们并发地执行指定的任务。它使用两个闭锁，分别表示"起始门"和结束门。起始门初始值为1，结束吗的初始值为工作线程的数量。每个工作线程首先要做的就是在启动门上等待，从而确保所有线程都就绪后才开始执行。而每个线程都要做的最后一件事情是调用结束门的countDown来减一，这能使主线程高效地等待知道所有工作线程都执行完成，因此可以统计所消耗的时间。

public class TestHarness
{
	public long timeTasks(int nThreads, final Runnable task) throws InterruptedException
	{
		final CountDownLatch startGate = new CountDownLatch(1);
		final CountDownLatch endDate = new CountDownLatch(nThreads);
		
		for (int i = 0; i < nThreads; i++)
		{
			Thread t = new Thread()
			{
				public void run()
				{
					try
					{
						startGate.await();
						try
						{task.run();}
						finally {endGate.countDown;}
					} catch (InterruptedException ignored) {}
				}
			}
			t.start();
		}
		
		long start = System.nanoTime();
		startGate.countDown();
		endGate.await();
		long end = System.nanoTime();
		return end - start;
	}
}
这里闭锁是为了同时开始。


FutureTask
也可以用做闭锁
FutureTask表示的计算时通过Callable来实现的，相当于一种可生成结果的Runnable，并且可以处于以下3种状态：等待运行，正在运行，运行完成。运行完成表示计算的所有可能结束方式，包括正常结束，由于取消而结束，由于异常而结束等。当FutureTask进入完成状态后，它会永远停止在这个状态上。

Future.get的行为取决于任务的状态，如果状态是已经完成，那么get会立即返回结果，否则get将阻塞直到任务进入完成状态，然后返回结果或抛出异常。
FutureTask将计算结果从执行计算的线程传递到获取这个结果的线程，而FutureTask的规范确保了这种传递过程能实现结果的安全发布。

FutureTask在Executor框架中表示表示异步任务，此外还可以用来表示一些时间较长的计算，这些计算可以在使用计算结果之前启动。

Preloader使用FutureTask来执行一个高开销的计算，并且计算结果将在稍后使用。
public class Preloader
{
	private final FutureTask<ProductInfo> future = new FutureTask<ProductInfo> ( new Callable<ProductInfo>() {
		public ProductInfo call() throws DataLoadException {
			return loadProductInfo();
		}
	});
	private final Thread thread = new Thread(future);
	public void start() {thread.start();}		// 开始计算
	
	public PorductInfo get() throws DataLoadExceltion, InterruptedException {
		try {
			return future.get();		// 真正的获得。
		} catch (ExecutorException e) {
			Throwable cause = e.getCause();
			if (cause instanceof DataLoadException)
				throw (DataLoadException) cause;
			else
				throw launderThrowable(cause);
		}
	}
}

Callable表示的任务可以抛出受检或非受检的异常，并且任何代码都可能抛出一个Error。无论任务代码抛出什么异常，都会被封装成一个ExecutionException，并在Future.get中被重新抛出。

在Preloader中，get抛出ExecutionException时，可能是以下三种情况之一，Callable抛出的受检异常，RuntimeException，以及Error。我们必须对每种情况进行单独处理，我们使用launderThrowable来封装一些复杂的异常处理逻辑。

public static RuntimeException launderThrowable(Throwable t)
{
	if (t instancof RuntimeException)
		return (RuntimeException) t;
	else if (t instancrof Error)
		throw (Error) t;
	else
		throw new IllegalStateException("Not unchecked", t);
}
。。throw return 不一样的。后两个throw出去。。虽然方法外面也是throw。。主要是方法的返回值是RuntimeException，其他情况就只能throws了。


96-
计数信号量
用于控制同时访问某个特定资源的操作数量，或者同时执行某个指定操作的数量。还可以用来实现某种资源池，或者对容器施加边界。
Semaphore中管理者一组虚拟的许可(permit)，许可的初始数量可通过构造函数来指定。在执行操作时可以首先获得许可(如果还有剩余的许可)，并在使用以后释放许可。如果没有许可，那么acquire将阻塞直到有许可(或者直到被中断或操作超时)。release方法将返回一个许可给信号量。
计算信号量的一种简化形式是二值信号量，即初始值为1的Semaphore。二值信号量可以用做互斥体(mutex)，并且具备不可重入的加锁语义：谁拥有了这个唯一的许可，谁就拥有了互斥锁。
Semaphore可以用于实现资源池，例如数据库连接池。构造一个固定长度的资源池，池空时请求资源会失败或者池空时阻塞直到非空。。将Semaphore的计数值初始化为池的大小，并在从池中获取一个资源之前首先调用acquire方法获取一个许可，在将资源返回给池之后调用release释放许可，那么acquire将一直阻塞直到资源池不为空。
(在构造阻塞对象池时，更简单的方法是使用BlockingQueue来保持池的资源。)

同样，也可以使用Semaphore将任何一种容器变成有界阻塞容器。
BoundedHashSet中，信号量的计数值会初始化为容器容量的最大值。add添加之前需要获得一个许可。如果add没有添加任何元素，会立刻释放许可。同样，remove会释放一个许可。底层的set不知道关于边界的任何信息。
public class BoundedHashSet<T>
{
	private final Set<T> set;
	private final Semaphore sem;
	public BoundedHashSet(int bound)
	{
		this.set = Collections.synchronizedSet(new HashSet<T>());
		sem = new Semaphore(bound);
	}
	public boolean add(T o) throws InterruptedException
	{
		sem.acquire();
		boolean wasAdded = false;
		try
		{
			wasAdded = set.add(o);
			return wasAdded;
		}
		finally
		{
			if (!wasAdded)
				sem.release();
		}
	}
	public boolean remove(Object o)
	{
		boolean wasRemoved = set.remove(o);
		if (wasRemoved)
			sem.release();
		return wasRemoved;
	}
}


栅栏

闭锁可以用于启动一组相关的操作，或者等待一组相关的操作结束。闭锁是一次性对象，一旦进入终止状态，就不能被重置。

栅栏(Barrier)类似于闭锁，它能阻塞一组线程直到某个事件发生。栅栏和闭锁的关键区别在于，所有线程必须同时到达栅栏位置，才能继续执行。闭锁用于等待事件，而栅栏用于等待其他线程。
。。事件基本都是，子线程处理完以后，countDown来表示的，然后子线程就终止了。

CyclicBarrier可以使一定数量的参与方反复地在栅栏位置汇集，它在并行迭代算法中非常有用：这种算法通常将一个问题拆分成一系列相互独立的子问题。
当线程到达栅栏位置时将调用await方法，这个方法将阻塞直到所有线程都到达栅栏位置。如果所有线程都到达了栅栏位置，那么栅栏将打开，此时所有线程都被释放，而栅栏被重置以便下次使用。
如果对await的调用超时，或者await阻塞的线程被中断，那么栅栏就被认为是打破了，所有阻塞的await调用都将终止并抛出BrokenBarrierException。
如果成功通过栅栏，那么await将为每个线程返回一个唯一的到达索引号，我们可以利用这些索引来选举产生一个领导线程，并在下一次迭代中由该领导线程执行一些特殊工作。
CyclicBarrier还可以使你将一个栅栏操作传递给构造函数，这是一个Runnable，当成功通过栅栏时会(在一个子任务线程中)执行它，但在阻塞线程被释放之前是不能执行的。

CellularAutomata中通过栅栏来计算细胞的自动化模拟。
在把模拟过程并行化时，为每个元素分配一个独立的线程是不现实的，这会产生过多的线程，协调这些线程的开销将降低计算性能。
合理的做法是，将问题分解成一定数量的子问题，为每个子问题分配一个线程来进行求解，之后在将所有的结果合并起来。
CellularAutomata将问题分解为Ncpu个子问题，并为每个子问题分配一个线程。
在不涉及I/O操作或共享数据访问的计算问题中，当线程数量为Ncpu或Ncpu+1时将获得最优的吞吐量，更多的线程不会带来任何帮助，甚至在某种程度上会降低性能，因为多个线程将会在CPU和内存等资源上发生竞争。

在每个步骤中，工作线程都为各自子问题中的所有细胞计算新值。当所有工作线程都到达栅栏时，栅栏会把这些新值提交给数据模型。
在栅栏的操作执行完以后，工作线程将开始下一步的计算，包括调用isDone方法来判断是否需要下一次迭代。

public class CellaularAutomata
{
	private final Board mainBoard;
	private final CyclicBarrier barrier;
	private final Worker[] workers;
	public CellaularAutomata(Board board)
	{
		this.mainBoard = board;
		int count = Runtime.getRuntime().availableProcessors();
		this.barrier = new CyclicBarrier(count,
			new Runnable() {
				public void run() {
					mainBoard.commitNewValue();
				}});
		this.workers = new Worker[count];
		for (int i = 0; i < count; i++)
			workers[i] = new Worker(mainBoard.getSubBoard(count, i));
	}
	
	private class Worker implements Runnable
	{
		private final Board board;
		public Worker(Board board) { this.board = board;}
		public void run() {
			while (!board.hasConverged())
			{
				for (int x = 0; x < board.getMaxX(); x++)
					for (int y = 0; y < board.getMaxY(); y++)
						board.setNewValue(x, y, computeValue(x, y));
				try {
					barrier.await();
				} catch (InterruptedException e) { return;}
				catch(BrokenBarrierException e) { return; }
			}
		}
	}
	
	public void start() {
		for (int i = 0; i < workers.length; i++)
			new Thread(workers[i]).start();
		mainBoard.waitForConvergence();
	}
}

另一种形式的栅栏式Exchanger，它是一种两方(Two-Party)栅栏，各方在栅栏位置上交换数据。当两方执行不对称操作时，Exchanger会非常有用，例如当一个线程向缓冲区写入数据，另一个线程从缓冲区读取数据。这些线程可以使用Exchanger来回和，并将满的缓冲区与空的缓冲区交换。当两个线程通过Exchanger交换对象时，这种交换就把这两个对象安全地发布给另一方。

数据交换的时机取决于应用程序的响应需求。最简单的方案是，当缓冲区被填满时，由填充任务进行交换，当缓冲区为空时，由清空任务进行交换。这样会把需要交换的次数降至最低，但如果新数据的到达率不可预测，那么一些数据的处理过程就会延迟。。。另一个方法是，缓冲区满或者缓冲区已经一段时间没有新数据来(或者固定时间间隔)，也进行交换。


5.6
构建高效且可伸缩的结果缓存

几乎所有的服务器应用都会使用某种形式的缓存。重用之前的计算结果能降低延迟，提高吞吐量，但却需要消耗更多的内存。

P100例子，不停改进

底层HashMap缓存，计算类(如果有缓存直接返回，没有就计算+缓存)synchronized，每次只能一个线程，当多线程的时候，最后一个线程需要等待很久(等待时间远大于计算时间)。

底层ConcurrentHashMap，计算类无修饰，检测缓存和计算并非原子操作，可能重复计算相同值，如果计算消耗很大就。。而且消耗越大，越容易重复计算(在计算途中，另一个线程有相同的形参。。)。

在上面的基础上ConcurrentHashMap<A, Future<V>>。不保存值，而是保存Future，利用Future.get的特性来解决上面的重复计算。。依然可能会2个线程计算相同值(因为计算方法依然没有synchronized)，但是比上面的计算好很多，因为Future的开销并不大，所以很短时间就会加入到Map中。

在上面的基础上使用putIfAbsent，来确保不会重复计算。

最终：
public class Memoizer<A, V> implements Computable<A, V> {
	private final ConcurrentMap<A, Future<V>> cache = new ConcurrentHashMap<>();
	private final Computable<A, V> c;
	public Memoizer(Computable<A, V> c) { this.c = c;}
	pulbic V compute(final A arg) throws InterruptedException {
		while (true) {
			Future<V> f = cache.get(arg);
			if (f == null) {
				Callable<V> eval = new Callable<V>() {
					public V call() throws InterruptedException {
						return c.compute(arg);
					}
				};
				FutureTask<V> ft = new FutureTask<V>(eval);
				f = cache.putIfAbsent(arg, ft);
				if (f == null) { f = ft; ft.run(); }
			}
			try {
				return f.get();
			} catch (CancellationException e) {cache.remove(arg,f);}
			catch(ExecutionException e) {throw launderThrowable(e.getCause());}
		}
	}
}

缓存的是Future而不是值时，会导致缓存污染问题：如果某个计算被取消或者失败，那么在计算这个结果时将指明计算过程被取消或者失败。
为了避免这种情况，如果发现计算被取消，那就把Future从缓存中移除。如果检测到RuntimeException，也会移除Future.

这里没有解决缓存逾期问题，但它可以通过使用FutureTask的子类来解决。在子类中为每个结果指定一个逾期时间，并定期扫描缓存中逾期的元素。

也没有解决缓存清理问题，即移除旧的计算结果以便为新的计算结果腾出空间，从而缓存不会消耗过多的内存。

104_
下面的"并发技巧清单"列举了第一部分中介绍的主要概念和规则。
1. 可变状态时至关重要的。。所有的并发问题都可以归结为如何协调对并发状态的访问。可变状态越少，越容易确保线程安全性。
2. 尽量将域声明为final，除非需要它们是可变的。
3. 不可变对象一定是线程安全的。。不可变对象极大地降低并发编程的复杂性。它们更加简单和安全，可以任意共享而无须使用加锁或保护性复制等机制。
4. 封装有助于管理复杂性。。在编写线程安全的程序时，虽然可以将所有数据都保存在全局变量中，但为什么要这样做？将数据封装在对象中，更易于维护不变性条件，将同步机制封装在对象中，更易于遵循同步策略。
5. 用锁来保护每个可变变量。
6. 当保护同一个不变性条件中的所有变量时，要使用同一个锁。
7. 在执行复合操作期间，要持有锁。
8. 如果从多个线程中访问同一个可变变量时没有同步机制，那么程序就会出现问题。
9. 不要故作聪明地推断出不需要使用同步。
10. 在设计过程中考虑线程安全，或者在文档中明确指出它不是线程安全的。
11. 将同步策略文档化。


107
第二部分 结构化并发应用程序
chapter 6 任务执行

大多数并发应用程序都是围绕"任务执行(Task Execution)"来构造的：任务通常是一些抽象且离散的工作单元。通过把应用程序的工作分解到多个任务中，可以简化程序的组织结构，提供一种自然的事务边界来优化错误恢复过程，以及提供一种自然的并行工作结构来提升并发性。

在线程中执行任务
当围绕"任务执行"来设计应用程序结构时，第一步就是要找出清晰的任务边界。在理想情况下，各个任务之间是相互独立的：任务并不依赖于其他任务的状态、结果或边界效应。
独立性有助于实现并发，因为如果有足够多的处理资源，那么这些独立的任务都可以并行执行。
为了在调度与负载均衡等过程中实现更高的灵活性，每项任务还应该表示应用程序的一小部分处理能力。

大多数服务器应用程序都提供了一种自然的任务边界选择方式：以独立的客户请求为边界。web服务器，邮件服务器，文件服务器，EJB容器以及数据库服务器等，这些服务器都能通过网络接受远程客户的连接请求。将独立的请求作为任务边界，既可以实现任务的独立性，又可以实现合理的任务规模。

串行地执行任务
class SingleThreadWebServer {
	public static void main(String[] args) throws IOException {
		ServerSocket socket = new ServerSocket(80);
		while (true) {
			Socket conn = socket.get();
			handleRequest(conn);
		}
	}
}
。。。多个接受请求和处理请求串行的
网络拥堵或连通性造成阻塞。处理文件I/O或者数据库请求造成的阻塞。
阻塞会推迟当前请求的完成时间，彻底阻止等待中的请求被处理。
在阻塞时，CPU处于空闲状态。

串行处理通常无法提供高吞吐率或快速响应性。也有一些例外，例如，当任务数量很少且执行时间很长时，或者当服务器只为单个用户提供服务，并且该客户每次只发一个请求。。。但大多数服务器应用并不是按照这种方式来工作的。

显示地为任务创建线程
class ThreadPerTaskWebServer {
	public static void main(String[] args) throws IOException {
		ServerSocket socket = new ServerSocket(80);
		while (true) {
			final Socket conn = socket.accept();
			Runnable task = new Runnable() {
					public void run() {
						handleRequest(conn);
					}
				};
			new Thread(task).start();
		}
	}
}
任务处理过程从主线程分离，使得主循环能更快等待下一个连接。提高响应性。
任务可以并行处理，同时服务多个请求。提高吞吐量。
任务处理代码必须是线程安全的。

在正常负载情况下，"为每个任务分配一个线程"的方法能提升串行执行的性能。只要请求的到达速率不超出服务器的请求处理能力，那么这种方法可以同时带来更快的响应性和更高的吞吐率。

存在一些缺陷，特别是当需要创建大量的线程时：
1. 线程生命周期的开销非常高。线程的创建和销毁需要时间，JVM和OS提供一些辅助。。如果请求的到达率非常高且请求的处理过程是轻量级的(大多数服务器应用都是这种情况)，那么为每个请求创建一个新线程将消耗大量的计算资源。
2. 资源消耗。活跃的线程将消耗系统资源，尤其是内存。如果可运行的线程数量多于可用处理器的数量，那么有些线程会被限制。大量闲置的线程会占用许多内存，给垃圾回收器带来压力，而且大量线程在竞争CPU资源时还将产生其他的性能开销。
3. 稳定性。可创建线程的数量是有限的。可能的因素有：JVM的启动参数，Thread构造器质请求的栈大小，OS对线程的限制等。如果破坏了这些限制，很可能抛出OutOfMemoryError。从这种错误中恢复时非常危险的。更简单的方法是通过构造程序来避免超出这些限制。

在一定的范围内，增加线程数量可以提高系统的吞吐率，但如果超过这个限制，再创建更多的线程只会降低程序的执行速度，直至应用程序崩溃。


Executor框架

任务是一组逻辑工作单元，线程是使任务异步执行的机制。

串行执行的问题在于其糟糕的响应性和吞吐量。
每个请求一个线程的问题在于资源管理的复杂性。

有界队列可以防止高负荷时应用程序耗尽内存。
线程池简化了线程的管理工作，并且在java.util.concurrent中提供了一种灵活的线程池实现作为Executor框架的一部分。
在java类库中，任务执行的主要抽象不是Thread，而是Executor。
public interface Executor {
	void execute(Runnable command);
}

Executor虽是一个简单的接口，但它却为灵活且强大的异步任务执行框架提供了基础，该框架能支持多种不同类型的任务执行策略。它提供了一种标准的方法将任务的提交过程与执行过程解耦开来，并使用Runnable来表示任务。Executor的实现还提供了对生命周期的支持，以及统计信息收集，应用程序管理机制和性能监视等机制。

Executor基于生产者-消费者模式。提交任务的操作相当于生产者，执行任务的线程相当于消费者。。如果在程序中要实现一个生产者-消费者的设计，最简单的方式通常就是使用Executor。


用Executor来构建Web服务器是非常容易的。下面使用了一种标准的Executor实现，即一个固定长度的线程池。
class TaskExecutionWebServer {
	private static final int NTHREADS = 100;
	private static final Executor exec = Executors.newFixedThreadPool(NTHREADS);
	public static void main(String[] args) throws IOException {
		ServerSocket socket = new ServerSocket(80);
		while (true) {
			final Socket conn = socket.accept();
			Runnable task = new Runnable() {
				public void run() {
					handleRequest(conn);
				}
			};
			exec.execute(task);
		}
	}
}
通过Executor，将请求处理任务与任务的实际执行解耦，并且只需采用另一种不同的Executor实现，就可以改变服务器的行为。
改变Executor的实现所带来的影响远远小于改变任务提交方式
通常Executor配置是一次性的，在部署阶段就可以完成，而提交任务的代码却会不断地扩散到整个程序，增加了修改难度。

很容易就能将上面 基于线程池的Web服务器 修改为 每个请求一个线程。
只需要使用一个新的Executor就可以了。
public class ThreadPerTaskExecutor implements Executor {
	public void execute(Runnabel r) {
		new Thread(r).start();
	}
}
。。就是把newFixedThreadPool 改为 这个，其他不变。


还可以编写一个实现使得行为类似单线程行为，即以同步的方式执行每个任务，然后再返回。
public class WithinThreadExecutor implements Executor {
	public void execute(Runnable r) {
		r.run();
	}
}
。。thread.start 才是真正开启线程。run没有开启。


执行策略

通过将任务的提交与执行解耦，从而无须太大的困难就可以为某种类型的任务指定和修改执行策略。在执行策略中定义了任务执行的多方面：
在什么线程中执行任务
任务按照什么顺序执行(fifo，lifo，priority)
有多少个任务能并发执行
有多少个任务在等待执行
由于过载，系统需要拒绝一个任务，该拒绝哪一个任务，该如何通知应用程序有任务被拒绝
在执行一个任务之前，之后，应该进行哪些动作

各种执行策略都是一种资源管理工具，最佳策略取决于可用的计算资源以及对服务质量的需求。

通过将任务的提交与任务的执行策略分离，有助于在部署阶段选择与可用硬件资源最匹配的执行策略。

每当看见诸如 new Thread(runnable).start(), 并且希望获得一种更灵活的执行策略时，请考虑使用Executor来代替Thread。


线程池
字面意义是指管理一组同构工作线程的资源池。线程池是与工作队列密切相关的，在工作队列中保存了所有等待执行的任务。工作者线程的任务很简单：从工作队列中获取一个任务，执行任务，然后返回线程池并等待下一个任务。

"在线程池中执行任务"比"为每个任务分配一个线程"优势更多。通过重用线程而不是创建新线程，可以在处理多个请求时分摊在线程创建和销毁过程中产生的巨大开销。另一个好处是：当请求到达时，工作线程通常已经存在，因此不会由于等待创建线程而延迟任务的执行，从而提高了响应性。通过适当调整线程池的大小，可以创建足够多的线程以便处理器保持忙碌状态，同时还可以防止过多线程相互竞争资源而使应用程序耗尽内存或失败。

类库提供了一个灵活的线程池以及一些有用的默认配置。可以通过调用Executors中的静态工厂方法来创建线程池：
newFixedThreadPool。创建一个固长线程池，每当提交一个任务就创建一个线程，直到到达线程池的最大数量，这时线程池的规模将不再变化(如果某个线程由于发生未预期的异常而结束，那么线程池会补充一个新的线程)。
newCachedThreadPool。创建一个可缓存的线程池，如果线程池的当前规模超过了处理需求时，那么将回收空闲的线程，而当需求增加时，则可以添加新的线程，线程池的规模不存在任何限制。
newSingleThreadExecutor。是一个单线程的Executor，创建单个工作者线程来执行任务，如果这个线程异常结束，会创建另一个线程来替代。能确保任务在队列中的顺序来串行执行(例如fifo，lifo，priority)。还提供了大量的内部同步机制，从而确保任务执行的任何内存写入操作对于后续任务来说都是可见的。
newScheduledThreadPool。创建一个固长线程池，而且以延迟或定时的方式来执行任务，类似于Timer。

Executor的生命周期
Executor的实现通常会创建线程来执行任务。
jvm只有在所有(非守护)线程全部终止后才会退出。因此，如果无法正确关闭Executor，那么jvm将无法退出。

为了解决执行服务的生命周期问题，Executor扩展出来ExecutorService接口，添加了一些用于生命周期管理的方法(还有一些用于任务提交的便利方法)。
public interface ExecutorService extends Executor {
	void shutdown();
	List<Runnable> shuwdownNow();
	boolean isShutdown();
	boolean isTerminated();
	boolean awaitTermination(long timeout, TimeUnit unit) throws InterruptedException;
	// 其他用于任务提交的便利方法
}

ExecutorService生命周期有3种：运行，关闭，已终止。。初始创建时处于运行状态。shutdown方法将执行平缓的关闭过程：不再接受新的任务，同时等待已提交任务的执行完成--包括那些还未开始执行的任务。shutdownNow执行粗暴的关闭过程：它将尝试取消所有运行中的任务，并不再启动队列中尚未开始执行的任务。

在ExecutorService关闭后提交的任务将由"拒绝执行处理器(Rejected Execution Handler)"来处理，它会抛弃任务，或者使得execute方法抛出一个未检查的RejectedExecutionException。
等所有任务都完成后，ExecutorService将转入终止状态。
可以调用awaitTermination来等待ExecutorService到达终止状态，或者通过调用isTerminated来轮询ExecutorService是否已经终止。
通常在调用awaitTermination之后会立即调用shutdown，从而产生同步地关闭ExecutorService的效果。
。。应该是shuwdown之后调用awaitTermination吧？

115
Timer类负责管理延迟任务以及周期任务。然而Timer存在一些缺陷，因此应该考虑使用ScheduledThreadPoolExecutor来代替它(Timer支持基于绝对之间而不是相对时间的调度机制，因此任务的执行对系统时钟变化很敏感，而ScheduledThreadPoolExecutor只支持基于相对时间的调度)。
使用ScheduledThreadPoolExecutor的构造器或者newScheduledThreadPool工厂方法来创建该类的对象。

Timer在执行所有定时任务时只会创建一个线程。如果某个任务的执行时间过长，那么将破坏其他TimerTask的定时精确性。例如，某个周期TimerTask需要每10ms执行一次，而另一个TimerTask需要执行40ms，那么这个周期任务或者在40ms任务执行完后快速连续地调用4次，或者彻底丢失这4次调用(取决于它是基于固定速率调度还是基于固定延时来调度)。
线程池能弥补这个缺陷，它可以提供多个线程来执行延时任务和周期任务。

Timer的另一个问题是，如果TimerTask抛出一个未检查的异常，那么Timer将表现出糟糕的行为。Timer线程并不捕获异常，因此当TimerTask抛出未检查的异常时将终止定时线程。这种情况下，Timer也不会恢复线程的执行，而是会错误地认为整个Timer都被取消了。那些已被调度但是尚为执行的TimerTask将不会再执行，新的任务也不能被调度。(这个问题被称为"线程泄漏",7.3介绍)

下面的代码给出了Timer中为什么会出现这种问题，以及如何使得试图提交TImerTask的调用者也出现问题。你可能认为程序会运行6s以后退出，但实际情况是运行1s就结束了，并抛出一个异常消息"Timer already cancelled"。
ScheduledThreadPoolExecutor能正确地处理这些表现出错误行为的任务。java5及之后很少使用Timer。

public class OutOfTime
{
	public static void main(String[] args) throws Exception {
		Timer timer = new Timer();
		timer.schedule(new ThrowTask(), 1);
		SECONDS.sleep(1);
		timer.schedule(new ThrowTask(), 1);
		SECONDS.sleep(5);
	}
	
	static class ThrowTask extends TimerTask() {
		public void run() { throw new RuntimeException(); }
	}
}
。。大约的意思应该是：执行第一个ThrowTask后就直接中断了整个TImer，第二个不再执行了。

如果要构建自己的调度服务，可以使用DelayQueue，它实现了BlockingQueue，并为ScheduledThreadPoolExecutor提供调度功能。DelayQueue管理着一组Delayed对象。每个Delayed对象都有一个相应的延迟时间，在DelayQueue中，只有某个元素逾期后，才能从DelayQueue中执行take操作。从DelayQueue中返回的对象将根据它们的延迟时间进行排序。


116
6.3 找出可利用的并行性

Executor框架帮助指定执行策略，但如果要使用Executor，必须将任务表述为一个Runnable。在大多数服务器应用程序中都存在一个明显的任务边界：单个客户请求。但有时候，任务边界并非显而易见的，例如在很多桌面应用程序中。即使是服务器应用程序，在单个客户请求中仍可能存在可挖掘的并行性，例如数据库服务器。

我们将开发一些不同版本的组件，并且每个版本都实现了不同程度的并发性。该组件实现浏览器程序中的页面渲染功能：将HTML页面绘制到图像缓存中。假设HTML只包含标签文本，以及预定义大小的图片和URL。

串行的页面渲染器
一种是，遇到文本标签，将其绘制到图像缓存中，当遇到图像引用时，先通过网络获取它，然后再将其绘制到图像缓存中。。但这种方法需要很长时间才能显示所有的文本。
另一种是，先绘制文本元素，同时为图像预留出占位空间，处理完第一遍文本后，程序再开始下载图像，并将它们绘制到相应的占位空间中。

public class SingleThreadRender {
	void renderPage(CharSequence source) {
		renderText(source);
		List<ImageData> imageData = new ArrayList<ImageData>();
		for (ImageInfo imageInfo : scanForImageInfo(source))
			imageData.add(imageInfo.downloadImage());
		for (ImageData data : imageData)
			renderImage(data);
	}
}
图像下载过程的大部分时间都是在等待I/O操作，这期间CPU几乎不做任何工作。通过将该问题分解为多个独立的任务并发，能获得更高的CPU利用率和响应灵敏度。


携带结果的任务Callable和Future
Exector框架使用Runnabel作为基本的任务表示形式，Runnable是一种有很大局限的抽象。虽然run能写入到日志文件或将结果放入某个共享的数据结构，但它不能返回一个值或者抛出一个受检查异常。

许多任务实际上都是存在延迟的计算--执行数据库查询，从网络上获取资源，或者计算某个复杂的功能。对于这些任务，Callable是一种更好的抽象：它认为主入口点(即call)将返回一个值，并可能抛出一个异常。Executor中包含了一些辅助方法能将其他类型的任务封装成一个Callable，例如Runnable和java.security.PrivilegedAction.

Runnable和Callable描述的都是抽象的计算任务。这些任务通常都是有范围的，即都有一个明确的起始点，并且最终会结束。
Executor执行的任务有4个生命周期阶段：创建，提交，开始，完成。由于某些任务可能要执行很长时间，因此通常希望能取消这些任务。在Executor框架中，已提交但是尚未开始的任务可以取消，但对于那些已经开始执行的任务，只有当它们能响应中断时，才能取消。

Future表示一个任务的生命周期，并提供了相应的方法来判断是否已经完成或取消，以及获取任务的结果和取消任务等。
在Future规范中包含的隐含意义是：任务的生命周期只能前进，不能后退。就像ExecutorService的生命周期一样，当某个任务完成后，它就永远停留在"完成"状态上。

get方法的行为取决于任务的状态(未开始，正在运行，已完成)。如果已完成，get会立刻返回或抛出一个异常。如果任务没有完成，get将阻塞直到任务完成。
如果任务抛出异常，get将该异常封装为ExecutionException并重新抛出。如果任务被取消，那么get抛出CancellationException。。如果get抛出ExecutionException，那么可以通过getCause来获得被封装的初始异常。

public interface Callable<V> {
	V call() throws Exception;
}

public interface Future<V> {
	boolean cancel(boolean mayInterrupteIfRunning);
	boolean isCancelled();
	boolean isDone();
	V get() throws InterruptedException, ExecutionException, CancellationException;
	V get(long timeout, TimeUnit unit) throws InterruptedException, ExecutionException, CancellationException, TimeoutException;
}

。test。。。Callable通过Executors框架，的submit方法来运行。返回一个Future。Runnable是通过Executors的execute方法来运行的。。no，execute是没有返回值的，。submit是有返回值Future的。submit可以接受Callable或Runable

118-
从java6开始，ExecutorService实现可以改写AbstractExecutorService中的newTaskFor方法，从而根据已提交的Runnable或Callable来控制Future的实例化过程。在默认实现中仅创建了一个新的FutureTask。
protected <T> RunnableFuture<T> newTaskFor(Callable<T> task) {
	return new FutureTask<T>(task);
}

在将Runnable或Callable提交到Executor的过程汇总，包含了一个安全发布过程，即将Runnable/Callable从提交线程发布到最终执行任务的线程。
类似的，在设置Future结果的过程中也包含了一个安全发布，即将这个结果从计算它的线程发布到任何通过get获得它的线程。


为了使页面渲染器实现更高的并发性，首先将渲染过程分解为2个任务：一个是渲染所有的文本，另一个是下载所有的图像。(因为其中一个是CPU密集型，另一个任务是I/O笔记型，因此这种方法即使在单CPU系统上也能提升性能。)

Callable，Future有助于表示这些协同任务之间的交互。下面的代码中创建一个Callable来下载所有的图像，并将其提交到一个ExecutorService，这将返回一个描述任务执行情况的Future。
public class FutureRenders {
	private final ExecutorService executor = ...;
	void renderPage(CharSequence source) {
		final List<ImageInfo> imageInfos = scanForImageInfo(source);
		Callable<List<ImageData>> task = 
			new Callable<List<ImageData>>() {
				public List<ImageData> call() {
					List<ImageData> result = new ArrayList<>();
					for (ImageInfo info : imageInfos) {
						result.add(info.downloadImage());
					}
					return result;
				}
			};
		Future<List<ImageData>> future = executor.submit(task);
		renderText(source);
		try {
			List<ImageData> imageData = future.get();
			for (ImageData data : imageData)
				renderImage(data);
		} catch (InterruptedException e) {
			// 重新设置线程的中断状态
			Thread.currentThread().interrupt();
			// 不需要结果，因此取消任务
			future.cancel(true);
		} catch (ExecutionException e) {
			throw launcherThrowable(e.getCause());
		}
	}
}

Future.get的异常处理diamante将处理2个可能的问题，任务遇到一个异常，调用get的线程在获得结果之前被中断。

我们还可以，每下载完一副图片就立刻显示出来。


在上面的例子中，我们尝试并行执行2个不同类型的任务---下载图像与渲染页面。。然而，通过异构任务进行并行化来获得重大的性能提升是很难的。

无法将任务平均分配，分成2个任务，其中一个任务的执行时间是另一个任务的10倍，那么总体提升也就9%。。而且分解任务时，还需要一定的任务协调开销。

只有当大量相互独立且同构的任务可以并发进行处理时，才能体现出将程序的工作负载分配到多个任务中带来的真正性能提升。


CompletionService:Executor和BlockingQueue

如果想Executor提交一组计算任务，并希望在计算后获得结果，那么可以保留与每个任务关联的Future，然后反复调用get方法，同时将参数timeout指定为0，从而通过轮询来判断任务是否完成。可行但繁琐。有一种更好的方法：完成服务(CompletionService)。
。。test。。get的timeout为0，代表永不过时，还是立刻过时？

CompletionService将Executor和BlcokingQueue的功能融合在一起，可以将Callable任务提交给它来执行，然后使用类似与队列操作的take和poll等方法来获得已完成的结果，这些结果会在完成时被封装为Future。
ExecutorCompletionService实现了CompletionService，当将计算部分委托给一个Executor。

ExecutorCompletionService实现非常简单。构造器中创建一个BlockingQueue来保存计算完成的结果。当计算完成时，调用FutureTask的done方法。当提交某个任务时，该任务将首先包装为一个QueueingFuture，这是FutureTask的一个子类，然后再改写子类的done方法，并将结果放入到BlockingQueue中。
take和poll委托给了BlockingQueue，这些方法会在得出结果之前阻塞。

有ExecutorCompletionService使用的QueueingFuture类。
private class QueueingFuture<V> extends FutureTask<V> {
	QueueingFuture(Callable<V> c) { super(c); }
	QueueingFuture(Runnable t, V t) { super(t, r); }
	protected void done() {
		completionQueue.add(this);
	}
}

CompletionService从2个方面提高页面渲染器的性能：缩短总运行时间以及提高响应性。
为每幅图像的下载都创建一个独立任务，并在线程池中执行它们。
通过从CompletionService中获取结果以及使每张图片在下载完后立刻显示出来。

public class Render {
	private final ExecutorService executor;
	Render(ExecutorService executor) { this.executor = executor; }
	void renderPage(CharSequence source) {
		List<ImageInfo> info = scanForImageInfo(source);
		CompletionService<ImageData> completionService = new ExecutorCompletionService<ImageData>(executor);
		for (final ImageInfo imageInfo : info) {
			completionService.submit(new Callable<ImageData>() {
				public ImageData call() {
					return imageInfo.downloadImage();
				}
			});
		}
		renderText(source);
		try {
			for (int t = 0, n = info.size(); t < n; t++) {
				Future<ImageData> f = completionService.take();
				ImageData imageData = f.get();
				renderImage(imageData);
			}
		} catch (InterruptedException e) {
			Thread.currentThread().interrpte();
		} catch (ExecutionException e) {
			throw launderThrowable(e.getCause());
		}
	}
}

多个ExecutorCompletionService可以共享一个Executor，因此可以创建一个对于特定计算私有，又能共享一个公共Executor的ExecutorCompletionService。因此，CompletionService的作用就相当于一组计算的句柄，这与Future作为单个计算的句柄是非常相似的，通过记录提交给CompletionService的任务数量，并计算出已经获得的已完成结果的数量，即使使用一个共享的Executor，也能知道已经获得了所有任务结果的时间。


为任务设置时限
在有限时间内执行任务的主要困难在于，要确保得到答案的时间不会超过限定时间，或者在限定的时间内无法获得答案。
在支持时间限制的Future.get中支持这种需求：当结果可用时，立刻返回，如果在指定时限内没有计算出结果，那么抛出TimeoutException。

当任务超时后应该立即停止，避免浪费计算资源。
要实现这个功能，可以由任务本身来管理它的限定时间，并且在超时后中止执行或取消任务。此时可再次使用Future，如果一个现实的get方法抛出了TimeoutException，那么可以通过Future来取消任务。如果编写的任务是可取消的，那么可以提前中止它。

下面是Future.get的一种典型应用。在它生产的页面中包括响应用户请求的内容以及从广告服务器上获得的广告。它将获取广告的任务提交给一个Executor，然后计算剩余的文本页面内容，最后等待广告信息，直到超时。如果get超时，那么将取消广告获取任务，并装而使用默认的广告信息。

Page renderPageWithAd() throws InterruptedException {
	long endNanos = System.nanoTime() + TIME_BUDGET;
	Future<Ad> f = exec.submit(new FetchAdTask());
	Page page = renderPageBody();
	Ad ad;
	try {
		long timeLeft = endNonos - System.naneTime();
		ad = f.get(timeLeft, NANOSECONDS);
	} catch (ExecutionException e) {
		ad = DEFAULT_AD;
	} cathc (TimeoutException e) {
		ad = DEFAULT_AD;
		f.cancel(true);	// true表示可以在运行过程中中断。
	}
	page.setAd(ad);
	return page;
}


旅行预订门户网站

预订时间方法很容易就扩展到任意数量的任务上，考虑这样一个旅行预订门户网站：用户输入旅行日期和其他要求，门户网站获取并显示来自多条航线，旅店或汽车租赁公司的报价。在获取不同公司的报价过程中，可能会调用web服务，访问数据库，执行一个EDI事务或其他机制。
不宜让页面受限于最慢的响应时间，而一个只显示在指定时间内受到的信息。对于没有及时响应的服务提供者，页面可以忽略它们，或者显示一个提示信息。

从一家公司获取报价的过程与从其他公司获取报价的过程无关，因此可以将获取报价的过程当成一个任务，从而使得获得报价的过程并发。
创建n个任务，将其提交到一个线程池，保留n个Future，并使用限时get方法通过Future串行地获取结果，这一切都很简单，但还有一个更简单的方法---invokeAll。

下面使用了支持限时的invokeAll，将多个任务提交到一个ExecutorService并获得结果。invokeAll的参数是一组任务，并返回一组Future。这两个集合有着相同的结构。
按任务的迭代器顺序添加到返回的集合中。
当所有任务执行完毕时，或者调用线程被中断时，又或者超过指定时限时，invokeAll将返回。
超过指定时限后，任何还未完成的任务都会取消。
invokeAll返回后，每个任务要么正常完成，要么被取消，客户端代码可以通过get或isCancelled来判断是什么情况。

private class QuoteTask implements Callable<TravelQuote> {
	private final TravelCompany company;
	private final TravelInfo travelInfo;
	...
	public TravelQuote call() throws Exception {
		return company.solicitQuote(travelInfo);
	}
}

public List<TravelQuote> getRankedTravelQuotes(
	TravelInfo travelInfo, Set<TravelCompany> companies,
	Comparator<TravelQuote> ranking, long time, TimeUnit unit)
		throws InterruptedException {
	
	List<QuoteTask> tasks = new ArrayList<QuoteTask>();
	for (TravelCompany company : companies)
		tasks.add(new QuoteTask(company, travelInfo));
	
	List<Future<TravelQuote>> futures = exec.invoketAll(tasks, time, unit);
	
	List<TravelQuote> quotes = new ArrayList<TravelQuote>(tasks.size());
	
	Interator<QuoteTask> taskIter = tasks.iterator();
	for (Future<TravelQuote> f : futures) {
		QuoteTask task = taskIter.next();
		try {
			quotes.add(f.get());
		} catch (ExecutionException e) {
			quotes.add(task.getFailureQuote(e.getCause()));
		} catch (CancellationException e) {
			quotes.add(task.getTimeoutQuote(e));
		}
	}
	Collections.sort(quotes, ranking);
	return quotes;
}


通过围绕任务执行来设计应用程序，可以简化开发过程，并有助于实现并发。Executor框架将任务提交与执行策略解耦，同时还支持多种不同类型的执行策略。
当需要创建线程来执行任务是，可以考虑使用Executor。
要想在将应用程序分解为不同的任务时获得最大的好处，必须定义清晰的任务边界。


125
chapter 7
取消和关闭

任务和线程的启动很容易。
要是任务和线程能安全，快速，可靠地停止下来，并不是一件容易的事。
java没有提供任何机制来安全地终止线程。但它提供了中断，这是一种协作机制，能够使得一个线程终止另一个线程的当前工作。
(Thread.stop和suspend方法提供了终止线程功能，但是存在一些严重的缺陷，应避免使用。)

这种协作式方法是必要的，我们很少希望某个任务，线程或服务立刻停止，因为这种立即停止会使共享的数据结构处于不一致的状态。
相反，在编写任务和服务是可以使用一种协作的方式：当需要停止时，它们首先会清楚当前正在执行的工作，然后在结束。这提供了更好的灵活性，因为任务本省的代码比发出取消请求的代码更清楚如何执行清楚工作。

7.1 任务取消
如果外部代码能在某个操作正常完成之前将其置入"完成"状态，那么这个操作就可以成为可取消的。取消某个操作的原因很多：
用户请求取消。。用户点击图形界面的"取消"按钮，或者通过管理接口来发送取消请求，如JMX(Java Management Extensions)。
有时间限制的操作。。在有限之间内搜索数据，并选择最佳结果。超时时，需要取消所有正在搜索的任务。
应用程序事件。。程序对问题空间进行分解并搜索，当其中一个任务找到解决方案时，所以其他仍在搜索的任务都将被取消。
错误。。爬虫搜索页面，并将页面数据保存到硬盘，当一个爬虫发生错误时(如，磁盘已满)，那么所有的搜索任务都会取消，此时可能会记录它们的当前状态，以便稍后启动。
关闭。。当一个程序或服务关闭时，必须对正在处理和等待处理的工作执行某种操作。在平缓的关闭过程中，当前正在执行的任务将继续执行直到完成，而在立即关闭过程中，当前任务则可能取消。

java中没有一种安全的抢占式方法来停止线程，因此也就没有安全的抢占式方法来停止任务。只有一些协作式的机制，使请求取消的任务和代码都遵循一种协商好的协议。

。。抢占式，os能把cpu从当前的进程抢过来，然后再分配。。协作式，os只能等cpu当前的进程执行完，再分配。
。。os - 进程 - 线程。

其中一种协作机制能设置某个"已请求取消(Cancellation-Requested)"标志，任务将定期查看该标志，如果设置了这个标志，那么任务将提前结束。

@ThreadSafe
public class PrimeGenerator implements Runnable {
	private final List<BigInteger> primes = new ArrayList<>();
	private volatile boolean cancelled;
	public void run () {
		BigInteger p = BigInteger.ONE;
		whlie (!cancelled) {
			p = p.nextProbablePrime();		// 。。test。。。
			synchronized(this) {
				primes.add(p);
			}
		}
	}
	public void cancel() { this.cancelled = true; }
	public synchronized List<BigInteger> get() {
		return new ArrayList<>(primes);
	}
}

使用：
List<BigInteger> aSecondOfPrimes() throws InterruptedException {
	PrimrGenerator generatro = new PrimeGenerator();
	new Thread(generator).start();
	try {
		SECONDS.sleep(1);
	} finally {
		generator.cancel();		// finally保证sleep被中断也能运行。
	}
	return generator.get();
}

一个可取消的任务必须拥有取消策略。这个策略中详细地定义了：其他代码如何请求取消该任务，任务在何时检查是否已经请求了取消，在响应取消请求时要执行哪些操作。

PrimeGrenerator使用了一种简单的取消策略：客户代码通过调用cancel来请求取消，PrimeGenerator在每次搜索素数前检查是否存在取消请求，如果存在则退出。


127
PrimeGenerator的取消机制最终会使搜索素数的任务退出，但在退出过程中需要花费一定的时间。
然而，如果使用这种方法的任务调用一个阻塞方法，如BlockingQueue.put，可能会导致--任务可能永远不会检查取消标志，因此永远不会结束。

下面说明这个问题。生产者产生素数，并把它们放入一个阻塞队列。如果生产者的速度超过了消费者的处理速度，队列将被填满，put方法会阻塞。当生产者在put方法中阻塞时，如果此时消费者取消了生产者任务，将cancel设置为true，但是此时生产者无法从put的阻塞中恢复，无法检查这个标记。


一些特殊的阻塞库的方法支持中断。线程中断时一种协作机制，线程可以通过这种机制来通知另一个线程，告诉它在合适的或者可能的情况下停止当前工作。

在java的api或语言规范中，并没有将中断与任何取消语义关联起来，但实际上，如果在取消之外的其他操作中使用中断，那么都是不合适的，并且很难支撑起更大的应用。

每个线程都有一个boolean类型的中断状态。当中断线程是，这个状态被置为true。
public class Thread {
	public void interrupt() {...}		// 中断目标线程
	public boolean isInterrupted() {...}// 返回目标线程的中断状态
	public static boolean interrupted() {...}	// 清除当前线程的中断状态，并返回它之前的值，这也是清除中断状态的唯一方法。
	...
}
。。interrupted在1.8中是这样的。在java6中被修改过。现在功能和isInterrupted似乎一致。。。no，isInterrupted()实际调用isInterrupted(false)
    public static boolean interrupted() {
        return currentThread().isInterrupted(true);
    }
。。
		是否重置中断状态。。。reset是指取反还是设为true？后者？
    /**
     * Tests if some Thread has been interrupted.  The interrupted state
     * is reset or not       based on the value of ClearInterrupted that is
     * passed.
     */
    private native boolean isInterrupted(boolean ClearInterrupted);
。。。



阻塞库方法，例如Thread.sleep，Object.wait等，都会检查线程何时中断，并且在发现中断时提前返回。它们在响应中断时执行的操作包括：清除中断状态，抛出InterruptedException，表示阻塞操作由于中断而提前结束。
jvm并不能保证阻塞方法检测到中断的速度，但在实际情况中响应速度还是非常快的。

当线程在非阻塞状态下中断时，它的中断状态将被设置，然后根据将被取消的操作来检查中断状态以判断发生了中断。。。(.?)。。通过这样的方法，中断操作将变得"有黏性"---如果不触发InterruptedException，那么中断状态将一直保持，直到明确地清除中断状态。

对中断操作的正确理解是：它并不会真正地中断一个正在运行的线程，而只是发出中断请求，然后有线程在下一个合适的时刻中断自己(这些时刻也被称为取消点)。有些方法，例如wait，sleep，join等，将严格地处理这种请求，当它们收到中断请求或者在开始执行时发现某个已被设置好的中断状态时，将抛出一个异常。
设计良好的方法完全可以忽略这种请求，只要它们能使调用代码对中断请求进行某种处理。
设计糟糕的方法可能会屏蔽中断请求，从而导致调用栈中的其他代码无法对中断请求作出响应。

使用static方法interrupted时要小心，因为它会清除当前线程的中断状态。如果在调用interrupted时返回了true，那么除非你想屏蔽这个中断，否则必须对它进行处理---可以抛出InterruptedException，或者通过再次调用interrupt来恢复中断状态。


下面的代码使用中断而不是cancel标记来请求取消。
每次迭代时，有2个位置可以检测到中断，阻塞的put方法调用中，循环开始处查询中断状态。
由于调用了阻塞的put方法，因此这里并不一定需要进行显式的检测，但执行检测会使程序对中断具有更高的响应性。

class PrimeProducer extends Thread {
	private final BlockingQueue<BigInteger> queue;
	PrimeProducer(BlockingQueue<BigInteger> queue) {
		this.queue = queue;
	}
	
	public void run() {
		try {
			BigInteger p = BigInteger.ONE;
			while (!Thread.currentThread().isInterrupted())
				queue.put(p = p.nextProbablePrime());
		} catch (InterruptedException consumed) {
			// 允许线程退出
		}
	}
	public void cancel() { interrupted(); }
}



中断策略

正如任务中包含了取消策略一样，线程同样应该包含中断策略。
中断策略规定了线程如何解释某个中断请求---当发现中断请求时，应该做哪些工作，哪些工作单元对于中断来说是原子操作，以及以多快的速度响应中断。

最合理的中断策略是某种形式的线程级取消操作或服务及取消操作：尽快退出，在必要时进行清理，通知某个所有者该线程已经退出。

还可以建立其他的中断策略：暂停服务或重新开始服务，但对于那些包含非标准状态中断策略的线程或线程池，只要用于能知道这些策略的任务中。

130







任务交给Future，future.get(1000ms).超时就Future.cancel



public static ExecutorService newFixedThreadPool(int nThreads) {  
		return new ThreadPoolExecutor(nThreads, nThreads,  
				  0L, TimeUnit.MILLISECONDS,  
				  new LinkedBlockingQueue<Runnable>());  
									  
public static ExecutorService newCachedThreadPool() {  
		return new ThreadPoolExecutor(0, Integer.MAX_VALUE,  
			  60L, TimeUnit.SECONDS,  
			  new SynchronousQueue<Runnable>());  


executorPool.execute(new TaskAction(taskId));  
submit

Executors里是不是都是ThreadPoolExecutor的实例？
ExecutorService 和 newFixedExectorPool 关系。。没，就是上面的方法。
ThreadPoolExecutor 继承/实现 ExecutorService


Executor扩展出来ExecutorService接口，添加了一些用于生命周期管理的方法(还有一些用于任务提交的便利方法)。
public interface ExecutorService extends Executor {
	void shutdown();
	List<Runnable> shuwdownNow();
	boolean isShutdown();
	boolean isTerminated();
	boolean awaitTermination(long timeout, TimeUnit unit) throws InterruptedException;
	// 其他用于任务提交的便利方法
}
。。就是这本书里的。。


重定义Callable中的cancel方法
重定义ThreadPoolExecutor中newTaskFor方法，如果是上面的Callable那么就用上面的新建方法，其他类用super.newTaskFor.


ExecutorService.shutdown  shutdownnow
前者不结束运行中任务。而是等待结束。


exectorService.shutdown();
executorService.awiatTermination(Timeout, Unit);


另一种关闭生产者-消费者的方式是使用"毒丸"对象：毒丸是指：一个放在队列上的对象，当得到这个对象时，立即停止。

FIFO中，毒丸对象能确保消费者关闭之前完成了毒丸之前的所有工作/任务。
生产者提交毒丸之后，不会再提交任何工作。


.。test。。
线程能访问外部线程的数据？.。不，看错了，这个是内部类。。代码分开了。。
142  毒丸的例子。crawler完以后加个毒丸。
public class IndxingServic {
	private BlockingQueue<File> queue;
	private IndexThread consumer = new IndexThread();
	private CrawlerThread producer = new CrawlerThread();
	
}

只有在生产者和消费者的数量都已知的情况下才可以使用毒丸对象。

有N个生产者时，只需每个生产者都想队列中放入一个毒丸。并且消费者只有在接受到N个毒丸对象是才停止
也可以扩展到N个消费者，，生产者放入N个毒丸，每个消费者消费一颗毒丸。

。。毒丸里加个int，，然后消费者队列中序号大于int的停止。。。how？。。。需要特定的ThreadPoolExecutor，ExecutorService。Executor。


TrackingExecutor

run方法里最好加try-catch，。多线程的栈调用非常难懂。而且不加的话，不会有日志。


Thread API中提供了UncaughtExceptionHandler，
它能检测出某个线程由于未捕捉的异常而终结的情况
这个方法和上面的主动try-catch，是互补的。通过两者结合，能有效防止线程泄漏问题。
。。对，try只是代码块的异常，调用线程时就出现异常的话，没办法。

当一个线程由于未捕获异常而退出时，jvm会把这个时间报告给应用程序提供的UncaughtExceptionHandler异常处理器。
如果没有提供任何异常处理器，那么默认的行为是将栈追踪信息输出到System.err。。。

public interface UncaughtExceptionHandler {
	void uncaughtException(Thread t, Throwable e);
}

怎么处理，取决于对服务质量的要求。
最常见的是写入应用程序日志中。
还可以采用更直接的响应：尝试重启线程，关闭应用程序。等。

java5之前，控制UncaughtHandler的唯一方法就是对ThreadGroup进行子类化。
5及之后，Thread.setUncaughtExceptionHandler为每个线程设置一个Unca-handler，还可以使用setDefaultUncaughtExceptionHandler来设置默认的Unca-handler。。这些异常处理器，只有一个会被调用，---jvm先搜索每个线程的异常处理器，然后搜索ThreadGroup的异常处理器，ThreadGroup逐级往上搜索直到存在handler能处理。。顶层的ThreadGroup的异常处理器委托给默认的系统处理器，如果没有，则输出到控制台。。


要为线程池中的所有线程设置一个UncauchtExceptionHandler，需要为ThreadPoolExecutor的构造器提供一个ThreadFactory(和线程的操控一样，只有线程的拥有者才能修改线程的UncaughtExHandler)。
标准线程池允许当前发生未捕获异常时结束线程，但由于使用try-finally来接收通知，因此当线程结束时，将有新的线程来代替它。
如果没有异常处理器或其他的故障通知机制，那么任务会悄悄失败。

如果希望在任务由于异常而失败时获得通知，并执行特定的操作，那么可以将任务封装在能捕获异常的Runnable或Callable中，或改写ThreadPoolExecutor的afterExecute方法。
。。test。。

只有通过execute提交的任务，才能将它抛出的异常交给未捕获异常处理器。
submit提交的任务，无论抛出的是未检查异常还是已检查异常，都将被认为是任务返回状态的一部分，会被Future.get封装到ExecutionException中重新抛出。



149
7.4 jvm关闭

jvm可以正常关闭，也可以强行关闭。正常关闭的处罚方式有多种，包括：当最后一个"正常(非守护)"线程结束时，或者调用了System.exit时，或通过其他特定于平台的方法关闭时(如发送SIGINT信号或键入Ctrl+c)。
也可以通过Runtime，halt或在os中"杀死"jvm进程(如发送SIGKILL)来强行关闭jvm

正常关闭时，先调用所有已注册的关闭钩子(Shutdown-Hook)。关闭钩子是指通过Runtime.addShutdownHook注册的但尚未开始的线程。
jvm不保证关闭钩子的调用顺序。
。。test。。

在关闭应用程序线程时，如果有(守护或非守护)线程仍然在运行，那么这些线程接下来将与关闭进程并发执行。
所有的关闭钩子都执行结束时，如果runFinaliersOnExit为true，那么jvm将运行终结器，然后再停止。
jvm不会停止或中断任何在关闭时仍然运行的应用程序线程。当jvm最终停止时，这些线程将被强行结束。

如果关闭钩子或终结器没有执行完成，那么正常关闭进程"挂起"且jvm必须被强制关闭，当被强制关闭时，只是关闭jvm，不会运行关闭钩子。

关闭钩子应该是线程安全的，访问共享数据时必须使用同步机制，并避免死锁
关闭钩子不应该对应用程序的状态(如，其他服务是否已关闭，所有正常线程是否已执行完毕)或者jvm的关闭原因作出任何假设，因此在编写关闭钩子的代码时必须考虑周全。
最后，关闭钩子必须尽快退出，因为它们会延迟jvm的结束时间，而用户可能希望jvm能尽快终止。

关闭钩子可以用于实现服务或应用程序的清理工作，如，删除零时文件，或清除无法由系统自动清除的资源。

public void start() {
	Runtime.getRuntime().addShutdwonHook(new Thread() {
		public void run() {
			try { LogService.this.stop(); }
			catch {InterruptedException ignored} {}
		}
	});
}

守护线程
希望一个线程来执行一些辅助工作，又不希望这个线程阻碍jvm的关闭。这种情况下使用守护线程(Daemon Thread).

线程分为2种：普通线程，守护线程。
jvm启动时创建的所有线程中，除了主线程以外，其他的线程都是守护线程(如，垃圾回收器以及其他执行辅助工作的线程)。

创建一个新线程时，新线程继承创建它的线程的守护状态，因此默认情况下，主线程创建的线程都是普通线程。

普通，守护线程之间的差异仅在于当线程退出时发生的操作。
当一个线程退出时，jvm会检查其他正在运行的线程，如果这些都是守护线程，那么jvm会正常退出。当jvm停止时，所有仍存在的守护线程都将被抛弃--不会执行finally，不会执行回卷栈，是直接退出。
。。？？？

少用守护线程。很少有操作能在不清理的情况下安全地被抛弃。

守护线程最好用于执行"内部"操作，如周期性地从内存缓存中移除逾期数据。

守护线程通常不能用来替代应用程序管理程序中的各个服务的生命周期。


终结器
内存可以垃圾回收器来回收。
其他一些资源，如文件句柄，套接字句柄，不需要时，必须显示地交还给os。通过finalize方法，垃圾回收器在释放内存后会执行这个方法来释放一些持久化的资源。

终结器可以在某个有jvm管理的线程中执行，因此终结器的任何状态都可能被多个线程访问，这样就必须对其访问操作进行同步。
终结器不能保证它们将在何时运行甚至是否会运行，复杂的终结器通常会在对象上产生巨大的性能开销。
编写正确的终结器是非常困难的。
大多数情况下，finally和现实close方法，比终结器更好用。唯一的例外是，当需要管理对象，并且该对象持有的资源是通过本地方法获得的。


chapter 8 线程池的使用

Executor框架将任务的提交于任务的执行策略解耦。
虽然为制定和修改执行策略提供了相当大的灵活性，但并非所有的任务都适用所有的执行策略。有些类型的任务需要明确指定执行策略：

依赖性任务。。大多数任务都是独立的，不依赖其他任务的执行次序，执行结果或其他效果。在线程池中执行独立的任务时，可以随意改变线程池的大小和配置，这些修改只对性能产生影响。。。如果任务依赖于其他任务，那么就隐含地给执行策略带来了约束，必须小心维持这些执行策略以免产生活跃性问题。

使用线程封闭机制的任务。。与线程池相比，单线程的Executor能够对并发性做更强的承诺。它们能确保任务不会并发执行。对象可以封闭在任务线程中，使得在该线程中执行的任务在访问该对象时不需要同步(即使这些资源不是线程安全的)。这种情形使得任务与执行策略之间形成隐式耦合--任务要求Executor是单线程的。。如果Executor从单线程环境改为线程池环境，那么会失去线程安全性。

对响应时间敏感的任务。。GUI应用程序对于响应时间是敏感的。如果将一个运行时间较长的任务提交到线程的Executor中，或者将多个运行时间较长的任务提交到一个只包含少量线程的线程池中，那么将降低由该Executor管理的服务的响应性。

使用ThreadLocal的任务。。tl使得每个线程都可以拥有某个变量的一个私有版本。然而，只要条件允许，Executor可以自由地重用这些线程。在标准Executor实现中，当执行需求较低时将回收空闲线程，当需求增加时添加新线程，并且如果任务抛出一个未检查异常，那么一个新的工作者线程将用来替代抛出异常的线程。只有当线程本地值的生命周期受限于任务的生命周期时，在线程池的线程中使用tl才有意义，而在线程池中的线程不应该使用tl在任务间传递值。

只有当任务是同类型并且相互独立时，线程池的性能才达到最佳。
如果运行时间较长的任务与运行时间较短的混合在一起，除非线程池很大，否则将可能造成"拥塞"。
如果提交任务依赖于其他任务，除非线程池无限大，否则可能造成死锁。


正在执行任务的线程由于等待其他仍处于工作队列中的任务而阻塞，这种称为线程饥饿死锁。
。。可能是单线程正在执行的任务依赖于本队列中下一个任务的结果。
。。多线程，线程间相互依赖对方任务队列中下一个任务。

有一些隐式限制，无穷大的线程池，任务使用了一个包含10连接的jdbc连接池，每个任务需要一个连接，并没有及时释放，并且依赖于其他任务的结果。可能会由于jdbc连接池不够而死锁。


运行时间较长的任务线
线程池的响应会非常糟糕。

有一项技术可以缓解执行时间较长任务造成的影响，即限定任务等待资源的时间，而不要无限制地等待。在平台类库的大多数可阻塞方法中，都同时定义了限时版本和无限时版本，例如Thread.join,BlockingQueue.put,CountDownLatch.await,Selector.select等。如果等待超时，那么可以把任务标记为失败，然后终止任务或者将任务重新放回队列以便随后执行。这样，能确保任务总是不停地执行，并将线程释放出来以执行一些更快的任务。如果线程池中总是充满了被阻塞的任务，那么可能表明线程池的规模太小。
。。？超时重放回队列，下次依然超时吧。。可能超时一次，timeout*2。。或者换到一个更适合任务时间长的线程池中？。。或者暂存结果？。利用Future。下次运行的时候直接get出来？。干脆两段式任务，第一段submit并获得future，然后重新放回队列中，第二次，Future.get然后处理。
。。test。。。


8.2 设置线程池大小

线程池过大，会竞争CPU和内存。
线程过小，CPU空闲。

计算密集型任务，N个cpu的系统中，线程池大小为N+1，通常能实现最优利用率。
对于包含I/O或其他阻塞操作的任务，线程池的规模应该更大。需要估计任务的等待时间与计算时间的比值：
Nthreads = Ncpu * Ucpu * (1 + W/C)
Utilization,利用率，[0,1].
W/C = wait time / compute time
Runtime.getRuntime().availableProcessors();

CPU并不是唯一的约束，还有内存，文件句柄，套接字句柄和数据库连接等。
计算每个任务对该资源的需求量，然后用该资源的可用总量/每个任务的需求量，结果就是线程池大小的上限。
。。还是需要W/C的吧，毕竟不是一直持有的啊。持有时间/计算时间。

线程池和资源池的大小相互影响。


8.3 配置ThreadPoolExecutor
TPE为一些Executor提供了基本的实现，这些Executor是由Executors中的newCachedThreadPool,newFixedThreadPool,newScheduledThreadExecutor等工厂方法返回的。

TPE有很多构造器，下面是最常见的形式：
public ThreadPoolExecutor(
	int corePoolSize,		// 基本大小，没有任务执行时的大小，工作队列满后才会增加线程。
	int maximumPoolSize,	// 最大大小，同时活动的线程数量上限。
	long keepAliveTime,		// 存活时间，空闲时间超过这个值，标记为可回收的，当线程池的当前大小超过基本大小时，这个线程将被终止。
	TimeUnit unit,
	BlockingQueue<Runnable> workQueue,
	ThreadFactory threadFactory,
	RejectedExecutionHandler handler
) { ... }

。在创建TPE初期，线程不会立即启动，而是等到有任务提交时才启动，除非调用prestartAllCoreThreads
。有时基本大小设为0，从而最终销毁工作者线程以免阻碍jvm退出。然而，如果线程池中没有使用SynchronousQueue作为其工作队列，会产生奇怪的行为。如果线程池中的数量等于线程池的基本大小，那么仅当工作队列满的情况下TPE才会创建新的线程。因此，如果基本大小为0，且工作队列有一定的容量，那么只有当工作队列满后，才会开始执行任务。java6中可以通过allowCoreThreadTimeOut来使线程中所有线程超时。对于一个大小有限的线程池并且在该线程池中包含了一个工作队列，如果希望这个线程池在没有任务的情况下能销毁所有的线程，那么可以启用这个特性并将基本大小设置为0.

newFixedThreadPool，将线程池的基本大小和最大大小设置为参数中的值，而且创建的线程池不会超时。

newCachedThreadPool将线程池的最大大小设置为Integer.MAX_VALUE，基本大小为0，超时为1分钟。


如果无限制创建线程，将导致不稳定性。
固定大小的线程池也有问题，在高负载的情况下，应用程序的资源仍可能耗尽，几率较小。如果新请求的到达速度大于线程池的处理速度，那么新请求会累积到由Executor管理的Runnable队列中等待。通过一个Runnable和一个链表节点来表示一个等待中的任务，比使用线程来表示开销低很多。但如果客户提交个服务器请求的速度超过服务器处理速度，依然可能会耗尽资源(队列占尽内存)。

抑制请求的到达率以免耗尽内存，通行网络中的流量控制：告诉发送端停止发送，过段时间再发送。
随着队列增长，响应越来越慢，直到耗尽内存。

TPE允许提供一个BlockingQueue来保存等到执行的任务。基本的任务排队方法有3种：无界队列，有界队列和同步移交(Synchronous Handoff)。队列的选择与其他配置参数有关，如线程池的大小等。

newFixedThreadPool,newSingleThreadExecutor，默认情况下使用一个无界的LinkedBlockingQueue，如果所有工作者线程都处于忙碌中，那么任务将在队列中等待，如果到达速度>处理速度，那么队列将无限制增加。

更稳妥的资源管理策略是使用有界队列，如ArrayBlockingQueue，有界的LinkedBlockingQueue，PriorityBlockingQueue。有界队列有助于避免资源耗尽的情况发生，但它带来了新问题，队列满后，新任务该怎么办？(有许多饱和策略可以解决这个问题，下一节8.3.3。)
使用有界的工作队列时，队列的大小与线程池的大小必须一起调节。线程池小队列大，有助于减少内存使用量，降低cpu使用率，减少上下文切换，代价是限制吞吐量。

对于非常大或无界的线程池，通过使用SynchronousQueue来避免任务排队，以及直接将任务从生产者移交到工作者线程。SynchronousQueue不是一个真正的队列，而是一个线程间进行移交的机制，要将一个元素放入SynchronousQueue中，必须有另一个线程正在等待接受这个元素。如果没有线程正在等待，并且线程池的当前大小小于最大值，那么TPE会创建一个新的线程，否则根据饱和策略，这个任务将被拒绝。
只有当线程池是无界或者可以拒绝任务时，SynchronousQueue才有实际价值。newCachedThreadPool中就使用率SynchronousQeueu。

使用LinkedBlockingQueue或ArrayBlockingQueu这样的FIFO队列时，任务执行顺序与它们的到达顺序相同。如果要进一步控制任务执行顺序，还可以使用PriorityBlockingQueue。

对于Executor，newCachedThreadPool时一个很好的默认选择，能提供比固定大小的线程池更好哦的排队性能。
当要限制当前任务数量以满足资源管理需求时，那么可以选择固定大小的线程池。

只有当任务相互独立时，为线程池或工作队列设置界限才是合理的。


8.3.3 饱和策略
有界队列满后，饱和策略开始起效。
ThreadPoolExecutor的饱和策略可以通过调用setRejectedExcutionHandler来修改。(如果某个任务被提交到一个已关闭的Executor时，也会用到饱和策略)
jdk提供了几种不同的RejectedExcutionHandler，每种实现含有不同的策略：

中止(abort)策略是默认的饱和策略，抛出未检查的RejectExecutionException。

抛弃(Discard)策略，当新提交的任务无法保存到队列中等待执行时抛弃。

抛弃最旧(Discard-Oldest)策略，。。无法保存时。。。抛弃下一个将被执行的任务，然后尝试重新提交新任务。(如果是工作队列是一个优先队列，那么会抛弃优先级最高的，所以最好不要将抛弃最旧与优先队列一起使用)

调用者运行(Caller-Runs)策略实现了一种调节机制，该策略不会抛弃任务，也不会抛出异常，而是将某些任务(不是本次任务)回退到调用者，从而降低新任务的流量。它不会在线程池的某个线程中执行新提交的任务，而是在一个调用了execute的线程中执行该任务。
当线程中所有线程都被占用，并且工作队列被填满后，下一个任务会在调用execute时在主线程中执行。由于执行任务需要一定的时间，因此主线程在一段时间内不能提交任何任务，从而使得工作者线程有时间来处理正在执行的任务，在此期间，主线程不会调用accept，因此到达的请求被保存在TCP层的队列中而不是在应用程序的队列中。如果持续过载，那么TCP层会发现它的请求队列满，此时同样会开始抛弃请求。当服务器过载时，这种过载请求会逐渐向外蔓延--从线程池--工作队列--应用程序--TCP层--客户端，使得服务器在高负载下实现一种平缓的性能降低。

创建Executor时，可以选择策略。
ThreadPoolExecutor executor = new ThreadPoolExecutor(N_THREADS, N_THREADS, 0L, TimeUnit.MILLSECONDS, new LinkedBlockingQueue<Runnable>(CAPACITY));
executor.setRejectExecutionHandler(new ThreadPoolExecutor.CallerRunsPolicy());

159
使用Semephore来限制任务的到达率
使用一个无界队列(因为不能限制队列的大小和任务的到达率)，设置信号量的上界为线程池大小+可排队任务的数量，这是因为信号量需要控制正在执行的和等待执行的任务数量。
@ThreadSafe
public class BoundedExecutor {
	private final Executor exec;
	private final Semaphore semaphore;
	
	public BoundedExecutor(Executor exec, int bound) {
		this.exec = exec;
		this.semaphore = new Semaphore(bound);
	}
	public void submitTask(final Runnable command) throws InterruptedException {
		semaphore.acquire();
		try {
			exec.execute(new Runnable() {
				public void run() {
					try {
						command.run();
					} finally {
						semaphore.release();
					}
				}
			});
		} catch (RejectedExectuionExceptione e) {
			semaphore.release();
		}
	}
}


线程工厂
当线程池需要线程时，都是通过线程工厂方法来完成的。
默认的线程工厂方法将创建一个新的，非守护的线程，且不包含特殊的配置信息。
。。test。。不是说守护线程建立的线程是守护的吗，main算不算jvm的主线程？还是说jvm的主线程是没办法获得的？只有jvm主线程才是守护线程。其他都是非守护的，如何才能建立跨界的线程？？
。。下面说到了，Thread能修改自己的守护状态。

线程工厂是指ThreadFactory接口，里面只有一个方法Thread newThread(Runnable r);

很多情况下都需要定制的线程工厂方法，如，希望为线程池中每个线程指定一个UncaughtExceptionHandler，或实例化一个定制的Thread类用于执行调试信息的记录。可能希望修改线程的优先级(这通常不是一个好主意)或者守护状态(也不是一个好主意)。或许你希望给线程取一个更有意义的名字，用来解释线程的转储信息和错误日志。

下面是一个自定义的线程工厂，将一个特定于线程池的名字传递给MyAppThread的构造函数，从而可以在线程转储和错误日志信息中区分来自不同线程池的线程。
public class MyThreadFactory implements ThreadFactory {
	private final String poolName;
	public MyThreadFactory (String poolName) {
		this.poolName = poolName;
	}
	public Thread newThread(Runnable runnable) {
		return MyAppThread(runnable, poolName);
	}
}

MyAppThread还可以定制其他行为：指定线程名字，设置自定义UncaughtExceptionHandler想Logger中写入信息，维护一些统计信息(多少个线程被创建和销毁)，在线程创建或终止时把调试信息写入日志。
public class MyAppThread extends Thread {
	public static final String DEFAULT_NAME = "myappthread";
	private static volatile boolean debugLifecycle = false;
	private static final AtomicInteger created = new AtomicInteger();
	- static final AtomicInteger alice = new AtomicInteger();
	- static final Logger log = Logger.getAnonymousLogger();
	
	public MyAppThread(Runnable r) { this(r, DEFAULAT_NAME); }
	
	public MyAppThread(Runnable runnable, String name) {
		super(runnable, name + "-" + created.incrementAndGet());
		setUncaughtExceptionHandler(
			new Thread.UncaughtExceptionHanlder() {
				public void uncaughtException(Thread t, Throwable e)
				{
					log.log(Level.SEVERE, "uncaught in thread " + t.getName(), e);
				}
			}
		);
	}
	
	public void run() {
		boolean debug = debugLifecycle;
		if (debug) log.log(Level.FINE, "Created " + getName());
		try {
			alive.incrementAndGet();
			super.run();
		} finally {
			alive.decrementAndGet();
			if (debug) log.log(Level.FINE, "Exiting " + getName());
		}
	}
	
	+ static int getThreadsCreated() { return created.get(); }
	+ s int getThreadAlive() { return alive.get(); }
	+ s boolean getDebug() { return debugLifecycle; }
	+ s void setDebug(boolean b) { this.debugLifecycle = b; }
}

如果在应用程序中需要利用安全策略来控制对某些特殊代码库的访问权限，那么可以通过Executor的privilegedThreadFactory来定制自己的线程工厂。
通过这种方式创建的线程，将与创建privilegeedThreadFactory的线程拥有相同的访问权限，AccessControlContext和contextClassLoader。
如果不使用privilegedThreadFactory，线程池创建的线程将从在需要新线程时调用execute或submit的客户端程序中继承访问权限，从而导致令人困惑的安全性异常。


在调用构造函数后再定制ThreadPoolExecutor。
可以通过setter来修改大多数传递给它的构造器的参数(如基本法小，最大大小，存活之间，线程工厂及拒绝执行处理器(RejectedExecutionHandler))。
如果Executor是通过Executors中某个(newSingleThreadExecutor除外)工厂方法创建的，那么可以将结果的类型转为ThreadPoolExecutor以访问setter。

ExecutorService exec = Executors.newCachedThreadPool();
if (exec instanceof ThreadPoolExecutor)
	((ThreadPoolExecutor) exec).setCorePoolSize(10);
else
	throw new AssertionError("...");

Executors中包含了一个unconfigurableExecutorService工厂方法，该方法对一个现有的ExecutorService进行包装，使其只暴露出ExecutorService的方法，因此不能对它进行配置。newSingleThreadExecutor返回按这种方式封装后的ExecutorService，而不是最初的TPE。
。。test。。怎么能把父类的方法隐藏掉？。难不成是重写方法throw异常？。。主要是下面的内容。。。

可以在自己的Executor中使用这项技术以防止执行策略被修改。如果将ExecutorService暴露给不信任的代码，又不希望对其进行修改，就可以通过unconfigurableExecutorService来包装它。


8.4 扩展ThreadPoolExecutor
tpe是可扩展的，提供了可以在子类中改写的方法：beforeExecute，afterExecute，terminated。
beforeExecute，afterExecute，可以增加日志，计时，监视或统计信息收集的功能。无论是正常从run中返回还是抛出一个异常，afterExecute都会被调用(如果任务在完成后出现一个Error，那么就不会调用afterExecute)。如果beforeExecute抛出一个RuntimeException，那么任务将不会执行，afterExecute也不会执行。
线程池完成关闭操作时调用terminated，也就是所有任务都已经完成且所有的工作者线程都已关闭后。terminated可以释放Executor在生命周期中分配的各种资源，还可以执行发送通知，记录日志，收集finalize统计信息等。


8.5 递归算法的并行化
如果在循环体中包含了一些密集计算，或者需要执行可能阻塞的I/O操作，那么只有每次迭代是独立的，都可以对其进行并行化。
如果在循环中的迭代操作都是独立的，并且不需要等待所有的迭代操作都完成再继续执行，那么就可以使用Executor将串行循环转化为并行循环。

void processSequentially(List<Element> elements) {
	for (Element e : elements)
		process(e);
}

void processInParallel(Executor exec, List<Element> elements) {
	for (final Element e : elements)
		exec.execute(new Runnable() {
			public void run() { process(e); }
		});
}

后者返回更快，因为不会等待任务完成，只是把所有任务放入Excutor队列中。
如果需要提交一个任务集并等待它们完成，那么可以使用ExecutorService.invokeAll并在所有的任务都执行完后调用CompletionService来获取结果。
.invokeAll的参数是一组任务，并返回一组Future。

。。test。。。Executor只有一个方法execute，ExecutorService才有submit的？

当串行循环中各个迭代操作相互独立，且每个迭代操作的工作量比管理一个新任务带来的开销更多，那么这个串行循环就适合并行化。

在一些递归设计中同样可以采用循环并行化的方法。
递归算法中通常都会存在串行循环，这些循环可以按照上面的方式进行并行化。
一种简单的情况是：每个迭代操作都不需要来自后续迭代的结果。下面是用深度优先算法遍历一棵树，在每个节点上执行计算并将结果放入一个集合。修改后的方法同样执行深度优先遍历，但它并不是在访问节点时进行计算，而是为每个节点提交一个任务来完成计算。
。。test。。。工作密取怎么和Executor结合？没什么问题，Runnable是内部类，可以访问到类的ExecutorService属性的。。

public<T> void sequentialRecursive(List<Node<T>> nodes, Collections<T> results) {
	for (Node<T> n : nodes) {
		results.add(n.compute());
		sequentialRecursive(n.getChildren(), results);
	}
}

public<T> void parallelRecursicve(final Executor exec, List<Node<T>> nodes, final Collection<T> results) {
	for (final Node<T> n : nodes) {
		exec.execute(new Runnable() {
			public void run() {
				results.add(n.compute());
			}
		});
		parallelRecursive(exec, n.getChildren(), results);
	}
}

parallelRecursice的调用者可以通过以下方式等待所有的结果：创建一个特定于遍历过程的Executor，并使用shutdown和awaitTermination等方法。
public<T> Collection<T> getParallelResults(List<Node<T>> nodes) throws InterruptedException {
	ExecutorService exec = Executors.newCachedThreadPool();
	Queue<T> resultQueue = new ConcurrentLinkedQueue<T>();
	parallelRecursive(exec, nodes, resultQueue);
	exec.shutdown();
	exec.awaitTermination(Long.MAX_VALUE, TimeUnit.SECONDS);
	return result;
}


165  例子
大约是一个递归寻找可达路径

168 闭锁
为了在找到结果后停止搜索，需要通过某种方式来检查是否有线程已经找到结果。如果需要这个结果，那么还需要在其他任务都没有找到结果时更新结果。这些需求描述的是一种闭锁(Latch)机制，具体说是一种包含结果的闭锁。

@ThreadSafe
public class ValueLatch<T> {
	@GuardedBy("this") private T value = null;
	private final CountDownLatch done = new CountDownLatch(1);
	public boolean isSet() {
		return (done.getCount() == 0);
	}
	+ synchronized void setValue(T newValue) {
		if (!isSet()) {
			value = newValue;
			donw.countDown();
		}
	}
	+ T getValue() throws InterruptedException {
		done.await();
		synchronized (this) {			// 返回有必要synchronized？
			return value;
		}
	}
}

第一个找到结果的线程还会关闭Executor，从而阻止新任务。要避免RejectedExecutionException，需要将拒绝执行处理器设置为"抛弃已提交的任务"

如果不存在解答，那么可能会一直执行下去。。可以记录活动任务的数量，当该值为0时，将解答设置为null。


chapter 9 图像用户界面应用程序。

GUI都是单线程的，有人写过多线程GUI框架，但是由于竞态条件和死锁导致的稳定性问题而失败。
单线程的事件队列模型：采用一个专门的线程从队列中抽取事件，并将它们转发到应用程序定义的事件处理器。

9.5 其他形式的单线程子系统
线程封闭不仅可以用在GUI中，每当某个工具需要被实现为单线程子系统时，都可以使用这项技术。有时候，当程序员无法避免同步或死锁等问题时，也将不得不使用线程封闭。例如，一些原生库(Native Library)要求：所有对库的访问，甚至当通过System.loadLibrary来加载库时，都必须放在同一个线程中执行。

借鉴在GUI框架中的方法，可以很容易创建一个专门的线程或一个单线程的Executor来访问这些库，并提供一个代理对象来拦截所有对线程封闭对象的调用，并把这些调用作为一个任务来提交这个专门的线程。将Future和newSingleThreadExecutor一起使用，可以简化这项工作。在代理方法中可以调用submit提交任务，然后立即调用Future.get来等待结果(如果在线程封闭的类中实现了一个接口，那么每次都可以自动地让方法将一个Callable提交给后台线程并通过动态的代理来等待结果。)


183
第三部分 活跃性、性能和测试

chapter 10 避免活跃性危险

安全性与活跃性之间通常存在着制衡。我们使用加锁机制来确保线程安全，但过度地使用加锁，可能会导致锁顺序死锁。同样，我们使用线程池和信号量来限制对资源的使用，这些限制可能会导致资源死锁。


10.1 死锁
哲学家进餐问题。

当一个线程永远地持有一个锁，并且其他线程都尝试获得这个锁时，它们将永远被阻塞。
线程A持有锁L，期望锁M；线程B持有锁M，期望锁L，这2个线程会永远等待下去。这就是最简单的死锁，多个线程由于存在环路的锁依赖关系而永远地等待下去。

数据库服务器检测到一组事务发生死锁时，将选择一个牺牲者并放弃这个事务，作为牺牲者的事务会释放它所持有的资源，从而使其他事务继续进行。应用程序可以重新执行被强制中止的事务，这个事务现在可能可以成功完成。

jvm在解决死锁问题方面没有数据库服务器那么强大。当一组java线程发生死锁时，这些线程永远不可能再使用了。
恢复应用程序的唯一方式就是中止并重启它。

和许多其他的并发危险一样，死锁造成的影响很少会立刻显现出来。
一个类可能发生死锁，不代表每次都会死锁。但是死锁出现时，往往是最糟糕的时候--在高负载情况下。


A持有L，期望M，B持有M，期望L。
这种死锁的原因是：2个线程试图以不同的顺序来获得相同的锁。
如果按照相同的顺序来请求锁，就不会出现循环的加锁依赖性。就不会有死锁。

简单的锁顺序死锁
public class LeftRightDeadlock {
	private final Object left = new Object();
	private final Object right = new Object();
	
	public void leftRight() {
		synchronized(left) {
			synchronized(right) {
				doSth();
			}
		}
	}
	
	public void rightLeft() {
		synchronized(right) {
			synchronized(left) {
				doSth();
			}
		}
	}
}

动态的锁顺序死锁

+ void transferMoney(Account fromAccount, Account toAccount, DollarAmount amount) throws InsufficientFundsException {
	syncheonized(fromAccount) {
		synchronized(toAccount) {
			if (fromAmount.getBalance().compareTo(amount) < 0)
				throw new InsufficientFundsException();
			else {
				fromAccount.debit(amount);
				toAccount.credit(amount);
			}
		}
	}
}
所有的线程似乎都是按照相同顺序来获取锁的，但实际上，锁的顺序取决于参数顺序。
如果2个线程同时调用这个方法，一个线程从A转账到B，一个线程从B转账到A。

由于我们无法控制参数的顺序，因此要解决这个问题，必须定义锁的顺序，并在整个应用程序中都按照这个顺序来获取锁。

制定锁的顺序时，可以使用System.identityHashCode方法，该方法返回由Object.hashCode返回的值。
改进后：
private static final Object tieLock = new Object();
public void transferMoney(final Account fromAcct, final Account toAcct, final DollarAmount amount) throws InsufficientFundsException{
	class Helper {
		public void transder() throws InsufficientFundsException {
			if (from < amount) throws xxxException();
			else { from.debit, toAcct.credit}		// 直接用transferMoney的形参。。。test。。。可以？
		}
	}
	int fromHash = System.identifyHashCode(fromAcct);
	int toHash = System.identifyHashCode(toAcct);
	if (fromHash < toHash) {
		synchronized(fromAcct) {
			synchronized(toAcct) {
				new Helper().transfer();
			}
		}
	}
	else if（fromHash > toHash） {
		synchronized(toAcct) {
			synchronized(fromAcct) {
				new Helper().transfer();
			}
		}
	}
	else {
		synchronzied(tieLock) {					/// !!!.....
			synchronized(fromAcct) {
				synchronized(toAcct) {
					new Helper().transfer();
				}
			}
		}
	}
}

如果2个对象有相同的散列值，此时必须以某种方式决定锁的顺序。可以使用"加时赛"锁。在获得两个account锁之前，先获得这个加时赛锁。从而保证每次只有一个线程以未知的顺序获得这两个锁。

如果经常出现散列冲突(fromHash==toHash)，那么这种技术可能成为并发性的一个瓶颈(这类似于在整个系统中只有一个锁的情况)。但System.identityHashCode出现散列冲突的几率非常小。所以以最小的代价，换来了最大的安全性。

如果Account中包含唯一，不变，可比较的键值，如帐号，那么要指定锁的顺序就更容易了。通过键值对对象排序，不再需要"加时赛"锁。

188
在协作对象之间发生的死锁。
某些获取多个锁的操作不像上面那样明显。2个锁不一定在同一个方法中被获取。
例子是2个类，全是synchronized方法，类A的方法A调用了类B的方法B。类B的方法A调用了类A的方法B。。由于是Synchronized方法，所以类A执行方法A的时候，需要先获得A的锁，然后方法中调用了类B的方法，此时需要获得B的锁。。2个线程分别走A.A和B.A时，各自锁住A，B，并且需要B，A的锁。。死锁。

如果在持有锁的情况下调用某个外部方法，就要警惕死锁。


如果调用某个方法时，不需要持有锁，那么这种调用被称为开放调用(open-call)
。。test。。是指在无锁情况下调用synchronized方法。还是说调用的方法不能是synchronized的？？？

依赖于开放调用的类通常能表现出更好的行为，并且与那些在调用方法是需要持有锁的类相比，也更易于编写。

通过开放调用来避免死锁的方法，类似于采用封装机制来提供线程安全的方法：虽然在没有封装的情况下也能确保线程安全，但对一个使用了封装的程序进行线程安全分析，比没有使用封装的程序容易得多。。同理，分析一个完全依赖于开放调用的程序的活跃性，要比那些不依赖开放调用的程序简单。

通过尽可能地使用开放调用，将更易于找出那些需要获得多个锁的代码路径，因此也就更容易确保采用一致的顺序来获得锁。这些对开放调用以及锁顺序的依赖，反映了在构造同步对象(而不是对已构造好的对象进行同步)过程中存在的复杂性。

190
例子是将synchronized从整个方法变成了同步代码块。主要是同步那些和类属性有关的操作，组成一个原子操作。.将调用另一个类的方法移出同步代码块。

有时，在重新编写同步代码块以使用开放调用时，会导致原子操作变成非原子的。
很多情况下，某个操作变成非原子是可接受的。
某些情况下，丢失原子性会引发错误，需要另一种技术来实现原子性：
例如，在构造一个并发对象时，使得每次只有单个线程执行使用了开放调用的代码路径。
。。。？？。。和类属性比较，设置类属性的话，没有办法吧，。想不出适用环境。。

例如，在关闭某个服务时，你可能希望所有正在执行的操作完成后，再释放这些服务占用的资源。如果在等待操作完成的同时持有该服务的锁，很容易导致死锁。但在服务关闭前就释放服务的锁，则可能导致其他线程开始新的操作。
解决方法是：在将服务器的状态更新为关闭之前一直持有锁，这样其他想要开始新操作，或关闭该服务的线程会发现服务不可用，因此不会试图开始新的操作。然后，你可以等待关闭操作结束，并知道当开放调用完成后，只有执行关闭操作的线程才能访问服务的状态。
因此，这项技术依赖于构造一些协议(而不是加锁)来防止其他线程进入代码的临界区。
。。。解决方法还是看不懂啊。似乎应该是，持有锁，修改状态为关闭，放弃锁。等其他执行完，真正关闭？


资源死锁

2个资源池，线程A持有d1，期望d2，线程B持有d2，期望d1。

资源池越大，死锁概率越小。

另一种基于资源的死锁是线程饥饿死锁。一个任务提交另一个任务，并等待被提交任务在单线程的Executor中执行完成。这种情况下，第一个任务将永远等待下去，并使得另一个任务以及这个Executor中执行的所有其他任务都停止执行。
如果某些任务需要等待其他任务的结果，那么这些任务往往是产生线程饥饿死锁的主要来源，有界线程池/资源池与相互依赖的任务不能一起使用。


10.2 死锁的避免与诊断
如果一个程序每次至多只能获得一个锁，那么就不会产生锁顺序死锁。当然，这种情况通常并不现实。
如果必须获得多个锁，那么在设计时必须考虑锁的顺序：尽量减少潜在的加锁交互数量，将获得锁时需要遵循的协议写入正式文档并始终遵守这些协议。

使用细粒度锁的程序中，可以通过使用一种两阶段策略来检查代码中的死锁：首先，找出在什么地方将获得多个锁，然后对所有这些实例进行全局分析，从而确保它们在整个程序中--获取锁的顺序是一致的--。尽可能使用开放调用，这能极大简化分析过程。如果所有的调用都是开放调用，那么要发现获取多个锁的实例时非常简单的，可以通过代码审查，或者借助自动化的源代码分析工具。

支持定时的锁
一项技术可以检测死锁和从死锁中恢复，即显式使用Lock类中的tryLock功能来代替内置锁机制。
使用内置锁时，只要没有获得锁，就会永远等待。
限时锁则可以指定一个超时时限，在等待超过该事件后tryLock会返回一个失败信息。如果超时时限比获取锁的时间要长很多，那么就可能在发生某个意外情况后重新获得控制权。

定时锁失败时，并不需要知道失败的原因。或许是因为发生了死锁，或许是因为某个线程在持有锁时进入了无限循环，还可能是某个操作的执行时间远超预期。。。至少你能记录所发生的失败，以及关于这次操作的其他有用信息，并通过一种更平缓的方式来重新启动计算，而不是关闭整个进程。

即使在整个系统中没有始终使用定时锁，使用定时锁来获取多个锁也能有效应对死锁问题。如果在获取某个锁时超时，那么可以释放这个锁，然后后退并在一段时间后重试。(这项技术只有在同时获取两个锁时才有效，如果在嵌套的方法中调用请求多个锁，那么即使你知道已经持有了外层的锁，也无法释放它。)


jvm通过线程转储(Thread Dump)来帮助识别死锁的发生。
线程转储包括各个运行中的线程的栈追踪消息，加锁信息，被阻塞的线程正在等待获取哪个锁。
在生成线程转储前，jvm将在等待关系图中通过搜索循环来找出死锁。如果发现一个死锁，则获取相应的死锁信息，如在死锁中涉及哪些锁和线程，以及这个锁的获取操作位于程序的哪些位置。

unix上触发线程转储操作，通过下jvm进程发送sigquit信号(kill -3)，或者ctrl+\。
windows下ctrl+break。
许多IDE中都可以请求线程转储。

使用显式Lock类而不是内部锁，那么java5并不支持Lock相关的转储信息。
java6包含对显式Lock的线程转储和死锁检测等的支持，但这些锁上获得的信息比在内置锁上获得的信息精确度低。内置锁与获得它们所在的线程栈帧时相关联的，而显式的Lock只与获得它的线程相关联。

jdbc的Connection并不要求是线程安全的。

10.3 其他线程活跃性问题
饥饿，丢失信号，活锁。

当线程由于无法访问它所需要的资源而不能继续执行时，就发生了"饥饿"。引发饥饿的最常见资源就是CPU时钟周期。如果在java应用程序中对线程的优先级使用不当，或者在持有锁时执行了一些无法结束的结构(如无限循环，或无限等待某个资源)，那么也可能导致饥饿，因为其他需要这个锁的线程将无法得到它。

ThreadAPI中定义的线程优先级只是作为线程调度的参考，其中定义了10个等级，JVM根据需要将它们映射到操作系统的调度优先级。这种映射是与特点平台相关的，因此，某个os中2个不同的java优先级可能被映射到同一个优先级，而在另一个os中可能被映射到另一个不同的优先级。

os的线程调度器会尽力提供公平的，活跃性良好的调度，甚至超过java规范的要求范围。在大多数java应用程序中，所有线程都具有相同的优先级Thread.NORM_PRIORITY。
线程优先级并不是一种直观的机制，通过修改线程优先级所带来的效果通常也不明显。当提高某个线程的优先级时，可能不会起到任何作用，也可能会使某个线程的调度优先级高于其他线程，导致饥饿。

通常，我们尽量不修改线程的优先级。只要修改了优先级，程序的行为就与平台相关，并且会导致发生饥饿问题的风险。
经常能发现某个程序在一些奇怪的地方调用Thread.sleep或者Thread.yield，这是因为该程序试图克服优先级调整问题或响应性问题，并试图让低优先级的线程执行更多的时间。

Thread.yield，sleep，的语义都是未定义的。jvm既可以将它们实现为空操作，也可以将它们视为线程调度的参考。尤其是，unix中并不要求它们有用sleep的语义----将当前线程放在与该优先级对应的运行队列末尾，并将执行权交给拥有相同优先级的其他线程，尽管有些jvm是按这种方式来实现yield方法的。
。。yeild是放弃cpu时间片，线程重新竞争。自己可能再次竞争到cpu时间。


cpu密集型会导致糟糕的响应性。可以选择修改线程优先级。

不良的锁管理也会导致糟糕的响应性，如一个线程长时间占有一个锁(或者正在迭代一个大容器，并且对每个元素进行计算密集的处理)，其他想要访问这个日期的线程就必须等待。


活锁
Livelock是另一种形式的活跃性问题，该问题不会阻塞线程，但也不能继续执行因为线程将不断重复执行相同额操作，而且总会失败。
活锁通常发生在处理事务消息的应用程序中：如果不能成功处理某个消息，那么消息处理机制将回滚整个事务，并将它放到队列开头。。如果处理代码总是对某种消息处理失败，那么就是一个无限循环。
这种形式的活锁通常是由于过度的错误恢复造成的，因为它错误地将不可修复的错误作为可修复的错误。

当多个相互协作的线程都对彼此进行相应从而修改各自的状态，并使得任何一个线程都无法继续执行时，就发生了活锁。这就像2个过于礼貌的人在半路上面对面遇见，他们彼此都让出对方的路，然而又在另一条路上相遇了，如此反复避让。
解决方法是，在重试机制中加入随机性。在并发程序中，通过等待随机长度的时间和回退可以有效地避免活锁的发生。


197
chapter 11 性能与可伸缩性

线程最主要的目的是提高程序的运行性能。

很多提升性能的技术同样会增加复杂性，增加了在安全性和活跃性上发生失败的风险。
更糟糕的是，有些技术的初衷是提升性能，但事实上却与之相反，或又带来了其他新的性能问题。

我们希望获得更好的性能，但始终要把安全性放在第一位。


使用多线程的目的是提升整体性能，但与单线程的方法相比，使用多线程总会引入一些额外的性能开销，线程之间的协调(锁，触发型号，内存同步等)，增加的上下文切换，线程的创建和销毁，线程的调度等。

单cpu系统，程序是cpu密集型，那么多线程没有意义。

性能与可伸缩性
应用程序的性能可以采用多个指标来衡量，例如服务时间，延迟时间，吞吐率，效率，可伸缩性以及容量等。其中一些指标(服务时间，等待时间)用于衡量程序的"运行速度"，即某个指定的任务单元需要"多快"才能完成。另一些指标(生产量，吞吐量)用于程序的"处理能力"，即在计算资源一定的情况下，能完成"多少"工作。

可伸缩性是指：当增加计算资源(如cpu，内存，存储容量或I/O带宽)，程序的吞吐量或处理能力能相应地增加。

198

针对可伸缩性进行设计与调整时采用的方法与传统的性能调优方法截然不同。
性能调优时，目的通常是用更小的代价完成相同的工作，例如通过缓存来重用之前计算的结果，或优化算法。
可伸缩性优化时，目的是设法将问题的设计并行化，从而能利用更多的计算资源来完成更多工作。

大多数提高单线程性能的技术，往往会破坏可伸缩性。

避免不成熟的优化。首先使程序正确，然后再提高运行速度---如果它还不够快。

在进行决策时，有时会通过增加某种形式的成本来降低另一种形式的开销，也会增加开销来换取安全性。
很多性能优化措施通常是以可读性，可维护性为代价的。
有时，优化措施会破坏面向对象的设计原则。
有时，它们会带来更高的错误风险，因为通常越快的算法就越复杂。
(如果你无法找出其中的代价或风险，那么或许还没有对这些优化措施进行彻底的思考和分析)

大多数性能决策都包含多个变量，并且依赖于运行环境。在使某个方案比其他方案更快之前，首先问自己一些问题：
"更快"的含义是什么？
该方法在什么条件下运行得更快？低负载还是高负载？大数据集还是小数据集？能否通过测试结果来验证你的答案？
这些条件在运行环境中发生频率？能否通过测试结果来验证你的答案？
在其他不同条件的环境中能否使用这里的代码？
在实现这种性能提升时需要付出哪些隐含的代价，如增加开发风险或维护开销？这种权衡是否合适？


虽然你的初衷可能是用安全性换性能，但最终可能什么都得不到。
特别是，当提到并发时，许多开发人员对哪些地方存在性能问题，哪种方法的运行速度更快，以及哪种方法的可伸缩性更高，往往会存在错误的直觉。
因此，在对性能的调优时，一定要有明确的性能要求(这样才能知道什么时候需要调优，以及什么时候应该停止)，此外还需要一个测试用程序，真实的配置与负载等环境。

市场上有成熟的分析工具可以用于评估性能以及找出性能瓶颈。

11.2 Amdahl定律
有些问题，如果可以资源越多，那么问题的解决速度越快。
有些任务本质上是串行的。

如果使用线程主要是为了发挥多个处理器的处理能力，那么就必须对问题进行合理的并行分解，并使得程序能有效地使用这种潜在的并行能力。

Amdahl定律：在增加计算资源的情况下，程序在理论上能够实现的最高加速比，这个值取决于程序中可并行组建与串行组建所占的比重。
F是必须被串行执行的部分，N个处理器
最高加速比 <= 1/(F+(1-F)/N)

当N趋向无穷大，最大的加速比趋近于1/F。因此，如果程序有50%的计算需要串行执行，那么最高的加速比只能是2。如果有10%需要串行，那么最高的加速比接近10。

随着处理器数量的增加，即使可串行部分所占的百分比很小，也会极大限制增加计算资源时所能提升的吞吐率。

。。201 的曲线图是什么。。。是  (提升后的速度-提升前的速度)/提升前的速度？
。。cpu满载时间/总计算时间。。((1-F)/Ncpu)/(F/1+(1-F)/Ncpu)
..F是串行比例。


使用LinkedBlockingQueue作为工作队列，出列操作被阻塞的可能性小于使用同步LinkedList。因为LinkedBlockingQueue使用了一种可伸缩性更高的算法。
。。test。。。同步LinkedList是指ConcurrentLinkedList(不知道有没有这个)还是Collections.synchronizedLinkedList？。。
。。下面有张曲线图是ConcurrentLinkedQueue和synchronized_LinkedList对比。.ConcurrentLinkedQeueu,8线程时达到最高吞吐率4.sync_linekdList一直都是1(不是，书上文字描述是：线程<3时，吞吐量有某种程度的提升，但是之后会由于同步开销的增加而下跌。线程4/5个时，竞争非常激烈，甚至每次访问队列都会在锁上发生竞争，此时的吞吐量主要受上下文切换的限制)。。应该是synchronized整个方法和部分核心代码的区别。(书上：吞吐量的差异来源于2个队列中不同比例的串行部分。同步的LinkedList采用单个锁来保护整个队列的状体，并在offer，reomve等方法的调用期间都将持有这个锁。ConcurrentLinkedQueue使用一种更复杂的非阻塞队列算法(15.4.2节)，该算法使用原子引用来更新各个链接指针。在第一个队列中，整个插入和删除都将串行。第二个队列中，只有对指针的更新操作需要串行)

所有的并发程序中都包含一些串行部分。如果你认为程序中不存在串行部分，那么再仔细检查一遍。


随着多核cpu成为主流，系统可能拥有数百，数千个cpu。一些在4核系统中看似具有可伸缩性的算法，却可能含有一些隐藏的可伸缩性瓶颈。

在评估一个算法时，要考虑算法在数百，数千处理器的情况下的性能表现，从而对出现的可伸缩性局限有一定程度的认识。
11.4.2,11.4.3分别介绍了2中降低锁粒度的技术：锁分解(将一个锁分解为2个锁)和锁分段(将一个锁分解为多个锁)。当通过amdahl定律来分析这两项技术时，我们会发现，如果将一个锁分解为2个锁，似乎并不能充分利用多处理器的能力。锁分段技术似乎更有前途，因为分段的数量可以随着处理器数量的增加而增加。
。。。到底哪个有前途。。。

11.3 线程引入的开销

单线程程序不存在线程调度，不存在同步开销，不需要锁来保证数据结构的一致性。
在多个线程的调度和协调过程中都需要一定的性能开销：对于为了提升性能而引入的线程来说，并行带来的性能提升必须超过并发导致的开销。

上下文切换
如果主线程是唯一线程，那么它基本上不会被调度出去。
如果可运行线程数大于cpu数量，那么os会将某个正在运行的线程调度出来，从而是其他线程能够使用cpu。这将导致一次上下文切换，在这个过程中将保存当前运行的线程的上下文，并将新调度进来的线程的执行上下文设置为当前上下文。

切换上下文需要一定的开销，在线程调度过程中需要访问由os和jvm共享的数据结构。应用程序，os，jvm都使用相同的cpu。在os和jvm的代码中消耗越多的cpu时钟，应用程序的cpu时间片就越少。。上下文切换的开销不只是jvm和os的开销。当一个新的线程被切换进来时，它锁需要的数据可能不再当前cpu的cache中，因此上下文切换将导致一些缓存损失，因为线程在首次调度运行时更加缓慢。。这就是为什么调度器会为每个可运行的线程分配一个最小执行时间，即使有许多其他线程正在等待执行。它将上下文切换的开销分摊到更多不会中断的执行时间上，从而提升整体吞吐率(以损失响应性为代价)。

当线程由于等待某个发生竞争的锁而被阻塞时，jvm通常会将这个线程挂起，并允许它被交换出去。如果线程频繁地发生阻塞，那么它们将无法使用完整的调度时间片。在程序中发生越多的阻塞(阻塞I/O，等待获取发生竞争的锁，在条件变量上等待)，cpu密集型的程序就会发生越多的上下文切换，从而增加调度开销，并因此降低吞吐量。(无阻塞算法同样有助于减小上下文切换。)

上下文切换的实际开销随着平台的不同而变化，按照经验来看，在大多数通用的处理器中，上下文切换的开销相当于5000-10000个cpu时钟周期，也就是几微秒。

unix的vmstat命令和windows的perfmon工具都能报告上下文切换次数以及在内核中执行时间所占比例等信息。如果内核占有率高(>10%),通常表示调度活动发生得很频繁，这可能是由于I/O或竞争锁导致的阻塞引起的。

11.3.2 内存同步
同步操作的性能开销包括多个方面，在synchronized和volatile提供的可见性保证中可能会使用一些特殊指令，即内存栅栏(Memory-Barrier)。内存栅栏可以刷新缓存，使缓存无效，刷新硬件的写缓存，以及停止执行管道。内存栅栏可能同样会对性能带来间接的影响，因为它们将抑制一些编译器优化操作。在内存栅栏中，大多数操作都是不能被重排序的。

在评估同步操作带来的影响时，区分有竞争的同步和无竞争的同步非常重要，synchronized机制针对无竞争的同步进行优化(volatile通常是非竞争的)，而在编写本书时，一个"快读通道(Fast-Path)"的非竞争同步将消耗20-250个时钟周期。虽然无竞争同步的开销不为0，但它们对应用程序整体性能的影响微乎其微，而另一种方法不仅会破坏安全性，而且还会使的经历非常痛苦的除错过程。
。。有竞争，无竞争，似乎是指，这个锁会不会发生竞争？。。不会发生竞争的锁，，好像没有意义吧。

现代jvm能通过优化来去掉一些不会发生竞争的锁，从而减少不必要哦的同步开销。
如果一个锁对象只能由当前线程访问，那么jvm可以通过优化来去掉这个锁获取操作。因为其他线程无法与当前线程在这个锁上发生同步
synchronized (new Object()) {}		// 无作用的同步

一些更完备的jvm能通过逸出分析来找到不会发布到队的本地对象引用(因此这个引用是线程本地的。)
下面的代码中，对List的唯一引用就是局部变量stooges，并且所有封闭在栈中的变量都会自动成为线程本地变量。在方法执行中，至少会将Vector的锁获取/释放4次(3个add+1个toString)。一个智能的运行时编译器通常会分析这些调用，从而使stooges及其内部状态不会逸出，因此可以去掉这4次对锁获取操作。(这个编译器优化也被称为锁清除优化(Lock-Elision)，IBM的jvm支持这种优化，并预计从java7开始在HotSpot中支持。)

public String getStoogesNames() {
	List<String> stooges = new Vector<>();
	stooges.add()""Moe;
	stooges.add()"Larry";
	stooges.add()"Curly";
	return stooges.toString();
}

即使不执行逸出分析，编译器也可以执行锁粒度粗化操作，即将临近的同步代码块用同一个锁合并起来。在上面的代码中，如果jvm进行锁粒度粗化，那么可能会把3个add，1个toString调用合并为单个锁获取/释放操作。并采用启发式方法来评估同步代码块中采用同步操作以及指令之间的相对开销。
(一个智能的动态编译器会发现该方法总是返回相同的字符串，因此在第一次执行后，把代码重新编译成仅返回第一次执行的结果。)

不要过度担心非竞争同步带来的开销，这个基本机制已经非常快了，并且jvm还能进行额外的优化以进一步降低或消除开销。因此，我们的优化重点是那些发生锁竞争的地方。

某个线程中的同步可能会影响其他线程的性能。同步会增加共享内存总线上的通信量，总线的带宽是有限的，并且所有处理器都共享这条总线。如果有多个线程竞争同步带宽，那么所有使用了同步的线程都会受到影响。


非竞争的同步可以完全在jvm中进行处理，竞争的同步可能需要os的介入，从而增加开销。
在锁上发生竞争时，竞争失败的线程肯定会阻塞，jvm在实现阻塞时，可以采用自旋等待(Spin-Waiting，指通过循环不断地尝试获取锁，直到成功)或者通过os挂起被阻塞的线程。这两种方式的效率高低，取决于上下文切换的开销以及在成功获取锁之前需要等待的时间。等待时间短，自旋等待合适。等待时间长，线程挂起合适。。有些jvm将根据历史等待时间的分析数据在这2者间作出选择，但大多数jvm在等待锁时都只是将线程挂起。


11.4 减少锁的竞争

串行操作降低可伸缩性。
上下文切换降低性能。
在锁上发生竞争同时导致这2个问题。因而减少锁的竞争能够提高性能和可伸缩性。

在并发程序中，对可伸缩性的最主要威胁就是独占方式的资源锁。

2个因素影响在锁上发生竞争的可能性：锁的请求频率，每次持有该锁的时间。如果2者乘积很小，那么大多数获取锁的操作不会发生竞争。因此该锁上的竞争不会对可伸缩性造成严重影响。

3种方式减低锁的竞争程度：
减少锁的持有时间
降低锁的请求频率
使用带有协调机制的独占锁，这些机制允许更高的并发性
。。协调机制的独占锁？？。。test。。。


207

11.4.1 缩小锁的范围
缩小范围来减少锁的持有时间。

原子操作不能分割。
同步需要一定的开销，把一个同步块分割成多个同步块，可能对性能产生负面影响，而且如果jvm执行锁粒度粗化操作，分割的代码块可能由会合并。

在分解同步代码块时，理想的平衡点将与平台相关，但实际情况中，仅当可以把一些"大量"的计算或阻塞操作从同步代码块中移出时，才应该考虑同步代码块的大小。


11.4.2 减小锁的粒度
降低线程请求锁的频率，这可以通过锁分解，锁分段等技术实现，这些技术中采用多个相互独立的锁来保护独立的状态变量，从而改变之前这些变量由单个锁来保护的情况。
这些操作能减小锁操作的粒度，并能实现更高的可伸缩性，然而，使用的锁越多，那么发生死锁的风险也越高。
。。锁少的话，竞争激烈。锁多，竞争少，可伸缩性高，死锁高。

如果一个锁需要保护多个相互独立的状态变量，那么可以将这个锁分解为多个锁，并且每个锁只保护一个变量，从而提升可伸缩性，并最终降低每个锁被请求的频率。

public class ServerStatus {
	public final Set<String> users;
	public final Set<String> queries;
	public synchronzied void addUser(String u) { users.add(u);}
	public synchronized void addQuery(String q) { queries.add(q);}
	public synchronized void removeUser(String u) { users.remove(u)}
	public synchronized void removeQuery(String q) { qs.remove(q)}
}

ServerStatus中的两种信息是完全独立，甚至可以分解为2个类，同时确保功能不会丢失。

对锁进行分解后，每个新的细粒度锁上的访问量比最初的访问量少。
通过将用户状态和查询状态委托给一个线程安全的Set，而不是使用显示的同步，能隐含地对锁进行分解，因为每个Set都会使用一个不同的锁来保护其状态。

public class ServerStatus {
	public final Set<String> users;
	public final Set<String> queries;
	public void addUser(String u) {
		synchronized(users) {
			users.add(u);
		}
	}
	public void addQuery(String q) {
		synchronized(queries) {
			queries.add(q);
		}
	}
	//...
}

如果锁上存在适中而不是激烈的竞争，通过将一个锁分解为2个，能最大限度提升性能。
如果对竞争并不激烈的锁进行分解，那么在性能和吞吐量等方面带来的提升非常有限，但是也会提高性能随着竞争提高而下降的拐点值。
对竞争适中的锁分解时，实际上是把这些锁转变为非竞争的锁，从而有效地提高性能和可伸缩性。
。。。对于竞争非常激烈的锁呢？。。。。下面说了。。

11.4.3 锁分段

把一个竞争激烈的锁分解为2个锁，这2个锁可能都存在激烈的竞争。虽然采用两个线程并发能提高一部分可伸缩性，但在一个拥有多核的系统中，仍然无法给可伸缩性带来极大的提高。上面的ServerStatus中，无法再对锁进行分解。

某些情况下，可以将锁分解技术进一步扩展为对一组独立对象上的锁进行分解，这种情况被称为锁分段。
例如，在ConcurrentHashMap的实现中，使用了一个包含16个锁的数组，每个锁保护所有散列桶的1/16，其中第N个散列桶由第(N%16)个锁来保护。假设散列函数有合理的分布性，且关键字是均匀的，那么这大约能把对于锁的请求减少到原来的1/16。正是这项技术能使ConcurrnetHashMap支持16个并发的写入器。
要使得拥有大量处理器的系统在高访问量的情况下实现更高的并发性，还可以进一步增加锁的数量，但仅当你能证明并发写入线程的竞争足够激烈并需要突破这个限制时，才能将锁分段的数量超过默认的16个。

锁分段的劣势：与采用单个锁来实现独占访问相比，要获取多个锁来实现独占访问将更加困难并且开销更高。通常在执行一个操作时最多只需获取一个锁，但在某些情况下需要加锁整个容器，例如当ConcurrentHashMap需要扩展映射范围，以及重新计算键值的散列值以分布到更大的桶集合中时，就需要获取分段锁集合中的所有锁。
要获取内置锁集合，能采用的唯一方式是递归
。。test。。看下源代码。。

211
例子，大多数方法，例如get，都只需要获得一个锁，而有些方法需要获得全部锁，但并不要求同时获得，例如clear

public class StripedMap {
	private static final int n_locks = 16;
	private final Node[] buckets;		// final, 无法扩大了。。
	private final Object[] locks;
	
	private static class Node { ... }
	
	public StricpedMap(int numBuckets) {
		buckets = new Node[numBuckets];		// 形参
		locks = new Object[n_locks];			// 16
		for (int i = 0; i < n_locks; i++)
			locks[i] = new Object();
	}
	private final int hash(Object key) {
		return Math.abs(key.hashCode() % buckets.length);	// 有道理。。自定义的hashCode，return一个负数。。。% 桶数量
	}
	
	public Object get(Object key) {
		int hash = hash(key);
		synchronized (locks[hash % n_locks]) {
			for (Node m = buckets[hash]; m != null; m = m.next)
				if (m.key.equals(key))
					return m.value;
		}
		return null;
	}
	public void clear() {
		for (int i = 0; i < buckets.length; i++) {
			synchronized(locks[i % n_locks]) {
				buckets[i] = null;
			}
		}
	}
	...
}


11.4.4 避免热点域
锁分解，锁分段，都能提高可伸缩性，因为它们都能使不同的线程在不同的数据(或一个数据的不同部分)上操作，而不会相互干扰。

如果采用锁分段，那么一定要表现出在锁上的竞争频率高于在锁保护的数据上发生竞争的频率。如果一个锁保护两个2个独立变量x，y，线程a想要访问x，线程b想要访问y(类似于ServerStatus)，那么这2个线程不会在任何数据上发生竞争，即使它们会在同一个锁上发生竞争。
。。test。。这不是锁分解么。。

当每个操作都请求多个变量时，锁的粒度将很难降低。这是性能与可伸缩性之间相互制衡的另一个方面，一些常见优化，例如将一些反复计算的结果缓存起来，都会引入一些"热点域"，而这些热点域往往会限制可伸缩性。

在实现HashMap时，size方法中计算元素数量。最简单的方法是每次调用size时统计一次。一种常见优化是：在插入和移除元素时更新计数器，虽然这在插入和移除方法中增加了一些开销，但这将size方法从O(n)降低到O(1)。
单线程或完全同步的实现中，使用一个独立的计数器能很好的提高类似size，isEmpty这些方法的执行速度，但却导致更难以提升实现的可伸缩性，因为每个修改map的操作都需要更新这个共享的计数器。即使使用锁分段技术来实现散列链，但在对计数器的访问进行同步时，也会重新导致在使用独占锁时存在的可伸缩性问题。。一个看似性能优化的措施--缓存size的结果，已经变成了一个可伸缩性问题。这种情况下，计数器也被称为热点域，因为每个导致元素数量变化的操作都需要访问它。

为了避免这个问题，ConcurrentHashMap中的size将对每个分段进行枚举并将每个分段中的元素数量相加，而不是维护一个全局计数器。为了避免枚举每个元素，ConcurrentHashMap为每个分段都维护了一个独立的计数器，并通过每个分段的锁来维护这个值。
如果size的频率和修改map的频率相当，可以采用：调用size时，将返回值缓存到volatile中，容器修改时，是这个缓存的值无效(-1)，如果该值非负，size直接返回，否则重新计算元素数量。


11.4.5 一些替代独占锁的方法

第三种降低锁竞争的方法就是放弃使用独占锁，用友好并发的方式来管理共享状态，如使用并发容器，读-写锁，不可变对象以及原子变量。

ReadWriteLock(13章)实现了一种在多个读取操作以及单个写入操作情况下的加锁规则:如果多个读操作都不会修改共享资源，那么这些读操作可以同时访问该共享资源，但在执行写入时必须以独占的方式来获取。对于读取操作占多数的数据结构，ReadWriteLock能提供比独占锁更高的并发。对于只读的数据结构，其中包含的不变性可以完全不需要加锁操作。

原子变量(15章)提供了一种方式来降低更新"热点域"时的开销，例如静态计数器，序列发生器，或者对链表数据结构中头节点的引用。原子变量类提供了在整数或对象引用上的细粒度原子操作(因此可伸缩性更高)，并使用了现代处理器中提供的底层并发原语(如cas)。
如果类中只有少量的热点域，并且这些域不会与其他变量参与到不变性条件中，那么用原子变量来替代它们可以提高可伸缩性。


11.4.6 检测cpu的利用率
测试可伸缩性时，通常要保证处理器得到充分利用。一些工具，例如unix上的vmstat，mpstat，windows的perfmon，都能给出cpu的状态。

如果所有的cpu的利用率不均匀(有些cpu忙碌，有些空闲)，那么首要目标是找出程序中的并行性，不均匀的利用率表明大多数计算都是由一小组线程完成的，并且应用程序没有利用其他的处理器。

cpu没有得到充分利用，通常有以下的原因：

负载不充足。。测试的程序中没有足够多的负载。增加负载。得确认现实中是否可能有这么多的负载。以及，客户端是否有能力发送这么多的请求。

I/O密集。可以通过iostat或perfmon来判定某个应用程序是否是磁盘I/O密集型的，或者通过检测网络的通信流量级别来判断它是否需要高带宽。

外部限制。如果应用程序依赖与外部服务，如数据库或web服务，那么性能瓶颈可能并不在自己的代码中。可以使用分析工具或数据库管理工具来判断在等待外部服务的结果时需要多少时间。

锁竞争。使用分析工具可以知道在程序中存在何种程度的锁竞争，以及在哪些锁上存在"激烈竞争"。也可以通过其他方式来获得相同的信息，例如随机取样，触发一些线程转储，并查看其中在锁上发生竞争的线程。如果线程由于等待某个锁而被阻塞，那么在线程转储信息中将存在相应的栈帧，其中包含的信息形如"waiting to lock monitor..."。非竞争的锁很少出现在线程转储中，而对于竞争激烈的锁，通常至少会有一个线程在等待获取它，因此将在线程转储中频繁出现。

如果应用程序正在使cpu保持忙碌，那么可以使用监视工具来判断是否能通过增加额外的cpu来提升程序的性能。
如果一个程序只有4个线程，那么可以充分利用一个4核os的计算能力，但是当移植到8核时，无法获得性能提升。
在vmstat命令的输出中，有一栏信息是当前处于可运行状态但(由于没有足够的cpu)没有运行的线程数量。如果cpu利用率很高，且总有可运行线程在等待，那么增加cpu数量，性能会提升。

11.4.7 向对象池说"不"
在jvm早期，对象分配和垃圾回收等操作执行速度非常慢，但后续版本中，这些操作的性能已经极大提升了。

为了解决"缓慢的"对象生命周期，许多开发人员都选择使用对象池技术，在对象池中，对象能被循环利用，而不是由垃圾回收器回收，并在需要的时候重新分配。在单线程程序汇总，尽管对象池技术能降低垃圾收集操作的开销，但对于高开销对象以外的其他对象来说，仍然存在性能缺失。(对于轻量级和中量级对象来说，这种损失更为严重)
(除了损失CPU指令外，对象池技术还存在问题，最大的问题就是如何正确地设置对象池的大小(太小，没有作用，太大，给垃圾回收器带来压力，因为过大的对象池将占用其他程序需要的内存资源)。如果重新使用某个对象是没有将其恢复到正确的状态，那么可能会产生一些"微妙的"错误。此外，还可能存在一个线程在将对象还给对象池后仍然使用该对象的问题，从而产生一种"从旧对象到新对象"的引用。导致垃圾回收器要执行更多的工作。)

在并发应用程序中，对象池的表现更糟糕。当线程重新分配新对象时，基本上不需要在线程间进行协调，因为对象分配器通常会使用线程本地的内存块，所以不需要在堆上进行同步。
如果这些线程从对象池中请求一个对象，那么就需要通过某种同步来协调对对象池数据结构的访问，从而可能导致某个线程被阻塞。由于竞争而被阻塞的开销是内存分配操作开销的数百倍，因此即使对象池带来的竞争很小，也可能形成一个可伸缩性瓶颈。(即使是一个非竞争的同步，所导致的开销也会比分配一个对象的开销大。)，看似一种性能优化，但实际上导致了可伸缩性问题。

对象池有其特定的用途(在特定环境中(如J2ME，RTSJ)，需要对象池技术来提高内存管理或响应性管理的效率)，但是对于性能优化来说，用途是有限的。

通常，对象分配操作的开销比同步的开销更低。


11.5
单线程下，ConcurrentHashMap的性能比synchronizedHashMap好一点，在并发环境中则好很多。
ConcurrentHashMap的实现中假设，大多数常用的操作都是获取某个已经存在的值，因此它对各种get操作进行优化从而提供最高的性能和并发性。

在同步Map的实现中，可伸缩性的最主要障碍在于整个map中只有一个锁，因此每次只有一个线程能够访问这个map。
ConcurrentHashMap对于大多数读操作并不会加锁，在写入操作及其他一些需要锁的读操作中使用了锁分段技术。因此，多个线程能并发地访问这个map而不会发生阻塞。

ConcurrentHashMap，ConcurrentSkipListMap，通过synchronizedMap包装的HashMap和TreeMap。前两者是线程安全的，后2个通过同步封装器来确保线程安全性。
每次运行时，N个线程并发，执行一个紧凑的循环：选择一个随机值，尝试获取这个键值对应的值。如果不存在，那么插入到map中的概率为p=0.6，如果存在，那么删除这个值的概率为p=0.02。。这个测试在8路Sparc V880系统上，基于java6.图中给出了将ConcurrentHashMap归一化为单个线程时的吞吐量。

p215 图
						1核		2核		4核		8核		16及以后
ConcurrentHashMap		1		1.3		1.8		2.5		3
ConcurrentSkipListMap	0.4		0.6		1		1.5		1.9
synchronizedHashMap		0.9		0.2，之后也是
synchronizedTreeMap		0.5		0.2，之后也是
。。ConcurrentHashMap 1核是的吞吐率设置为1.


11.6 减少上下文切换的开销
许多任务中都包含一些可能被阻塞的操作。当任务在运行和阻塞这两个状态间切换时，就相当于一次上下文切换。
在服务器应用程序汇总，发生阻塞的原因之一就是在处理请求时产生各种日志消息。
为了说明如何通过减少上下文切换的次数来提高吞吐量，我们将对两种日志方法的调度行为进行分析。

大多数日志框架中都是简单地对println进行包装，当需要记录消息时，只需将其写入日志文件中。
第7章LogWriter给出了另一种方法：记录日志的工作由一个专门的后台线程完成，而不是发出请求的线程完成。
。。反正这种好。写日志只有一个线程，不会发生阻塞。

p140  LogWriter
BlockingQueue，msg放入到这个中。然后内置线程属性有个whileTrue，从这里获得。并且有类属性来表明是否应该停止。

。。始终有一个线程，并且线程是BlockingQueue.take等待，这种是否值得？。在何种日志流量的情况下值得？



chapter12 并发程序的测试
编写并发程序时，可以采用和编写串行程序时相同的设计原则与设计模式。差异在于，并发程序中有一定程度的不确定性，而在串行程序中不存在这个问题。

活跃性测试，不发生任何错误的行为
安全性测试，某个良好的行为终究会发生

构造测试代码也许更难，因为被测试代码是并发的，说明测试代码也需要并发。

随机数发生器是线程安全的。所以可以使用hashCode，nanoTIme，然后经过<<,>>等操作，获得一个数。

模拟线程并发：CountDownLatch，CyclicBarrier

。。其他线程.join,,本线程会等其他线程执行完后再执行
。。Thread.yield，放弃cpu时间片，开始下次cpu时间片的竞争。

228
提高交替操作的数量
Thread.yield会产生上下文切换。(得看平台，有些jvm，yield是一个空操作，有些是sleep)

功能测试时服务段的测试
性能测试将衡量典型测试用例中的端到端性能，根据经验值来调整各种限值，线程数量，缓存容量等。


栅栏每次都会运行run，所以可以在run里用boolean，第一次记录start，第二次记录end，来记录运行时间。


响应性衡量
关于服务质量的问题，如"操作在100ms内成功执行的比例是多少"


12.3 避免性能测试的陷阱

垃圾回收
执行时序是无法预测的。可能N次凑没有触发垃圾回收，但是N+1次是触发了垃圾回收。
2种方法防止垃圾回收对测试结果产生偏差：
1.确保测试期间不会执行垃圾回收(jvm -verbose: gc来判断是否执行了垃圾回收操作)
2.确保垃圾回收操作在测试期间执行多次。能充分反映运行期间的内存分配和垃圾回收等开销

第二种更好。


动态编译
类第一次加载时，jvm通过解释字节码方式运行。如果某个时刻一个方法运行的次数足够多，动态编译器会将它编译成机器代码，编译完后，代码的执行方式从解释执行，变成了直接执行。

基于各种原因，代码还可能被反编译(退回到解释执行)以及重新编译，例如加载了一个会是编译假设无效的类，或者在收集足够的分析信息后，决定采用不同的优化措施来重编译某条代码路径。

一种方法防止动态编译对测试结果产生偏差，就是是程序运行足够上的时间(至少数分钟)，这样编译过程以及解释执行都只是总执行时间的很小一部分。
另一种方法是，是代码预先运行一段时间，并且不测试这段时间内的代码性能。在Hotspot中，如果在运行程序时使用命令行选项-xx: +PrintCompilation，那么当动态编译运行时将输出一条信息。通过这条信息判断动态编译时在测试运行前，而不是运行过程中执行。

jvm会使用不同后台线程来执行辅助任务。当在单次运行中测试多个不相关的计算密集型操作时，一种好的做法是在不同操作的测试之间插入显示的暂停，从而使jvm能与后台任务保持步调一致，同时将被测试任务的干扰降至最低
当测试多个相关操作时，例如将相同测试运行多次，如果按照这种方式来排除jvm后台任务，那么可能会得到不真实的结果。


对代码路径的不真实采样
运行时编译器根据收集到的信息对已编译的代码进行优化。jvm可以与执行过程特定的信息来生产更优的代码，这意味这在编译某个程序的方法M是生产的代码，将可能与编译另一个不同程序中的方法M时生产代码不同。
某些情况下，jvm可能会基于一些只是临时有效的假设进行优化，并在这些假设实效时抛弃已编译的代码。(如，如果当前已加载的类都没有改写某个方法，那么jvm会通过单一调用转换将虚拟方法调用专为直接方法调用。但如果后来加载了一个改写了该方法的类，那么之前已编译的代码将实效)

因此，测试程序要尽量覆盖该应用程序中将执行的代码路径集合。否则，动态编译器可能会对一个单线程测试程序进行一些优化，但在真是环境中包含了一点并行，会使这些优化不复存在。


不真实的竞争程度


无用代码的消除
在编写优秀的基准测试程序时，一个需要面对的挑战是：优化编译器能找出并消除那些不会对输出结果产生任何影响的无用代码。
在Hotspot中，许多基准测试在-server下比-client下运行得更好，这不仅是因为-server的编译器产生更有效的代码，且这种模式更易于通过优化消除无用代码。
在多处理器系统上，无论正式还是测试版本，都应该选择-server

一个简单技巧可以避免运算被优化掉而且不会引入过高的开销：即计算某个派生对象中域的散列值，并将它与一个任意值进行比较，例如System.nanoTIme，如果二者相等，那么输出一个无用，可忽略的信息
if(foo.x.hashCode() == System.nanoTime())
	System.out.print(" ");

每个计算结果都应该被使用，而且还应该是不可预测的。否则，一个智能的动态优化编译器会用预先计算的结果来代替计算过程。


12.4 其他的测试方法

代码审查

静态分析工具
FindBugs，SonaLint


面向切面的测试技术

分析与监测工具


241
第四部分	高级主题
chapter13 显式锁

java5之前，协调对共享对象的访问时可以使用的机制只有synchronized，volatile。
java5增加了ReentrantLock，并不是一种替代内置加锁的方法，而是当内置加锁机制不适用时，作为一种可选的高级功能。


public interface Lock {
	void lock();
	void lockInterruptibly() throws InterruptedException;
	boolean tryLock();
	boolean tryLock(long timeout, TimeUnit unit) throws InterruptedException;
	void unlock();
	Condition newCondition();
}

与内置锁机制不同，Lock提供了一种无条件的，可轮询的，定时的以及可中断的锁获取操作，所有加锁和解锁的方法都是显式的。
在Lock的实现中必须提供与内部锁相同的内存可见性语义，但在加锁语义，调度算法，顺序保证以及性能特性等方面可以有所不同。

ReentrantLock实现了Lock接口，提供了与synchronized相同的互斥性和内存可见性。获取ReentrantLock时，有着与进入synchronized代码块相同的内存语义，在释放RLock时，有着与退出同步代码块相同的内存语义。
与synchronized一样，RLock提供了可重入的加锁语义

RLock支持在Lock接口中定义的所有获取锁模式，并与synchronized相比，它还为处理锁的不可用性问题提供了更高的灵活性。

synchronized应用方面的一些劣势：无法中断一个正在等待获取锁的线程，无法在请求获取一个锁时无限地等待下去，内置锁必须在获取该锁的代码块中释放，这简化编码，并且与异常处理实现了很好的交互，但却无法实现非阻塞结构的加锁规则。

Lock接口的标准使用形式。必须在finally中释放锁，否则，如果被保护的代码中抛出了异常，那么这个锁永远无法被释放。使用加锁时，必须考虑try中抛出异常的情况，如果可能使对象处于某种不一致的状态，那么就需要更多的try-catch或try-finally代码块。(当使用某种形式的加锁时，包括内置锁，都应该考虑出现异常时的情况)

Lock lock = new ReentrantLock();

lock.lock()
try {
	// 更新对象状态
	// 捕获异常，并在必要时恢复不变性条件
} finally {
	lock.unlock();
}

如果没有finally释放lock，那么就相当于启动了一颗炸弹，且保证时，很难追踪到最初发生错误的位置，因为没有记录应该释放锁的位置和时间。这就是ReentreantLock不能完全替代synchronized的原因：它更加"危险"。


轮询锁与定时锁

可定时与可轮询的锁获取模式是由tryLock方法实现的，与无条件的锁获取模式相比，它具有更完善的错误恢复机制。在内置锁中，死锁是一个严重的问题，恢复程序的唯一方法是重启程序，而防止死锁的唯一方法就是在构造程序时，避免出现不一致的锁顺序。可定时与可轮询的锁提供了另一种选择：避免死锁的发生

如果不能获得所有需要的锁，那么可以使用可定时或可轮询的锁获取方式，从而使你重新获得控制权，它会释放已经获得的锁，然后重新尝试获取所有锁(或者至少会把这个失败记录到日志，或采取其他措施)。

下面的代码来解决动态顺序死锁问题，使用tryLock来获取2个锁，如果不能同时获得，那么就回退并重新尝试，休眠时间包含固定和随机部分，来降低发生活锁的可能性。如果指定时间内无法获得所有需要的锁，那么会返回一个失败状态，从而使该操作平缓地失败。

public boolean transferMoney(Account fromAcct, Account toAcct,
			DollarAmount amount, long timeout, TimeUnit unit)
	throws InsufficientFundsException, InterruptedException {
	
	long fixedDelay = getFixedDelayComponentNanos(timeout, unit);
	long randMod = getRandomDelayModulusNanos(timeout, unit);
	long stopTime = System.nanoTime() + unit.toNanos(timeout);
	
	while (true) {
		if (fromAcct.lock.tryLock()) {
			try {
				if (toAcct.lock.tryLock()) {
					try {
						if (fromAcct.getBalance < amount) {
							throw new Insufficient;
						} else {
							fromAcct.debit(amount);
							toAcct += amount;
							return true;
						}
					} finally {
						toAcct.lock.unlock();
					}
				}
			} finally {
				fromAcct lock unlock;
			}
		}
		if (System.nanoTime() < stopTIme)
			return false;
		NANOSECONDS.sleep(fixedDelay + rnd.nextLong() % rndMod);
	}
}


可中断的锁获取操作
正如定时的锁获取操作能在带有时间限制的操作中使用独占锁，可中断的锁获取操作能在可取消的操作中使用加锁。
lockInterruptibly方法能在获得锁的同时保持对中断的响应，并且由于它包含在Lock中，因此无需创建其他类型的不可中断阻塞机制。

可中断锁的获取操作的标准结构比普通的锁获取操作略微复杂一些，因为需要2个try块。(如果在可中断的锁获取操作中抛出了InterrupedException，那么可以使用标准的try-finally加锁模式)。

public boolean sendOnSharedLine(String msg) throws InteruptedExce{
	lock.lockInterruptibly();
	try {
		return cancellableSendOnSharedLine(msg);
	} finally {
		lock.unlock();
	}
	
	private boolean cancellableSendOnSharedLine(msg) throws InterruptedException { ... }
}
。。2个try块的标准结构呢。。。是指throws出去的InterrupedExce？

定时的tryLock同样能响应中断，因此当需要实现一个定时的和可中断的锁获取操作时，可以使用tryLock方法。


非块结构的加锁
内置锁中，锁的获取和释放等操作时基于代码块的---释放锁的操作和获取锁的操作总处于同一个代码块，而不考虑控制权如何退出该代码块。自动的锁释放操作简化了对程序的分析，避免了可能的编码错误，但有时候需要更灵活的锁。

锁分段技术在基于散列的容器中实现了不同的散列链，以便使用不同的锁。
我们可以通过类似的原则来降低链表中锁的粒度，即为每个链表节点增加一个独立的锁，使得不同线程能独立对链表的不同部分操作。节点上的锁保护链接指针与存储的数据，因而当遍历或修改链表时，我们必须持有该节点上的这个锁，直到获得下一个节点的锁，只有这样，才能释放前一个节点上的锁，这种方式称之为连锁式加锁或锁耦合。
。。synchronized(list.get(i))，，也能加锁，不过没办法获得下一个节点的锁后，再释放上一个节点的锁。


13.2 性能考虑因素
java5时，ReentrantLock比synchronized提供更好的竞争性能。
对于同步原语来说，竞争性是可伸缩性的关键要素：如果有越多的资源被消耗在锁的管理和调度上，那么应用程序得到的资源就越少。锁的实现越好，将需要越少的系统调用和上下文切换，并且在共享内存总线上的内存同步通信量也越少。

java6优化了synchronized，优化后算法和ReentLock类似，提高了可伸缩性。

246 图
java5，ReentreLock在>=8根线程的情况下，吞吐率是synchron的4倍，2线程是1.7倍，4线程实3.6倍。
java6，所有线程数都大约是1.(吞吐率接近)
随着线程增加，吞吐率/性能都是下降，只不过java5的synch下降得太快。


。。test。。。不可重入锁，重入的话是不是必然死锁，有什么应用场景？。。为什么，公平锁(fifo)比非公平锁(一起抢)慢，。。非公平锁不是一起抢，它的定义在下面。


13.3 公平性

ReentrantLock的构造器提供了两种选择：创建一个非公平的锁(默认)或创建一个公平的锁。

公平锁：线程将按照它们发出请求的顺序来获得锁。
非公平锁允许"插队"：当一个线程请求非公平锁时，如果在发出请求的同时该锁的状态变为可用，那么这个线程将跳过队列中所有的等待线程并获得这个锁。(Semephore同样可以选择公平or非公平的获取顺序。)

非公平的ReentrantLock并不提倡"插队"行为，但无法阻止某个线程在合适的时候"插队"。
非公平锁中，只有当锁被某个线程持有时，新发出的请求线程才会放入队列中。。公平锁是如果另一个线程持有这个锁或有其他线程在队列中等待这个锁，那么放入队列中。
(即使对于公平锁，可轮询的tryLock仍然会"插队")

。。获取的时候都是从队列头获取？


执行加锁时，公平性将由于在挂起线程和恢复线程时存在的开销而极大降低性能。
在实际情况中，统计上的公平性保证---确保被阻塞的线程能最终获得锁，通常已经够用了，并且开销小很多。
有些算法依赖于公平的排队算法以确保它们的正确性，但这些算法并不常见。
大多数情况下，非公平锁的性能要高于公平锁的性能。


图
ConcurrentHashMap，公平的RenentrantLock+HashMap，非公平的RL+HashMap。的吞吐率
			1线程	2		4
Concurrent	1		2		4
非公平		0.8		0.5		0.4
公平		0.7		0.03	0.03


激烈竞争下，非公平锁的性能高于公平锁的性能的一个原因是：在恢复一个被挂起的线程与该线程真正开始运行之间存在着严重的延迟。A持有锁，B请求这个锁，A结束，B被唤醒，会再次尝试获取锁。同时，C也请求这个锁，那么C很可能会在B被完全唤醒之前获得，使用，释放这个锁。这种情况是一种"双赢"的局面：B获得锁的时刻并没有推迟，C更早获得了锁，吞吐量得到了提升。

当持有锁的时间相对较长，或请求锁的平均时间间隔较长，那么应该使用公平锁。在这些情况下，"插队"带来的吞吐量提升(当锁处于可用状态时，线程却还处于被唤醒的过程中)则可能不会出现。


与默认的ReentrantLock一样，内置加锁并不会提供确定的公平性保证。


13.4 synchronized or ReentrantLock

在一些内置锁无法满足需求的情况下，ReentrantLock可以作为一种高级工具。当需要一些高级功能时才使用RL，如：可定时的，可轮询的与可中断的锁获取操作，公平队列，以及非块结构的锁。否则，还是应该优先synchronized。

除非确实需要ReentrantLock的可伸缩性，否则就性能方面来说，应该选择synchronized而不是ReentrantLock。

13.5 读-写锁
ReL实现了一种标准的互斥锁：每次最多只有一个线程能只有RL。
互斥是一种保守的加锁策略，在避免"写/写"，"写/读"冲突，但也避免了"读/读"冲突。

一个资源可以被多个读操作访问，或者被一个写操作访问，但两者不能同时进行。

ReadWriteLock暴露了2个Lock对象，一个用于读操作，一个用于写操作。
要读取有ReadWriteLock保护的数据，必须先获得读取锁，要修改时，必须先获得写入锁。
虽然这2个锁看上去是彼此独立的，但读取锁和写入锁只是读-写锁对象的不同视图。

public interface ReadWriteLock {
	Lock readLock();
	Lock writeLock();
}

RWL可以有多种实现，性能，调度保证，获取优先性，公平性，加锁语义等方面有所不同。

读写锁是一种性能优化措施，在一些特定环境下实现更高的并发性。
在实际情况中，对于多处理器系统上被频繁读取的数据结构，RWL能提升性能。其他情况下，性能比独占锁略差，因为RWL的复杂性更高。

由于RWL使用Lock来实现锁的读写部分，所以如果分析结果表明RWL没有提高性能，那么很容易就将RWL改为独占锁。

读取锁和写入锁之间的交互可以采用多种实现方式。RWL中一些可选实现包括：
释放优先。当一个写入锁被释放，队列中同时存在读线程，写线程，那么应该优先读，还是写，还是最先发出请求的线程？

读线程插队。锁由读线程持有，有写线程正在等待，那么新到达的读线程能否立刻获得访问权。还是应该在写线程后等待？如果允许读线程插队到写线程之前，那么会提高并发性，但却可能造成写线程发生饥饿问题。

重入性。读取锁，写入锁，是否可重入的

降级。如果一个线程持有写入锁，那么它能否在不释放该锁的情况下，获得读取锁？这可能会是写入锁被降级为读取锁。

升级。读取锁能否优先于其他正在等待的读线程和写线程而升级为一个写入锁？大多数的RWL实现中不支持升级，因为如果没有显示的升级操作，很容易造成死锁(如果2个读线程同时升级为写入锁，那么2者都不会释放读取锁。)


ReentrantReadWriteLock为这2种锁都提供了可重入的加锁语义。构造时也可以选择非公平锁(默认)or公平锁。
公平锁中，等待时间最长的线程优先获得锁。如果现在是读线程持有锁，而另一个线程请求写入锁，那么其他读线程都不能获得读取锁，直到写线程使用完并释放写入锁。
非公平锁中，线程获得访问许可的顺序是不确定的。写线程降级为读线程是可以的，但读线程升级为写线程是不行的(会导致死锁)。

public class ReadWriteMap<K, V> {
	private final Map<K, V> map;
	private final ReadWriteLock lock = new ReentrantReadWriteLock);
	private final Lock r = lock.readLock();
	private final Lock w = lock.writeLock();
	
	public ReadWriteMap(Map<K, V>, map) { this.map = map; }
	
	public V put(K key, V value) {
		w.lock();
		try { return map.put(key, value);}
		finally {
			w.unlock();
		}
	}
	
	public V get(Object key) {
		r.lock();
		try {
			return map.get(key);
		} finally {
			r.unlock();
		}
	}
	// ...
}

4核cpu运算，
4线程后，ReentrantRWL，达到2.5倍左右；ReentrantLock，0.8倍。


252
chapter 14 构建自定义的同步工具

类库中包含了许多存在状态依赖性的类，如FutureTask，Semaphore，BlockingQueue等。这些类的一些操作中有着基于状态的前提条件，如不能从一个空队列中移除元素，不能获得一个尚未结束的任务的结果。

创建状态依赖类的最简单方法通常是在类库中现有的状态依赖类的基础上进行构造。

14.1 状态依赖性的管理
单线程中，调用一个方法时，如果某个基于状态的前提啊条件未得到满足，那么这个条件永远无法成真。因此，编写顺序过程中的类时，要使得这些类在它们的前提条件未满足时就失败。

并发程序中，基于状态的条件可能由于其他线程的操作而改变：资源池空->非空。对于并发对象上依赖状态的方法，虽然有时候在前提条件不满足的情况下不会失败，但通常有一种更好的选择，即等待前提条件为真。

依赖状态的操作可以一直阻塞直到可以继续运行，这比使他们先失败，再运行，更方便且不易出错。内置的条件队列可以使线程一直阻塞，直到对象进入某个线程可以继续执行的状态，并且当被阻塞线程可以继续执行时再唤醒它们。

我们先介绍如何通过轮询和休眠等方式来(勉强地)解决状态依赖性问题。
加锁模式有些不同寻常，因为锁是在操作的执行过程中被释放与重新获取的。构成前提条件的状态变量必须由对象的锁来保护，从而使它们在测试前提条件的同时保持不变。如果前提条件未满足，就释放锁，以便其他线程可以修改对象的状态。

申请锁
while (条件不满足) {
	释放锁
	等待(直到超时或中断)
	申请锁
}
执行方法
释放锁

生产者-消费者的设计中经常使用类似ArrayBlockingQueue这样的有界缓存。
在有界缓存提供的put，take操作都包含有一个前提条件：不能从空缓存中获取元素，也不能将元素放入已满的缓存中。当前提条件未满足时，依赖状态的操作可以抛出一个异常或返回一个错误状态，也可以保持阻塞直到对象进入正确的状态。

例子，基类实现doGet，子类实现get(){ check; doGet() }

1. put时，isFull则throw异常，get时，isEmpty则throw
异常应该用于发生异常条件的情况中，"缓存已满"并不是有界缓存的一个异常条件，就像红灯不代表交通信号灯出问题。
在实现缓存时得到的简化(使调用者管理状态依赖性)并不能抵消在使用时存在的复杂性，因为现在调用者必须做好捕获异常的准备。
(如果将状态依赖性交给调用者管理，那么将导致一些功能无法实现。例如维持FIFO顺序)

while (true) {
	try {
		V item = buffer.take();
		// doSth.
	} catch (e) { Thread.sleep(x); }
}

这种方法的一种变化形式是，当缓存处于某种错误的状态时返回一个错误值。但并没有解决根本问题：调用者必须自行处理前提条件失败的情况。

上面的代码不是唯一的调用方式，可以不调用sleep，而是直接继续take方法，这种方法被称为忙等待或自旋等待。。如果缓存的状态很长时间内不会发生变化，那么这种方法就会消耗大量cpu。如果调用sleep，那么响应性就会降低。
(除了忙等待，休眠外，还有一种选择就是调用Thread.yield)

public V take() throws InterruptedException {
while (true) {
	synchronized (this) {
		if (!isEmpty())
			return doTake();
	}
	Thread.sleep(SLEEP_);
}
}
这种方式需要调用者自己处理InterruptedException。当一个方法由于某个等待(条件变成真)而阻塞时，需要提供一种取消机制。与大多数具备良好行为的阻塞库方法一样，这里通过中断来支持取消，如果该方法被中断，那么将提前返回并抛出异常。

从调用者的角度看，这种方法能很好地运行，如果某个操作可以执行，那么就立即执行，否则就阻塞，调用者无须处理失败和重试。
需要选择合适的休眠时间。


14.1.3 条件队列
名字来源于：它使得一组线程(称为等待线程集合)能够通过某种方式来等待特定的条件变成真。传统队列的元素是一个个数据，条件队列中是一个个正在等待相关条件的线程。

正如每个java对象都可以作为一个锁，每个对象同样也可以作为一个条件队列，并且Object中的wait，notify，notifyAll就构成了内部条件队列的api。对象的内置锁与其内部条件队列是相互关联的，要调用对象X中条件队列的任何一个方法，必须持有对象X上的锁。这是因为"等待由状态构成的条件"与"维护状态一致性"这2种机制必须被紧密地绑定在一起：只有能对状态进行检查时，才能在某个条件上等待，并且只有能修改状态时，才能从条件等待中释放一个线程。

Object.wait会自动释放锁，并请求os挂起当前线程，从而使其他线程能够获得这个锁并修改对象的状态。当被挂起的线程醒来时，它将在返回之前重新获取锁。

下面使用wait，notifyAll来实现一个有界缓存，这比使用"休眠"的有界缓存更简单，更高效，响应性更高。这是一个较大的改进，但要注意：与使用"休眠"的有界缓存相比，条件队列并没有改变原来的语义。它只是优化了：cpu效率，上下文切换开销，响应性等。如果某个功能无法通过"轮询和休眠"来实现，那么使用条件队列也无法实现，但条件队列在表达和管理状态依赖性时更加简单和高效。

@ThreadSafe
public class BoundedBuffer<V> extends BaseBoundedBuffer<V> {
	public synchronized void put(V v) throws InterruptedException {
		while (isFull())
			wait();
		doPut(v);
		notifyAll();
	}
	
	public synchronized V take() throws InterruptedException {
		while (isEmpty())
			wait();
		V v = doTake();
		notifyAll();
		retuen v;
	}
}

简单易用，明晰的状态依赖性管理。在正式版本中还应包括限时版本的put和take，通过使用定时版本的Object.wait，很容易实现。


14.2 使用条件队列
条件队列使构建高效，高响应的状态依赖类变得容易，但同时也很容易被错误地使用。。虽然许多规则都能确保正确使用条件队列，但在编译器或os上却没有强制要求遵循这些规则。

14.2.1 条件谓词
要正确地使用条件队列，关键是找出对象在哪个条件谓词上等待。
条件谓词将在等待与通知过程中导致许多困惑，因为在api中没有对条件谓词实例化的方法，java/jvm规范也没有任何信息可以确保正确使用它们。
条件谓词是使某个操作称为状态依赖操作的前提条件。在有界缓存中，只有缓存非空，take才能执行，so对于take来说，它的条件谓词就是"缓存非空"，take执行前必须测试该条件谓词。同样，put的条件谓词是"缓存不满"。
条件谓词是由类中各个状态变量构造的表达式。(缓存不为空：count与0比较，缓存不满，count与缓存大小比较)

将与条件队列相关的条件谓词及这些条件谓词上等待的操作都写入文档。

在条件等待中有一种重要的三元元素，包括加锁，wait，一个条件谓词。条件谓词中包含多个状态变量，而状态变量由一个锁保护，因此测试条件谓词前必须先持有这个锁。锁对象与条件队列对象(wait方法所在随心)必须是同一个对象。

如果条件谓词非真(缓存为空)，take必须等待直到其他线程在缓存中放入一个对象。take将在缓存的内置条件队列上调用wait方法，这需要持有条件队列对象上的锁。这是一种谨慎的设计，因为take方法已经持有在测试条件谓词是需要的锁(???wait必须有锁？。。test。。？)。wait将释放锁，阻塞当前线程，并等待直到超时，然后线程被中断或者通过一个通知被唤醒。在唤醒进程后，wait在返回前还要重新获得锁。当线程从wait中被唤醒，它在重新请求锁时，不具有任何特殊优先级，和其他尝试进入同步块的线程一起竞争。

每一次wait调用都会隐式地与特定的条件谓词关联起来。当调用某个特定条件谓词的wait时，调用者必须已经持有与条件队列相关的锁，并且这个锁必须保护这构成条件谓词的状态变量。

14.2.2 过早唤醒
wait方法返回并不一定意味着线程正在等待的谓词变成真了。
内置条件队列可以与多个条件谓词一起使用。当一个线程由于notifyAll而醒来时，并不意味这该线程等待的条件谓词已经变成真了。另外，wait还可以"假装"返回，而不是由于某个线程调用notify。
也可能在wait被唤醒的途中，其他线程获得锁并修改了条件谓词，使之对本线程不成立。。。对，notifyAll多个，那么多个wait醒来必然要竞争锁，赢的那个将条件谓词又变成false了，剩下的挨个获得锁，醒来，条件谓词不成立，继续wait。。。。应该是这样吧，就是notifyAll，会导致所有wait中的线程迟早都会醒来一遍，还是说先竞争锁，只有赢的那个醒来，其他不可能醒来。。。应该是前者，后者的话，如果后续没有修改条件谓词，会永远wait的。。。。擦，。。test。。。notify唤醒随机一个，notifyAll唤醒全部。。。那如果notify唤醒的那个线程，它特定的条件谓词依然false，岂不是死锁了？。。下面说了，单一的通知容易导致类似信号丢失的问题。

BoundedBuffer中使用的条件队列与非满，非空2个条件谓词有关。

条件等待的标准形式：
void stateDependentMethod() throws IntertuptedException {
	synchronized (lock) {
		while (!conditionPredicate())
			lock.wait();
		// 合适的状态。doSth.
	}
}

当使用条件等待时(如，Object.wait，Condition.await)
1. 通常都有一个条件谓词---包括一些对象状态的测试，线程在执行前必须先通过这些测试。
2. 在调用wait之前测试条件谓词，并且从wait中返回后再次进行测试。
3. 在一个循环中调用wait
4. 确保使用与条件队列相关的锁来保护构造条件谓词的各个状态变量。
5. 当调用wait，notify，notifyAll时，一定要持有与条件队列相关的锁。
6. 在检查条件谓词之后，开始执行相关操作之前，不要释放锁。


14.2.3 丢失的信号
活跃性故障：死锁，活锁，丢失的信号。
丢失的信号：线程在等待一个已经为真的条件，因为在开始之前没有检查条件谓词。。。是由于编码错误。

261
14.2.4 通知
之前介绍条件等待的一半内容，是：等待，剩下一半内容是通知。

notify：jvm从这个条件队列上等待的多个线程中选择一个来唤醒。
notifyAll：唤醒这个条件队列上等待的线程。

由于调用notify，notifyAll必须持有条件队列对象的锁，wait醒来也需要锁。所以发出通知的线程应该尽快释放锁。

由于多个线程可以基于不同的条件谓词在同一个条件队列上等待，因此，使用notify，是一种危险的操作，因为单一的通知很容易导致类似型号丢失的问题。

只有同时满足下面2个条件时，才能使用notify，而不是notifyAll
1. 所有等待线程的类型都相同。只有一个条件谓词与条件队列有关，并且每个线程在从wait返回后将执行相同的操作。
2. 单进单出。在条件变量上的每次通知，最多只能唤醒一个线程来执行。

notify只唤醒一个，很快，但可能唤醒错。notifyAll唤醒的线程中大部分竞争后又会休眠。性能与安全相矛盾。

BoundedBuffer的一种优化：
之前是：
public synchronized void put(V v) throws InterruptedException {
	while (isFull())
		wait();
	doPut(v);
	notifyAll();
}
优化后：
public synchronized void put(V v) throws InterruptedException {
	while (isFull())
		wait();
	boolean wasEmpty = isEmpty();
	doPut(v);
	if (wasEmpty)
		notifyAll();
}
状态是，非空，非满
只有在操作影响这些状态转换时，才发出通知，这也被称为"条件通知"。
虽然条件通知可以提升性能，但却很难正确实现(还会使子类的实现变复杂)。使用时需要谨慎。

单次通知和条件通知都属于优化措施。。先保证正确，然后再优化。。如果不能正确使用这些优化措施，很容易引入奇怪的活跃性故障。


阀门类
@ThreadSafe
public class ThreadGate {
	private boolean isOpen;
	private int generation;
	
	public synchronized void close() {
		isOpen = false;
	}
	public synchronized void open() {
		++generation;
		isOpen = true;
		notifyAll();
	}
	public synchronized void await() throws InterruptedExcepiton {
		int arrivelGeneration = generation;
		while (!isOpen && arrivalGrneration == generation)
			wait();
	}
}
条件谓词复杂，但，是必须的。。因为如果阀门打开时有N个线程在等待，那么这些线程都应该被允许执行。然后如果阀门在打开后有立刻关闭，并且awiat只检查isOpen，那么所有线程可能都无法执行。


14.2.6 子类的安全问题
使用条件通知或单次通知时，一些约束条件使得子类化过程变得更加复杂。要想支持子类化，那么在设计类时需要保证：如果在实施子类化时违背了条件通知或单次通知的某个需求，那么在子类中可以增加合适的通知机制来代表基类。
对于状态依赖的类，要么将其等待和通知等协议完全像子类公开(并写入正式文档)，要么完全阻止子类参与到等到和通知等过程中(final类，或隐藏条件队列，锁，状态变量，使子类看不到它们)。


14.2.7 封装条件队列
通常，我们应该把条件队列封装起来，因而除了使用使用条件队列的类，就不能在其他地方访问它。否则，调用者会自以为了解等待和通知协议，并采用一种违背设计的方式来使用队列。
不幸的是，这条建议---将条件队列封装起来，与线程安全类的最常见设计模式并不一致，在这种模式中建议使用对象的内置锁来保护对象自身的状态。BoundedBuffer就是例子，缓存对象自身既是锁，又是条件队列。可以很容易将其设计为使用私有锁对象和条件队列，唯一不同之处是，新的BoundedBuffer不再支持任何形式的客户端加锁。


14.2.8 入口协议与出口协议
对于每个依赖状态的操作，以及每个修改其他操作依赖状态的操作，都应该定义一个入口协议和出口协议。入口协议就是该操作的条件谓词，出口协议则包括，检查被该操作修改的所有变量，并确认它们是否使某个其他的条件谓词变为真，如果是，则通知相关的条件队列。

265
14.3 显示的Condition对象
13章曾介绍过，某些情况下，当内置锁过于灵活时，可以使用显式锁。
正如Lock是一种广义的内置锁，Condition也是一种广义的内置条件队列。

public interface Condition {
	void await() throws InterrutepedEx;
	boolean await(long time, TimeUnit unit) throws InterrutedEx;
	long awaitNanos(long nanosTimeout) throws InterruptedEx;
	void awaitUninterruptibly();
	boolean awaitUntil(Date deadline) throws InterruptedEx;
	
	void signal();
	void signalAll();
}

内置条件队列存在一些缺陷。每个内置锁都只能有一个相关联的条件队列，因而在像BoundedBuffer这种类中，多个线程可能在同一个条件队列上等待不同的条件谓词，并且在最常见的加锁模式下公开条件队列对象。这些因素都使得无法满足在使用notifyAll是所有等待线程为同一类型的需求。
如果想编写一个带有多个条件谓词的并发对象，或者想获得除了条件队列可见性之外的更多控制权，就可以使用显式的Lock和Condition，而不是内置锁和条件队列。
一个Condition和一个Lock关联在一起，就像一个条件队列和一个内置锁相关联一样。

要创建Condition，可以在相关联的Lock上调用Lock.newCondition方法。
Lock比内置锁提供更多功能，Condition同样比内置条件队列提供更多功能：在每个锁上可以存在多个等待队列，条件等待可以是可中断或不可中断哦，基于时限的等待，公平或非公平的队列操作。

对于每个Lock，可以有任意数量的Condition对象。Condition继承了Lock的公平性，对于公平锁，线程按照FIFO从Condition.await中释放。

在Condition中，与wait，notify，notifyAll对应的是await，signal，signalAll。。任何类都是Object，所以Condition也有wait，nofity方法。。使用时需要注意。


下面是有界缓存的另一种实现，使用2个Condition，notFull,notEmpty。缓存为空时，take阻塞并等待notEmpty。。put向notEmpty发信号，可以解除任何在take中阻塞的线程。

@ThreadSafe
public class ConditionBoundedBuffer<T> {
	protected final Lock lock = new ReentrantLock();
	private final Condition notFull = lock.newCondition();
	private final Condition notEmpty = lock.newCondition();
	private final T[] items = (T[]) new Object[BUFFER_SIZE];
	private int tail, head, count;
	
	public void put(T x) throws InterruptedException {
		lock.lock()
		try {
			while (count == item.length)
				notFull.await();
			items[tail] = x;
			if (++tail == items.length)
				tail = 0;
			++count;
			notEmpty.signal();
		} finally {
			lock.unlock();
		}
	}
	
	public T take() throws InterruptedException {
		lock.lock();
		try {
			while (count == 0)
				notEmpty.await();
			T x = items[head];
			items[head] = null;
			if (++head == items.length)
				head = 0;
			--count;
			notFull.signal();
			return x;
		} finally {
			lock.unlock();
		}
	}
}
。。后续应该会有 条件通知吧。

使用Lock，Condition，也必须满足锁，条件谓词，条件变量之间的三元关系，在条件谓词中包含的变量必须由lock保护，并且在检查条件谓词以及调用await和signal时，必须持有lock对象。


14.4 Synchronizer剖析
ReentrantLock，Semaphore存在很多共同点，这2个类都可以用作一个"阀门"，及每次只允许一定数量的线程通过，并当线程到达阀门时，可以通过(在调用lock或acquire是返回成功)，也可以等待(lock,acquire阻塞)，还可以取消(tryLock,tryAcquire返回false，表示指定时间内无法获得锁)。而且这2个接口都支持可中断的，不可中断的，以及限时的获取操作，并且也都支持等待线程执行公平或非公平的队列操作。

或许你认为Semaphore是基于ReentrantLock实现的，或者认为ReentrantLock实际上是带有一个许可的Semaphore。。这些实现方式都可行的，一个很常见的练习就是，证明可以通过锁来实现技术信号量(代码如下)，以及可以通过技术信号量来实现锁。

@ThreadSafe
pubic class SemaphoreOnLock {
	private final Lock lock = new ReentrantLock();
	private final Condition permitsAvailable = lock.newCondition();
	private int permite;
	
	SemaphoreOnLock(int initialPermits) {
		lock.lock();
		try {
			permits = initialPermits;
		} finally {
			lock.unlock();
		}
	}
	
	public void acquire() throws InterruptedException {
		lock.lock();
		try {
			while (permits <= 0)
				permitsAviailable.await();
			--permits;
		} finally {
			lock.unlock();
		}
	}
	
	public void release() {
		lock.lock();
		try {
			++permits;
			permitsAvailable.signal();
		} finally {
			lock.unlock();
		}
	}
}


事实上，它们在实现时使用了一个共同的基类，即AbstractQueuedSynchronizer(AQS),这个类也是其他许多同步类的基类。
AQS是一个用于构建锁和同步器的框架，许多同步器都可以通过AQS容易且高效地构造出来。
其他基于AQS的：CountDownLatch，ReentrantReadWriteLock,SynchronousQueue(java6中被替换为一个可伸缩性更高的非阻塞版本),FutureTask.

AQS解决了在实现同步器时涉及的大量细节问题，例如等待线程采用FIFO队列操作顺序。在不同的同步器中还可以定义一些灵活的标准来判断某个线程是应该通过还是需要等待。

基于AQS来构建同步其能带来许多好处。它不仅能极大减少实现工作，而且也不必处理在多个位置上发生的竞争问题(这是在没有使用AQS来构建同步器时的情况)。
在上面的SemaphoreOnLock中，获取许可的操作可能在2个时刻阻塞---当锁保护信号量状态时，以及当许可不可用时。在基于AQS的同步器中，只可能在一个时刻发生阻塞，从而降低了上下文切换，提高吞吐量。
在设计AQS是充分考虑了可伸缩性。因此java.util.concurrent中所有基于AQS构建的同步器都能获得这个优势。
。。。test。。。AQS！

268
14.5 AbstractQueuedSynchronizer
大多数开发者不会直接使用AQS，标准同步器类的集合能满足绝大多数需求。

在基于AQS的同步器类中，最基本的操作包括各种形式的获取操作和释放操作。获取操作是一种基于依赖状态的操作，并且通常会阻塞。

如果一个类想成为状态依赖的类，那么它必须拥有一些状态。AQS负责管理同步器类中的状态，它管理类一个整数状态星系，可以通过getState，setState，compareAndSetState等protected方法来操作。
这个整数可以表示任意状态，ReentrantLock中表示所有者线程已经重复获取该锁的次数，Semaphore中表示剩余的许可数量，FutureTask中表示任务的状态(尚未开始，正在运行，已完成，已取消)。

// 。。。。
AQS中获取，释放的标注形式
boolean acquire() throws InterruptedException {
	while (当前状态不允许获取操作) {
		if (需要阻塞获取请求) {
			如果当前线程不在队列中，则将其插入队列
			阻塞当前线程
		}
		else
			返回失败
	}
	可能更新同步器的状态
	如果线程位于队列中，则将其移出队列
	返回成功
}

void release () {
	更新同步器状态
	if (新的状态允许某个被阻塞的线程获取成功)
		解除队列中一个或多个线程的阻塞状态
}

/// 太多了//

14.6 concurrent中的AQS

14.6.1 ReentrantLock
只支持独占方式的获取操作，因此它实现了tryAcquire，tryRelease，isHeldExclusively。
ReentrantLock将同步状态用于保存锁获取操作的次数，还维护一个owner变量来保存当前所有者线程的标识符，只有在当前线程刚获取到锁，或正要释放锁时，才会修改这个变量。tryRelease中检查owner，以确保当前线程执行unlock前已获得锁，tryRelease中使用这个owner域来区分获取操作时重入的还是竞争的。

ReeLock还利用了AQS对多个条件变量和多个等待线程集的内置支持。Lock.newCondition将返回一个新的ConsitionObject实例，这是AQS的一个内部类。

14.6.2 Semaphore与CountDownLatch
Semaphore将AQS的同步状态用于保存当前可用许可的数量。
tryAcquireShared方法首先计算剩余许可的数量，如果没有足够的许可，那么会返回一个值表示获取操作失败。如果还有剩余许可，会通过compareAndSetState以原子方式来降低许可的计数。如果这个操作成功，那么返回一个值表示获取操作成功。

CountDownLatch使用AQS的方式和Semaphore类似：同步状态中保存的是当前的计数值。countDown方法调用release来减少计数值，计数值为0时，解除所有等待线程的阻塞。await调用acquire，当计数器为0时，acquire将立刻返回，否则阻塞


14.6.3 FutureTask
FutureTask看上去不像一个同步器。但Future.get语义非常类似于闭锁的语义---如果发生某个事件，那么线程就可以恢复执行，否则这些线程将停留在队列中直到该事件发生。

FT中，AQS同步状态被用来保存任务的状态，FT中还维护一些额外的状态变量，用来保存计算结果或者抛出的机场。它还维护了一个引用，指向正在执行计算任务的线程(如果它当前处于运行状态)，因而如果任务取消，该线程就会中断。


14.6.4 ReentrantReadWriteLock
ReadWriteLock接口表示存在2个锁，一个读取锁，一个写入锁。但在基于AQS实现的ReentrantReadWriteLock中，单个AQS子类将同时管理读取加锁和写入加锁。
ReenRWL使用了一个16位的状态来表示写入锁的计数，并且使用另一个16位的状态来表示读取锁的计数。在读取锁上的操作将使用共享的读取方法与释放方法，在写入锁上的操作将使用独占的获取方法与释放方法。
AQS在内部维护一个等待线程队列，其中记录了某个线程请求的是独占访问还是共享访问。在ReenRWL中，当锁可用时，如果位于队列头部的线程执行写入操作，那么线程会得到这个锁，如果位于队列头部的线程执行读取访问，那么队列中在第一个写入线程之前的所有线程都将获得这个锁。(这种机制并不允许选择读取/写入线程优先策略，某些读写锁中也采用了这种方式。因此，要么AQS的等待队列不能是一个FIFO队列，要么使用2个队列。然后实际中很少需要这么严格的排序策略。如果非公平的ReenRWL无法提供足够的活跃性，那么公平的ReenRWL通常会提供令人满意的排序保证，并且能确保读取线程和写入线程不会发生饥饿问题)

275
chapter 15
原子变量与非阻塞同步机制

concurrent包中许多类，例如，Semaphore，ConcurrentLinkedQeueu，都提供了比synchronized更高的性能和可伸缩性。。本章将介绍这种性能提升的主要来源：原子变量和非阻塞的同步机制。

并发领域的大多数研究都侧重于非阻塞算法，这种算法用底层的原子机器指令代替锁来确保数据在并发访问中的一致性。
非阻塞算法被广泛用于os和jvm中实现线程/进程调度机制，垃圾回收机制，锁，其他并发数据结构。

与基于锁的方案相比，非阻塞算法在设计和实现上都要复杂得多，但它们在可伸缩性和活跃性上却拥有巨大的优势。
由于非阻塞算法可以使多个线程在竞争相同的数据时不会发生阻塞，因此它能在粒度更细的层次上进行协调，并极大减少调度开销。而且，非阻塞算法中不存在死锁和其他活跃性问题。


15.1 锁的劣势
通过使用一致的锁定协议来协调对共享状态的访问，可以确保无论哪个线程持有守护变量的锁，都能采用独占方式访问这些变量，并且对变量的任何修改对随后获得这个锁的其他线程是可见的。

jvm对非竞争锁获取和锁释放等操作做了极大优化，但如果有多个线程同时请求锁，那么jvm就需要借助os的功能。如果出现了这种情况，那么一些线程将被挂起并且在稍后回复运行(当线程在锁上发生竞争时，智能的jvm不一定会挂起线程，而是根据之前获取操作中对锁的持有时间长短来判断是使此线程挂起还是自旋等待。)。
当线程恢复时，必须等待其他线程执行完它们的时间片后才能被调度执行。在挂起和恢复线程等过程中存在很大的开销，并且通常存者较长时间的中断。如果在基于锁的类上包含有细粒度的操作(例如同步容器类，在其大多数方法中只包含了少量操作)，那么当在锁上存在激烈竞争时，调度开销和工作开销的比值会非常高。

与锁相比，volatile变量是一种更轻量级的同步机制，因为在使用这种情况时不会发生上下文切换或线程调度等操作。然而，volatile变量同样存在一些局限：虽然它们提供了相似的可见性保证，但不能用于构建原子的复合操作。因此，当一个变量依赖其他变量时，或者当变量的新值依赖于旧值时，就不能使用volatile变量。这些都限制了volatile变量的使用，因此它们不能用来实现一些常见的工具，如计数器，互斥体。

Counter是线程安全的，在没有竞争的情况下运行得非常好。但在竞争的情况下，其性能会由于上下文切换的开销和调度延迟而降低。如果锁的持有时间非常短，那么当在不恰当的时间请求锁时，是线程休眠将付出很高的代价。
。。test。。。Counter is Java's API or self's ?

锁定还有其他缺点。当一个线程在等待锁时，它不能做任何其他事情。如果一个线程在持有锁的情况下被延迟执行(如发生了缺页，调度延迟)，那么所有需要这个锁的线程都无法执行下去。
如果被阻塞线程的优先级较高，而持有锁的线程优先级低，那么这是一个严重的问题---被称为优先级反转。即使高优先级的线程可以抢先执行，但仍然需要等待锁被释放，从而导致它的优先级会降至低优先级线程的级别。
如果持有锁的线程被永久阻塞(无限循环，死锁，活锁。)，所有等待这个锁的线程都无法执行

即使忽略这些风险，锁定方式对于细粒度的操作(如递增计数器)来说仍然是一种高开销的机制。


15.2 硬件对并发的支持
独占锁是一种悲观技术---它假设最坏情况(不加锁，就肯定有其他线程会捣乱)

对于细粒度的操作，还有一种更高效的方法，也是一种乐观的方法。通过这种方法可以在不发生干扰的情况下完成更新操作。这种方法需要借助冲突检查机制来判断在更新过程中是否存在来自其他线程的干扰。如果存在，这个操作将失败，并且可以选择是否重试。
这种乐观的方法就行一句谚语：原谅比准许更容易得到。在这里更容易==更高效

在为多处理器操作而设计的处理器中提供了一些特殊指令，用于管理对共享数据的并发访问。
早期处理器支持原子的测试并设置，获取并递增，交换等指令，这些指令足以实现各种互斥体，而这些互斥体又可以实现一些更复杂的并发对象。
现在，几乎所有的处理器都包含了某种形式的原子读-改-写指令，例如比较并交换，关键加载/条件存储。
os和jvm使用这些指令来实现锁和并发的数据结构。


15.2.1 比较并交换
大多数处理器架构中采用的方法是实现一个比较并交换(CAS)指令。
CAS包含3个操作数：需要读写的内存地址V，进行比较的值A，拟写入的新值B。当且仅当V的值等于A时，CAS才会通过原子方式用新值B来更新V的值，否则不会执行任何操作。无论V的值是否等于A，都会返回V原有的值。

CAS是一项乐观的技术。

当多个线程试图使用CAS同时更新一个变量时，只有一个线程能更新变量的值，其他线程都将失败。然而，失败的线程并不会挂起(与锁不同，获取锁失败，就会挂起)。而是被告知在这次竞争中失败，并可以再次尝试。

线程在竞争CAS失败时不会阻塞，因此他可以决定是否重新尝试，或执行一些恢复擦偶在哦，或不执行任何操作。

非阻塞的计数器
下面的代码，在一些竞争很激烈的情况下，更好的方式是在重试之前等待一段时间或者回退，避免造成活锁。

@ThreadSafe
public class CasCounter {
	private SimulateCAS value;
	public int getValue() { return value.get(); }
	public int increment() {
		int v;
		do {
			v = value.get();
		} while (v != value.compareAndSwap(v, v + 1));
		return v + 1;
	}
}
实际情况下，可以直接用AtomicInteger/AtomitLong

竞争度不高时，基于CAS的计数器在性能上远超基于锁的计数器，在没有竞争时甚至更高。

CAS主要缺点是，它将使调用者处理竞争问题(通过重试，回退，放弃)，而锁中能自动处理竞争问题(线程在获得锁之前一直阻塞)

CAS的性能随着cpu核数的不同而变化很大，单核中，CAS只需要很少的时钟周期，因为不需要处理器之间的同步。编写本书时，非竞争的CAS在多CPU系统中需要10-150个时钟周期的开销。
CAS的执行性能在不同体系架构之间变化很大，甚至在相同处理器的不同版本之间也会发生变化。

一个经验法则：大多数处理器上，无竞争的锁获取和释放的"快速代码路径"上的开销，大约是CAS开销的两倍。

15.2.3 JVM对CAS的支持
java5之前不支持，需要自己写明确的代码。
java5引入了底层的支持，在int，long，对象的引用等类型上公开了CAS操作。并且JVM把它们编译为底层硬件提供的最有效方法。
在支持CAS的平台上，运行时编译为相应的机器指令。
如果不支持CAS，那么jvm将使用自旋锁。


15.3 原子变量类

原子变量类相当于一种泛化的volatile变量，能支持原子的和有条件的读-改-写操作。

共有12个原子变量类，分为4组：标量类，更新器类，数组类，复合变量类。

最常用的原子变量就是标量类：AtomicInteger，AtomicLong，AtomicBoolean，AtomicReference。都支持CAS，前两者还支持算术运算。
(要模拟其他基本类型的原子变量，可以将short，byte等类型与int类型进行转换，以及使用floatToIntBits或doubleToLongBits来转换浮点数。)
。。。test。。。floatToIntBits？

原子数组类(只支持Integer,Long,Reference)中的元素可以实现原子更新。原子数组类为数组的元素提供了vloatile类型的访问语义，这是普通数组所不具备的---volatile数组仅在数组的引用上具有volatile，元素上没有。

原子的标量类扩展了Number类，但没有扩展一些基本类型的包装类。事实上，它也不能扩展：基本类型的包装类是不可修改的。而原子变量类是可修改的。原子变量类中没有重写hashCode，equals，每个实例都是不同的。与其他可变对象相比，它们也不适宜用作基于hash的容器中的键值。


原子变量是一种更好的valotile


283
图
激烈竞争，ReentrantLock和AtomicInteger实现的随机数生成器，吞吐量都较低，其中AtomicInteger更低一点。

适中竞争，AtomicInteger的吞吐量远远高于ReentrantLock。


15.4 非阻塞算法
在基于锁的算法中可能会发生各种活跃性故障。如果线程在持有锁时由于阻塞I/O，内存也确实，或其他延迟导致推迟执行，那么很可能所有线程都不能继续执行下去。

如果在某种算法中，一个线程的失败或挂起不会导致其他线程也失败或挂起，那么这种算法就被称为非阻塞算法。

如果在算法的每个步骤中都存在某个线程能够执行下去，这种算法被称为无锁算法。

如果在算法中仅将CAS用于协调线程之间的操作，并能正确实现，那么它既是一种无阻塞算法，又是一种无锁算法。

在非阻塞算法中通常不会出现死锁和优先级反转问题(但可能出现饥饿和活锁问题)


284
15.4.1 非阻塞的栈
在实现相同功能的前提下，非阻塞算法通常比基于锁的算法更为复杂。
创建非阻塞算法的关键在于，找出如何将原子修改的范围缩小到单个变量上，同时还要维护数据的一致性。

链式容器类中，有时无须将状态转换操作表示为对节点链接的修改，也无须使用AtomicReference来表示每个必须采用原子操作来更新的链接。

@ThreadSafe
public class ConcurrentStack<E> {
	AtomicReference<Node<E>> top = new AtomicReference<>();
	
	public void push(E item) {
		Node<E> newHead = new Node<E>(item);
		Node<E> oldHead;
		do {
			oldHead = top.get();
			newHead.next = oldHead;
		} while (!top.compareAndSet(oldHead, newHead));
	}
	
	public E pop() {
		Node<E> oldHead;
		Node<E> newHead;
		do {
			oldHead = top.get();
			if (oldHead == null)
				return null;
			newHead = oldHead.next;
		} while (!top.compareAndSet(oldHead, newHead));
		return oldHead.item;
	}
	
	// static!!!
	private static class Node<E> {
		public final E item;
		public Node<E> next;
		public Node(E item) { this.item = item; }
	}
}

非阻塞算法的特性：某项工作的完成具有不确定性，必须重新执行。

compareAndSet类似锁定机制，既能提供原子性，也能提供可见性。


非阻塞的链表
CAS的基本使用模式：在更新某个值时存在不确定性，以及在更新失败时重新尝试。
构建非阻塞算法的技巧在于：将执行原子修改的范围缩小到单个变量上。

链表比栈复杂，因为它必须支持头节点，尾节点的快速访问，因此，它需要单独维护头指针和尾指针。
有2个指针位于尾部的节点：当前最后一个元素的next指针，尾节点。当成功插入一个元素时，这两个指针都需要采用原子操作来更新。
。。似乎是有额外的节点放在尾巴上，遍历的时候==这个节点，就是尾巴。
。。下面更新的是next指向新节点，新节点.next指向尾节点，一个指针修改。。。但是这是3步啊。。
。。最后一个元素是不是尾节点？
。。根据下面，尾节点应该是指指向最后一个元素的类成员。这样能快速访问。
。。。但是为什么要记录。。
。。ok。。2个指针：尾节点，next指针，，意思是指一次插入动作，这2个指针会发生变化。并不是说类保存了这2个指针。。

初看起来，这个操作无法通过原子变量来实现。更新这2个指针时需要不同的CAS，并且如果第一个CAS成功，第二个CAS失败，那么队列将处于不一致的状态。即使2个CAS都成功，依然可能有其他线程在两个CAS之间访问这个队列。

需要使用一些技巧，第一个，即使在一个包含多个步骤的更新操作中，也要确保数据结构总处于一致的状态。。这样，当线程B到达时，如果发现线程A正在执行更新，那么线程B就可以知道有一个操作已经部分完成，自己的更新操作无法立即开始。B可以等待直到A完成。
这种方法，如果一个线程在更新中失败了，那么其他线程都无法再访问这个队列。
第二个技巧，如果B达到时A正在修改数据结构，那么在数据结构中应该有足够多的信息，使B能完成A的更新操作。如果B完成了A的操作，那么B可以执行自己的操作，而不用等待A完成。当A恢复后试图完成其他操作时，会发现B已经替它完成了。

下面是Micheal-Scott提出的非阻塞链接队列算法中的插入部分，在ConcurrentLinkedQeueu中使用的正是该算法。
在许多队列算法中，空队列通常都包含一个哨兵节点或哑节点。并且头节点和尾节点在初始化时都指向该哨兵节点。
尾节点通常要么指向哨兵节点(如果队列为空)，即队列的最后一个元素。要么(当有操作正在执行更新时)指向倒数第二个元素。
。。。。那么尾节点在正常状态(非空，无操作)下是指向哪个元素。。。尾节点是为了快速访问最后一个元素。。。。

@ThreadSafe
public class LinkedQueue<E> {
	private static class Node<E> {
		final E item;
		final AtomicReference<Node<E>> next;
		
		public Node(E item, Node<E> next) {
			this.item = item;
			this.next = new AtomicReference<>(next);
		}
	}
	
	private final Node<E> dummy = new Node<E>(null, null);
	private final AtomicReference<Node<E>> head = new AtomicReference<>(dummy);
	private final AtomicReference<Node<E>> tail = new AtomicReference<>(dummy);
	
	public boolean put(E item) {
		Node<E> newNode = new Node<E>(item, null);
		while (true) {
			Noede<E> curTail = tail.get();
			Node<E> tailNext = curTail.next.get();
			if (curTail == tail.get()) {
				if (tailNext != null) {
					// 队列处于中间状态，推进尾节点
					tail.compareAndSet(curTail, tailNext);
				} else {
					// 处于稳定状态，尝试插入新节点
					if (curTail.next.compareAndSet(null, newNode)) {
						// 插入成功，尝试推进尾节点
						tail.compareAndSet(curTail, newNode);
						return true;
					}
				}
			}
		}
	}
}

插入一个新元素时，需要更新2个节点。首先更新当前最后一个元素的next指针，将新节点链接到列表队尾，然后更新尾节点。在这2个操作之间，队列处于一种中间状态。

关键在于：当队列处于稳定状态时，尾节点的next域为空，如果队列处于中间状态，那么tail.next将非空。因此，任何线程都可以通过tail.next来确定队列当前状态。
当队列处于中间状态时，可以通过将尾节点向前(？？不是后？？)移动一个节点，结束其他线程正在执行的插入元素操作，并使得队列恢复为稳定。


15.4.3 原子的域更新器

ConcurrentLinkedQueue中并没有使用原子引用来表示每个Node，而是使用普通的volatile类型引用，并通过基于反射的AtomicReferenceFieldUpdater来进行更新。

private class Node<E> {
	private final E item;
	private volatile Node<E> next;
	public Node(E item) { this.item = item; }
}

private static AtomicReferenceRieldUpdater<Node, Node> nextUpdater = AtomicReferenceFieldUpdater.newUpdater(Node.class, Node.class, "next");

原子的域更新器类表示现有volatile域的一种基于反射的"视图"，从而能够在已有的volatile域上使用CAS。。更新器类没有构造函数，使用newUpdater工厂方法，并指定类和域的名字。域更新器没有和特定的实力相关联，因而可以更新目标类的任意实例中的域。
更新器类提供的原子性保证比普通原子类更弱一些，因为无法保证底层的域不被直接修改---compareAndSet以及其他算术方法只能确保其他使用原子域更新器方法的线程的原子性。

在ConcurrentLinkedQueue中，使用nextUpdater的compareAndSet来更新Node.next域，有点繁琐，但完全是为了提升性能。
对于一些频繁分配且生命周期短暂的对象，例如队列的链接节点，如果能去掉每个Node的AtomicReference创建过程，那么将极大地降低插入操作的开销。然而，几乎是所有情况下，普通原子变量的性能都很不错，只有很少情况下，才需要使用原子的域更新器。(如果在执行原子更新的同时还需要维持现有类的串行化形式，那么原子的域更新器非常有用。)

15.4.4 ABA问题
更新2个值，一个引用和一个版本号。

AtomicStampedReference，AtomicMarkableReference支持2个变量上执行原子的条件更新。
AtomicStampedReference更新一个"对象-引用"二元组，通过在引用上加上版本号，从而避免ABA
AtomicMarkalbeReference更新一个"对象引用-布尔值"二元组，某些算法中将通过这种二元组使节点保存在链表中同时又将其标记为"已删除的节点"


291
chapter 16
Java内存模型

假设一个线程为变量赋值：
aVariable = 3;

内存模型需要解决：在什么条件下，读取aVariable的线程将看到这个值为3？

如果缺少同步，那么会有许多因素使得线程无法立即甚至永远，看到另一个线程的记过。

在编译器中生产的指令顺序，可以与源代码中的顺序不同，此外编译器还会把变量保存在寄存器而不是内存中，处理器可以采用乱序或并行等方式来执行指令，缓存可能会改变将写入变量提交到主内存的次序，而且保存在处理器本地缓存中的值，对其他cpu是不可见的。

java规范要求jvm在线程中维护一种类似串行的语义：只要程序的最终结果与在严格串行环境中执行的结果相同，那么上述所有操作都是允许的。

计算性能的提升在很大程度上要归功于这些重新排序措施。当然，还有：时钟频率的提高，并行性的提升(采用流水线的超标量执行单元)，动态指令调度，猜测执行，多级缓存。

时钟频率越来越难以提高，所以多核成为主流。

JMM规定了JVM必须遵循的一组最小保证，这组保证规定了对变量的写入操作在何时将对于其他线程可见。
JMM在设计时就在可预测性和程序的易于开发新之间做了权衡，从而在各种主流处理器体系架构上能实现高性能jvm。


16.1.1 平台的内存模型
在共享内存的多处理器体系架构中，每个处理器都拥有自己的缓存，并且定期地与主内存进行协调。
不同处理器架构提供不同级别的缓存一致性(Cache Coherence)，其中一部分只提供最小保证，即允许不同的cpu在任意时刻从同一个存储位置上看到不同的值。。os，compiler，runTime需要弥合这种在硬件能力与线程安全需求之间的差异。

要确保每个cpu在任意时刻都能知道其他cpu正在进行的工作，将需要非常大的开销。
cpu释放放宽存储一致性保证，以换取性能的提升。在架构定义的内存模型中将告诉应用程序可以从内存系统中获得怎样的保证，此外还定义了一些特殊的指令(称为内存栅栏或栅栏)，当需要共享数据时，这些指令就能实现额外的存储协调保证。
为了使java开发人员无须关系不同架构上内存模型之间的差异，java还提供了自己的内存模型，并且jvm通过在适当位置插入内存栅栏来屏蔽jmm域底层平台内存模型之间的差异。

程序执行一种简单假设：想象在程序中只存在唯一的操作执行顺序，而不考虑这些操作在何种cpu上执行，并且每次读取变量时，都能获得在执行序列中最近一次写入该变量的值。
这种乐观的模型被称为串行一致性。
开发人员往往会错误地假设存在串行一致性，但在任何一款多核处理器中都不会提供这种串行一致性，JMM也是如此。

在多核cpu中，当跨线程共享数据时，会出现一些奇怪的情况，除非通过使用内存栅栏来防止这些情况发生。
幸运的是，java程序不需要指定内存栅栏的位置，只需要通过正确地使用同步来找出合适将访问共享状态。


16.1.2 重排序
在没有充分同步的程序中，如果调度器采用不恰当的方式来交替执行不同线程的操作，那么将导致不正确的结果。
更糟的是，JMM还使得不同线程看到的操作执行顺序是不同的，从而导致在缺乏同步的情况下，要推断操作的执行顺序将变得更复杂，各种使操作延迟或者看似乱序执行的不同原因，都可以归为重排序。

pubic class PossibleReordering {
	static int x = 0, y = 0;
	static int a = 0, b = 0;
	
	public static void main (String[] args) throws InterrtepedEx {
		Thread one = new Thread(new Runnable() {
			public void run() {
				a = 1;
				x = b;
			}
		});
		Thread two = new Thread(new Runnable() {
			public void run() {
				b = 1;
				y = a;
			}
		});
		one.start(); two.start();
		one.join(); two.join();
		Sysout("x "+" y");
	}
}

可能的重排序后的执行顺序：
x = b，b = 1， y = a, a = 1

内存级的重排序会使得程序的行为变得不可预测。
没有同步，那么推断执行顺序会非常困难。
同步将限制，编译器，运行时，硬件对内存操作重排序，从而在实施重排序是不会破坏JMM提供的可见性保证。


16.1.3 Java内存模型简介
java内存模型是通过各种操作来定义的，包括对变量的读/写操作，监视器的加锁和释放操作，以及线程的启动和合并操作。JMM为程序中所有的操作定义了一个偏序关系，称之为Happens-Begore。
要保证执行操作B的线程看到操作A的结果(无论A，B是否在一个线程中执行)，那么A和B必须满足Happends-Before关系。如果两个操作之间缺乏Happens-Before关系，那么JVM可以对它们进行任意重排序。

当一个变量被多个线程读取并且至少被一个线程写入时，如果在读操作和写操作之间没有按照Happens-Beofre来排序，那么会产生数据竞争问题。在正确同步的程序中不存在数据竞争，并会表现出串行一致性，这意味着程序中所有的操作都是按照一种固定的和全局的顺序执行。

Happens-Before规则：
程序顺序规则。。如果程序中操作A在操作B之前，那么线程中A操作将在B操作之前执行。。。。test。。那么上面为什么会出现x=b，a=1这种排序。
监视器锁规则。。在监视器锁上的解锁操作必须在同一个监视器锁上的加锁操作之前执行。。。？？？之前，之后？是否同一个线程？？
volatile变量规则。。对于volatile变量的写入操作必须在对该变量的读操作之前执行。
线程启动规则。。在线程上对Thread.start的调用必须在该线程中执行任何操作之前执行。
线程结束规则。。线程中任何操作都必须在其他线程检测到该线程已经结束之前执行，或者从Thread.join中成功返回，或者在调用Thread.isAlive是返回false。
中断规则。。当一个线程在另一个线程上调用interrupt时，必须在被中断线程检测到interrupt调用之前执行。
终结器规则。。对象的构造器必须在启动该对象的终结器之前执行完成。
传递性。。如果A在B之前执行，并且B在C之前执行，那么A必须在B之前执行。


16.1.4 借助同步
由于HB的排序功能很强大，因此有时可以借助现有同步机制的可见性属性。
这需要将HB的程序顺序规则与某个其他顺序规则(通常是监视器锁规则或volatile变量规则)结合起来，从而对某个未被锁保护的变量的访问操作进行排序。。这项技术由于对语句的顺序非常敏感，因此很容易出错。它是一项高级技术，并且只有当需要最大限度提升某些类(如ReentrantLock)的性能时，才应该使用这项技术。
在FutureTask的保护方法AbstractQueuedSynchronizer中说明了如何使用这种"借助"技术。AQS维护了一个表示同步器状态的整数，FutTask用这个整数来保证任务的状态：正运行，已完成，已取消。但FutuTask还维护了其他一些变量，例如计算结果。当一个线程调用set来保存结果并且另一个线程调用get来获取该结果时，这2个线程最好按照HB进行排序。这可以通过将执行结果的引用声明为volatile来实现，但利用现有同步机制可以更容易地实现相同功能。
。。test。。volatile还能管 线程的顺序？不同的线程间，无法确定对volatile的操作顺序吧。一个线程间，能根据volatile规则确定某个操作必须在另一个操作之前。。多线程怎么可能确定。。

FutTask在设计时能确保，在调用tryAcquireShared之前总能成功调用tryReleaseShared。tryReleaseHared会写入一个volatile类型的变量，而tryAcquireShared将读取这个变量。
下面的代码给出了innerSet，innerGet等，在保存和获取result时将调用这些方法，由于innerSet将在调用releaseShared(这又将调用tryReleaseShared)之前写入result，并且innerGet将在调用acquireShared(这将调用tryReleaseShared)之后读取result，因此将程序顺序规则与volatile变量规则结合在一起，就可以确保innerSet的写入操作在innerGet的读取操作之前执行。

// FutureTask的内部类
private final class Sync extends AbstractQueuedSynchronizer {
	private static final int RUNNING = 1, RAN = 2, CANCELLED = 4;
	private V result;
	private Exception exception;
	
	void innerSet(V v) {
		while (true) {
			int s = getState();
			if (ranOrCancelled(s))
				return;
			if (compareAndSetState(s, RAN))
				break;
		}
		result = v;
		releaseShared(0);
		done();
	}
	
	V innerGet() throws InterrptedExce, ExecutionExec {
		acquiredSharedInterruptibly(0);
		if (getState() == CANCELLED)
			throw new CancellationException();
		if (excepiton != null)
			throw new ExectuionException(exception);
		return result;
	}
}

之所以将这项技术称为"借助"，是因为它使用了一种现有的HB顺序来确保对象X的可见性。
在FutuTask中使用借助技术很容易出错，因此要谨慎使用，但在某些情况下，这种借助技术是非常合理的。如，当某个类在其规范中规定它的各个方法之间必须遵循一种HB关系，基于BlockingQueue实现的安全发布就是一种借助。如果一个线程将对象置入队列，并且另一个线程随后获取这个对象，那么这就是一种安全发布，因为在BlockingQueue的实现中包含有足够的内部同步来确保入列操作在出列操作之前执行。

在类库中提供的其他HB排序包括：
将一个元素放入一个线程安全容器的操作将在另一个线程从该容器中获得这个元素的操作之前执行。
在CountDownLatch上的倒数操作将在线程从闭锁上的await方法中返回之前执行。
释放Semaphore许可的操作将在从该Semaphore上获得一个许可之前执行。
Future表示的任务的所有操作将在从Future.get中返回之前执行
向Executor提交一个Runnabel/Callable的操作将在任务开始执行之前执行。
一个线程达到CyclieBarrier或Exchanger的操作将在其他到达该栅栏或交换点的线程被释放之前执行。如果CyclcBarrier使用了一个栅栏操作，那么到达栅栏的操作将在栅栏操作之前执行，栅栏操作会在线程从栅栏中释放之前执行。


16.2 发布

造成不正确发布的真正原因就是在发布一个共享对象与另一个线程访问该对象之间缺少一种HB排序。


16.2.1 不安全的发布
当缺少HB关系时，就可能出现重排序问题，这就解释了为什么在没有充分同步的情况下发布一个对象会导致另一个对象看到一个只被部分构造的对象。
在初始化一个新的对象时需要写入多个值到新对象的各个域。同样，在发布一个引用是也需要写入一个变量，即新对象的引用。如果无法确保发布共享引用的操作在另一个线程加载该共享引用之前执行，那么对新对象的引用的写入操作将与对象中各个域的写入操作重排序。这种情况下，另一个线程可以看到对象引用的最新值，但同时也将看到对象的某些或全部状态中包含的是无效值，即一个被部分构造的对象。

public class UnsafeLazyInitializetion {
	private static Resource resource;
	public static Reference getInstance() {
		if (resource == null)
			resource = new Resource();		// 不安全的发布
		return resource;
	}
}

线程A先调用，看到null，开始初始化一个新的Resource，然后将resource设置为执行这个新实例。线程B调用getInstance，看到resource非空，直接使用。。但是线程A写入resource的操作和线程B读取resource的操作不存在HB关系。当发布对象时存在数据竞争问题，因此B不一定能看到Resource的正确状态。

除了不可变对象以外，使用被另一个线程初始化的对象通常都是不安全的，除非对象的发布操作时在使用该对象的线程开始之前执行。


16.2.2 安全的发布
线程A将对象X放入BlockingQueue(并且随后没有线程修改它)，线程B从队列中获取X，那么可以确保B看到的X与A放入的X相同，因为BlockingQueue的实现中有足够的内部同步保证put方法在take方法之前执行。同样，通过使用一个由锁保护的共享变量或使用共享的volatile类型变量，也可以确保对该变量的读取操作和写入操作按照HB关系来排序。

HB比安全发布提供了更强的可见性与顺序保证。
HB排序是在内存访问级别上操作的，它是一种"并发级汇编语言"，而安全发布的运行级别更接近程序设计。安全发布更符合程序设计。

16.2.3 安全初始化模式
有时，我们需要懒初始化。
	public static Reference getInstance() {
		if (resource == null)
			resource = new Resource();		// 不安全的发布
		return resource;
	}
这个方法变成synchronized方法，就是安全的发布。

或者提前初始化
private static Resource = new Resource();
public static Reference getInstance() { return resouce; }

延长初始化占位类模式
使用一个专门的类来初始化Resource，JVM将推迟ResourceHolder的初始化操作，直到开始使用这个类时才初始化。并且由于通过一个静态初始化来初始化Resource，因此不需要额外的同步。

public class ResourceFactory {
	private static class ResourceHolder {
		public static Resource resource = new Resource();
	}
	public static Resource getResourcde() {
		return ResourceHolder.recource;
	}
}


16.2.4 双重检验加锁 DCL
在早期jvm中。同步(甚至是无竞争的同步)都存在巨大的开销，因此，人们想出了许多"聪明"的技巧来降低同步的影响，有些很好，有些不好，DCL属于糟糕的一类

@NotThreadSafe
public class DoubleCheckedLocking {
	private static Resource resuource;
	
	public static Resource getInstance() {
		if (resour == null) {
			synchronzied(DoubleChekcedLocking.class) {
				if (resouece == null)
					resource = new Resource();
			}
		}
		return resuource;
	}
}

线程可能看到一个仅被部分构造的Resource。

DCL的真正问题在于：当没有同步的情况下读取一个共享对象时，可能发生的最糟糕事情只是看到一个失效值。此时DCL方法通过在持有锁情况下再次尝试来避免这种风险。然而，实际情况比这种情况糟糕---线程可能看到引用的当时值，但对象的状态却是失效的，这意味这线程可以看到对象处于无效或错误的状态。
。。？？？。。test。。。失效说明new了2次，导致第二次把第一次给失效了，但是如何才能new两次？classLoader？。synchonized能保证new必然执行完吧。是没有volatile的原因？两个线程间对内存的操作没有同步？不，synchrinized能保证同步内存了吧。

DCL已经被废弃，它不是一种高效的优化措施。延迟初始化占位类模式能带来同样的优势，并且更容易理解。


16.3 初始化过程中的安全性
如果能确保初始化过程的安全性，那么就可以使得被正确构造的不可变对象在没有同步的情况下也能安全地在多个线程间共享，而不管它们是如何发布的，甚至通过某种数据竞争来发布。

初始化安全性将确保，对于被正确构造的对象，所有线程都能看到有构造函数为对象的各个final域设置的正确值，而不管采用何种方式来发布对象。而且，对于可以通过被正确构造对象中某个final域到达的任意变量(如，某个final数组中的元素，或final域引用的HashMap中的内容)将同样对于其他线程是可见的。

对于含有final域的对象，初始化安全性可以防止对对象的初始引用被重排序到构造过程之前。
当构造器完成时，构造器对final域的所有写入操作，以及通过这些域能到达的任何变量的写入操作，都将被冻结，并且任何获得该对象引用的线程都至少能确保看到被冻结的值。对于通过final域可到达的初始变量的写入操作，不会与构造过程后的操作一起被重排序。

初始化安全性意味着，下面的代码可以安全地发布，即使通过不安全的延迟初始化，或者没有同步的情况下将SafeStates的引用放到一个共有的静态与，或者没有使用同步以及依赖于非线程安全的HashSet。

@ThreadSafe
public class SafeStates {
	private FINAL Map<String, String> states;
	
	public SafeStates() {
		states = new HashMap<>();
		states.put("alaska", "AK");
		...
		states.put("Wyoming", "WY");
	}
	
	public String getAbbreviation(String s) {
		return states.get(s);
	}
}

许多对SafeStates的细微修改都可能破坏它的线程安全性，如states不是final，或者存在除构造器以外的地方能修改states。
如果SafeStates中还有其他的非final域，那么其他线程仍然可能看到这些域上的不正确值。这也导致了对象在构造过程中逸出，从而使初始化安全性的保证无效。

初始化安全性只能保证通过final域卡到达的值从构造过程完成时开始的可见性。对于通过非final可达的值，或者在构造过程完成后可能改变的值，必须采用同步来确保可见性。






























jdk静态代理。
就是手动写个xxxProxy类。里面显式调用了xxx的方法


jdk动态代理，只能代理接口
java.lang.reflect.InvocationHandler

public interface Subject {
    void doSomething();
}

public class RealSubject implements Subject {

创建一个代理类JDKDynamicProxy实现java.lang.reflect.InvocationHandler接口，重写invoke方法
public class JDKDynamicProxy implements InvocationHandler {
    private Object target;
    public JDKDynamicProxy(Object target) {
        this.target = target;
    }

    /**
     * 获取被代理接口实例对象
     * @param <T>
     * @return
     */
    public <T> T getProxy() {
        return (T) Proxy.newProxyInstance(target.getClass().getClassLoader(), target.getClass().getInterfaces(), this);
    }

    @Override
    public Object invoke(Object proxy, Method method, Object[] args) throws Throwable {
        System.out.println("Do something before");
        Object result = method.invoke(target, args);
        System.out.println("Do something after");
        return result;
    }
}

public static void main(String[] args) {
	// 保存生成的代理类的字节码文件
	System.getProperties().put("sun.misc.ProxyGenerator.saveGeneratedFiles", "true");

	// jdk动态代理测试
	Subject subject = new JDKDynamicProxy(new RealSubject()).getProxy();
	subject.doSomething();
}

输出结果：
Do something before
RealSubject do something
Do something after

。。subject竟然用法和正常使用一样。。以前都以为是proxy.invoke...



cglib动态代理
pom引入依赖
<dependency>
    <groupId>cglib</groupId>
    <artifactId>cglib</artifactId>
    <version>2.2.2</version>
</dependency>

直接代理类(非接口)

public class UserServiceCglib implements MethodInterceptor{
    private Object target;

    /**
     * 创建代理实例
     * @param target
     * @return
     */
    public Object getInstance(Object target){
        this.target = target;
        Enhancer enhancer = new Enhancer();
        enhancer.setSuperclass(this.target.getClass());
        // 设置回调方法
        enhancer.setCallback(this);
        // 创建代理对象
        return enhancer.create();
    }

    /**
     * 实现MethodInterceptor接口要重写的方法。
     * 回调方法
     */
    public Object intercept(Object obj, Method method, Object[] args, MethodProxy proxy) throws Throwable {
        System.out.println("事务开始。。。");    
        Object result = proxy.invokeSuper(obj, args);    
        System.out.println("事务结束。。。");    
        return result;    
    }
}

UserServiceCglib cglib = new UserServiceCglib();
UserServiceImpl bookFacadeImpl = (UserServiceImpl)cglib.getInstance(new UserServiceImpl());
bookFacadeImpl.addUser();

如果业务实现类被定义成final类，就会报以下错误
Exception in thread "main" java.lang.IllegalArgumentException: Cannot subclass final class class cn.xx.xx.cgilb.UserServiceImpl



jdk动态代理会根据被代理对象生成一个继承了Proxy类，并实现了该业务接口的jdk代理类，该类的字节码会被传进去的ClassLoader加载，创建了jdk代理对象实例，

cglib动态代理是继承代理，通过ASM字节码框架修改字节码生成新的子类，重写并增强方法的功能。


jdk静态代理类只能为一个被代理类服务，如果需要代理的类比较多，那么会产生过多的代理类。jdk静态代理在编译时产生class文件，运行时无需产生，可直接使用，效率好。

jdk动态代理必须实现接口，通过反射来动态代理方法，消耗系统性能。但是无需产生过多的代理类，避免了重复代码的产生，系统更加灵活。

cglib动态代理无需实现接口，通过生成子类字节码来实现，比反射快一点，没有性能问题。但是由于cglib会继承被代理类，需要重写被代理方法，所以被代理类不能是final类，被代理方法不能是final。

cglib的应用更加广泛一点。


jdk创建对象的速度远大于cglib，这是由于cglib创建对象时需要操作字节码。cglib执行速度略大于jdk，所以比较适合单例模式。另外由于CGLIB的大部分类是直接对Java字节码进行操作，这样生成的类会在Java的永久堆中。如果动态代理操作过多，容易造成永久堆满，触发OutOfMemory异常。spring默认使用jdk动态代理，如果类没有接口，则使用cglib。


似乎是低版本java，cglib快，高版本(7，8),jdk动态代理快。。可能是invoke的提升吧。

















Thread.join。。调用这个方法的线程会阻塞，直到被调用join的线程完成(靠isAlive判断是否完成)。




Servlet

dubbo




委托 代理


int asw = (-2) & 7;
是6.也是，必然本来就是按位的，计算机的位就是补码。














偏向锁，轻量级锁，自旋锁，重量级锁
https://www.cnblogs.com/wade-luffy/p/5969418.html

JVM规范规定JVM基于进入和退出Monitor对象来实现方法同步和代码块同步，但两者的实现细节不一样。代码块同步是使用monitorenter和monitorexit指令实现，而方法同步是使用另外一种方式实现的，细节在JVM规范里并没有详细说明，但是方法的同步同样可以使用这两个指令来实现。monitorenter指令是在编译后插入到同步代码块的开始位置，而monitorexit是插入到方法结束处和异常处， JVM要保证每个monitorenter必须有对应的monitorexit与之配对。任何对象都有一个 monitor 与之关联，当且一个monitor 被持有后，它将处于锁定状态。线程执行到 monitorenter 指令时，将会尝试获取对象所对应的 monitor 的所有权，即尝试获得对象的锁。


锁存在Java对象头里。如果对象是数组类型，则虚拟机用3个Word（字宽）存储对象头，如果对象是非数组类型，则用2字宽存储对象头。在32位虚拟机中，一字宽等于四字节，即32bit。
长度		内容			说明
32/64bit 	Mark Word 		存储对象的hashCode或锁信息等
32/64bit 	Class Metadata Address 	存储到对象类型数据的指针
32/64bit 	Array length 	数组的长度（如果当前对象是数组）

Java对象头里的Mark Word里默认存储对象的HashCode，分代年龄和锁标记位。32位JVM的Mark Word的默认存储结构如下：
			25 bit			4bit	1bit是否是偏向锁	2bit锁标志位
无锁状态 	对象的hashCode 	对象分代年龄 	0 			01


在运行期间Mark Word里存储的数据会随着锁标志位的变化而变化。Mark Word可能变化为存储以下4种数据：
轻量级锁	指向栈中锁记录的指针
重量级锁	指向互斥量(重量级锁)的指针
GC标记		空
偏向锁		线程ID，Epoch，对象分代年龄


线程的阻塞和唤醒需要CPU从用户态转为核心态，频繁的阻塞和唤醒对CPU来说是一件负担很重的工作。
Java SE1.6为了减少获得锁和释放锁所带来的性能消耗，引入了“偏向锁”和“轻量级锁”，所以在Java SE1.6里锁一共有四种状态，无锁状态，偏向锁状态，轻量级锁状态和重量级锁状态，它会随着竞争情况逐渐升级。锁可以升级但不能降级，意味着偏向锁升级成轻量级锁后不能降级成偏向锁。这种锁升级却不能降级的策略，目的是为了提高获得锁和释放锁的效率。


偏向锁

大多数情况下锁不仅不存在多线程竞争，而且总是由同一线程多次获得。偏向锁的目的是在某个线程获得锁之后，消除这个线程锁重入（CAS）的开销，看起来让这个线程得到了偏护。另外，JVM对那种会有多线程加锁，但不存在锁竞争的情况也做了优化，听起来比较拗口，但在现实应用中确实是可能出现这种情况，因为线程之前除了互斥之外也可能发生同步关系，被同步的两个线程（一前一后）对共享对象锁的竞争很可能是没有冲突的。对这种情况，JVM用一个epoch表示一个偏向锁的时间戳（真实地生成一个时间戳代价还是蛮大的，因此这里应当理解为一种类似时间戳的identifier）

偏向锁的获取

当一个线程访问同步块并获取锁时，会在对象头和栈帧中的锁记录里存储锁偏向的线程ID，以后该线程在进入和退出同步块时不需要花费CAS操作来加锁和解锁，而只需简单的测试一下对象头的Mark Word里是否存储着指向当前线程的偏向锁，如果测试成功，表示线程已经获得了锁，如果测试失败，则需要再测试下Mark Word中偏向锁的标识是否设置成1（表示当前是偏向锁），如果没有设置，则使用CAS竞争锁，如果设置了，则尝试使用CAS将对象头的偏向锁指向当前线程。

偏向锁的撤销

偏向锁使用了一种等到竞争出现才释放锁的机制，所以当其他线程尝试竞争偏向锁时，持有偏向锁的线程才会释放锁。偏向锁的撤销，需要等待全局安全点（在这个时间点上没有字节码正在执行），它会首先暂停拥有偏向锁的线程，然后检查持有偏向锁的线程是否活着，如果线程不处于活动状态，则将对象头设置成无锁状态，如果线程仍然活着，拥有偏向锁的栈会被执行，遍历偏向对象的锁记录，栈中的锁记录和对象头的Mark Word，要么重新偏向于其他线程，要么恢复到无锁或者标记对象不适合作为偏向锁，最后唤醒暂停的线程。
。。那岂不是永远都是一个线程先执行了？而且epoch的作用呢？

偏向锁的设置

关闭偏向锁：偏向锁在Java 6和Java 7里是默认启用的，但是它在应用程序启动几秒钟之后才激活，如有必要可以使用JVM参数来关闭延迟-XX：BiasedLockingStartupDelay = 0。如果你确定自己应用程序里所有的锁通常情况下处于竞争状态，可以通过JVM参数关闭偏向锁-XX:-UseBiasedLocking=false，那么默认会进入轻量级锁状态。


自旋锁

线程的阻塞和唤醒需要CPU从用户态转为核心态，频繁的阻塞和唤醒对CPU来说是一件负担很重的工作。同时我们可以发现，很多对象锁的锁定状态只会持续很短的一段时间，例如整数的自加操作，在很短的时间内阻塞并唤醒线程显然不值得，为此引入了自旋锁。

所谓“自旋”，就是让线程去执行一个无意义的循环，循环结束后再去重新竞争锁，如果竞争不到继续循环，循环过程中线程会一直处于running状态，但是基于JVM的线程调度，会出让时间片，所以其他线程依旧有申请锁和释放锁的机会。

自旋锁省去了阻塞锁的时间空间（队列的维护等）开销，但是长时间自旋就变成了“忙式等待”，忙式等待显然还不如阻塞锁。所以自旋的次数一般控制在一个范围内，例如10,100等，在超出这个范围后，自旋锁会升级为阻塞锁。
。。没有获得锁，那就while。
。。nnnn多线程岂不是爆炸，。。不过nnnn多线程的阻塞和唤醒也很爆炸。。
。。难道不能缓冲池？不过缓冲池也要唤醒和阻塞。。。阻塞唤醒的原理还不清楚呢。。
。。最后说了，会升级为阻塞锁。。


轻量级锁

加锁

线程在执行同步块之前，JVM会先在当前线程的栈桢中创建用于存储锁记录的空间，并将对象头中的Mark Word复制到锁记录中，官方称为Displaced Mark Word。然后线程尝试使用CAS将对象头中的Mark Word替换为指向锁记录的指针。如果成功，当前线程获得锁，如果失败，则自旋获取锁，当自旋获取锁仍然失败时，表示存在其他线程竞争锁(两条或两条以上的线程竞争同一个锁)，则轻量级锁会膨胀成重量级锁。

解锁

轻量级解锁时，会使用原子的CAS操作来将Displaced Mark Word替换回到对象头，如果成功，则表示同步过程已完成。如果失败，表示有其他线程尝试过获取该锁，则要在释放锁的同时唤醒被挂起的线程。

。。自旋锁里说会升级为阻塞锁，这里说，轻量级锁->自旋锁->重量级锁，，重量级锁 == 阻塞锁？
。。自旋锁、阻塞锁、重入锁、偏向锁、轻量锁和重量锁。。有这么多锁？


重量级锁

重量锁在JVM中又叫对象监视器（Monitor），它很像C中的Mutex，除了具备Mutex(0|1)互斥的功能，它还负责实现了Semaphore(信号量)的功能，也就是说它至少包含一个竞争锁的队列，和一个信号阻塞队列（wait队列），前者负责做互斥，后一个用于做线程同步。


锁		优点		缺点		适用场景
偏向锁 	加锁和解锁不需要额外的消耗，和执行非同步方法比仅存在纳秒级的差距 	如果线程间存在锁竞争，会带来额外的锁撤销的消耗 	适用于只有一个线程访问同步块场景

轻量级锁 	竞争的线程不会阻塞，提高了程序的响应速度 	如果始终得不到锁竞争的线程使用自旋会消耗CPU 	追求响应时间,锁占用时间很短

重量级锁 	线程竞争不使用自旋，不会消耗CPU 	线程阻塞，响应时间缓慢 			追求吞吐量,锁占用时间较长

。。重量级的缺点就是 线程阻塞。。




Collections.binarySearch
// Arrays.binarySearch




java.util.Observale
java.util.Observer
























Person[] arr = list.toArray(new Person[] {});
Arrays.asList(arr);
java.lang.Integer.sum(int, int)
java.lang.Integer.max(int, int)


