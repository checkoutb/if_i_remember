2023-06-24 21:43

[[toc]]


# 592_架构设计面试精讲24474

拉勾

刘海丰 - 京东

## v0 开篇词

初级：
redis 是否可以用作分布式锁？
    存在哪些问题
    怎么实现多节点数据一致性


中高级
分布式缓存系统的数据分布，复制，共识算法等问题



面试：
    1. 假设一种场景，让候选人根据场景做出技术设计
    2. 让候选人画出自己做过的最复杂的系统的架构图，然后再提出具体的设计问题
    
    涉及： 架构原理，分布式技术，中间件，数据库，缓存，业务系统架构


正好是本课程的6个模块
1. 架构原理与技术认知
2. 分布式技术原理与设计
3. 中间件常用组件的原理和设计问题
4. 数据库原理与设计问题
5. 分布式缓存原理与设计问题
6. 互联网高性能高可用设计问题



## v1 提升面试竞争力，需要具备的3个技术认知

要提升面试竞争力，需要具备的3个技术认知是什么？

### 规划，似乎我完全没有。

架构设计认知
分析问题的认知
能力边界认知


架构设计的问题，回答一定要 立足于点，连接成线，扩散成面。


。。
拆分系统的理由
1. 某一部分(子系统)，业务稳定，不会频繁迭代，如果和其他子系统耦合在一起，那么在其他子系统发布上线的时候，这部分会被影响。所以需要拆分出一个独立的子系统。
2. 某一部分，是非核心系统，单独拆分出来，不影响核心流程。发生异常的时候，这部分可以降级。
3. 某一部分，变更频繁，需要快速迭代，专业化，所以拆分出来，以快速响应需求变化。
4. 虽然系统拆分会导致系统交互更加复杂，但是在规范了API的格式定义和调用方法后，系统的复杂度可以维持在可控的范围内。
。。


架构不止系统拆分，要理解拆分背后的深层原因。

### 对架构设计的认知

为什么要做架构拆分
    最直接的目的是 系统/子系统/模块 之间的解耦

为什么要做系统解耦
    使得原本错综复杂的调用逻辑能有序地分布在各个系统中，使得拆分后的各个系统，职责更为单一，功能更为内聚

为什么要职责单一
    因为职责单一的系统功能逻辑的迭代速度会更快，会提高研发团队响应业务需求的速度，也就是提高了团队的开发效率

为什么要关注开发效率
    研发迭代效率的提升是任何一家公司在业务发展期间都最为关注的问题，所以从某种程度上看，架构拆分是系统提效最直接的手段


### ==架构拆分其实是管理在技术上提效的一种手段==


### 对分析问题的认知
业务方，关注系统能力，是否能满足市场需求
管理者，关注升级后，团队的研发效能是否得到提升
技术人员，需要找到自己做系统设计的立足点，来满足不同人对技术的诉求，而这个立足点通常就是==系统设计原则==。

系统的设计原则不是乱提出来的，而是==针对系统现阶段业务发展带来的主要矛盾提出==才会更有价值且被认可

回答系统设计问题时要根据 系统现阶段的主要矛盾 来回答，不要直接 高可用，高性能。


人月神话中提高：软件复杂性来源于两点：本质复杂度和偶然复杂度
    开发工具、开发框架、开发模式，以及高性能和高可用这些仅是偶然复杂性
    架构最重要的是要解决本质复杂性，这包括人的复杂性和业务的复杂性

这时有人可能会说，我只想做技术，不想做业务，然而你会慢慢发现，在职业生涯中处理的最有价值的事情，一般都是利用技术解决了业务领域的某阶段的主要问题，这也是最复杂的。




### 对能力边界的认知
你觉得一个高级研发工程师和一个架构师的区别在哪？

|_|中高级研发|架构师|
|--|--|--|
|功能性需求|采用合理的技术 实现 系统功能性需求|采用合理的技术 设计 系统功能性架构|
|非功能性需求|无|在系统高可用，高性能，高扩展，容灾性等技术导向方面做出有价值的贡献|

中高级研发工程师 需要能驾驭 模块或子系统层面
架构师 需要能驾驭 全系统层面
高级架构师 需要能驾驭 某一领域层面







## v2 如何以架构师视角回答架构设计方案

面试中会遇到：你是如何设计这个系统的？请介绍你的思路。
    很多人忽略 系统设计思路 这个关键词，陷入到某个技术点细节中。

从全局技术视角介绍技术方案

解决技术问题的方法有很多，这是"术"
解决技术问题的底层思维逻辑是一样的，这是"道"


一个系统从sync rpc调用多个系统，业务量上升后，变成了瓶颈，所以变成MQ异步，如何评价？
评价的步骤：
1. 复杂来源
2. 解决方案
3. 评估标准
4. 技术实现


复杂来源
只有正确分析后，才能明确设计原则，进而设计架构方案，整体项目才不会找错方向。
如何评估复杂度：
1. 功能性复杂度：业务
2. 非功能性复杂度：高性能，高可用，扩展性，安全性，低成本 等。 需要确定哪些需要考虑，有时候qps远达不到压测的基准，那么就不需要考虑 高性能。


系统的目标不是以平均值来计算，而是应该以峰值来计算，所以取 平均值 * 4。
。。不知道这个峰值 = 平均值 * 4 是哪里来的。


高性能：tps，qps
高可用：如果mq挂掉，会发生什么


解决方案
1. 开源的MQ消息管道： kafka，rocketmq，rabbitmq

2. 使用Redis实现消息队列。 第一个方案 引入了 消息中间件，所以带来了运维成本。所以这里使用 轻量级的redis实现，来降低维护成本和实现复杂度。

3. 使用内存队列+mysql来实现。 方案2 还不够轻量，还是引入了缓存系统，带来运维成本。通过内存队列，异步持久化到数据库，然后通过定时任务，读取mysql中的消息并处理。


一般情况，你至少要设计两到三套备选方案，考虑通过不同的技术方式来解决问题。方案设计不用过于详细，而是要确定技术的可行性和优缺点


评估标准
功能性，非功能性

一些非功能性复杂度，为了确保高可用，考虑下面的3个原则：
1. 系统无单点原则，保证系统各节点部署的时候是冗余的，没有单点。 3种方案都可以。
2. 可水平扩展原则，mq，redis具有优势， 内存队列+mysql 需要做分库分表的开发改造，并且根据业务来预估容量。
3. 可降级原则，当系统出现故障时，为了可用性，执行一些备用方案
    1. 限流，抛弃 预估容量外的用户
    2. 降低，抛弃 不重要的功能，如产品详情页不展示 收藏数量。
    3. 熔断，抛弃 对故障系统的调用， 一般情况下，熔断伴随着降级处理，比如，展示兜底数据。
    一般情况下，默认数据库不可降级，mq和redis 都可以通过 降级到数据库 来进行容灾处理。 所以my 和redis 还需要考虑到 降级到 mysql。

方案没有优劣，只有更适合。
考虑问题的方式，比具体的选型结果更为重要。


技术实现

在确定具体的架构解决方案后，需要进一步说明技术上的落地实现方式和深层原理。
比如选择redis后，需要考虑是 pub/sub模式，list 还是 zset。



架构师视角，就是全局的视角，包括 空间全局(看到整个系统的领域边界)，时间全局(整个系统的发展周期)








## v3 如何考察CAP相关的分布式理论

CAP
consistency 一致性
available   可用性
partition   分区容错


分布式中p是必须的，所以只有 CP， AP


CAP理论用于 指导 在系统设计时需要 衡量的因素，并不是 绝对地选择。


即使做不到强一致性，也应该尽可能做到最终一致性

### BASE
Basically Available, Soft state, Eventually consistent
基本可用，
软状态，
最终一致性。


### 基本可用性

服务降级
    电商，双11大促时，压力较大，会关闭商品排行等次要功能，来保证商品交易主流程的可用性。
流量削峰
    预售商品的 支付延后10-20分钟
延迟队列
    抢购商品的时候，会在队列中等待处理


### 软状态和最终一致性

允许数据存在中间状态
    在用户下单的时候，并不会扣减库存，而是仅在前台计个数，然后通过异步任务在后台批量处理。


### redis作为分布式锁的问题

一般使用redis的setnx方法实现 锁和 超时时间 来控制锁的失效时间。
在极端情况下， redis 主节点挂掉，但锁还没有同步到从节点时，根据哨兵机制，从就变成了主，继续提供服务。这时，另外的线程可以再来请求锁，此时就会出现两个线程拿到了锁的情况。

==redis的设计模型是 AP 模型==，而 ==分布式锁是一个CP场景==
将 Redis 这种 AP 模型的架构应用于 CP 的场景，在底层的技术选型上就是错误的


Redis 属于分布式存储系统，你的头脑里就要有对分布式存储系统领域的知识体系。思考它的==数据存储、数据分布、数据复制，以及数据一致性==都是怎么做的，用了哪些技术来实现，为什么要做这样的技术或算法选型。你要学会从多维度、多角度去对比、分析同一分布式问题的不同方法，然后综合权衡各种方法的优缺点，最终形成自己的技术认知和技术判断力。










## v4 亿级商品存储下，如何深度回答分布式系统的原理性问题？

以异地商品存储为背景，考察对分布式原理的掌握程度。涉及 海量数据的存储、分片、复制，以及一致性共识算法的答题思路。

问题：
- 如何设计一个支持海量商品存储的高扩展性架构？
- 在做分库分表时，基于 Hash 取模和一致性 Hash 的数据分片是如何实现的？
- 在电商大促时期，如何对热点商品数据做存储策略 ？
- 强一致性和最终一致性的数据共识算法是如何实现的 ？


互联网业务场景下，为了解决 单台 存储设备的 局限性，会把数据 分布到多台存储节点上，来实现数据的 ==水平扩展==。
要把 数据分布到 多个节点，就需要 数据分片。 数据分片 就是 按照一定的规则 将数据 路由到 相应的存储节点中，常见的实现方案有 Hash（哈希分片）与 Range（范围分片）

明确了如何分片后，就需要对数据进行复制，数据复制会产生副本，而==副本==是分布式存储系统解决==高可用的唯一手段==，这也是我们熟知的主从模式
在分布式存储系统中，通常会设置数据副本的主从节点，当主节点出现故障时，从节点可以替代主节点提供服务，从而保证业务正常运行。

如何让从节点替代主节点呢？这就涉及数据一致性的问题了（只有在主从节点数据一致的情况下，才能进行主从替换）

关于数据一致性，通常要考虑一致性强弱（即强一致性和最终一致性的问题）。而要解决一致性的问题，则要进行一系列的一致性协议：如两阶段提交协议（Two-Phrase Commit，2PC）、Paxos 协议选举、Raft 协议、Gossip 协议。

## 所以分布式数据存储的问题可以分成
- 数据分片
- 数据复制
- 数据一致性


场景：将单点上百G的商品做数据重构，存储到多个节点上，你会如何设计？

由于是 商品存储扩容的设计问题，所以很容易想到 分库分表， 也就是重新设计 数据的分片规则，常用的 分片策略有 2种，hash 和range 分片。

## hash分片的原理：

商品表 包括 主键，商品ID，商品名称，所属品类，上架时间等。

|主键|商品ID|商品名称|所属品类|上架时间|
|--|--|--|--|--|
|1|100|huawei|phone|2020-11-22|
|2|101|apple|phone|2020-11-22|
|3|102|xx|xx|xx|
|4|103|xx|xx|xx|
|5|104|xx|xx|xx|

如果使用商品ID作为关键字进行分片，系统会通过一个hash函数来计算商品ID的hash值，然后取模，就得到了对应的 分片。

### 优点
数据分布非常均匀
实现简单

### 缺点
扩展性差，当节点数量变动时，就需要重新计算hash。会导致 大规模的数据迁移。


## 一致性hash
保证数据均匀分布，且保证扩展性。

它是指将存储节点和数据都映射到一个首尾相连的哈希环上。存储节点一般可以根据 IP 地址进行 Hash 计算，数据的存储位置是从数据映射在环上的位置开始，依照顺时针方向所找到的第一个存储节点。

实际运用中，通常使用 带有虚拟节点的一致性hash。假设有10个虚拟节点，那就有 10个分片，整个hash空间就由这 10个分片组成。 让A节点对应 虚拟节点0-3， B节点对应虚拟节点 4-6， C->7-8, D->9

。。不知道为什么这么分，不是应该 3,3,2,2 吗？

使用 商品ID % 10 就获得了 hash环上的位置，然后就能找到 存储节点。

。。这个说得应该不对吧。。 这样扩容也会导致 大量 数据迁移啊。
。。难道 不会扩容超过10个？ 就是扩容的时候，把 虚拟节点分开，这样 数据迁移 就少很多， 但是一旦 10个节点以后，难道 直接*2? 就是 虚拟节点倍增， %20？， 倍增的话， 实际节点存储的值 不会变的。

。。我认为的一致性hash：hash以后 mod INT_MAX，然后向后找到的第一个节点，就是这条数据的存储节点。
。。就是上面的 %10 有点太小了啊。

。。==视频里说的 应该不是 一致性hash，只是普通的hash==

。。网上开始

一致性hash在节点太少时，容易 由于分布不均匀而导致 数据倾斜。
为了避免数据倾斜， 一致性hash算法引入了 虚拟节点的机制。 也就是 ==每个机器节点会进行多次hash==，这样，每个节点 在 hash环 上会有 多个虚拟节点存在， 使用这种方法来避免数据倾斜。

。。是的,是多次hash，我看到一种实现，hash(ip), for i in (0..3) { hash(ip + "#" + i); } 。。或者直接 for，不需要之前的 hash(ip)。

实际运用中，通常将 虚拟节点数 设置为 32 或更大， 这样，即使 很少的服务节点 也能做到相对均匀的 数据分布。


dubbo的lb中使用了 带虚拟节点的一致性hash。

redis集群 没有直接使用 一致性hash， 而是使用了 hash slot 的概念， 
redis 没有直接使用 hash算法，而是使用 crc16 校验算法。
slot 就是 空间的单位。
hash slot 的本质 和 一致性hash算法 非常相似，不同点 是 对于 hash空间的定义：
- 一致性hash的空间是一个 圆环，节点分布式基于圆环的，无法很好地控制数据分布，可能会产生数据倾斜
- slot 空间是自定义分配的，类似于window 盘分区的 概念。这种分区可以自定义大小，自定义位置。

redis集群包含了 16384 个hash slot，每个key 经过计算后 会落在一个具体的slot上， slot具体是在 哪个机器上，是用户 根据机器情况配置的， 性能差的 可以少分配一些。 所以 hash slot 很好地解决了 一致性hash的弊端。


### 一致性hash也用作lb

。。网上结束


虽然一致性hash提升了稳定性，使得 节点的加入和退出 不会导致 大规模的 数据迁移， 但是本质上，hash分片 是一种静态分片， 必须提前设置 分片的最大规模， 而且 无法避免 单一热点问题。

。。突然感觉 也就如此。。 分片的最大规模， 说明是 hash分片， 和 一致性hash 根本不是一回事。 一致性hash不需要设置 分片的最大规模，因为是 2^32-1，不可能超过的。 
。。单一热点的话，可以 监控 节点，如果 节点 过热，那么就 增加 节点。
。。不过 不太好 保证 这个新增的节点 能帮助 降低压力( 就是hash后位置 能出现在 热点数据的 区域内)。 难道还要增加一次 映射？
。。好吧，我的问题， 单一热点，是 单个产品 成为热点。 不是 单个节点成为热点。。。。++

无论如何hash，数据也只可能出现在 一个节点上，这会带来 热点请求问题。


## 如何解决单一热点

使用 range 分片。

range分片可以结合 业务逻辑规则。 比如，我们可以使用 Category (商品类目) 作为关键字进行分片时，对于商品多的品类可以按照 3级品类设置分片，对于商品少的，可以按照一级品类 进行分片，这样可以让 分片间的 数据更加平衡。

要达到这种灵活性，前提是要有能力控制数据流向哪个分区，
一个简单的实现方式是：预先设定主键的生成规则，根据规则进行数据的分片路由，但这种方式会侵入商品各条线主数据的业务规则
更好的方式是基于分片元数据，就是调用端在操作数据的时候，先问一下分片元数据系统数据在哪，然后在根据得到的地址操作数据。元数据中存储的是数据分片信息，分片信息就是数据分布情况。在一个分布式存储系统中，承担数据调度功能的节点是分片元数据，当客户端收到请求后，会请求分片元数据服务，获取分片对应的实际节点地址，才能访问真正的数据。而请求分片元数据获取的信息也不仅仅只有数据分片信息，还包括数据量、读写 QPS 和分片副本的健康状态等

这种方式的灵活性在于分片规则不固定，易扩展，但是高灵活性就会带来高复杂性，从存储的角度看，元数据也是数据，特殊之处在于它类似一个路由表，每一次请求都要访问它，所以分片元数据本身就要做到高可用。如果系统支持动态分片，那么分片信息的变更数据还要在节点之间进行同步，这又带来==多副本之间的一致性问题==

最直接的方式是专门给元数据做一个服务集群，并通过一致性算法复制数据。在实现方式上，就是将元数据服务的高可用和数据一致性问题转嫁给外围协调组件，如 ETCD 集群，这样既保证了系统的可靠，数据同步的成本又比较低。知道了设计思路，那具体的架构实现上怎么做 ？
- 给分片元数据做集群服务，并通过 ETCD 存储数据分片信息
- 每个数据存储实例节点定时向元数据服务集群同步心跳和分片信息。
- 当调用端的请求过来时，元数据服务节点只需要做好高可用和缓存即可


### 共识算法

如果面试官想挖掘你的能力，还会深入聊到共识算法，在一致性共识算法和最终一致性共识算法方面提出类似的问题

比如， ETCD 是如何解决数据共识问题的？为什么要选择这种数据复制方式呢？
思路是：清楚 ETCD 的共识算法是什么，还有哪些常用的共识算法，以及为什么 ETCD 会做这样的选型。

ETCD 的共识算法是基于 Raft 协议实现的强一致性算法，同类的强一致性算法还有 Paxos，在面试过程中，面试官很可能让你从自己的角度理解一下这两个算法，当然也会直接问：为什么没有选择 Paxos 而选择了 Raft ？
主要考核你对以下内容的理解
- Paxos 算法解决了什么问题？
- Basic Paxos 算法的工作流程是什么？
- Paxos 算法和 Raft 算法的区别又是什么？


在分布式系统中，造成系统不可用的场景很多，比如服务器硬件损坏、网络数据丢包等问题，解决这些问题的根本思路是多副本，副本是分布式系统解决高可用的唯一手段，也就是主从模式，那么如何在保证一致性的前提下，提高系统的可用性，Paxos 就被用来解决这样的问题，而 Paxos 又分为 Basic Paxos 和 Multi Paxos，然而因为它们的实现复杂，工业界很少直接采用 Paxos 算法，所以 ETCD 选择了 Raft 算法


Raft 算法对于 Leader 领导者的选举是有限制的，只有最全的日志节点才可以当选。


基于强一致性的共识机制还是可能存在性能的问题，有没有更好的架构思路呢？

既然要解决可用性的问题，根据 Base 理论，需要实现最终一致性，那么 Raft 算法就不适用了，因为 Raft 需要保证大多数节点正常运行后才能运行。这个时候，可以选择基于 Gossip 协议的实现方式。

Gossip协议原理有一种传播机制叫谣言传播，指的是当一个节点有了新数据后，这个节点就变成了活跃状态，并周期性地向其他节点发送新数据，直到所有的节点都存储了该条数据。这种方式达成的数据一致性是 “最终一致性”，即执行数据更新操作后，经过一定的时间，集群内各个节点所存储的数据最终会达成一致，很适合动态变化的分布式系统。


#### 总结
共识算法的选择和数据副本数量的多少息息相关，
- 如果副本少、参与共识的节点少，推荐采用广播方式，如 Paxos、Raft 等协议。
- 如果副本多、参与共识的节点多，那就更适合采用 Gossip 这种最终一致性协议。



## v5 高并发下，如何回答分布式事务一致性问题？

一个系统被拆分成多个子系统，要想完成一次写入操作，你需要同时协调多个系统，这就带来了分布式事务的问题

分布式事务是指：一次大的操作由多个小操作组成，这些小的操作分布在不同的服务器上，分布式事务需要保证这些小操作要么全部成功，要么全部失败

以京东旅行为例，早起的交易系统是通过 .NET 实现的，所有的 交易下单逻辑 都写在一个 独立的 系统中。
后来 用Java 重写了 核心系统，原本的系统 也被拆分为 多个 子系统，如：商品系统，促销系统，订单系统 等。

用户下单时，订单系统生成订单，商品系统 扣减库存，促销系统扣减优惠券，只有当 3个系统的 事务 都提交之后，才认为 此次下单成功。

### 分析
这是一个很典型的 分布式问题，解决方案也很多，有 ==两阶段提交协议（Two-Phase Commit，2PC）、3PC 、TCC 和基于消息队列的实现方式==。

在实际工作中，很少采用前几种方案，基本都是基于 MQ 的可靠消息投递的方式来实现。

因为 2PC 或 TCC 在工业界落地代价很大，不适合互联网场景，所以只有少部分的强一致性业务场景（如金融支付领域）会基于这两种方案实现。


### 2PC
2PC 是分布式事务==教父级==协议，它是==数据库领域==解决分布式事务最典型的协议。它的处理过程分为==准备和提交两个阶段==，每个阶段都由协调者（Coordinator）和参与者（Participant）共同完成

协调者就是事务管理器；参与者就是具体操作执行的资源管理器(一般指 数据库实例)。

Java 程序员都知道，XA 是由 X/Open 组织提出的分布式事务的规范，规范主要定义了事务管理器（Transaction Manager）和资源管理器（Resource Manager）之间的接口，
事务管理器负责全局事务的协调者，
资源管理器负责管理实际资源（如 MySQL、Oracle 等数据库）。
而Java 平台上事务规范 JTA（Java Transaction API）就是对 XA 分布式事务规范标准的实现。
例如在 Spring 中就通过 JtaTransactionManager 来配置分布式事务，然后通过管理多个 ResourceManager 来管理多个数据源，进而操作多个数据库之间的事务。

#### 准备阶段
事务管理器首先通知所有资源管理器开启事务，询问是否做好提交事务的准备。
如资源管理器此时会将 undo 日志和 redo 日志计入事务日志中，并做出应答，
当协调者接收到反馈 Yes 后，则准备阶段结束

#### 提交阶段

当收到所有数据库实例的 Yes 后，事务管理器会发出提交指令。
每个数据库接受指令进行本地操作，正式提交更新数据，然后向协调者返回 Ack 消息，事务结束。

#### 中断阶段

如果任何一个参与者向协调者反馈了 No 响应，
例如用户 B 在数据库 D3 上面的余额在执行其他扣款操作，导致数据库 D3 的数据无法锁定，则只能向事务管理器返回失败。
此时，协调者向所有参与者发出 Rollback 请求，参与者接收 Rollback 请求后，会利用其在准备阶段中记录的 undo 日志来进行回滚操作，并且在完成事务回滚之后向协调者发送 Ack 消息，完成事务==回滚==操作。


#### 缺点
2PC 在准备阶段会要求每个资源管理器进行资源锁定，如 MySQL 的行锁。
否则如果在提交阶段提交之前数据发生改变，就会出现数据不一致的情况。

导致 死锁，性能下降，数据不一致。



### 基于MQ的可靠消息投递方案

在应对高并发场景下的分布式事务问题时，一种方案通过放弃强一致性，而选择最终一致性，来提高系统的可用性。


#### MQ的自动ACK导致消息丢失，所以要手动ACK

#### 没有及时消费的消息积压在MQ队列中。
。。这个没有说，感觉视频中是认为和下面的问题一起的，但是我感觉2个问题还是有所差异的啊。

#### 高并发场景下消息积压导致消息丢失，通过数据库进行队列双向确认
上下游可能因为各种原因而导致消息丢失。
比如优惠券系统由于流量过大而触发限流，不能保证事件消息能够被及时地消费，这个消息就会被消息队列不断地重试，最后可能由于超过了最大重试次数而被丢弃到死信队列中。
。。但是 consume是主动consume的啊，限流后，consume也少了啊，除非限流的是下游，consume正常。
但实际上，你需要人工干预处理移入死信队列的消息，于是在这种场景下，事件消息大概率会被丢弃。而这个问题源于订单系统作为事件的生产者进行消息投递后，无法感知它下游（即优惠券系统）的所有操作，那么优惠券系统作为事件的消费者，是消费成功还是消费失败，订单系统并不知道

如果让订单知道消费执行结果的响应，即使出现了消息丢失的情况，订单系统也还是可以通过==定时任务==扫描的方式，将未完成的消息==重新投递来进行消息补偿==。
这是基于==消息队列实现分布式事务的关键==，是一种==双向消息确认==的机制。

可以先让订单系统把要发送的消息持久化到本地数据库里，然后将这条消息记录的状态设置为代发送，紧接着订单系统再投递消息到消息队列，优惠券系统消费成功后，也会向消息队列发送一个通知消息。当订单系统接收到这条通知消息后，再把本地持久化的这条消息的状态设置为完成。
。。幂等性，所以收到消息后，也要看下数据库是不是已经被处理了。



基于 MQ 的可靠消息投递的考核点是可落地性，所以你在回答时要抓住“双向确认”的核心原则，只要能实现生产端和消费端的双向确认，这个方案就是可落地了，又因为基于 MQ 来实现，所以天生具有业务解耦合流量削峰的优势。


在实际工作中，并不是所有的业务对事务一致性的要求都那么高。因为更高的要求意味着更多的成本，这也是很多架构复杂度来源之一，所以你要尽可能地站在业务实际场景的立足点来回答分布式事务问题。

。。不过我还是觉得 扣减优惠券 是需要 2PC的。 不太可能MQ吧。
。。评论中也有提到，多次消费优惠券，只能人工。。但 总不能 砍单吧。
。。还是感觉 2PC，毕竟 消费券就是一个 小功能，2PC应该不消耗很多。。对，之前说，加锁，性能下降之类的， 优惠券(这里是指 我自己的优惠券，不是公共的，需要抢的优惠券，不过后者应该没有了吧。即使有，也是 先抢好，变成 自己的优惠券，然后再 消费的) 并不是一个 竞争很激烈的 东西。 
。。或者说，完全不需要 分布式啊。 只需要在 提交订单的 时候(还没有支付) -1 优惠券，取消订单(放弃支付) 的时候 +1 优惠券 就可以了。  这样 就和 支付没有任何关系了啊。
。。而且 在提交订单的时候 就 -1优惠券，更好啊。


## v6 如何回答：分布式系统中锁的实现原理

分布式锁是解决协调分布式系统之间，同步访问共享资源的一种方式。

一些面试官会深挖==如何控制并发访问共享资源；如何解决资源争抢==等技术细节

场景：
为了防止商品库存超售，在并发场景下用到了分布式锁的机制，做商品扣减库存的串行化操作。然后问你：“你如何实现分布式锁？”你该怎么回答呢？
- 基于关系型数据库MySQL实现分布式锁
- 基于分布式缓存Redis实现分布式锁

setnx 和 expire 是不能 原子性的。需要使用 `set key value [EX seconds] [PX milliseconds] [NX|XX]`
EX是失效时长，单位秒
PX是失效时长，单位毫秒
NX：key不存在时设置 value，成功则返回 OK，失败返回 (nil)
XX：key存在时设置 value。

有些面试官会继续追问：“分布式锁用 Zookeeper 实现行不行？”，“分布式锁用 etcd 实现行不行？” 借机考察你对分布式协调组件的掌握
面试官提问的重点不是停留在组件的使用上，而是你对分布式锁的原理问题的掌握程度。


### 如果让借助第三方组件，你怎么设计分布式锁？
涉及了分布式锁的底层设计逻辑，是你需要掌握的

虽然你可以借助数据库 DB、Redis 和 ZooKeeper 等方式实现分布式锁，
但要设计一个分布式锁，就需要明确分布式锁经常出现哪些问题，以及如何解决。
- 可用性问题，无论何时都要保证锁服务的可用性（这是系统正常执行锁操作的基础）。
- 死锁问题，客户端一定可以获得锁，即使锁住某个资源的客户端在释放锁之前崩溃或者网络不可达（这是避免死锁的设计原则）
- 脑裂问题，集群同步时产生的数据不一致，导致新的进程有可能拿到锁，但之前的进程以为自己还有锁，那么就出现两个进程拿到了同一个锁的问题。


### 基于关系型数据库实现分布式锁

先查询数据库是否存在记录，为了防止幻读取
（幻读取：事务 A 按照一定条件进行数据读取，这期间事务 B 插入了相同搜索条件的新数据，事务 A 再次按照原先条件进行读取时，发现了事务 B 新插入的数据 ）
通过数据库行锁 `select for update` 锁住这行数据，然后将查询和插入的 SQL 在同一个事务中提交。

。。？锁住了，然后别人想释放都释放不了啊。 不，应该要锁的，乐观锁 或悲观锁。这里是 悲观锁。 释放的时候 只能无限 retry 了。。
。。不是。。别人锁住了，我锁不了的。。。。。。
。。确实， 先悲观锁，然后 判断是否有锁可获取，修改数据，然后update回去。

基于关系型数据库实现分布式锁比较简单，不过你要注意，基于 MySQL 行锁的方式会出现==交叉死锁==，比如事务 1 和事务 2 分别取得了记录 1 和记录 2 的排它锁，然后事务 1 又要取得记录 2 的排它锁，事务 2 也要获取记录 1 的排它锁，那这两个事务就会因为相互锁等待，产生死锁。

当然，你可以通过“==超时控制==”解决交叉死锁的问题，但在高并发情况下，出现的大部分请求都会排队等待，所以“基于关系型数据库实现分布式锁”的方式在性能上存在缺陷，所以如果你回答“基于关系型数据库 MySQL 实现分布式锁”，通常会延伸出下面两个问题
- 数据库的事务隔离级别
    四种隔离级别是 读未提交，读已提交，可重复读，可串行化，隔离级别越高，并发性能越差。
- 基于乐观锁的方式实现分布式锁
    `select amount, ver as old_v from order where order_id=xxx;`
    `update order set ver=old_v+1, amount=yyy where order_id=xxx and ver = old_v`
    如果更新结果的记录数为1，就表示成功，如果更新结果的记录数为 0，就表示已经被其他应用更新过了，需要做异常处理。


### 基于分布式缓存实现分布式锁

`set lock_key unique_value NX PX 10000`

解锁的过程就是将 lock_key 键删除，但不能乱删，要保证执行操作的客户端就是加锁的客户端。
而这个时候， unique_value 的作用就体现出来，实现方式可以==通过 lua 脚本判断 unique_value 是否为加锁客户端==。

```Lua
if redis.call("get", KEYS[1]) == ARGV[1] then
    return redis.call("del", KEYS[1])
else
    return 0
end
```
选用 Lua 脚本是为了保证解锁操作的原子性。因为 Redis 在执行 Lua 脚本时，可以以原子性的方式执行，从而保证了锁释放操作的原子性

以上，就是基于 Redis 的 SET 命令和 Lua 脚本在 Redis ==单节点==上完成了分布式锁的加锁、解锁，
不过在实际面试中，你不能仅停留在操作上，因为这并不能满足应对面试需要掌握的知识深度，
所以你还要清楚:
- 基于 Redis 实现分布式锁的优缺点；
- Redis 的超时时间设置问题；
- 站在架构设计层面上 Redis 怎么解决集群情况下分布式锁的可靠性问题。

你不用一股脑全部将其说出来，而是要做好准备，以便跟上面试官的思路，同频沟通。


### 基于Redis的分布式锁的优缺点

优点3个
- 性能高效，这是选择缓存实现分布式锁最核心的出发点
- 实现方便，要选型 Redis 2.6.12 后的版本或通过 Lua 脚本执行加锁和设置超时时间。2.6.12之前 设置锁 和 设置过期 是2个操作，不是原子性的。
- 避免单点故障

。。2.6.12？ 是的。
从Redis 2.6.12 版本开始 SET 可以代替 SETNX 从Redis 2.6.12 版本开始,SET 命令增加了以下选项: EX seconds :设置键的过期时间,单位为秒。 PX milliseconds


缺点
- 不合理设置超时时间
- Redis集群数据同步机制 (AP)

一个线程 A 获取到了锁之后，由于业务代码执行时间可能比较长，导致超过了锁的超时时间，自动失效，后续线程 B 又意外的持有了锁，当线程 A 再次恢复后，通过 del 命令释放锁，就错误的将线程 B 中同样 key 的锁误删除了。
。。unique_value 是 每个线程 唯一， 应该就能 阻止 A 删除 B的lock 了。
。。锁的超时 这个没有办法，心跳吗？线程无法一边 处理业务，一边维护心跳的。 不知道有没有 伴生线程 这种概念。哈哈。 意义不太大。 擦，下面。

合理设置超时时间，是基于缓存实现分布式锁很难解决的一个问题。
你可以基于续约的方式设置超时时间：先给锁设置一个超时时间，然后启动一个==守护线程==，让守护线程在一段时间后，重新设置这个锁的超时时间。实现方式就是：写一个守护线程，然后去判断锁的情况，当锁快失效的时候，再次进行续约加锁，当主线程执行完成后，销毁续约锁即可。


如何解决集群情况下分布式锁的可靠性
Redis 官方已经设计了一个分布式锁算法 Redlock 解决了这个问题。

Redlock 算法的基本思路，是让客户端和多个独立的 Redis 实例依次请求申请加锁，如果客户端能够和半数以上的实例成功地完成加锁操作，那么我们就认为，客户端成功地获得分布式锁，否则加锁失败。

。。但是，每台redis上 过期时间有 微小的差异啊。 而且 性能呢？ 还有 集群同步的时候，是怎么 解决 这种 冲突的？
。。不，应该都是在 master 节点上进行的，但是这里说 多个独立redis实例。。。算了。

在设计分布式锁的时候，为了解决可用性、死锁、脑裂等问题，一般还会再考虑一下锁的四种设计原则。
- 互斥性，分布式系统环境下，对于某一共享资源，需要保证在同一时间只能一个线程或进程对该资源进行操作。
- 高可用，锁服务不能有单点风险，要保证分布式锁系统是集群的
- 锁释放，具备锁失效机制，防止死锁
- ==可重入==，一个节点获取了锁之后，还可以再次获取整个锁资源




## v7 RPC: 如何在面试中展现"造轮子"的能力

很多应用系统发展到一定规模之后，都会向着服务化方向演进，演进后的单体系统就变成了由一个个微服务组成的服务化系统，各个微服务系统之间通过远程 RPC 调用的方式通信。

主流的 RPC 框架很多，比如 Dubbo、Thrift、gRPC 等

面试问题存在一个误区，认为面试官只会问这样几个问题：
- RPC 的一次调用过程是怎样的？
- RPC 的服务发现是如何实现的？
- RPC 的负载均衡有哪些？

这些问题看似专业，却很容易搜索到答案，如果作为面试题很难区分候选人的技术能力

场景：
在电商 App 商品详情页中，用户每次刷新页面时，App 都会请求业务网关系统，并由网关系统远程调用多个下游服务（比如商品服务、促销服务、广告服务等）。

问
“对于整条 RPC 调用链路（从 App 到网关再到各个服务系统），怎么设置 RPC 的超时时间，要考虑哪些问题？”

App 远程调用网关系统的超时时间要大于网关系统调用后端各服务的超时时间之和。这样至少能保证在网关与下游服务的每个 PRC 调用执行完成之前不超时。 这个回答 基本是不合格的

PRC 接口的超时设置看似简单，但其中却涉及了很多技术层面的问题。比如 RPC 都有超时重传的机制，如果后端服务触发超时重传，这时对 App 来说，也会存在请求等待超时的风险，就会出现后端服务还没来得及做降级处理，商品详情页就已经等待超时了

问题
- 即使考虑到整个调用链的平均响应时长会受到所有依赖服务的耗时和重传次数影响，那么依据什么来设置 RPC 超时时间和重试次数呢？
- 如果发生超时重传，怎么区分哪些 RPC 服务可重传，哪些不可重传呢？
- 如果请求超过了 PRC 的重传次数，一般会触发服务降级，这又会对商品详情页造成什么影响？

### TP99

解题思路
- 结合 TP99 请求耗时：首先如果你要回答“超时时间设置和重传次数问题”，需要根据每一个微服务 TP99 的请求耗时，以及业务场景进行综合衡量。
- RPC 调用方式：你要站在业务场景下，讲清楚网关调用各下游服务的串并行方式，服务之间是否存在上下服务依赖。
- 分析核心服务：分析出哪些是核心服务，哪些是非核心服务，核心服务是否有备用方案，非核心服务是否有降级策略


商品详情页的 QPS 已达到了 2 万次/s，在做了服务化拆分之后，此时完成一次请求需要调用 3 次 RPC 服务，计算下来，RPC 服务需要承载大概 6 万次/s 的请求。那么你怎么设计 RPC 框架才能承载 6 万次/s 请求量呢？
。。就是商品详情页 会 通过RPC 分别调用 商品服务，促销服务，广告服务。 所以 * 3

建议你从两个角度分析
- 优化 RPC 的网络通信性能：高并发下选择高性能的网络编程 I/O 模型。
- 选型合适的 RPC 序列化方式：选择合适的序列化方式，进而提升封包和解包的性能。


一些同学虽然做了准备，但只能说出个别 RPC 框架的大致流程，不能深刻理解每个环节的工作原理，所以整体给我的感觉就是：应用层面通过，原理深度不够


### 完成的RPC流程

- 网络通信，要保证可靠性，所以一般使用 TCP
- 网络只能传输 二进制数据，所以要 序列化 和 反序列化。
- 网络传输中，拆包。粘包，半包。需要约定传输数据的格式。 大多数协议分别 数据头 和 消息体，
  - 数据头一般用于身份识别，包括协议标识、数据大小、请求类型、序列化类型等信息；
  - 消息体主要是请求的业务参数信息和扩展属性等。

完整的RPC步骤
- 调用方持续把请求参数对象序列化成二进制数据，经过 TCP 传输到服务提供方；
- 服务提供方从 TCP 通道里面接收到二进制数据；
- 根据 RPC 协议，服务提供方将二进制数据分割出不同的请求数据，经过反序列化将二进制数据逆向还原出请求对象，找到对应的实现类，完成真正的方法调用；
- 然后服务提供方再把执行结果序列化后，回写到对应的 TCP 通道里面；
- 调用方获取到应答的数据包后，再反序列化成应答对象。


RPC 通信流程中的==核心==组成部分包括了==协议、序列化与反序列化，以及网络通信==

### 序列化方式
- JSON，Key-Value 结构的文本序列化框架，易用且应用最广泛，基于 HTTP 协议的 RPC 框架都会选择 JSON 序列化方式，但它的空间开销很大，在通信时需要更多的内存
- Hessian，一种紧凑的二进制序列化框架，在性能和体积上表现比较好。
- Protobuf，Google 公司的序列化标准，序列化后体积相比 JSON、Hessian 还要小，兼容性也做得不错。

考虑时间与空间开销，切勿忽略兼容性。 当然还有安全性、易用性等指标，不过并不是 RPC 的关键指标。


### 如何提升网络通信性能
翻译一下就是：一个 RPC 框架如何选择高性能的网络编程 I/O 模型？

网络编程中的五个 I/O 模型：
- 同步阻塞IO，BIO
- 同步非阻塞IO
- IO多路复用，NIO
- 信号驱动
- 异步IO，AIO

最常用 BIO， NIO

BIO
```Java
public class BIOServer {
    ServerSocket ss = new ServerSocket();
    ss.bind(new InetSocketAddress("localhost", 9090));
    sysout("server start... " + 9090);

    try {
        Socket s = null;
        while (true) {
            s = ss.accept();
            new Thread(new ServerTaskThread(s)).start();
        }
    } catch (Exception e) {

    } finally {
        if (ss != null) {
            ss.close();
            ss = null;
        }
    }
}

public class ServerTaskThread implements Runnable {
    // ...
    while (true) {
        String readLine = in.readLine();
        if (readLine == null)
            break;
        // ...
    }
    // ...
}
```

所以BIO中
每当客户端发送一个连接请求给服务端，服务端都会启动一个新的线程去处理客户端连接的读写操作，即每个 Socket 都对应一个独立的线程，
客户端 Socket 和服务端工作线程的数量是 ==1 比 1==，
这会导致服务器的资源不够用，无法实现高并发下的网络开发。
所以 BIO 的网络模型只适用于 Socket 连接不多的场景，无法支撑几十甚至上百万的连接场景。

有2处阻塞
服务端阻塞等待客户端发起连接。在第 11 行代码中，通过 serverSocket.accept() 方法服务端==等待用户发连接请求==过来。
连接成功后，工作线程阻塞读取客户端 Socket 发送数据。在第 27 行代码中，通过 in.readLine() 服务端从网络中==读客户端发送过来的数据==，这个地方也会阻塞。如果客户端已经和服务端建立了一个连接，但客户端迟迟不发送数据，那么服务端的 readLine() 操作会一直阻塞，造成资源浪费。


NIO
用一个线程处理多个连接，使得每一个工作线程都可以处理多个客户端的 Socket 请求，
这样工作线程的利用率就能得到提升，所需的工作线程数量也随之减少。
此时 NIO 的线程模型就变为 ==1 个工作线程对应多个客户端 Socket 的请求==，这就是所谓的 I/O多路复用。

当图中的客户端 A 的输入已经准备好后，就由这个调度者去通知服务端的工作线程，告诉它们由工作线程 1 去服务于客户端 A 的请求。这种思路就是 NIO 编程模型的基本原理，==调度者就是 Selector 选择器==。

在目前主流的 RPC 框架中，广泛使用的也是 I/O 多路复用模型，Linux 系统中的 select、poll、epoll等系统调用都是 I/O 多路复用的机制。


对于高级研发工程师的考察，还会有两个技术扩展考核点。
- Reactor 模型（即反应堆模式），以及 Reactor 的 3 种线程模型，分别是单线程 Reactor 线程模型、多线程 Reactor 线程模型，以及主从 Reactor 线程模型。
- Java 中的高性能网络编程框架 Netty。

在高性能网络编程中，大多数都是基于 Reactor 模式，其中最为典型的是 Java 的 Netty 框架，而 Reactor 模式是基于 I/O 多路复用的，所以，对于 Reactor 和 Netty 的考察也是避免不了的。


一个产品级别的 RPC 框架的开发，除了要具备网络通信、序列化和反序列化、协议等基础的功能之外，还要具备如连接管理、负载均衡、请求路由、熔断降级、优雅关闭等高级功能的设计，虽然这些内容在面试中不要求你掌握，但是如果你了解是可以作为加分项的，例如连接管理就会涉及连接数的维护与服务心跳检测




## v8 MQ：如何回答消息队列的丢失，重复，积压问题

在使用 MQ 的时候，怎么确保消息 100% 不丢失？

场景
以京东系统为例，用户在购买商品时，通常会选择用京豆抵扣一部分的金额，在这个过程中，交易服务和京豆服务通过 MQ 消息队列进行通信。在下单时，交易服务发送“扣减账户 X 100 个京豆”的消息给 MQ 消息队列，而京豆服务则在消费端消费这条命令，实现真正的扣减操作。


### 使用MQ的目的
在互联网面试中，引入 MQ 消息中间件最直接的目的是：做==系统解耦合，流量控制==，追其根源还是为了解决互联网系统的高可用和高性能问题。

系统解耦：用 MQ 消息队列，可以隔离系统上下游环境变化带来的不稳定因素，比如京豆服务的系统需求无论如何变化，交易服务不用做任何改变，即使当京豆服务出现故障，主交易流程也可以将京豆服务降级，实现交易服务和京豆服务的解耦，做到了系统的高可用

流量控制：遇到秒杀等流量突增的场景，通过 MQ 还可以实现流量的“削峰填谷”的作用，可以根据下游的处理能力自动调节流量

### MQ问题
引入 MQ 虽然实现了系统解耦合流量控制，也会带来其他问题。
影响系统之间数据传输的一致性。
消费端处理能力不足从而导致消息积压


### 考点
其中的几个考点
- 如何知道有消息丢失？
- 哪些环节可能丢消息？
- 如何确保消息不丢失？

一条消息从生产到消费完成这个过程，可以划分三个阶段，分别为==消息生产阶段，消息存储阶段和消息消费阶段==。

消息生产阶段
从消息被生产出来，然后提交给 MQ 的过程中，只要能正常收到 MQ Broker 的 ack 确认响应，就表示发送成功，所以只要处理好返回值和异常，这个阶段是不会出现消息丢失的。

消息存储阶段
这个阶段一般会直接交给 MQ 消息中间件来保证，但是你要了解它的原理，比如 Broker 会做副本，保证一条消息至少同步两个节点再返回 ack（这里涉及数据一致性原理，我在 04 讲中已经讲过，在面试中，你可以灵活延伸）。

消息消费阶段
消费端从 Broker 上拉取消息，只要消费端在收到消息后，不立即发送消费确认给 Broker，而是等到执行完业务逻辑后，再发送消费确认，也能保证消息的不丢失。

方案看似万无一失，每个阶段都能保证消息的不丢失，但在分布式系统中，故障不可避免，作为消费生产端，你并不能保证 MQ 是不是弄丢了你的消息，消费者是否消费了你的消息，所以，本着 Design for Failure 的设计原则，你还是需要一种机制，来 Check 消息是否丢失了。

#### 怎么进行消息检测
在消息生产端，给每个发出的消息都指定一个全局唯一 ID，或者附加一个连续递增的版本号，然后在消费端做对应的版本校验。
可以利用拦截器机制。在生产端发送消息之前，通过拦截器将消息版本号注入消息中（版本号可以采用连续递增的 ID 生成，也可以通过分布式全局唯一 ID生成）。然后在消费端收到消息后，再通过拦截器检测版本号的连续性或消费状态，这样实现的好处是消息检测的代码不会侵入到业务代码中，可以通过单独的任务来定位丢失的消息，做进一步的排查。

如果同时存在多个消息生产端和消息消费端，通过版本号递增的方式就很难实现了，因为不能保证版本号的唯一性，此时只能通过全局唯一 ID 的方案来进行消息检测，具体的实现原理和版本号递增的方式一致。


你已经知道了哪些环节（消息存储阶段、消息消费阶段）可能会出问题，并有了如何检测消息丢失的方案，然后就要给出解决防止消息丢失的设计方案。解决方案你可以参考 05 讲中的 “基于 MQ 的可靠消息投递”的机制

#### 如何解决重复消费
回答完“如何确保消息不会丢失？”之后，面试官通常会追问“怎么解决消息被重复消费的问题？”
换一种说法，就是如何解决消费端幂等性问题

最简单的实现方案，就是在数据库中建一张消息日志表， 这个表有两个字段：消息 ID 和消息执行状态。这样，我们消费消息的逻辑可以变为：在消息日志表中增加一条消息记录，然后再根据消息记录，异步操作更新用户京豆余额。
因为我们每次都会在插入之前检查是否消息已存在，所以就不会出现一条消息被执行多次的情况，这样就实现了一个幂等的操作。当然，基于这个思路，不仅可以使用关系型数据库，也可以通过 Redis 来代替数据库实现唯一约束的方案。

要解决“消息丢失”和“消息重复消费”的问题，有一个前提条件就是要实现一个全局唯一 ID 生成的技术方案。这也是面试官喜欢考察的问题，你也要掌握。

#### 全局唯一ID生成策略
在分布式系统中，全局唯一 ID 生成的实现方法有数据库自增主键、UUID、Redis，Twitter-Snowflake 算法

|方案|顺序性|重复性|存在问题|
|--|--|--|--|
|数据自增主键|递增|不会重复|数据库宕机不可用|
|UUDI|无序|随机字符重复概率极低|一直可用|
|Redis|递增|RDB持久化模式下，会出现重复|Redis宕机不可用|
|SnowFlake|递增|不会重复|时钟回拨|

无论哪种方法，如果你想同时满足简单、高可用和高性能，就要有取舍，所以你要站在实际的业务中，说明你的选型所考虑的平衡点是什么。我个人在业务中比较倾向于选择 Snowflake 算法，在项目中也进行了一定的改造，主要是让算法中的 ID 生成规则更加符合业务特点，以及优化诸如时钟回拨等问题。

#### 消息积压
除了“怎么解决消息被重复消费的问题？”之外，面试官还会问到你“消息积压”

如果出现积压，那一定是性能问题，想要解决消息从生产到消费上的性能问题，就首先要知道哪些环节可能出现消息积压，然后在考虑如何解决。

因为消息发送之后才会出现积压的问题，所以和消息生产端没有关系，又因为绝大部分的消息队列单节点都能达到每秒钟几万的处理能力，相对于业务逻辑来说，性能不会出现在中间件的消息存储上面。毫无疑问，出问题的==肯定是消息消费阶段==

##### 生产
如果是线上突发问题，要临时扩容，增加消费端的数量，与此同时，降级一些非核心的业务。通过扩容和降级承担流量，这是为了表明你对应急问题的处理能力。

其次，才是排查解决异常问题，如通过监控，日志等手段分析是否消费端的业务逻辑代码出现了问题，优化消费端的业务处理逻辑。

如果是消费端的处理能力不足，可以通过==水平扩容==来提供消费端的并发处理能力
。。水平扩容是增加app实例？应该是的，下面是 扩容消费者

这里有一个考点需要特别注意，那就是在扩容消费者的实例数的同时，必须==同步扩容==主题 Topic 的分区数量，==确保消费者的实例数和分区数相等==。如果消费者的实例数超过了分区数，由于分区是单线程消费，所以这样的扩容就没有效果。

比如在 Kafka 中，一个 Topic 可以配置多个 Partition（分区），数据会被写入到多个分区中，但在消费的时候，Kafka 约定==一个分区只能被一个消费者消费==，Topic 的分区数量决定了消费的能力，所以，可以通过增加分区来提高消费者的处理能力。


### 消息中间件的其他知识体系

- 如何选项消息中间件
- 消息中间件中的队列模型与发布订阅模型的区别
- 为什么消息队列可以实现高吞吐
- 序列化，传输协议，内存管理




## 案例串联，如何让系统抗住双11的预约抢购活动？

抢购系统大约4个阶段
- 商品预约，用户进入商品详情页面，获取购买资格，并等待商品抢购倒计时。
- 等待抢购，等待商品抢购倒计时，直到商品开放抢购
- 抢购，商品抢购倒计时结束，用户提交抢购订单，排队等待抢购结果，抢购成功后，扣减系统库存，生成抢购订单。
- 支付，等待用户支付成功后，系统更新订单状态，通知用户购买成功


### 商品预约
很多电商平台为了方便流量运营，改造了传统秒杀场景，通过先预约再抢购的方式预热商品，并根据预约量调整运营策略。而且在预约抢购的活动中，为了增加商品售卖量，会允许抢购前，预约资格超过实际的库存数量

如何在高并发量的情况下，让每个用户都能得到抢购资格呢？
可以基于“06 | 分布式系统中，如何回答锁的实现原理？”来控制抢购资格的发放

我们基于 Redis 实现分布式锁（这是最常用的方式），在加锁的过程中，实际上是给 Key 键设置一个值，为避免死锁，还要给 Key 键设置一个过期时间
`SET lock_key unique_value NX PX 10000`

解锁的过程就是将 lock_key 键删除，但不能乱删，要保证执行操作的客户端就是加锁的客户端。而这个时候， unique_value 的作用就体现出来，你可以通过 Lua 脚本判断 unique_value 是否为加锁客户端。

通过使用 SET 命令和 Lua 脚本在 Redis 单节点上完成了分布式锁的加锁和解锁。但你要注意，此方案是基于单节点的 Redis 实例实现的

基于 Redis 实现分布式锁时，你还要掌握如何保证锁的可靠性，也就是怎么基于多个 Redis 节点实现分布式锁（这部分也可以参考 06 讲中的内容）。

### 等待抢购
用户预约成功之后，在商品详情页面中，会存在一个抢购倒计时，这个倒计时的初始时间是从服务端获取的，用户点击购买按钮时，系统还会去服务端验证是否已经到了抢购时间。

大部分用户会频繁刷新商品详情页，商品详情页面的读请求量剧增

如何解决等待抢购时间内的流量突增问题呢？有两个解决思路
- 页面静态化，提前对抢购商品的详情页面做静态化，生成一个静态页面，再把页面放到距离用户最近的 CDN 节点中，这样一来，当浏览器访问页面时，就会自动缓存该页面的静态资源文件（对于静态化技术，很多页面端的模板引擎都支持这样的功能，我就不展开讲了）
- 服务端限流，如果使用 Nginx 来做反向代理，可以直接==基于 Nginx 配置限流算法==，比如 Nginx 的 ngx_http_limit_req_module（限制单位时间内所有 IP 的请求数量）和 ngx_stream_limit_conn_module（限制单位时间内单个 IP 的请求数量）两个模块就提供了限流控制的功能，所以你还要提前掌握限流策略的原理，如令牌桶算法的原理。



### 抢购

短时间之内提交订单的写流量非常高，所以为了做流量削峰，会将提单请求暂存在消息队列中，并提示用户“抢购排队中……”然后再由后端服务异步处理用户的请求。

可以基于数据库和缓存两种方式，来实现校验库存和扣减库存的操作

因为抢购场景的瞬时流量极高，一般不会直接基于数据库来实现
如果非要基于数据库的话，你要通过分布式锁来优化扣减库存的并发操作，但此阶段的分布式锁对可靠性的要求会极高（因为在大促抢购阶段，小的可用性故障，都可能造成大的线上事故），所以基于单节点 Redis 实现的分布式锁不合适，你要选择多节点 Redis 实现分布式锁，或者选型 ZooKeeper。

一般基于缓存来存储库存，实现扣减库存的操作。这样在提交订单时，库存的查询和锁定就不会给数据库带来性能瓶颈。不过你仍要注意，基于缓存（如 Redis）的库存扣减操作，仍要考虑缓存系统的单点问题，就算是多节点存储库存，也要引入锁的策略，保证 Redis 实现库存的一致性

实现了校验库存和扣减库存之后，最后一步是生成抢购订单。由于数据库表会承载订单数据，一旦出现瞬时流量，磁盘 I/O、数据库请求连接数等资源都会出现性能瓶颈，你可以考虑对订单表分库分表，通过对用户 ID 字段进行 Hash 取模，实现==分库分表==，提高系统的并发能力。

从“商品抢购阶段的架构设计”中我们可以总结出三个技术考点：
- 流量削峰、MQ进行异步化， 参考08
- 扣减库存、Redis单点问题，主从切换导致的数据不一致， 参考06
- 分库分表。参考04讲


还有一个容易忽略的问题：带宽的影响。由于抢购入口的请求量会非常大，可能会占用大量带宽，为了不影响提交订单的请求，有时会从网络工程的角度解决，通过单独的子域名绑定独立的网络服务器，这里就会涉及 DNS 的设计与优化手段。

在用户支付订单完成之后，一般会由支付平台回调系统接口，更新订单状态。在支付回调成功之后，抢购系统还会通过异步通知的方式，实现订单更新之外的非核心业务处理，比如积分累计、短信通知等，此阶段可以基于 MQ 实现业务的异步操作


总的来说，
互联网中大数据里的存储设计（如商品与订单数据的存储设计），你可以参考 04 讲；
关于秒杀或抢购场景下的库存扣减设计，你可以参考 06 讲；
分布式系统之间的事务一致性的架构设计，你可以参考 05 讲；
关于架构设计中的服务强依赖的设计，一般会通过 RPC 远程同步调用的方式实现，你可以参考07讲；
系统解耦，流量削峰的设计问题，你可以参考 08讲。



## v9 如何回答MySQL的索引原理与优化问题？

针对下面这条 SQL，你怎么通过索引来提高查询效率呢？
`select * from order where status=1 order by create_time asc`

给 status 建立一个索引

更优的方式是建立一个 status 和 create_time 组合索引，这是为了避免 MySQL 数据库发生文件排序。因为在查询时，你只能用到 status 的索引，但如果要对 create_time 排序，就要用==文件排序 filesort==，也就是在 SQL 执行计划中，Extra 列会出现 Using filesort。

通过索引知识来考察候选人，并扩展出 MySQL 索引原理与优化策略的一系列问题，比如：
- 数据库索引底层使用的是什么数据结构和算法呢？
- 为什么 MySQL InnoDB 选择 B+Tree 当默认的索引数据结构？
- 如何通过执行计划查看索引使用详情？
- 有哪些情况会导致索引失效？
- 平时有哪些常见的优化索引的方法？

总结起来就是如下几点：
- 理解 MySQL InnoDB 的索引原理；
- 掌握 B+Tree 相比于其他索引数据结构（如 B-Tree、二叉树，以及 Hash 表）的优势；
- 掌握 MySQL 执行计划的方法；
- 掌握导致索引失效的常见情况；
- 掌握实际工作中常用的建立高效索引的技巧（如前缀索引、建立覆盖索引等）。


### MySQL InnoDB 的索引原理

从数据结构的角度来看， MySQL 常见索引有 B+Tree 索引、HASH 索引、Full-Text 索引。
MySQL 常见的存储引擎 InnoDB、MyISAM 和 Memory，下标是这些引擎支持的索引类型

本次只讲 InnoDB

|-|InnoDB|MyISAM|Memory|
|--|--|--|--|
|B+Tree Index| T | T | T |
|Hash Index| F | F | T |
|Full Text Index| F | T | F |

。。。InnoDB 只有 B+ 啊。。。

InnoDB 是MySQL 建表时的默认存储引擎。
建表时，InnoDB 默认使用 表的 主键 作为 主键索引，该主键索引就是==聚簇索引== clustered index。
如果没有主键， InnoDB 自己生成 一个 隐藏的 6个字节的 主键ID值 作为 主键索引。
创建主键索引，默认使用 B+ 树


首先，创建商品表
```SQL
CREATE TABLE `product`  (
  `id` int(11) NOT NULL,
  `product_no` varchar(20)  DEFAULT NULL,
  `name` varchar(255) DEFAULT NULL,
  `price` decimal(10, 2) DEFAULT NULL,
  PRIMARY KEY (`id`) USING BTREE
) CHARACTER SET = utf8 COLLATE = utf8_general_ci ROW_FORMAT = Dynamic;
```
新增一些数据
![c4ba175737b91a169149aa20b3582eb5.png](../_resources/c4ba175737b91a169149aa20b3582eb5.png)

查询SQL
`select * from product where id = 15`


我们假设一个B+树，有3个子节点。
每一层的父节点的数据值都会出现在 下一层的子节点中。因此，在叶子节点中，包含了所有的 数据。并且，每个叶子节点都指向 下一个叶子节点，形成一个链表。

![15a81c544c37f9e3006e344e01c2339b.png](../_resources/15a81c544c37f9e3006e344e01c2339b.png)


### 回表

聚集索引(主键索引) 的B+树 的叶子节点 保存了数据。
二级索引/辅助索引 (secondary index) 的B+树，叶子节点保存的是 主键值， 找到主键值后，再去 主键index的 B+ 数中查询 叶子节点，然后取得 整行数据。这个过程 叫 ==回表==。

### 为什么使用B+树 作为index数据结构

#### B+ vs B

B+ 只在叶子节点保存数据，B树 非叶子节点也要保存数据。所以B+ 的 单个节点的 数据量更小，相同的磁盘IO次数下，能查询更多的节点。
。。

B+ 的叶子节点 是 双链表 连接，适合 基于范围的 顺序查找， B树 不行。

#### B+ vs BinarySearch
B+的复杂度是 O(logN / logd), 在实际应用中，d>100，这样，即使数据 是千万级别，B+ 高度依然维持在 3-4 层。

#### B+ vs Hash
Hash 不能 范围查询



### 执行计划

商品信息表
```SQL
CREATE TABLE `product`  (
  `id` int(11) NOT NULL,
  `product_no` varchar(20)  DEFAULT NULL,
  `name` varchar(255) DEFAULT NULL,
  `price` decimal(10, 2) DEFAULT NULL,
  PRIMARY KEY (`id`) USING BTREE,
  KEY 'index_name' ('name').
  KEY 'index_id_name' ('id', 'name')
) CHARACTER SET = utf8 COLLATE = utf8_general_ci
```

表中有，主键索引，name的普通index， id+name 的联合index。

一条简单查询语句 及 执行计划：
![608a67e75584445d54b2cf8f36cac79a.png](../_resources/608a67e75584445d54b2cf8f36cac79a.png)

执行计划中：possible_keys 表示 可能用到的索引， key表示 实际用到的 index，key_len 表示 index的长度， rows 表示扫描的数据行数。

需要==重点关注type字段==，表示 数据扫描类型，即为找到数据 而使用的 扫描方式，常见的 扫描类型的 执行效率 从低到高：
- all：全表扫描
- index：全索引扫描
- range：索引范围扫描
- ref：非唯一index扫描
- eq_ref：唯一index扫描
- const：结果只有一条的 主键或 唯一index 扫描

### 索引失效

例子
![83f5c423670d37d9f6ce13e35a746c26.png](../_resources/83f5c423670d37d9f6ce13e35a746c26.png)

失效原因：
当MySQL优化器根据name like '%路由器' 这个条件，到 index_name 这个索引 上进行 查询评估时， 发现当前节点的 所有子节点 上的值 都可能 符合 '%路由器'，于是 优化器 判定 当前index 需要 扫描 整个index，并且还要 回表查询，不如直接 全表扫描。

还有其他的索引失效的情况
- 索引列上做了 计算，函数，类型转换操作，这些情况下 index 失效是因为 查询过程 需要 扫描整个index 并回表，代表高于 全表扫描。
- like 匹配使用了前缀匹配符 '%abc'
- 字符串不加引号导致类型转换

如果 MySQL 查询优化器预估走索引的代价比全表扫描的代价还要大，则不走对应的索引，直接全表扫描，如果走索引比全表扫描代价小，则使用索引。


### 常见index优化方法

- 前缀索引优化
前缀index，就是使用 某个字段中，字符串的前几个 字符建立index，
使用前缀索引是为了减小索引字段大小，可以增加一个索引页中存储的索引值，有效提高索引的查询速度。在一些大字符串的字段作为索引时，使用前缀索引可以帮助我们减小索引项的大小
前缀索引有一定的局限性，例如 order by 就无法使用前缀索引，无法把前缀索引用作覆盖索引。


- 覆盖索引优化
覆盖索引是指 SQL 中 query 的所有字段，在索引 B+tree 的叶子节点上都能找得到的那些索引，从辅助索引中查询得到记录，而不需要通过聚簇索引查询获得。假设我们只需要查询商品的名称、价格，有什么方式可以避免回表呢？

我们可以建立一个组合索引，即商品ID、名称、价格作为一个组合索引。如果索引中存在这些数据，查询将不会再次检索主键索引，从而避免回表。所以，使用覆盖索引的好处很明显，即不需要查询出包含整行记录的所有信息，也就减少了大量的 I/O 操作。


- 联合索引
联合索引时，存在最左匹配原则，也就是按照最左优先的方式进行索引的匹配。比如联合索引 (userpin, username)，如果查询条件是 WHERE userpin=1 AND username=2，就可以匹配上联合索引；或者查询条件是 WHERE userpin=1，也能匹配上联合索引，但是如果查询条件是 WHERE username=2，就无法匹配上联合索引。

另外，建立联合索引时的字段顺序，对索引效率也有很大影响。越靠前的字段被用于索引过滤的概率越高，实际开发工作中建立联合索引时，要把==区分度大的字段排在前面==，这样区分度大的字段越有可能被更多的 SQL 使用到。

区分度就是某个字段 column 不同值的个数除以表的总行数，比如性别的区分度就很小，不适合建立索引或不适合排在联合索引列的靠前的位置，而 uuid 这类字段就比较适合做索引或排在联合索引列的靠前的位置。


### 总结

容易在面试中被问到的，索引的使用原则

什么时候使用index
- 字段有唯一性限制的时候，比如商品编码
- 经常用于 where 查询条件的字段
- 经常用于 group by 和 order by 的字段

什么时候不需要创建index
- where, group by, order by 中用不到的字段
- 字段中存在大量重复数据
- 表数据太少
- 经常更新的字段，避免index 的维护成本高。

什么情况下index失效
- 索引进行了表达式计算
- 索引使用了 函数
- like %xx
- 联合索引，注意最左原则
- 为了更好利用index， 索引列 要设置为 not null 约束


index带来的问题：
- 数据的写入延迟
- 额外的空间消耗
- 海量数据下，通过索引提升查询效率也是有限的

考虑其他方案
- 读写分离
- 分库分表





## v10 如何回答MySQL的事务隔离级别和锁的机制？

事务隔离级别：当多个线程操作数据库时，数据库要负责隔离操作，来保证各个线程在获取数据时的准确性。它分为四个不同的层次，按隔离水平高低排序，读未提交 < 读已提交 < 可重复度 < 串行化。

读未提交：可能发生 脏读，不可重复度，幻读。 实际项目中，没有人使用。性能最高。

读已提交：保证事务不出现中间状态的数据，所有的数据都是已提交且更新的，解决了脏读的问题。允许事务间可并发修改数据，所以不保证再次读取时能得到同样的数据，也就是还会存在不可重复读、幻读的可能

可重复度：MySQL InnoDB 引擎的默认隔离级别，保证同一个事务中多次读取数据的一致性，解决脏读和不可重复读，但仍然存在幻读的可能。

可串行化：选择“可串行化”意味着读取数据时，需要获取共享读锁；更新数据时，需要获取排他写锁；如果 SQL 使用 WHERE 语句，还会获取区间锁。换句话说，事务 A 操作数据库时，事务 B 只能排队等待，因此性能也最低。


### 数据库锁，分为悲观锁和乐观锁
- 悲观锁一般利用 `SELECT … FOR UPDATE` 类似的语句，对数据加锁，避免其他事务意外修改数据
- 乐观锁利用 CAS 机制，并不会对数据加锁，而是通过对比数据的时间戳或者版本号，实现版本判断

MySQL事务和锁机制的高频考点：
- 举例说明什么是脏读、不可重复度和幻读（三者虽然基础，但很多同学容易弄混）？
- MySQL 是怎么解决脏读、不可重复读，和幻读问题的？
- 你怎么理解死锁？

### 怎么理解脏读、不可重复读和幻读？

- 脏读
读到了未commit的事务的数据

事务A读取数据，并且更新，(未commit)，事务B读取数据，读到了A更新后的数据，如果 A rollback，那么 B读到的就是 过时的数据，这种现象就是 脏读。

脏读对应的隔离级别是“读未提交”，只有该隔离级别才会出现脏读。
脏读的解决办法是升级事务隔离级别，比如“读已提交”。

- 不可重复读
事务A 读取一条数据，然后进行处理，处理过程中 B 更新了 这条数据， A再读取时，发现数据不匹配。这个现象就是 不可重复度。

简单理解是两次读取的数据中间被修改，对应的隔离级别是“读未提交”或“读已提交”。
不可重复读的解决办法就是升级事务隔离级别，比如“可重复度”。


- 幻读
在一个事务内，同一条查询语句，在不同时间段执行，得到不同的结果==集==。

事务A 读取一次商品表，得到 最大ID为3， 事务B也读了一次，也是3。
然后 事务A 插入一条数据，然后读了下 最新的ID 是4，正好是前面的ID +1.
然后 B也插入一条数据，读了下最新的ID，是5， 而不是 3+1。

这是，如果使用 ID 做判断 或做关键数据时， 会出现问题。 这种现象，让B 产生了幻觉一样，读取到了一个 意想不到的数据，所以叫幻读。
删除、修改数据也会发生类似的情况。


要想解决幻读不能升级事务隔离级别到“可串行化”，那样数据库也失去了并发处理能力。
行锁解决不了幻读，因为即使锁住所有记录，还是阻止不了插入新数据。
解决幻读的办法是锁住记录之间的“间隙”，为此 MySQL InnoDB 引入了新的锁，叫==间隙锁（Gap Lock）==，所以在面试中，你也要掌握间隙锁，以及==间隙锁与行锁结合的 next-key lock 锁==。


### 怎么理解死锁
回答思路：死锁是如何产生的，如何避免死锁。

死锁一般发生在多线程（两个或两个以上）执行的过程中。因为争夺资源造成线程之间相互等待，这种情况就产生了死锁

死锁的4个条件
- 互斥，资源只能被一根线程使用。
- 持有并等待，在等待其他资源的时候，已经持有的资源不会释放。
- 不可剥夺，在获得资源后，不会被其他线程抢占。
- 循环等待，发生死锁时，必然存在 线程的环形链。

只有同时满足上面 4个条件，才会死锁。

由于互斥是必须满足的，所以可以尝试 破坏其他3个条件中的 任意一个
- 持有并等待， 一次性申请所有资源，就不存在等待了
- 不可剥夺，申请其他资源失败时，释放它已持有的资源。
- 循环等待，资源的申请需要按照一定的顺序。

### 总结

从数据库领域应用开发者角度出发，至少还需要掌握以下几部分内容。

数据库设计基础：掌握数据库设计中的基本范式，以及基础概念，例如表、视图、索引、外键、序列号生成器等，掌握数据库的数据类型的使用，清楚业务实体关系与数据库结构的映射。

数据库隔离级别：掌握 MySQL 四种事务隔离级别的基础知识，并进一步了解 MVCC、Locking 等机制对于处理的进阶问题的解决；还需要了解不同索引类型的使用，甚至是底层数据结构和算法等。

SQL 优化：掌握基础的 SQL 调优技巧，至少要了解基本思路是怎样的，例如 SQL 怎样写才能更好利用索引、知道如何分析 SQL 执行计划等。

数据库架构设计：掌握针对高并发等特定场景中的解决方案，如读写分离、分库分表等。






## v11 读多写少，如何优化数据查询方案？

大流量时，订单系统，如何应对读写流量呢？

很多研发同学会回答：通过 Redis 作为 MySQL 的缓存，然后当用户查看“订单中心”时，通过查询订单缓存，帮助 MySQL 抗住大部分的查询请求。

如果你也是这么想，说明没认真思考过问题。因为应用缓存的原则之一是保证缓存命中率足够高，不然很多请求会穿透缓存，最终打到数据库上。然而在“订单中心”这样的场景中，每个用户的订单都不同，除非全量缓存数据库订单信息（又会带来架构的复杂度），不然缓存的命中率依旧很低。

分析
互联网大部分系统的访问流量是读多写少，读写请求量的差距可能达到几个数量级，就好比你在京东上的商品的浏览量肯定远大于你的下单量。

所以你要考虑优化数据库来抗住高查询请求，首先要做的就是区分读写流量区，这样才方便针对读流量做单独扩展，这个过程就是流量的“读写分离”。

==读写分离是提升 MySQL 并发的首选方案==，因为当单台 MySQL 无法满足要求时，就只能用多个具有相同数据的 MySQL 实例组成的集群来承担大量的读写请求。

MySQL 做==读写分离的前提，是把 MySQL 集群拆分成“主 + 从”结构的数据集群==，这样才能实现程序上的读写分离，并且 MySQL 集群的主库、从库的数据是通过主从复制实现同步的。

- 掌握读多写少场景下的架构设计思路，知道缓存不能解决所有问题，“读写分离”是提升系统并发能力的重要手段。
- 深入了解数据库的主从复制，掌握它的原理、问题，以及解决方案。
- 从实践出发，做到技术的认知抽象，从方法论层面来看设计。



### MySQL 主从复制的原理

MySQL 的主从复制依赖于 binlog ，也就是记录 MySQL 上的所有变化并以二进制形式保存在磁盘上。复制的过程就是将 binlog 中的数据从主库传输到从库上。这个过程一般是异步的，也就是主库上执行事务操作的线程不会等待复制 binlog 的线程同步完成。

把 MySQL 集群的主从复制过程梳理成 3 个阶段。
- 写入 Binlog：主库写 binlog 日志，提交事务，并更新本地存储数据。
- 同步 Binlog：把 binlog 复制到所有从库上，每个从库把 binlog 写到暂存日志中。
- 回放 Binlog：回放 binlog，并更新存储数据。

详细过程如下
- MySQL 主库在收到客户端提交事务的请求之后，会==先写入 binlog，再提交事务，更新==存储引擎中的数据，事务提交完成后，返回给客户端“操作成功”的响应。
- ==从库==会创建==一个专门的 I/O 线程==，连接==主库的 log dump== 线程，来**==接收==**主库的 binlog 日志，再把 ==binlog 信息写入 relay log== 的中继日志里，再返回给主库“复制成功”的响应。
- ==从库==会创建一个==用于回放 binlog 的线程==，去读 relay log 中继日志，然后回放 binlog 更新存储引擎中的数据，最终实现主从的数据一致性。

。。主库推送给从库


### MySQL 一主多从

那大促流量大时，是不是只要多增加几台从库，就可以抗住大促的并发读请求了？

当然不是。

因为从库数量增加，从库连接上来的 I/O 线程也比较多，主库也要创建同样多的 log dump 线程来处理复制的请求，对主库资源消耗比较高，同时还受限于主库的网络带宽。所以在==实际使用中，一个主库一般跟 2～3 个从库（1 套数据库，1 主 2 从 1 备主）==，这就是一主多从的 MySQL 集群结构。

MySQL 主从复制默认是异步模式：MySQL 主库提交事务的线程并不会等待 binlog 同步到各从库，就返回客户端结果。这种模式一旦主库宕机，数据就会发生丢失。


### MySQL 主从复制有哪些模型

- 同步复制：事务线程要等待所有从库的复制成功响应。
- 异步复制：事务线程完全不等待从库的复制成功响应。
- 半同步复制：MySQL 5.7 版本之后增加的一种复制方式，介于两者之间，事务线程不用等待所有的从库复制成功响应，只要一部分复制成功响应回来就行，比如一主二从的集群，只要数据成功复制到任意一个从库上，主库的事务线程就可以返回给客户端。


### 在系统设计上有哪些方案可以解决主从复制的延迟问题？

场景
用户发表评论后，需要调用 评论审核。

评论在更新完主库后，商品发布模块会异步调用审核模块，并把评论 ID 传递给审核模块，然后再由评论审核模块用评论 ID 查询从库中获取到完整的评论信息。此时如果主从数据库存在延迟，在从库中就会获取不到评论信息，整个流程就会出现异常

。。不过 评论 这种应该是 审核完再 发布的？

3个方案
- 使用数据冗余
调用 审核模块时，发送ID + 评论信息，避免从 从库中重新查询。 要注意 消息的大小，如果图片多的话，会占用 带宽 和通信时间。
。。那就是 只发文字， 图片发 url。

- 使用缓存解决
可以在写入数据主库的同时，把评论数据写到 Redis 缓存中，这样其他线程 再获取 评论信息时 会优先查询缓存，也可以保证 数据一致性。
会带来缓存和数据库的一致性问题。
。。这个好像薄纱前面的啊。 只说 评论审核 这个， 不太可能 一致性问题的，而且 修改评论后，再发一个 审核的请求 就可以了。

通过缓存解决 MySQL 主从复制延迟时，会出现数据库与缓存数据不一致的情况。虽然它和“使用数据冗余”的方案相比并不优雅，但我还是建议你在面试中做一下补充，这样可以引出更多的技术知识，展现自己与其他人的差异。

- 直接查询主库
使用时一定要谨慎，你要提前明确查询的数据量不大，不然会出现主库写请求锁行，影响读请求的执行，最终对主库造成比较大的压力


### 主库和从库的数据库访问的代码

一种简单的做法是：提前把所有数据源配置在工程中，每个数据源对应一个主库或者从库，然后改造代码，在代码逻辑中进行判断，将 SQL 语句发送给某一个指定的数据源来处理。
这个方案简单易实现，但 SQL 路由规则侵入代码逻辑，在复杂的工程中不利于代码的维护。
。。就是 select 开头发给 从库。  不过还有 select for update。。
。。而且说 侵入代码逻辑， 估计就是写DAO的时候，需要自己判断走哪里。
。。直接select 发从库的话，并没有侵入代码。 不过 hibernate 就有点难了。不知道hibernate 能不能识别出来 query 或 modify。
。。还有，事务中的查询，肯定也是要从 主库查的。

另一个做法是：独立部署的代理中间件，如 ==MyCat==，这一类中间件部署在独立的服务器上，一般使用标准的 MySQL 通信协议，可以代理多个数据库。
该方案的优点是隔离底层数据库与上层应用的访问复杂度，比较适合有独立运维团队的公司选型；缺陷是所有的 SQL 语句都要跨两次网络传输，有一定的性能损耗，再就是运维中间件是一个专业且复杂的工作，需要一定的技术沉淀。
。。MyCat 好像不行啊。


raft，redis cluster 的 主从数据同步都是通过 日志复制和回放。

几乎所有的存储系统或数据库，基本都用了这样一套方法来解决数据复制和备份恢复等问题




## v12 写多读少，如何优化数据存储方案？

场景
主从分离后，减少了读请求的压力，但是随着 业务发展，写入压力增加，导致 查询和写入 性能都在下降，此时，应该如何设计？

要想解决该问题，你可以对存储数据做分片，常见的方式就是对数据库做“分库分表”，在实现上有三种策略：==垂直拆分、水平拆分、垂直水平拆分==。

站在业务场景中，当数据出现写多读少时，考察你做分库分表的整体设计方案和技术实现的落地思路。一般会涉及这样几个问题：
- 什么场景该分库？什么场景该分表？
- 复杂的业务如何选择分片策略？
- 如何解决分片后的数据查询问题？


### 如何确定分库还是分表？

- 何时分表
数据量过大，导致事务执行缓慢 时，要考虑分表，因为减少 每次查询数据总量 是解决 查询缓慢的主要方法。
“查询可以通过主从分离或缓存来解决，为什么还要分表？”但这里的查询是指事务中的查询和更新操作。

。。分表解决的是数据量过大的问题，分库解决的是数据库性能瓶颈的问题。

- 何时分库
为了应对高并发，一个数据库实例撑不住，即单库的性能无法满足高并发的要求，就把并发请求分散到多个实例中去

总的来说，分库分表使用的场景不一样： 分表是因为数据量比较大，导致事务执行缓慢；分库是因为单库的性能无法满足要求。


### 如何选择分片策略？

- 垂直拆分
垂直拆分是根据==数据的业务相关性进行拆分==。
比如一个数据库里面既存在商品数据，又存在订单数据，那么垂直拆分可以把商品数据放到商品库，把订单数据放到订单库。一般情况，垂直拆库常伴随着系统架构上的调整。

比如在对做系统“微服务”改造时，将原本一个单体系统拆分成多个子系统，每个系统提供单独的服务，那么随着应用层面的拆分带来的也有数据层面的拆分，将一个主库的数据表，拆分到多个独立的子库中去。

对数据库进行垂直拆分最常规，优缺点也很明显。
- 垂直拆分可以把不同的业务数据进行隔离，让系统和数据更为“纯粹”，更有助于架构上的扩展。
- 依然不能解决某一个业务的数据大量膨胀的问题，一旦系统中的某一个业务库的数据量剧增，比如商品系统接入了一个大客户的供应链，对于商品数据的存储需求量暴增，在这个时候，就要把数据拆分到多个数据库和数据表中，也就是对数据做水平拆分。


- 水平拆分
垂直拆分随架构改造而拆分，关注点在于业务领域，而水平拆分指的是把单一库表数据按照规则拆分到多个数据库和多个数据表中，比如把单表 1 亿的数据按 Hash 取模拆分到 10 个相同结构的表中，每个表 1 千万的数据。并且拆分出来的表，可以分别存放到不同的物理数据库中，关注点在于数据扩展。

拆分的规则就是哈希分片和范围分片

对于范围分片，可以根据时间分，也可以根据category分。

category的业务热点不同，所以 商品数据存储 也会存在 热点数据问题，这时有2个办法：
- 垂直扩展
由于 Range 分片是按照业务特性进行的分片策略，所以可以对热点数据做垂直扩展，即==提升单机处理能力==。

- 分片元数据
单机性能总是有极限的，互联网分布式架构设计高并发终极解决方案还是水平扩展，所以结合业务的特性，就需要在 Range 的基础上引入“分片元数据”的概念：分片的规则记录在一张表里面，每次执行查询的时候，先去表里查一下要找的数据在哪个分片中。

这种方式的优点是灵活性高，并且分片规则可以随着业务发展随意改动。比如当某个分片已经是热点了，那就可以把这个分片再拆成几个分片，或者把这个分片的数据移到其他分片中去，然后修改一下分片元数据表，就可以在线完成数据的再分片了。

。。一致性hash

- 垂直水平拆分
垂直水平拆分，是综合垂直和水平拆分方式的一种混合方式，垂直拆分把不同类型的数据存储到不同库中，再结合水平拆分，使单表数据量保持在合理范围内，提升性能。


### 如何解决数据查询问题？

在未分库分表之前，我们查询数据总数时，可以直接通过 SQL 的 count() 命令，现在数据分片到多个库表中，如何解决呢？

解题思路很多，你可以考虑其他的存储方案，比如聚合查询使用频繁时，可以将聚合查询的数据同步到 ES 中，或者将计数的数据单独存储在一张表里。如果是每日定时生成的统计类报表数据，也可以将数据同步到 HDFS 中，然后用一些大数据技术来生成报表


MySQL 是每个后端开发人员都要精通的数据库，因为其开源、轻量级，且有着金融级别的事务保证，所以一直是互联网项目的标配。

但是随着近些年技术的发展，下一代存储技术上出现了 NewSQL ，我觉得未来它可能会取代 MySQL ：
NewSQL 是新一代的分布式数据库，不但具备分布式存储系统的高性能、高可用，弹性扩容等能力，还兼容传统关系型数据库的 SQL 标准。并且，还提供了和传统关系型数据库不相上下的事务保证，是具备了支撑未来交易类业务能力的。

NewSQL 的发展和相关开源产品，如 CockroachDB、TiDB


### 总结
总的来说，在面对数据库容量瓶颈和写请求并发量大时，你可以选择垂直分片和水平分片：
垂直分片一般随着业务架构拆分来进行；
水平分片通常按照 Hash（哈希分片）取模和 Range（范围分片）进行，
并且，通常的形态是垂直拆分伴随着水平拆分，即先按照业务垂直拆分后，再根据数据量的多少决定水平分片。

Hash 分片在互联网中应用最为广泛，简单易实现，可以保证数据非常均匀地分布到多个分片，但其过滤掉了业务属性，不能根据业务特性进行调整。而 Range 分片却能预估业务，更高效地扫描数据记录（Hash 分片由于数据被打散，扫描操作的 I/O 开销更大）。除了 Hash 分片和 Range 分片，更为灵活的方式是基于分片元数据。

不过你要注意，这几种方式也会引入诸如聚合查询的问题，要想解决聚合查询，你可以让聚合查询记录存储在其他存储设备中（比如 ES、HDFS）。

最后，除了中规中矩地回答面试官提出的问题，我也希望你能展示自己的技术视野，选择 NewSQL 作为切入点。





## v13 缓存原理：面试中需要哪些Redis原理？

### Redis是单线程还是多线程？

- Redis 只有单线程吗？
Redis 是单线程的，主要是指 Redis 的网络 I/O 线程，以及键值的 SET 和 GET 等读写操作都是由一个线程来完成的。但 Redis 的持久化、集群同步等操作，则是由另外的线程来执行的。
。。Redis 6 IO 也是多线程了吧。

- Redis 采用单线程为什么还这么快？
一般来说，单线程的处理能力应该要比多线程差才对，但为什么 Redis 还能达到每秒数万级的处理能力呢？主要有如下几个原因。
1. 大部分操作都在内存中完成，并且使用了高效的数据结构，如hash table 和 skip table
2. 单线程模型 避免了 多线程的竞争，省去了 多线程切换 导致的 时间和 性能上的开销，而且不会死锁。
3. 最重要的，使用了 IO多路复用 处理大量的客户端Socket请求，这让 Redis 可以高效进行网络通信。

Redis 4.0之前，单线程速度快的原因就是上面的几个

Redis 4.0之后，Redis增加了多线程的支持，但这时的多线程主要体现在大数据的异步删除功能上，例如 unlink key、flushdb async、flushall async 等

6.0之后，增加了 多线程IO的读写并发能力。


### Redis 如何实现数据不丢失？

为了保证数据不丢失，要把内存中的数据存储到磁盘，以便缓存服务器重启之后，还能够从磁盘中恢复原有的数据，这个过程就是 Redis 的数据持久化。

这也是 Redis 区别于其他缓存数据库的优点之一（比如 Memcached 就不具备持久化功能）

Redis 的数据持久化有三种方式。
- AOF 日志（Append Only File，文件追加方式）：记录所有的操作命令，并以文本的形式追加到文件中。
- RDB 快照（Redis DataBase）：将某一个时刻的内存数据，以二进制的方式写入磁盘。
- 混合持久化方式：Redis 4.0 新增了混合持久化的方式，集成了 RDB 和 AOF 的优点。


#### AOF 日志是如何实现的？

通常情况下，关系型数据库（如 MySQL）的日志都是“写前日志”（Write Ahead Log, WAL），也就是说，在实际写数据之前，先把修改的数据记到日志文件中，以便当出现故障时进行恢复，比如 MySQL 的 redo log（重做日志），记录的就是修改后的数据。

而 AOF 里记录的是 Redis 收到的每一条命令，这些命令是以文本形式保存的，不同的是，Redis 的 AOF 日志的记录顺序与传统关系型数据库正好相反，它是==写后日志==，“写后”是指 Redis 要先执行命令，把数据写入内存，然后再记录日志到文件。

Reids 为什么先执行命令，在把数据写入日志呢？
因为 ，Redis 在写入日志之前，不对命令进行语法检查；
所以，只记录执行成功的命令，避免了出现记录错误命令的情况；
并且，在命令执行完之后再记录，不会阻塞当前的写操作。

风险
- 数据可能丢失，执行完命令后，宕机。
- 可能阻塞其他操作，虽然aof是写后日志，但它也是在主线程中执行，所以把日志写入到磁盘的时候，还是会阻塞后续的操作。


#### 那么 RDB 快照是如何实现的呢？
因为 AOF 日志记录的是操作命令，不是实际的数据，所以用 AOF 方法做故障恢复时，需要全量把日志都执行一遍，一旦日志非常多，势必会造成 Redis 的恢复操作缓慢。

为了解决这个问题，Redis 增加了 RDB 内存快照（所谓内存快照，就是将内存中的某一时刻状态以数据的形式记录在磁盘中）的操作，它即可以保证可靠性，又能在宕机时实现快速恢复。

和 AOF 不同的是，RDB 记录 Redis 某一时刻的数据，而不是操作，所以在做数据恢复时候，只需要直接把 RDB 文件读入内存，完成快速恢复。

- RDB 做快照时会阻塞线程吗？
Redis 提供了两个命令来生成 RDB 快照文件，分别是 save 和 bgsave。save 命令在主线程中执行，会导致阻塞。而 bgsave 命令则会创建一个子进程，用于写入 RDB 文件的操作，避免了对主线程的阻塞，这也是 Redis RDB 的默认配置。


- RDB 做快照的时候数据能修改吗？
bgsave 的子进程，具体操作如下：
- 如果主线程执行读操作，则主线程和 bgsave 子进程互相不影响；
- 如果主线程执行==写操作，则被修改的数据会复制一份副本==，然后 bgsave 子进程会把该副本数据写入 RDB 文件，在这个过程中，主线程仍然可以直接修改原来的数据。


在 Redis 4.0 后，增加了 AOF 和 RDB 混合的数据持久化机制： 把数据以 RDB 的方式写入文件，再将后续的操作命令以 AOF 的格式存入文件，既保证了 Redis 重启速度，又降低数据丢失风险。


### Redis 如何实现服务高可用？

Redis 不仅仅可以用来当作缓存，很多时候也会直接作为数据存储，那么你就要一个高可用的 Redis 服务，来支撑和保证业务的正常运行。那么你怎么设计一个不宕机的 Redis 高可用服务呢？

==解决数据高可用的手段是什么？是副本。==

Redis 的主从复制、哨兵模式，以及 Redis 集群

- 主从同步 (主从复制)
Redis 高可用服务的最基础的保证，实现方案就是将从前的一台 Redis 服务器，同步数据到多台从 Redis 服务器上，即一主多从的模式，这样我们就可以对 Redis 做读写分离了，来承载更多的并发操作，这里和 MySQL 的主从复制原理上是一样的。

- Redis Sentinel（哨兵模式）
在使用 Redis 主从服务的时候，会有一个问题，就是当 Redis 的主从服务器出现故障宕机时，需要手动进行恢复，为了解决这个问题，Redis 增加了哨兵模式（因为哨兵模式做到了可以监控主从服务器，并且提供自动容灾恢复的功能）。

- Redis Cluster(集群)
Redis Cluster 是一种分布式去中心化的运行模式，是在 Redis 3.0 版本中推出的 Redis 集群方案，它将数据分布在不同的服务器上，以此来降低系统对单主节点的依赖，从而提高 Redis 服务的读写性能。
1. 根据键值对的 key，按照 CRC16 算法计算一个 16 bit 的值。
2. 再用 16bit 值对 16384 取模，得到 0~16383 范围内的模数，每个模数代表一个相应编号的哈希槽。

剩下的一个问题就是，这些哈希槽怎么被映射到具体的 Redis 实例上的呢？有两种方案。
1. 平均分配，在使用 cluster create 命令创建 Redis 集群时，Redis 会自动把所有哈希槽平均分布到集群实例上。比如集群中有 9 个实例，则每个实例上槽的个数为 16384/9 个。
2. 手动分配： 可以使用 cluster meet 命令手动建立实例间的连接，组成集群，再使用 cluster addslots 命令，指定每个实例上的哈希槽个数，为了方便你的理解，我通过一张图来解释数据、哈希槽，以及实例三者的映射分布关系。






## v14 缓存策略：如何回答缓存穿透，雪崩等问题？

场景
系统收到用户的频繁查询请求时，
会先从缓存中查找数据，
    如果缓存中有数据，直接从中读取数据，响应给请求方；
    如果缓存中没有数据，则从数据库中读取数据，然后再更新缓存，
这样再获取这条数据时，可以直接从缓存中获取，不用再读取数据库。

这种方案在查询请求并发较高时，会存在什么问题呢？

商品详情页的缓存经常存在缓存穿透、缓存并发、缓存雪崩，以及缓存设计等问题

### 缓存穿透问题
查询缓存中不存在的数据时，每次都要查询数据库。

方案：为所有指定的key 预先设置一个 默认值，比如字符串"null"。

### 缓存并发问题
缓存失效时，多个客户端并发请求 同一个key。所有请求都会到达 数据库，并且返回后，还会 反复更新redis缓存。

如何解决缓存并发？

首先，客户端发起请求，先从缓存中读取数据，判断是否能从缓存中读取到数据；
如果读取到数据，则直接返回给客户端，流程结束；
如果没有读取到数据，那么就在 Redis 中使用 setNX 方法设置一个状态位，表示这是一种锁定状态；
如果锁定状态设置成功，表示已经锁定成功，这时候请求从数据库中读取数据，然后更新缓存，最后再将数据返回给客户端；
如果锁定状态没有设置成功，表示这个状态位已经被其他请求锁定，此时这个请求会等待一段时间再重新发起数据查询；
再次查询后发现缓存中已经有数据了，那么直接返回数据给客户端。

保证在同一时间只能有一个请求来查询数据库并更新缓存系统，其他请求只能等待重新发起查询，从而解决缓存并发的问题。

。。加锁


### 缓存雪崩问题
开发时，会将缓存的过期时间设置为一个固定的时间常量（比如 1 分钟、5 分钟）。这就可能出现系统在运行中，同时设置了很多缓存 key，并且这些 key 的过期时间都一样的情况，然后当 key 到期时，==缓存集体同时失效==，如果此时请求并发很高，就会导致大面积的请求打到数据库，造成数据库压力瞬间增大，出现缓存雪崩的现象。

将缓存失效时间随机打散： 我们可以在原有的失效时间基础上增加一个随机值（比如 1 到 10 分钟）这样每个缓存的过期时间都不重复了，也就降低了缓存集体失效的概率。
设置缓存不过期： 我们可以通过后台服务来更新缓存数据，从而避免因为缓存失效造成的缓存雪崩，也可以在一定程度上避免缓存并发问题。



---

怎么设计一个动态缓存热点数据的策略？
怎么设计一个缓存操作与业务分离的架构？

场景&问题
由于数据存储受限，系统并不是将所有数据都需要存放到缓存中的，而只是将其中一部分热点数据缓存起来，那么就引出来一个问题，即
如何设计一个缓存策略，可以动态缓存热点数据呢？

现在 要求只缓存用户经常访问的Top 1000 的商品

缓存策略的总体思路：就是通过判断数据最新访问时间来做排名，并过滤掉不常访问的数据，只留下经常访问的数据，具体细节如下。
1. 先通过缓存系统做一个排序队列（比如存放 1000 个商品），系统会根据商品的访问时间，更新队列信息，越是最近访问的商品排名越靠前。
2. 同时系统会定期过滤掉队列中排名最后的 200 个商品，然后再从数据库中随机读取出 200 个商品加入队列中。
3. 这样当请求每次到达的时候，会先从队列中获取商品 ID，如果命中，就根据 ID 再从另一个缓存数据结构中读取实际的商品信息，并返回。
4. 在 Redis 中可以用 zadd 方法和 zrange 方法来完成排序队列和获取 200 个商品的操作。

。。redis 有 LRU啊。 不过好像是 key的，不能应用到 指定的某个 key？


前面的内容中，我们都是将缓存操作与业务代码耦合在一起，这样虽然在项目初期实现起来简单容易，但是随着项目的迭代，
代码的可维护性会越来越差，并且也不符合架构的“高内聚，低耦合”的设计原则，那么如何解决这个问题呢？

将缓存操作与业务代码解耦，实现方案上可以通过 ==MySQL Binlog + Canal + MQ== 的方式。

场景
用户在应用系统的后台添加一条配置信息，配置信息存储到了 MySQL 数据库中，同时数据库更新了 Binlog 日志数据，接着再通过使用 Canal 组件来获读取最新的 Binlog 日志数据，然后解析日志数据，并通过事先约定好的数据格式，发送到 MQ 消息队列中，最后再由应用系统将 MQ 中的数据更新到 Redis 中，这样就完成了缓存操作和业务代码之间的解耦。

![49ee3824e6e70681fea05281b91b28d9.png](../_resources/49ee3824e6e70681fea05281b91b28d9.png)


### 总结

![f9e4b892e40b86955cf9bb5364051680.png](../_resources/f9e4b892e40b86955cf9bb5364051680.png)

今天这一讲，我推荐采用预设值方案解决缓存穿透（当然还有基于布隆过滤器的实现方式，但它本身存在误判的情况，实现起来也较复杂，所以我不推荐使用，不过你可以了解一下）。另外，你可以利用 Redis 的 setNX 方法来配合解决缓存并发。除此之外，你可以通过将缓存失效时间随机打散，或者设置缓存不过期，解决缓存雪崩的问题。

最后，要强调一下，缓存的使用虽然给我们带来非常多的好处，但你也要充分考虑缓存使用上的一些坑。比如缓存和数据库的一致性、缓存容量限制，以及每次存放到缓存的数据大小等。





## v15 如何证明你做的系统是高可用的？

一般来讲，面试官在考察你系统架构的设计能力时，经常会让你说一下你在上一家公司是怎么设计系统架构的，以此了解你的设计能力和思路。

而你在讲解架构设计时，也是在向面试官逐步证明，自己负责的系统是如何做到高可用的。这会涉及一个公认的论证——==SLA。服务等级协议==（Service-Level Agreement，SLA）最根本的形式是协议双方（服务提供者和用户）签订的一个合约或协议。这个合约规范了双方的商务关系或部分商务关系。简单点儿说，你可以认为 SLA 是服务可用性一个重要衡量指标。

任何一家互联网公司，都有流量的低峰期和高峰期，你在低峰期停机 1 分钟和高峰期停机 1 分钟，对业务影响的结果完全不同

当你向面试官证明系统高可用时，其实是在回答这样几个问题：
- 如何评估系统高可用？
- 如何监控系统高可用？
- 如何保证系统高可用？


我们以设计一个保证系统服务 SLA 等于 4 个 9 的监控报警体系为例。监控系统包括三个部分：基础设施监控报警、系统应用监控报警，以及存储服务监控报警。

### 基础设施监控
由三个部分组成：监控报警指标、监控工具以及报警策略。

#### 监控报警
指标分为2类
- 系统要素指标：主要是CPU，内存，磁盘
- 网络要素指标：主要有带宽，网络IO，CDN，DNS，安全策略，负载均衡

它们是判断系统的基础环境是否为高可用的重要核心指标

#### 监控工具
常用的有==ZABBIX==（Alexei Vladishev 开源的监控系统，覆盖市场最多的老牌监控系统，资料很多）、=Open-Falcon==（小米开源的监控系统，小米、滴滴、美团等公司内部都在用）、==Prometheus==（SoundCloud 开源监控系统，对 K8S 的监控支持更好）。


#### 监控报警策略
一般由时间维度、报警级别、阈值设定三部分组成。

比如，1分钟内 80%CPU使用率 是 紧急级别， 60%是重要，50%是一般。



### 系统应用监控

业务状态监控报警，关注点在于系统自身状态的监控报警。
和基础设施监控一样，它也是由监控指标，监控工具，报警策略组成，
不同的是，系统应用监控报警的核心监控指标
主要有流量、耗时、错误、心跳、客户端数、连接数等 6 个==核心指标==，
==监控工具==有 CAT、SkyWalking、Pinpoint、Zipkin 等。


### 存储服务监控
一般来讲，常用的第三方存储有 DB、ES、Redis、MQ 等。

对于存储服务的监控，除了基础指标监控之外，还有一些比如集群节点、分片信息、存储数据信息等相关特有存储指标的监控。

---


很多互联网公司都很重视系统服务稳定性的工作，因为服务的稳定性直接影响用户的体验和口碑，线上服务稳定性是研发工程师必须要重点关注的问题。所以当你回答完上述问题后，有的面试官为了考察候选人的责任意识，一般还会追问：
“如果线上出现告警，你作为核心研发，该怎么做呢？

应急响应的目标
    线上故障发生时：快速恢复是第一优先
    线上故障发生后：及时总结，提高应急水平
    线上故障发生前：积极预防，尽可能避免或减少故障发生
应急响应的原则
    首要原则：应在第一时间恢复服务
    影响重大(比如 受影响用户范围大，受损资金多，关键功能受阻等) 应立即升级处理
    如果不能短时间解决问题，应及时升级处理。
应急响应流程
    事前预防，问题监控，事中应对，故障定位，故障解决，事后总结，故障回顾，改进措施




## v16 如何从架构师角度回答系统容错，降级等高可用问题？

场景
电商平台，有商品系统，促销系统，积分系统。
商品的一次查询操作是由 网关系统 先调用 商品系统 查询商品列表，然后根据返回的商品列表信息，再查询 促销和 积分系统，匹配商品信息的促销活动和积分奖励，最终返回给 客户端展示给用户。
出现流量高峰时，作为服务请求入口的商品系统很容易扩容，但对于商品系统 依赖的 其他服务，就不会有实时性的响应。
促销或积分系统 可能无法承担 大流量，请求处理缓慢，从而让 执行商品查询操作的服务线程阻塞，不能释放，直到所有线程资源被占满，无法处理后续请求。

。。这里的原文是，3个系统，3个团队各自处理，一个扩容了，其他的不扩容。。但是，高流量，不扩容，等死吗？
。。而且，有图，图是 网关系统调用商品系统，商品系统调用 促销系统和 积分系统， 并不是 上面文字描述的：网关调商品系统，然后调用 促销和积分 系统。

分析
这道题设计 高可用架构的 设计。
一次查询 经历了 3次调用，从网关系统开始，然后 依次调用 商品系统，促销系统，积分系统， 如果 积分系统 响应变长，那么 整条请求的 响应时间也会变长，整体服务 甚至会发生宕机， 这就是 ==服务雪崩现象：即 局部故障最终导致全局故障。==

分布式情况下，某个服务或组件 响应缓慢，从而拖垮整个系统的 情况随处可见。在15讲中提到，对于系统可见性，要通过3个方面来解决：分别是 ==评估，检测，保证==，具体如下：
1. 用科学的方法 评估 系统的可用性指标；
2. 通过实时监控预警 检测 系统的可用性；
3. 通过系统架构设计 保证 系统的可用性。

解决思路
在分布式系统中，当检测到某个系统或服务响应 经常出现异常时，要想办法 停止调用 该服务，让服务的 调用快速返回失败，从而释放此次请求持有的 资源。这就是 架构设计中 经常提到的==降级和熔断==机制

### 熔断设计的原理
在服务A调用服务B时，如果B返回错误或超时的次数超过一定阈值，服务A的后续请求将不再调用服务B。 这种设计方式就是 ==断路器模式==

在这种模式下，服务调用方为每个调用的服务维护一个==有限状态机==，在这个状态机中存在 ==关闭，半打开，打开，3种状态==。
- 关闭：正常调用
- 半打开：尝试调用
- 打开，直接返回错误，不调用

切换过程：
- 关闭->打开： 服务调用失败的 次数累计到一定的阈值时，服务熔断状态，将从关闭态 切换到 打开态。
- 打开->半打开： 处于打开状态时，启动计时器，一定时间后，切换到 半打开。
- 半打开->关闭： 处于半打开状态时，请求可以到达后端服务，累计一定的成功次数后，状态变成 关闭。


### 如何设计实现断路器

关闭->打开
请求到来时，先判断是否熔断中，如果没有熔断，正常调用系统服务，统计系统的调用状态，如果失败次数超过阈值，则断路器 打开
```Java
if (breaker.isClose()) {
    if (failCount.incrementAndGet() >= FAILS_THRESHOLD) {
        breaker.setOpen();
    }
}
```

打开->半打开
如果已经熔断，就初始化一个定时器，定期检测服务状态的可用性，如果服务达到了熔断的倒计时，则设置当前熔断器为 半打开 状态
```Java
new Timer("Service-Recover", true).scheduleAtFixedRate(new TimerTask() {
    @Override
    public void run() {
        if (breaker.isOpen()) {
            breaker.setHalfOpen();
        }
    }
}, 0, recoverInterval);
```

半打开->关闭
如果状态是半打开，则判断成功次数是否超过阈值，超过则设置断路器状态为 关闭
```Java
if (breaker.isHalfOpen()) {
    if (successCount.incrementAndGet() >= SUCCESS_THRESHOLD) {
        breaker.setClose();
    }
}
```


### 降级设计的原理
本质上是站在系统整体可用性的角度上考虑问题：当资源和访问量出现矛盾时，在有限的资源下，==放弃部分非核心功能或者服务，保证整体的可用性==。这是一种有损的系统容错方式。

这样看来，熔断也是降级的一种手段（除此之外还有限流、兜底服务等）。

降级的实现手段是：在请求流量突增的情况下，放弃一些非核心流程或非关键业务，释放系统资源，让核心业务正常运行。比如 618 零点大促，电商平台一般会暂时关闭评论、退款功能。

### 如何设计降级机制
从架构设计的角度出发，降级设计就是在做取舍，你要从==服务降级和功能降级==两方面来考虑。

在实现上，
==服务降级==
可以分为==读操作==降级和==写操作==降级。
读操作降级： 
做数据兜底服务，比如将兜底数据提前存储在缓存中，当系统触发降级时，读操作直接降级到缓存，从==缓存中读取兜底数据==，如果此时缓存中也不存在查询数据，则返回默认值，不在请求数据库。
。。但是缓存，访问数据库，应该不会太浪费时间吧。 不过都降级了，应该也有点影响。

写操作降级： 
同样的，将之前直接同步调用写数据库的操作，降级为==先写缓存==，然后再==异步写入数据库==。
。。异步写入，应该是 MQ吧。


这两种情况的设计原则。
- 读操作降级的设计原则，就是取舍非核心服务。
- 写操作降级的设计原则，就是取舍系统一致性：实现方式是把强一致性转换成最终一致性。比如，两个系统服务通过 RPC 来交互，在触发降级时，将同步 RPC 服务调用降级到异步 MQ 消息队列中，然后再由消费服务异步处理。

功能降级
就是在做产品功能上的取舍，既然在做服务降级时，已经取舍掉了非核心服务，那么同样的产品功能层面也要相应的进行简化。在实现方式上，可以通过==降级开关==控制功能的可用或不可用。

在设计降级时，离不开降级开关的配置，一般是通过参数化配置的方式存储在配置中心（如 Zookeeper），在高并发场景下，手动或自动开启开关，实现系统降级。


### 总结
需要了解的重点是：
- 服务熔断其实是一个有限状态机，实现的关键是三种状态之间的转换过程。
- 降级就是在做取舍（取舍服务、取舍功能），本质上是为了解决资源不足和访问量过大的问题。实现上可以降低系统一致性、裁剪非核心服务，以及简化产品功能。

总之，服务的熔断和降级是互联网保证系统稳定性和可用性的重要手段，在你的架构设计中，如果涉及系统与第三方服务调用的情况下，都需要考虑增加服务熔断和降级方案。当然，高可用的设计方案不仅仅只有熔断和降级，还有如服务冗余、负载均衡、故障隔离、服务限流等设计方式。

总而言之，既然系统出故障是不可避免的，那做架构设计时就要把故障当作不可或缺的一环来处理，因此在分布式系统设计的和开发的过程中，要通过各种架构手段来提高系统可用性。


### 评论

断路器模式，不一定是被调用方故障的时候才需要熔断，比如调用方的调用参数有问题code400，或者根本不存在的资源code404，但是他又是要去重试的，甚至是定时任务，或者测试，这种异常分支可能没有被处理。我之前的一种方法是把故障的响应信息缓存起来，加上过期时间，过期缓存失效，再去重试，有一定作用。

。。确实，4xx系列 重试了干嘛？感觉只有 网络不稳定的时候 才需要重试，忘记了 网络不稳定，是什么错误了？ 单纯的 timeout？





## v17 如何证明你的系统是高性能的？

高性能 和 业务 强相关
- 网络游戏服务器，支持200名玩家，就算高性能
- 网络直播，支持2000名，就算高性能
- 电商，20000名用户在线下单，就是 高性能。

在实际的业务场景中，你要关注很多 ==业务相关性指标==，比如
- 游戏需要关注稳定性；
- 视频需要关注延时；
- 电商需要关注一致性

在明确了业务场景之后，你还要关注系统的性能指标主要有==吞吐量、延迟以及 TP==。

分析
在拿到产品经理的 PRD 文档时，心里就会清楚要关心哪些系统性能指标，因为需求文档中会描述同时支持多少人在线访问，你也可以借此估算出系统的并发用户数。一般来讲，系统建立的会话数量就是用户同时访问系统的数量。你也可以通过公式，估算出系统的吞吐量（throughput）和延迟（latency）。

延迟和吞吐量，是衡量软件系统最常见的两个指标。
- 吞吐量（系统处理请求的速率）：反映单位时间内处理请求的能力（单位一般是TPS或QPS）。
- 延迟（响应时间）：从客户端发送请求到接收响应的时间（单位一般是ms、s）。

一般来说，延迟和吞吐量既互斥，又不绝对的互斥，你可以通过性能压测分别绘制吞吐量和延迟的曲线图：

![7294a43f68ca63ce9c68c9ec2d7b4a39.png](../_resources/7294a43f68ca63ce9c68c9ec2d7b4a39.png)

延迟总是非递减的曲线，开始时表现比较平稳，到了某一个特定值后，会迅速增大。
吞吐量曲线在开始时迅速增加，到达峰值后逐渐减小。

随着压力增大，单位时间内系统被访问的次数增加。结合延迟和吞吐量观察的话，吞吐量曲线的最高点，往往是延迟曲线最低偏后的一个时间点，这意味着延迟已经开始增大一段时间了。那么对一些延迟要求比较高的系统来说，系统优化性能指标是要找到延迟趋向最低和吞吐量趋向最高的点。

除了吞吐量和延迟，TP（Top Percentile）也经常被提到。 以 TP 99 为例，它是指请求中 99% 的请求能达到的性能，TP 是一个时间值，比如 TP 99 = 10ms，含义就是 99%的请求，在 10ms 之内可以得到响应。

计算 TP 指标： 比如 TP 99，把一段时间内所有请求的响应时间，从小到大进行排序，然后取 99% 对应的请求的响应时间，即为 TP99 的值。
TP指标相比于性能均值的意义： 为什么要用 TP 99 这样的比例方式，而不直接用平均数来定义性能呢？这是为了更符合实际系统的情况。


### 用架构师的视角分析系统性能指标
架构师视角说白了就是系统的全链路视角，我们从前端请求流程开始，来讲解一次请求链路会涉及哪些前后端性能指标。

![5e6125723814e5c94aecb1feb02d09e2.png](../_resources/5e6125723814e5c94aecb1feb02d09e2.png)

#### 1. DNS解析
用户在浏览器输入 URL 按回车，请求会进行 DNS 查找，浏览器通过 DNS 解析查到域名映射的IP 地址，查找成功后，浏览器会和该 IP 地址建立连接。对应的性能指标为：==DNS解析时间==。

通过 DNS缓存或 DNS 预解析，适当增大域名的TTL 值来增大 DNS 服务器缓存域名的时间，进而提升了缓存的命中率。也可以用 ==dns-prefetch 标签==实现域名的预解析，让浏览器在后台把要用的 DNS请求提前解析，当用户访问的网页中包含了预解析的域名时，再次解析 DNS 就不会有延迟了，比如京东针对静态资源域名的预解析如下：
`<link rel="dns-prefetch" href="//static.360buyimg.com">`

#### 2. 建立TCP连接
由于 HTTP 是应用层协议，TCP 是传输层协议，所以 HTTP 是基于 TCP 协议基础上进行数据传输的。
所以你要建立 TCP 请求连接，这里你也可以用 TCP的连接时间来衡量浏览器与 Web 服务器建立的请求连接时间。


#### 3. 服务器响应
这部分就是我们开篇讲到的最重要的性能指标了，即服务器端的延迟和吞吐能力。针对影响服务端性能的指标，还可以细分为基础设施性能指标、数据库性能指标，以及系统应用性能指标。
- 基础设施性能指标主要针对 CPU 利用率、磁盘 I/O，网络带宽、内存利用率等。
- 数据库的性能指标主要有 SQL 查询时间、并发数、连接数、缓存命中率等。
- 系统应用性能指标和系统业务有关，因为业务场景影响架构设计，比如==To C== 的系统一般会设计成同步 RPC 调用，因为要实时反馈 C 端用户的请求，而 ==To B== 的系统则可以设计成事件驱动模式，通过异步通知的方式，推送或拉取数据，两种架构对比，显然异步事件驱动的吞吐量会更高。


#### 4. 白屏时间
当浏览器与 Web 服务器建立连接后，就可以进行数据通信了。
Web 服务器接收请求后，开始处理请求，浏览器这时会等待Web 服务器的处理响应。

由于浏览器自上而下显示 HTML，同时渲染顺序也是自上而下的，所以当用户在浏览器地址栏输入 URL 按回车，到他看到网页的第一个视觉标志为止，这段白屏时间可以作为一个性能的衡量指标（白屏时间越长，用户体验越差）。

优化手段为减少首次文件的加载体积，比如用 ==gzip 算法压缩资源文件==，调整用户界面的浏览行为（现在主流的Feed流也是一种减少白屏时间的方案）。


#### 5. 首屏时间
用户端浏览界面的渲染，首屏时间也是一个重要的衡量指标，首屏时间是指：用户在浏览器地址输入 URL 按回车，然后看到当前窗口的区域显示完整页面的时间。
一般情况下，一个页面总的白屏时间在 2 秒以内，用户会认为系统响应快，2 ~ 5 秒，用户会觉得响应慢，超过 5 秒很可能造成用户流失。


### 如何分析系统的性能瓶颈？
通常情况下，系统性能不达标一般会反映在TP 99 的延迟上面，但这只是表层的现象，怎么找到系统真正的性能瓶颈呢？ 你可以遵循这几个步骤。

#### 设计阶段，定义系统性能目标
要在项目初期定义好系统大致的性能目标，比如希望单台服务器能够负载多少 TPS 的请求，因为不同的性能会影响到系统的架构设计，也会带来不同的成本，一旦过了设计阶段，再因为性能问题调整系统架构，成本极高。
比如，当前单机性能是 80 TPS，要想优化到100 TPS，可以做一些小的性能优化，但要提升到 1000 TPS，就要进行架构改造了，代价非常大。

#### 开发阶段，走查代码和业务流程
也就是评审代码，代码包括应用程序源代码、环境参数配置、程序整个调用流程和处理逻辑。
比如，用户在 App 中触发了“立即下单”按钮，服务端的应用程序从线程池里取得了线程来处理请求，然后查询了几次缓存和数据库，都读取和写入了什么数据，再把最终的响应返回给 App，响应的数据报文格式是什么，有哪些状态码和异常值……


#### 测试阶段，压测发现系统性能峰值
在系统上线前，对系统进行全方位的压力测试，绘制出系统吞吐量和延迟曲线，然后找到最佳性能点，并在==超过最佳性能点时做限流==，如果达不到最佳性能点（比如多数系统的吞吐量，随着压力增大，吞吐量上不去）就需要考虑出现延迟和吞吐量的这几种情况。

1. 定位延迟问题
你要本着端到端的策略，大到整体流程，小到系统模块调用，逐一排查时间消耗在哪里。

你可以使用 kill -3 PID， jstack 等命令打印系统当前的线程执行的堆栈；还可以用一些性能分析工具，如 JProfiler 来监控系统的内存使用情况、垃圾回收、线程运行状况，比如你发现了运行的 100 个线程里面，有 80 个卡在某一个锁的释放上面，这时极有可能这把锁造成的延迟问题。

2. 对吞吐量问题的定位
对于吞吐量指标要和 CPU使用率一起来看，在请求速率逐步增大时，经常会出现四种情况：

|-|CPU上升|CPU不变|
|--|--|--|
|吞吐量上升|合理情况，持续施加更高的压力，直到达到吞吐量峰值|持续压测，施加更高压力，直到达到吞吐量峰值|
|吞吐量不变|可能是CPU被其他任务占用|最常见的情况，持续加压，吞吐量和CPU都没有变化，检查磁盘IO，网络带宽，工作线程|


### 总结
对于怎么评估系统高性能，你可以从系统的吞吐量、延迟以及 TP 99，这三个指标出发回答面试官提出的问题。而对于高级研发工程师，不仅仅要了解后端的性能指标，还有对全链路的性能指标有所了解。

另外，在实际生产环境，还会涉及 CDN 加速、ISP 路由策略、边缘计算等一系列网络工程层面的性能优化指标，这里展开的内容相对较多，你可以自己课下学习。总的来说，你要在大脑里先建立起整个请求的链路蓝图，熟悉每个环节的性能损耗。







## v18 如何从架构师角度回答怎么应对千万级流量的问题？

### 高性能设计中的"术"
学完上一讲后，你应该知道自己要从系统全链路的视角，从前端请求到后端服务评估各环节的性能指标，那么对于系统性能的优化，你依然要从全链路的视角上进行高性能的设计。

#### 前端优化
前端的优化主要有三个环节：==减少请求次数、页面静态化、边缘计算==。

##### 减少请求次数
减少前端脚本与后端服务的请求次数，有三种方案。
1. 增加缓存控制：
   前端研发同学经常会设置 HTML 的缓存控制头部（Cache-Control 头），这样浏览器在请求同一个文件时，只访问本地保存的资源副本，从而加速文件的访问速度。

2. 减少图像的请求次数：
   你可能经常会发现，大部分网站会将所有用到的==多张图片拼成一张==，这样多张图片只需要下载一次，然后再通过 CSS 中的 background-image 和 background-position 来定位目标位置选择显示哪一张图片。

3. 减少脚本的请求次数：
   通用的做法就是 CSS 压缩和 JavaScript 压缩，将多个文件压缩成一个，目的是减少传输文件的大小，而更重要的是减少请求数。

##### 页面静态化(+CDN)
缓存的一种方式，相当于把整个页面元素缓存起来，那么缓存在哪里呢？
通常是将页面文件事先存储在 ==CDN== 节点中，比如将商品详情页做静态化，就是将商品详情页的页面元素存储在 CDN 节点，然后所有请求就可以直接以由 CDN 来提供服务，就不会到达后端服务了，就减少了对后端服务的压力。


##### 边缘计算
大数据处理的实时性越来越高，由集中式的服务系统提供实时性的计算能力捉襟见肘，所以很多大厂开始将计算能力放到距离用户最近的 CDN 节点中，这就要求原有的 CDN 节点不只作为静态资源文件的缓存，而是要提供可以定制化的计算能力。
这部分内容会涉及一些新的概念，比如无服务架构 Serverless、BaaS、FaaS，在面试中不要求候选人必须掌握，但它会是你的加分项。


#### 后端优化
后端环节的性能问题，可以从基础设施层面、网络层面、架构层面三个角度进行考量

![f207bc7221bd64172d674d492e69942f.png](../_resources/f207bc7221bd64172d674d492e69942f.png)

比如，网络层面可以考虑网络专线、CDN 优化；架构层面可以考虑动静分离、集群优化、数据隔离、服务拆分、异步驱动、负载均衡等方案。



### 高性能设计中的"道"
在设计高性能系统架构时，
首先是清楚认知系统的硬性性能指标，举个例子。
- 指标需求：我们要保证系统的 TP 99 为 2s；
- 表面意思：系统要保证 99% 的请求的响应时间都在  2s 内；
- 深层意思：对有经验的架构师来说，这样的需求其实是不明确的，任何系统都有自己的承载能力范围，换句话说就是在并发用户数限定范围之内，一定要保证系统的 TP 99 = 2s，例如“我们要保证系统并发数在 100 万用户内的时候，TP 99 为 2s”，对于系统设计者而言，要清楚系统有所能，有所不能。

对一个架构师来说，要设计一个高性能的架构，至少要有以下四个系统设计的思考步骤。
- 明确指标： 比如当系统小于 100 万并发用户时，要保证系统的 TP 99 = 2s 。
- 保护系统： 当系统的并发用户数量超过 100 万，要做到保证有 100 万用户的 TP 99 = 2s ，然后保护系统，并拒绝其他用户的连接请求。
- 用户体验： 为了用户体验，要给系统承载容量外的用户提供优雅的体验，比如服务器排队机制，并附加具体、明确的信息提示。
- 快速扩容： 这一步很容易被一些同学忽略，如今系统的性能指标还有一点就是贵在快速反应，比如能承诺出现流量压力时，可以在 3 分钟内完成扩容，并保证扩容后能承载的并发用户数量的 TP 99 = 2s。

明确了性能指标之后，高性能架构的落地工作，可以分为以下三个关键技术点。
- 做好系统限流： 
  通过流量控制来保证系统的稳定性。当实际并发压力超过系统性能设计指标的时候，就拒绝新的请求的连接，让用户进行排队。
- 做好快速扩容： 
  对于扩容能力，一般要储备额外的计算资源，用于不时之需，也就是事先通过预估流出一部分资源池。
- 做好系统优化： 
  就是我在上面讲的前后端优化的技术点，我要再补充一点，对系统设计者来说，性能设计要贯穿于系统建设的始终。以一个系统的研发管理过程为例，内容大致包括需求阶段、设计阶段、研发阶段、测试阶段、上线阶段、运行阶段

对于性能设计（不仅仅是性能设计，所有非功能性的设计）要在项目的各阶段都进行考虑，以便根据项目过程的推进随时进行调整和优化。


### 总结

技术行业发展到今天，很多技术上的问题都不存在挑战了，所谓的==高性能架构设计，也仅仅变成了一种标准化的应对流程==。

你要做的就是==将业务问题，抽象成一个技术问题==，比如具体到数据库设计、缓存设计、队列设计、线程设计等技术细节，然后不管你通过什么渠道，Google 也好，问同事也好，或者购买付费知识也好，都能找到技术的应对方案。

而对于面试，你的答题思路应该是这样的：
- 先落实到技术上，比如结合业务场景，识别系统最关键的服务，然后针对性地为关键服务进行性能设计与测试，确保关键服务没有问题，然后为非关键服务提供降级和熔断处理方案。
- 再深化自己对于技术的理解，你要记住，任何复杂问题都可以按时间（系统建设周期）和空间（系统设计分层）拆解为简单的问题，然后逐一攻克，这样你才能有的放矢，这其中体现出来的思维能力才是每一个技术人的安身立命之本。





## v 互联网架构设计面试，你需要掌握的知识体系

那架构师的能力到底由哪几部分组成呢？
- 基础技术架构：这部分是纯技术架构，所有非功能性的技术都是基础技术的范畴。
- 业务架构：在业务场景下对业务需求的抽象。
- 开发技能：这是架构师落地架构的能力。

我们在开发时会经历需求分析、架构设计、架构选型、架构落地几个阶段，这几个阶段对架构师的能力要求总结为一句话就是“架构师要把握系统技术”。
- 在需求分析阶段：架构师对于业务架构，要给出一个合理的需求分析抽象模型。
- 在架构设计和架构选型阶段：架构师要充分考虑技术的合理性，制定合理的设计方案。
- 在架构落地阶段：架构师要能指导研发进行落地，并推进项目的执行。

从需求分析、架构设计、到架构选型、再到架构落地，架构师都需要参与，而这些阶段体现出来的需求分析能力、架构设计能力、代码开发能力，最终都会作用在一个系统上，这就是所谓的“把握系统技术”。也就是说，你如果想成为架构师就要做到、做好系统开发各环节的技术把控！


### 架构师知识体系
对于从事互联网分布式设计的架构师来说，你可以从以下四个角度来进行知识体系的拆解。

#### 存储
存储指分布式存储系统，你要理解什么是分布式存储系统？为什么选型分布式存储系统？以及分布式存储中关注哪些问题？

首先，为了解决数据的水平扩展，要做数据分片，因为分布式系统区别于传统单机系统就在于能将数据分布到多个节点，并在多个节点间实现负载均衡。这种数据水平扩容的操作叫==数据分片==。

数据分片会涉及==分片规则==，常见的有范围分片和哈希分片，不同的分片规则就有不同的分片算法，如哈希分片就会涉及哈希取模算法、虚拟桶算法、一致性哈希算法。

又因为数据要分布到多个节点，你还需要==数据复制==，数据复制就会存在同步复制和异步复制。为了保证数据的可靠性和可用性，增强系统容错，数据复制就会产生副本，副本则是分布式存储系统解决高可用的唯一手段。

而多个副本同步会产生==一致性问题==，从而引出一致性问题的分类，如强一致性、弱一致、最终一致，要想解决一致性问题，会涉及一致性问题的协议：如两阶段提交协议（Two-PhraseCommit，2PC）、Paxos协议选举、向量时钟（VectorClock）、RWN协议、Raft协议。

多个副本还会带来==主选举==，这会涉及==分布式锁==的问题：多个机器竞争一个锁，当某个机器释放锁或者挂掉，其他机器可以竞争到锁，继续执行任务。为了解决锁的容错性，比如解决双主（脑裂）问题，就会涉及==租约机制==，租约机制可以解决网络分区问题造成的“双主”问题。

最后，为了衡量副本==可用性和一致性==，就会引出分布式系统的基础理论 CAP 、BASE，以及 PACELC。

这样一来，我们就梳理清楚了分布式存储的知识体系。可以说，==分布式存储是分布式系统知识体系中最基础的理论，也是最复杂的问题==。

#### 计算
分布式计算就会涉及三个概念：==并行计算、分布式计算、云计算==。
- 并行计算：
  同时使用多种计算资源解决计算问题的过程，比如多线程就是一种并行计算；服务集群也是一种并行计算。
- 分布式计算：
  是从集群技术发展而来，区别在于集群虽然连接了多台机器，但某项具体的任务执行时还是会被转发到某台服务器上，分布式计算则将任务分割到多台服务器上并行计算，然后得到结果。
- 云计算：
  分布式计算 + 虚拟化技术的综合技术的统称，不同商业公司有着各自不同的定义，通俗来讲就是开发者利用云 API 开发应用，然后上传到云上托管，并提供给用户使用，而不关心云背后的运维和管理，以及机器资源分配等问题。

作为架构师，你要了解分布式领域中的计算模式，如分布式并行计算框架 Hadoop 中的 MapReduce 的设计思想，以及基于流式计算框架 Storm、Spark、Flink 的架构设计方案。

当然对于计算领域，很多公司会设立大数据架构师的岗位，如果你面试的是系统架构师，了解这部分知识体系即可，不用过度聚焦于分布式计算上，不过很多计算框架的设计理念还是很有参考价值的，值得你去学习了解。


#### 输入输出
系统架构中的输入输出，是指系统间通信的技术。

其中会涉及一些基础知识，比如网络通信最基础的协议（诸如 TCP/UDP 协议等）；网络 I/O 模型（Blocking-IO，NonBlocking-IO、Asyn-IO），最后是偏应用的知识，需要了解例如连接复用、序列化/反序列化、RPC、MQ 消息队列等。

作为架构师，你要理解高性能的原理，掌握流量的流转过程以及应对方案，比如当请求到达网络设备时，你要依次考虑以下问题：
- 网络设备如何处理流量？这会涉及中断和缓存。
- 操作系统如何处理流量？这会涉及 I/O 模型，select、poll、epoll，以及 I/O 多路复用。
- 应用系统如何处理流量？这会涉及 NIO 的开发，如 Reactor 模式、Netty 框架原理等。
- 系统线程如何处理流量？还会涉及多线程的设计模式。

最后，你还要掌握分布式系统通信的==核心技术：RPC 和 MQ==。



#### 控制器

你可以把分布式系统知识体系中的控制器，理解为系统架构中的==调度系统，包括流量调度和资源调度==。
- 流量调度（我们常说的流量控制）：
  作为架构师就要掌握流量控制的常用方案策略，比如==负载均衡、服务路由、熔断、降级、限流等==，其实常用的高可用、高性能的解决方案很多都是基于流量上的调度。
- 资源调度：
  如果我们将流量调度迁移到服务器的计算资源、存储资源或基础资源上面的话，就会引出另一种基于资源的调度，如 ==Mesos、Yarn 基于计算资源的调度；HDFS、GlusterFS、Ceph 基于存储资源的调度；Kubernetes、Mesos 基于容器资源的调度（包括计算、存储、网络等综合性的资源调度）==。

总的来说，你至少要掌握常用系统调度设计，调度算法与负载策略。举个例子，如果让你对单个服务器的计算资源做调度，你至少要具备设计思路：让集群选举一个主节点，每个从节点会向主节点汇报自己的空闲资源，当请求到来时，主节点通过资源调度算法选择一个合适的从节点来处理该请求。


### 总结
无论你从事哪个领域的架构设计工作，都要明白作为架构师，一定是技术出身，但是要突破技术思维的限制，向上立足于部门和公司、向下管控系统和研发，站在全局的角度去规划、组织、系统技术的发展。

为了方便你理解，我把学习架构设计知识的思路总结为以下几点：
- 想要学习架构设计知识，可以从自己熟知的领域出发，这样你才有不断的正反馈，从而更有信心，容易理解新的知识。
- 形成知识网络图谱，如今技术错综复杂，各种技术又相互耦合，确实无法简单划分层次，所以我建议你把自己的核心知识梳理出一个脉络清晰的结构图，然后结合已有知识，再逐步将零散的知识点补充到这张网络图谱之上，这样你就拥有了核心知识和扩展知识。
- 养成对技术判断力，针对同一问题有不同方法，不同维度、不同角度的分析和对比。这是为了提升你今后在工作中对技术的领悟力。




## 结束语

发现了一个很明显的问题，那就是：作为技术人员，很容易在学习的过程中，纠结于具体的形式（比如案例、代码）。==在我看来，相比于形式，思维过程最为重要。== 比如我是怎么思考到某个点？有哪些合理或者不合理的地方？哪些能变成你自己的？哪些你只是看个热闹？

技术人员的职业规划和发展：不仅要关注专业技术（术），还要有自己的分析能力（道），并且要懂得顺势而为（势）。

职场建议
送给老人的四条建议
- 思考
  希望你的思维是敏感的，通过敏感驱动思考，通过思考驱动学习和总结，直至敏锐。这确实需要大量的练习，它也是一个潜移默化的过程，最终你会因为这个习惯受益一生。

- 表达
  要有良好的表达能力，无论是和同事还是领导之间的沟通，这里的沟通并不是指会说话，而是会表达、**==敢表达==**、表达准确。
  表达不是指口才好，而是建立在你充分思考基础之上的分析，而我建议你多学习一下结构化思维，比如《金字塔原理》。相信你会发现表达、汇报、甚至 PPT 功底都会有所提升。

- 惊艳
  这一点其实是我对自己的要求，我会暗示自己，当作一件很有价值的事情时，评估的方式就是要惊艳到自己。
  因为只有惊艳到自己，你做的事情才会超出别人的预期，超出领导对你的期望。领导要的可能是 1，你要尽力做到 1.2，甚至 1.5，因为 1 谁都能做到，而超出的 0.2 / 0.5 就是你与其他人拉开的差距。==事事有回应，件件有着落，回应和着落都要超出预期==。 千万不要当职场老油条，因为懒惰会变成习惯，最终会影响你的判断力。

- 认知
  工作几年的职场老人，一定要对“地位、格局、方法论、手段”，这些看似很空的词有明确的认知，你要让这些极空的词儿变得很具体。举个例子，比如一道面试题“什么是架构设计？”，作为一名合格的职场技术人，至少要有以下的认知。
  1. 和一面解释：架构就是系统设计，比我在做 A 项目时，考虑到问题 X，我的解决办法是 Y。
  2. 和二面解释：架构就是业务发展中将系统变得有序，比如架构设计就是合理的组织系统、模块、组件，让它们更加有序，为的是让系统有能力快速响应（需求/用户/市场）变化。
  3. 和部门总监解释：架构即管理


作为技术人，要在职业发展过程中，让自己体会到这样的三个阶段，“做下不做上”“做下也做上”“做上不做下”，

