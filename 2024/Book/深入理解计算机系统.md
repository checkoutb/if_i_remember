



2024-05-17 09:36

[[toc]]

---
---


# ch1 计算机系统漫游

计算机系统是由硬件和系统软件组成

你将会学习一些实践技巧，比如
- 如何避免由计算机表示数字的方式引起的奇怪的数字错误。
- 你将学会怎样通过一些小窍门来==优化自己的 C 代码==，以==充分利用现代处理器和存储器系统的设计==。
- 你将了解编译器是如何实现==过程调用==的，以及如何利用这些知识来==避免缓冲区溢出==错误带来的安全漏洞，这些弱点给网络和因特网软件带来了巨大的麻烦。
- 你将学会如何识别和避免==链接时==那些令人讨厌的错误，它们困扰着普通的程序员。
- 你将学会如何编写自己的 Unix ==shell==，自己的==动态存储分配包==，甚至于自己的 Web 服务器。
- 你会认识==并发带来的希望和陷阱==，这个主题随着单个芯片上集成了多个处理器核变得越来越重要。

尽管 hello 程序非常简单，但是为了让它实现运行，系统的每个主要组成部分都需要协调工作。
从某种意义上来说，本书的目的就是要帮助你了解当你在系统上执行 hello 程序时，系统发生了什么以及为什么会这样。

```C
#include <stdio.h>
int main()
{
    printf("hello, world\n");
    return 0;
}
```

## 1.1 信息就是 bit + 上下文

源程序实际上就是一个由值 0 和 1 组成的位(又称为比特)序列，8 个位被组织成一组，称为字节。每个字节表示程序中的某些文本字符

hello.c 程序是以字节序列的方式储存在文件中的。每个字节都有一个整数值，对应
于某些字符。例如，第一个字节的整数值是 35, 它对应的就是字符“# ”。

像 hello.c 这样只由 ASCII 字符构成的文件称为文本文件，所有其他文件都称为二进制文件。


## 1.2 程序被其他程序翻译成不同的格式

在 Unix 系统上，从源文件到目标文件的转化是由编译器驱动程序完成的
`gcc -o hello hello.c`

GCC 编译器驱动程序读取源程序文件 hello.c, 并把它翻译成一个可执行目标文件 hello,这个翻译过程可分为四个阶段完成
- 预处理器cpp，读取hello.c，生成hello.i
  处理所有 预处理命令。
- 编译器ccl，生成hello.s
  翻译成汇编语言
- 汇编器as，生成hello.o
  翻译成 机器语言指令，打包成 ==可重定位目标程序== (relocatable object program)
- 链接器ld，将printf.o链接进来，生成hello 可执行文件。


## 1.3 了解编译系统如何工作是大有益处的

有一些重要的原因促使程序员必须知道编译系统是如何工作的。
- 优化程序性能
- 理解链接时出现的错误
- 避免安全漏洞

现代编译器都是成熟的工具，通常可以生成很好的代码。
我们不必为了高效 而了解编译器的内部工作，但是也需要了解一些 编译器转换C代码的 方式，比如
- switch 和 if-else 哪个高效
- 函数调用的开销
- while vs for
- 指针引用 vs 数组索引
- 为什么 循环求和的结果放到 本地变量 比 放到 通过引用传进来的参数 快很多
- 为什么 只需要重排列 算术表达式的括号 就可以让 函数更快
3,5,6章


一些最令人困扰的程序错误往往都与==链接器==操作有关，尤其是当你试图构建大型的软件系统时。比如
- 链接器报告 它无法解析一个引用，是什么意思
- 静态变量 和 全部变量的区别 是什么
- 如果在不同的 C文件中 定义了 2个同名的 全局变量 会发生什么
- 静态库 ，动态库的区别
- 命令行中 库的顺序 有什么影响
- 为什么有些 链接错误 直到 运行时 才会出现
7章

缓冲区溢出错误 是大多数网络 和 Internet服务器上 安全漏洞的主要原因。
3章


## 1.4 处理器读并解释储存在内存中的指令

`./hello`

shell 是一个命令行解释器。
如果命令行的第一个单词不是 内置的 shell 命令，那么就会假设这是 一个 可执行文件的名字， 加载并运行这个文件。


### 1.4.1 系统的硬件组成

1. 总线
   携带信息字节 并负责在 各个部件间 传递。
   被设计成 传送 ==定长的 字节块，即 字(word)==，现代大多数机器 的 字长 要么 4字节，要么 8字节
2. IO设备
   系统与外部世界的联系通道。
   每个IO设备 通过一个 控制器或 适配器(功能一样的) 与 IO总线 相连。
   - 控制器 是 IO设备 本身 或系统的 主板 上的 芯片组
   - 适配器 是 插在 主板上的 卡
3. 主存
   临时存储设备，在处理 执行程序时，用来存放程序和 程序处理的数据。
   从物理上讲，主存是 动态随机存取存储器(DRAM) 芯片组成。
   从逻辑上讲，主存是 一个线性的字节数组。
4. 处理器
   解释(或执行) 存储在主存中的指令的引擎。
   CPU的核心 是一个 大小为 一个字 的 存储设备 (或 寄存器), 称为 程序计数器(PC)。 在任何时候，PC都指向 主存中 某条机器语言指令。
   围绕着 主存，寄存器文件(register file)，算术/逻辑单元(ALU) 进行。
   - 寄存器文件时一个 小的存储设备，由一些单个字长的 ==寄存器组成==，每个寄存器都有唯一的名字
   - ALU 计算新的数据和地址值
   
   下面是一些简单的操作
   - 加载，从主存复制一个字节 或 字 到 寄存器，覆盖原来的内容
   - 存储，从寄存器 复制一个字节 或字 到 主存，
   - 操作，把2个寄存器的 内容复制到 ALU，ALU进行算术运算，并将 结果放到 一个 寄存器。
   - 跳转，从指令本身中 抽取一个 字，并将这个 字 复制到 程序计数器中。


---

通过 DMA(直接存储器存取) ，数据可以不通过CPU 而直接 从 磁盘 到内存。


## 1.5 高速缓存至关重要

一个重要的问题，即系统花费了大量的时间把信息从一个地方挪到另一个地方

针对这种处理器与主存之间的差异，系统设计者采用了更小更快的存储设备，称为高速缓存存储器（cache memory, 简称为 cache 或高速缓存），

位于处理器芯片上的 L1 高速缓存的容量可以达到数万字节，访问速度几乎和访问寄存器文件一样快。
一个容量为数十万到数百万字节的更大的 L2 高速缓存通过一条特殊的总线连接到处理器。
进程访问 L2 高速缓存的时间要比访问 L1 高速缓存的时间长 5 倍，但是这仍然比访问主存的时间快 5-10 倍。
L1 和 L2 高速缓存是用一种叫做==静态随机访问存储器(SRAM)==的硬件技术实现的。

比较新的、处理能力更强大的系统甚至有三级高速缓存：LI，L2 和L3。



1.6 存储设备形成层次结构


## 1.7 操作系统管理硬件

操作系统有两个基本功能：
- 防止硬件被失控的应用程序滥用；
- 向应用程序提供简单一致的机制来控制复杂而又通常大不相同的低级硬件设备。

操作系统通过几个基本的抽象概念（==进程、虚拟内存和文件==）来实现这两个功能

- 文件是对I/O 设备的抽象表示，
- 虚拟内存是对 主存和磁盘 I/O 设备的抽象表示，
- 进程则是对 处理器、主存和 I/O 设备的抽象表示

进程是操作系统对一个正在运行的程序的一种抽象。

操作系统保持跟踪进程运行所需的所有状态信息。这种状态，也就是上下文，包括许多信息，比如
- PC 和
- 寄存器文件的当前值，以及
- 主存的内容。


从一个进程到另一个进程的转换是由操作系统内核(kernel)管理的。
内核是操作系统代码常驻主存的部分。当应用程序需要操作系统的某些操作时，比如读写
文件，它就执行一条特殊的==系统调用(system call==)指令，将控制权传递给内核。
然后内核执行被请求的操作并返回应用程序。
注意，内核==不是==一个独立的进程。相反，它是==系统管理全部进程所用代码和数据结构的集合==。

一个进程实际上可以由多个称为==线程的执行单元==组成，每个线程都运行在进程的上下文中，并共享同样的代码和全局数据

由于网络服务器中对并行处理的需求，线程成为越来越重要的编程模型，因为多线程之间比多进程之间==更容易共享数据==，也因为线程一般来说都比进程==更高效==。
当有多处理器可用的时候，多线程也是一种使得程序可以运行得更快的方法


虚拟内存是一个抽象概念，它为每个进程提供了一个假象，即每个进程都在独占地使用主存。每个进程看到的内存都是一致的，称为==虚拟地址空间==

在 Linux 中，地址空间最上面的区域是保留给操作系统中的代码和数据的，这对所有进程来说都是一样。
地址空间的底部区域存放用户进程定义的代码和数据。

![03cfbebb115f82b8ca25eb84b743be66.png](../_resources/03cfbebb115f82b8ca25eb84b743be66.png)



==文件就是字节序列==，仅此而已。每个 I/O 设备，包括磁盘、键盘、显示器，甚至网络，都可以看成是文件。

系统中的所有输人输出都是通过使用一小组称为 Unix I/O 的==系统函数调用==读写文件来实现的。


## 1.8 系统之间利用网络通信

随着 Internet 这样的全球网络的出现，从一台主机复制信息到另外一台主机已经成为计算机系统最重要的用途之一。
比如，像电子邮件、即时通信、万维网、FTP 和 telnet 这样的应用都是基于网络复制信息的功能。


## 1.9 重要主题

### Amdahl 定律

当我们对系统的==某个部分加速==时，其对系统整体性能的影响取决于==该部分的重要性和加速程度==。
若系统执行某应用程序需要时间为 T1，假设系统某部分所需执行时间与该时间的比例为a ，而运部分性能提升比例为 k， 即该部分初始所需时间为 a * T1，现在所需时间为 (a * T1) / k 。因此，总的执行时间是
`T2 = (1 - a) * T1 + (a * T1) / k = T1 * [(1-a) + a/k]`

加速比为
`S = 1 / [(1-a) + a/k]`

。。就是
程序需要 T1， 优化部分占比 a， 这部分性能提升了 k 倍， 所以 这部分 从 原先的 a * T1 优化到了 (a * T1) / k 。


Amdahl 定律一个有趣的特殊情况是考虑 A 趋向于 无穷大 时的效果
`S = 1 / (1-a)`


### 1.9.2 并发和并行

多核处理器

超线程

![f5421d4da975d19d2b753aad925df31f.png](../_resources/f5421d4da975d19d2b753aad925df31f.png)



指令级并行

现代处理器可以同时执行多条指令的属性称为指令级并行

超标量(super scalar)处理器, 可以达到比一个周期一条指令更快的执行速率


单指令、多数据并行
单指令、多数据，即 SIMD 并行

较新几代的 Intel 和 AMD 处理器都具有并行地对 8 对单精度浮点数(C 数据类型 float)做加法的指令。


# 第一部分 程序结构和执行

# ch2 信息的表示和处理

单个的位不是非常有用。
然而，当把位组合在一起，再加上某种解释(interpretation), 即赋予不同的可能位模式以含意，我们就能够表示任何有限集合的元素


## 2.1 信息存储

最低有效字节在最前面的方式，称为小端法(little endian)
最高有效字节在最前面的方式，称为大端法(big endian)

![e41fcec265e89732bdc1c167d1bd36ee.png](../_resources/e41fcec265e89732bdc1c167d1bd36ee.png)

。。大端法 符合 人。 但是似乎 全是小端模式， 除了网络传输 必须大端，其他都是 小端。
。。小端 符合代码，
```C
int idx = 0x100;
while (a > 0)
{
    memory[idx++] = a % 0xFF;
    a /= 0xFF;
}
```


字节顺序的影响
- 网络传输
- 反汇编
- 强制类型转换 或 union


## 2.2 整数表示

int32_t
uint32_t
int64_t
uint64_t

。。32位 和 64位上， 区别是 long， long 在 32位上是 32位，  在 64位上是 64位

。。unsigned， signed 之间 的强转， bit 不变，只是改变了 bit 的 解释方式。


这表明当把 short 转换成 unsigned 时，我们先要改变大小，之后再完成从有符号到
无符号的转换。
也就是说(unsigned) sx 等价于(unsigned)(int) sx, 求值得到 4294954951，而不等价于(unsigned)(unsigned short) sx, 后者求值得到 53191。
事实上，这个规则是 C 语言标准要求的。

转为更大的数据类型时
- 无符号数进行 0扩展
- 补码数进行 符号扩展

。。都是符号， 无符号数，肯定是 正数。

转换为更小的数据类型时，都是 截断， 但 有符号数 需要把 符号位 保留下来。



模数加法形成了一种数学结构，称为==阿贝尔群== (Abelian group), 这是以丹麦数学家Niels Henrik Abel(1802 - 1829)的名字命名。
也就说，它是可交换的（这就是为什么叫 abelian的地方）和可结合的。
它有一个单位元 0, 并且每个元素有一个加法==逆元==。


既然补码加法与无符号数加法有相同同的位级表示，我们就可以按如下步骤表示运算+: 将其参数转换为无符号数，执行无符号数加法，再将结果转换为补码

![8159a553903566c0ced148ef68c24cfd.png](../_resources/8159a553903566c0ced148ef68c24cfd.png)


乘法


## 2.4 浮点数

IEEE 浮点标准用 V = (-1)^s * M * 2^E  的形式来表示一个数

- 符号(sign) s决定是 正数还是 负数
- 尾数(significand) M 是一个 二进制小数，范围是 1 - 2-e, 或 0 - 1-e
- 阶码(exponent) E 对 浮点数 进行 加权。 权重是 2^E，E可能是负数。


![ac2467f7124cd6586d76bd44d80fee7c.png](../_resources/ac2467f7124cd6586d76bd44d80fee7c.png)


浮点加法不具有结合性，这是缺少的最重要的群属性。
。。因为舍入的存在

C 语言标准不要求机器使用 IEEE 浮点

将大的浮点数转换成整数是一种常见的程序错误来源

。。100道习题。。 而且 每节也有一些题目的。


# ch3 程序的机器级表示


## 3.2 程序编码

假设一个C程序，有2个文件 p1.c, p2.c， 使用命令编译这些代码
`gcc -Og - o p p1.c p2.c`

gcc就是 GCC C编译器， 可以使用 cc 启动。
-Og 告诉 编译器 生成 符合原始 C代码 结构的机器码。 较高的优化级别 会导致 代码 严重变形。

1. 预处理，生成 p1.i, p2.i
2. 编译器，生成 p1.s, p2.s
3. 汇编器，生成 p1.o, p2.o
4. 链接器，生成 p


对于机器级编程来说，其中两种抽象尤为重要。
第一种是由==指令集==体系结构或指令集架构(Instruction Set Architecture, ISA)来定义机器级程序的格式和行为，它定义了处理器状态、指令的格式，以及每条指令对状态的影响。

第二种抽象是，机器级程序使用的内存地址是==虚拟地址==，提供的内存模型看上去是一个非常大的字节数组。


程序内存包含：程序的可执行机器代码，操作系统需要的一些信息，用来管理过程调用和返回的运行时栈，以及用户分配的内存块

汇编格式：gcc 默认 AT&T, 微软默认 Intel


## 3.3 数据格式

Intel 使用 word 表示 16位数据类型， 32位是 双字(double words)， 64为 4字(quad words)

|C类型|Intel数据类型|汇编代码后缀|字节大小|
|--|--|--|--|
|char|字节|b|1|
|short|字|w|2|
|int|双子|l|4|
|long|四字|q|8|
|char*|四字|q|8|
|float|单精度|s|4|
|double|双精度|l|8|

l不会产生歧义，因为 整数 和 浮点数 使用的是 完全不同的 指令和寄存器

大多数 GCC 生成的 汇编指令 都有一个 字符后缀，表明 操作数的 大小，如 movb 传送字节，movw 传送字，movl 传送双字，movq 传送4字



## 3.4 访问信息(寄存器名字与用途)

一个 x86-64 CPU 包含 一组 16个存储 64位值的 ==通用目的寄存器==。 用于存储 整数 和 指针。
寄存器名称是由 指令集历史演化造成的。
最初 8086 有 8个16位的寄存器，即 图中的 %ax - %bp, 每个寄存器 有特殊的用途，它们的名字就反映了这些不同的用途
扩展到 IA32，这些寄存器 也扩展成了 32位寄存器，标号 从 %eax - %ebp.
扩展到 x86-64后， 原先的8个寄存器 扩展成 64位， 标号从 %rax - %rbp. 还增加了8个寄存器，标号 %r8 - %r15

![7ee6bb1aa7298ff419b49e133122d790.png](../_resources/7ee6bb1aa7298ff419b49e133122d790.png)

嵌套的方框表明，指令可以对 这16个寄存器的 低位字节 中存放的 不同大小的数据 进行操作。
字节级操作可以访问最低的字节
16位操作 可以访问 最低的 2个字节
32位操作  最低的 4字节
64位操作， 整个寄存器

对于生成 小于 8字节 结果的操作， 寄存器中 剩下的字节会怎么样？ 对此有2条规则
- 生成1,2 字节的指令 会保持 剩下的 高位字节 不变
- 生成4 字节的指令 会将 剩下的 高位 置为 0

不同的寄存器 扮演着 不同的角色。最特别的是 栈指针 %rsp ， 用来指明 运行时 栈的结束位置。 有些程序 会明确地 读写这个寄存器。
另外的 15个寄存器 的用法更灵活。 少量指令 会使用 特定的 寄存器。

有一组标准的编程规范控制着如何使用寄存器来管理栈、传递函数参数、从函数的返回值，以及存储局部和临时数据。  3.7中讲解。


### 3.4.1 操作数指示符

大多数 指令 有一个 或多个操作数，指出 执行一个操作 需要使用的 源数据值，以及存放结果的 目的位置。

x86-64 支持多种 操作数格式。  
源数据值 可以以 常数形式给出，或 从寄存器 或 内存中 读出。
结果可以放到 寄存器 或内存中。

不同的操作数可以 分为3种
- 立即数，表示 常数，ATT格式的汇编中，是 $ 后跟整数值，比如 $-555, $0x1F
- 寄存器，表示某个寄存器的内容。 用 R 表示
- 内存引用，根据计算出来的地址 访问某个内容位置。M

有多种 ==寻址模式==。
最后一个 Imm(rb,ri,s) 是最常用的， 由4个部分组成，
- 立即数偏移 Imm
- 基址寄存器 rb
- 变址寄存器 ri
- 比例因子s，s必须是 1,2,4,8

基址，变址 寄存器 必须是 64位寄存器。
有效地址是 `Imm + R[rb] + R[ri] * s`

![0a0e2e2f05ea83fc85a2b060b896176e.png](../_resources/0a0e2e2f05ea83fc85a2b060b896176e.png)



### 3.4.2 数据传送指令

最频繁使用的指令是将数据从一个位置复制到另一个位置的指令
MOV 类由四条指令组成：
movb,movw,movl,movq 。表格上还有个 movabsq
这些指令都执行同样的操作；主要区别在于它们操作的数据大小不同：分别是 1、2、4 和 8 字节

mov 的第一个操作数是 源，第二个是 目标

mov 的 源和目标 有 5种可能的组合
常数 - 寄存器
常数 - 内存
寄存器 - 寄存器
寄存器 - 内存
内存 - 寄存器

。。没有 内存到 内存。

将较小的源值 复制到 较大的目的 时，mov 有变种：
- movz，目的中 多余bit 填充为0
- movs，目的中 多余bit 填充为 符号位
最后2位 是 源，目的 大小指示符

0扩展
movzbw，字节->字
movzbl，字节->双字
movzwl，字 - 双字
movzbq，字节 - 四字
movzwq，字 - 四字

符号扩展
movsbw，
movsbl，
movswl，
movsbq，
movswq，
movslq，双字 - 四字
cltq

movl 双字 - 四字时， 是 0 扩展，所以没有 movzlq




### 3.4.4 压入和弹出栈数据

最后两个数据传送操作可以将数据压人程序栈中，以及从程序栈中弹出数据
- pushq, 将4字压入栈，修改 栈指针 %rsp - 8，保存数据
- popq，将4字弹出栈，弹出数据，修改 %rsp + 8

2个指令 都只有一个 操作数， 压入的数据源，弹出的目的地

因为栈和程序代码以及其他形式的程序数据都是放在同一内存中，所以程序可以用标准的内存寻址方法==访问栈内的任意位置==。
例如，假设栈顶元素是四字，指令 movq 8(%rsp), %rdx 会将第二个四字从栈中复制到寄存 %rdx



## 3.5 算术和逻辑操作

大多数指令都有 不同大小操作数的 变种，只有 leaq没有。
- leaq，加载有效地址  `leaq S, D`  `D = &S`
- inc，加1  `add D` `D = D + 1`
- dec
- neg，取负
- not，取补
- add，+  `add S, D`  `D = D + S`
- sub
- imul
- xor，异或
- or，或
- and，与
- sal，左移， `sal k, D`   `D = D<<k`
- shl，左移(等于 sal)
- sar，算术右移
- shr，逻辑右移


leaq
load effective address，实际上是 movq 的变形。
第一个操作数 看上去是 内存引用，但 该指令 并不是 读取 该位置的值， 而是 将 有效地址 写入 目标。
这条指令可以为后面的内存引用产生指针
目的操作数 必须是 寄存器

它还可以简洁地描述普通的算术操作
例如，如果寄存器 %rdx 的值为 x，那么指令 `leaq 7(%rdx,%rdx,4), %rax` 将设置寄存器 %rax 的值为 5x + 7

。。`7(%rdx,%rdx,4)` 就是寻址操作 (rdx + rdx * 4 + 7) ， 但是 上面是 &S，这个怎么 转换。 大约懂了， 上面的 D=&S 是指 将 S 转成地址 ，不是 取 S 的地址， 因为 S 基本都是 间接寻址，所以 leaq 就是 计算 间接寻址 的 结果，并保存到 D 中。。 对，名字也是 load effective address， 需要 绝对地址。

。。 但是，实际要做的 事情 并不会减少吧。 就是 leaq 是一个 比较 胖的操作？ 当然 比 多个 瘦的操作 快。 操作的 固定消耗很大，寻找指令，加载指令，执行指令 等

leaq 指令能执行加法和有限形式的乘法


### 3.5.5 特殊的算术操作

16字节， 8字(oct word)

- imulq 有符号 乘法
- mulq 无符号
- clto, 符号扩展转换为8字
- idivq 除法
- divq

%rdx, %rax 组成了8字，所以 上面的操作数 有一个 一直是 %rax， 另外一个 需要 指令中 提供。


## !! 3.6 控制(条件码寄存器) !!!

jump 指令可以改变 机器代码指令的执行顺序

除了整数寄存器，CPU还维护着 一组 单个位的 条件码(condition code) 寄存器。
它们描述了 最近的算术 或逻辑操作的 属性，可以检测这些 寄存器 来 执行 条件分支指令。 
最常用的条件码有
- CF，进位标志，最近的操作 使最高位 产生了进位，可以用来检查 无符号操作的溢出
- ZF，0标志，最近的操作的结果是0
- SF，符号标志，最近的操作得到的结果 是负数
- OF，溢出秒之，最近的操作 导致 一个补码溢出 (正溢出 或 负溢出)

leaq 不改变任何 条件码。

有2类 指令 会设置 条件码，不修改 任何其他 寄存器
- cmp
- test
各自都有 b,w,l,q 的变种。

cmp 的行为 和 sub 一样，test 的行为 和 add 一样， 但它们都只设置 条件码，不修改 目的寄存器的值


条件码 通常不会直接读取，常用的方法有3种
- 根据条件码的某种组合，将一个 字节设置为 0或1
- 条件跳转到 程序的 某个其他部分
- 有条件地 传输 数据

第一种指令 称为 set指令。比如 sete,setne,sets,setns,setg,setge,setl,setle,seta,setae,setb,setbe (等于0，负数，有符号大于等于，无符号大于等于)
。部分指令还有 同义名
。。配合上 溢出 很复杂。


跳转指令
jmp无条件跳转，跳转到 某个符号 或 寄存器/内存的值，前者是 直接跳转，后者是 间接跳转。

jmp,je,jne,js,jns,jg,jge,jl,jle,ja,jae,jb,jbe
。还有同义名
直接跳转，等于0，负数，有符号大于，无符号大于


我们不关心 机器代码格式 的细节， 但是要 理解 跳转指令的目标 是如何编码的，这对 第七章 研究 链接 非常重要。

跳转指令有 几种不同的编码，但 最常用的是 PC相对 (PC relative)。 也就是，它们会将 目标 指令的地址 与 紧跟在 跳转指令后面的 那条指令 的地址之间的差 作为 编码。
另一种是 绝对地址，用 4个字节 直接指定目标。

![0925e247fb6f9d4f8930b805f1b14504.png](../_resources/0925e247fb6f9d4f8930b805f1b14504.png)

右侧，jmp,jg 指明了 8和5。
左侧 eb 03, 7f f8, 03, f8 就是 相对地址，代表 +3，-8。

---

3.6.5 用条件控制来实现条件分支

我们可以看到 absdiff_se 对应汇编代码的控制流非常类似于gotodiff_se 的 goto 代码。

![fd82765d0930fb09220793edf017722f.png](../_resources/fd82765d0930fb09220793edf017722f.png)


C中的 if-else
```text
if (test)
    then-statement;
else
    else-statement;
```
会被翻译为

```text
    t = test;
    if (!t)
        goto false_;
    then-statement;
    goto done;
false_:
    else-statement
done:
```

3.6.6 用条件传送来实现条件分支

实现条件操作的传统方法是通过使用控制的条件转移。
当条件满足时，程序沿着一条执行路径执行，而当条件不满足时，就走另一条路径。
这种机制简单而通用，但是在现代处理器上，它可能会==非常低效==。

一种替代的策略是使用数据的条件转移。
这种方法计算一个条件操作的两种结果，然后再根据条件是否满足从中选取一个
只有在一些受限制的情况中，这种策略才可行

![68166b43c053264f6cef7b9b80b1844f.png](../_resources/68166b43c053264f6cef7b9b80b1844f.png)


为了理解为什么基于条件数据传送的代码会比基于条件控制转移的代码性能要好，我们必须了解一些关于现代处理器如何运行的知识。
正如我们将在第4章和第5章中看到的，处理器通过使用==流水线==(pipelining)来获得高性能，
在流水线中，一条指令的处理要经过一系列的阶段，每个阶段执行所需操作的一小部分（例如，从内存取指令、确定指令类型、从内存读数据、执行算术运算、向内存写数据，以及更新程序计数器）。 
这种方法通过==重叠连续指令==的步骤来获得==高性能==，例如，在取一条指令的同时，执行它前面一条指令的算术运算。
要做到这一点，要求能够==事先确定要执行的指令序列==，这样才能==保持流水线中充满了待执行的指令==。
当机器遇到条件跳转（也称为“分支”）时，只有当分支条件求值完成之后，才能决定分支往哪边走。
处理器采用非常精密的分支预测逻辑来猜测每条跳转指令是否会执行。
只要它的猜测还比较可靠（现代微处理器设计试图达到 90%以上的成功率），指令流水线中就会充满着指令。
另一方面，错误预测一个跳转，要求处理器丢掉它为该跳转指令后所有指令已做的工作，然后==再开始用从正确位置处起始的指令去填充流水线==。
正如我们会看到的，这样一个错误预测会招致很严重的惩罚，浪费大约 15-30 个时钟周期，导致程序性能严重下降。

。。就是
1. 要让 流水线够长，才能 发挥 流水线的 高效
2. 不能 预测错。 CPU会 通过 预测 来 预先填充 命令到流水线， 如果 预测错，那么 之前预先填充的 命令 就被 丢弃，重新去 读取命令
。。挺抽象的，因为上面的 代码 它还是有 跳转的。


条件传送指令，每个指令 都有 2个操作数，源寄存器/内存地址 S， 目的寄存器 R。
不同与 set，jmp， 这些指令的结果 取决于 条件码的 值。

cmove,cmovne, 受 ZF 影响
cmovs,cmovns, SF
cmovg,cmovge, SF,OF,ZF
cmovl,cmovle, SF,OF
cmova,cmovae, CF,ZF
cmovb,cmovbe, CF,ZF

还有很多 同义名

总的来说，条件数据传送 提供了一种用条件控制转移来实现条件操作的替代策略。
它们只能用于非常受限制的情况，但是这些情况还是相当常见的，而且与现代处理器的运行方式更契合


### 3.6.7 循环
do-while, while, for


do-while 可以翻译为
```text
loop:
    body-statement
    t = test-expr;
    if (t)
        goto loop;
```



while
第一种翻译方法
```text
    goto test;
loop:
    body-statement;
test:
    t = test-expr;
    if (t)
        goto loop;
```

第二种, 将 while 翻译为 do-while
```text
t = test-expr;
if (!t)
    goto done;
    do
        body-statement;
    while(test-expr);
done:
```
即
```text
t = test-expr;
if (!t)
    goto done;
loop:
    body-statement;
    t = test-expr;
    if (t)
        goto loop;
done:
```

利用这种实现策略，编译器常常可以优化初始的测试，例如认为测试条件总是满足



for
```text
init-expr;
while (test-expr) {
    body-statement;
    update-expr;
}
```
有2种while翻译，所以for也有2种翻译
```text
    init-expr;
    goto test;
loop:
    body-statement;
    update-expr;
test:
    t = test-expr;
    if (t)
        goto loop;
```

```text
    init-expr;
    t = test-expr;
    if (!t)
        goto done;
loop:
    body-statement;
    update-expr;
    t = test-expr;
    if (t)
        goto loop;
done:
```


### 3.6.8 switch

switch(开关)语句可以根据一个整数索引值进行多重分支(multiway branching)

在处理具有多种可能结果的测试时，这种语句特别有用。
它们不仅提高了 C 代码的==可读性==，而且通过使用==跳转表==(jump table)这种数据结构使得实现==更加高效==。
跳转表是一个数组，表项i 是一个代码段的地址，这个代码段实现当开关索引值等于 i 时程序应该采取的动作。

和使用一组很长的 if-else 语句相比，使用跳转表的优点是执行开关语句的时间与开关情况的数量无关。
GCC 根据开关情况的数量和开关情况值的稀疏程度来 翻译开关语句。
当开关情况数量比较多(例如 4 个以上)， 并且值的范围跨度比较小时，就会使用跳转表。


![e343f2812c22e7703579c1725a881903.png](../_resources/e343f2812c22e7703579c1725a881903.png)


![f3c958106b8b1390aa51e17e0bab0d90.png](../_resources/f3c958106b8b1390aa51e17e0bab0d90.png)


![2f8c07202b2a6749e4134daf519605cd.png](../_resources/2f8c07202b2a6749e4134daf519605cd.png)

这些声明表明，在叫做 .rodata (只读数据，Read-Only Data)的目标代码文件的段中


检査所有这些代码需要很仔细的研究，但是关键是领会使用跳转表是一种非常有效的实现多重分支的方法。
在我们的例子中，程序可以只用一次跳转表引用就分支到 5 个不同的位置。
甚至当 switch 语句有上百种情况的时候，也可以只用一次跳转表访问去处理。


## 3.7 过程

过程是软件中一种很重要的抽象。
它提供了一种封装代码的方式，用一组指定的参数和一个可选的返回值实现了某种功能。

假设过程P 调用过程 Q，Q 执行后返回到 P， 这些动作包括下面一个或多个机制：
- 传递控制
  进入Q前，要设置 程序计数器 的值 为 Q 的代码起始地址， 从Q返回时，需要设置PC为P中调用Q 后面那条指令的地址
- 传递数据
  P 要向 Q提供 1个或多个参数， Q需要向P 返回一个值
- 分配和释放内存
  开始时，Q可能需要为局部变量分配空间，返回前必须释放这些空间。

X86-64 的过程实现包括一组特殊的指令和一些对机器资源(例如寄存器和程序内存)使用的约定规则


运行时栈

转移控制
- call 调用过程
- ret 从过程返回

call 的效果是==将返回地址 0x400568 压入栈==中，并==跳到被调用函数的第一条指令==
ret 指令。这条指令从栈中弹出值 0x400568，然后跳转到这个地址，就在 call 指令之后，继续 main 函数的执行


X86-64 中，可以通过寄存器最多传递 6 个整型（例如整数和指针）参数。
寄存器的使用是有特殊顺序的，寄存器使用的名字取决于要传递的数据类型的大小，

|操作数大小(位)|第1个参数|2|3|4|5|6|
|--|--|--|--|--|--|--|
|64|%rdi|%rsi|%rdx|%rcx|%r8|%r9|
|32|%edi|%esi|%edx|%ecx|%r8d|%r9d|
|16|%di|%si|%dx|%cx|%r8w|%r9w|
|8|%dil|%sil|%dl|%cl|%r8b|%r9b|

如果一个函数有大于 6 个整型参数，超出 6 个的部分就要通过栈来传递。

假设过程 P 调用过程 Q, 有n 个整型参数，且n > 6。那么 P 的代码分配的桟帧必须要能容纳 7-n 号参数的存储空间

把参数 1 6 复制到对应的寄存器，把参数 7-n 放到栈上，而参数 7 位于栈顶。
通过==栈传递参数==时，所有的数据大小都向 ==8 的倍数对齐==


3.7.4 栈上的局部存储

有些时候，局部数据必须存放在内存中，常见的情况包括：
- 寄存器不足够存放所有的本地数据。
- 对一个局部变量使用地址运算符 &，因此必须能够为它产生一个地址。
- 某些局部变量是数组或结构，因此必须能够通过数组或结构引用被访问到。在描述数组和结构分配时，我们会讨论这个问题。





## 3.8 数组分配和访问

优化编译器非常善于简化数组索引所使用的地址计算。不过这使得 C 代码和它到机器代码的翻译之间的对应关系有些难以理解


3.8.4 定长数组

### 3.8.5 变长数组

ISO C99 引入了一种功能，允许数组的维度是表达式，在数组被分配的时候才计算出来。

`int A[expr1][expr2]`

。。C99 有， C++至今没有(不过有 vector)



## 3.9 异质的数据结构

C 语言提供了两种 将不同类型的对象组合到一起创建数据类型的机制
- struct
- union

结构的所有组成部分都存放在内存中一段连续的区域内，而指向结构的指针就是结构第一个字节的地址。
编译器维护关于每个结构类型的信息，指示每个字段(field)的字节偏移。
它以这些偏移作为内存引用指令中的位移，从而产生对结构元素的引用。


union 的语法 和 struct 一样，但 语义差别较大
```C
struct S3 {
    char c;
    int i[2];
    double v;
};

union U3 {
    char c;
    int i[2];
    double v;
};
```

在 x86-64 机器上，字段的偏移量，总大小 如下
|类型|c偏移|i|v|总大小|
|--|--|--|--|--|
|S3|0|4|16|24|
|U3|0|0|0|8|


二叉树，每个非叶子节点只有 指向 子女的指针，没有 数据
叶子节点 只有数据，没有 指向子女的指针
```C
union node_u {
    struct {
        union node_u *left;
        union node_u *right;
    } internal;
    double data[2];
};
```
不过，这样就没有办法 判断 节点 是不是 叶子节点。
通常的方法是 引入一个 枚举类型，定义这个union中 可能的 不同选择。

```C
typedef enum {N_LEAF, N_INTERNAL} nodetype_t;

struct node_t {
    nodetype_t type;
    union {
        struct {
            union node_u *left;
            union node_u *right;
        } internal;
        double data[2];
    } info;
};
```
这个 union 一共需要 24字节。 type是4字节，但是为了对齐，所以需要8字节。


```C
unsigned long double2bits(double d) {
    union {
        double d;
        unsigned long u;
    } tmp;
    tmp.d = d;
    return tmp.u;
}
```

下面的方法受到 小端，大端的影响。
小端，word0 是 d 的低4字节。
```C
double uu2double(unsigned word0, unsigned word1)
{
    union {
        double d;
        unsigned u[2];
    } tmp;
    tmp.u[0] = word0;
    tmp.u[1] = word1;
    return tmp.d;
}
```


### 3.9.3 数据对齐

计算机系统会对 基本数据类型的 合法地址 做出一些限制。
要求某种类型对象的地址必须是某个值 K(通常是 2、4 或 8)的倍数。
这种对齐限制简化了处理器和内存系统之间接口的硬件设计

无论数据是否对齐，X86-64 硬件都能正确工作。
不过，Intel 还是建议要对齐数据以提高内存系统的性能。
对齐原则是==任何 K 字节的基本对象的地址必须是 K 的倍数==

汇编代码中 `.align 8`
保证后面的数据的 起始地址 是8的倍数。

对于大多数 X86-64 指令来说，保持数据对齐能够提高效率，但是它不会影响程序的行为
如果数据没有对齐，某些型号的 Intel 和 AMD 对于 实现多媒体操作的 ==SSE指令== ，就无法正确执行。
。。SSE（Streaming SIMD Extensions），有70条 指令



## 3.10 在机器级程序中将控制与数据结合起来

3.10.1 理解指针

- 每个指针都有一个类型
- 每个指针都有一个值
- 使用 & 运算符创建指针
- 使用 * 运算符反引用指针
- 数组与指针紧密联系
- 将指针从一种类型 转换成 另一种类型，只改变了它的类型，不改变它的值
- 指针也可以指向函数

。。可以用指针 完成 double的bit -> long的bit 的转换吗？

```C
int fun(int x, int *p);

//////
int (*fp)(int, int*);
fp = fun;

//////
int y = 1;
int r = fp(3, &y);
```
函数指针的值是该函数机器代码表示中第一条指令的地址。

(*fp) 的 () 是必须的


3.10.2 使用 GDB 调试器

`gdb exefile` 启动 gdb

![8bee6e6419dd4b61b5e1746891c4ddfd.png](../_resources/8bee6e6419dd4b61b5e1746891c4ddfd.png)



3.10.3 内存越界引用和缓冲区溢出

### 3.10.4 对抗缓冲区溢出攻击

1. 栈随机化，已经是标准行为。
2. 栈破坏检测，在 栈帧的 任何局部缓冲 与 栈状态之间 存储一个 特殊值，该值 在运行时 随机产生。在恢复寄存器 和 从函数返回之前，程序检查 这个值是否被 修改。如果是，那么程序 异常终止。
3. 限制可执行代码区域，限制 哪些内存区域能存放 可执行代码。

3.10.5 支持变长栈帧

有些函数，需要的局部存储是变长的。
例如，当函数调用 alloca 时就会发生这种情况。alloca 是一个标准库函数，可以在栈上分配任意字节数量的存储



## 3.11 浮点代码

处理器的浮点体系结构包括多个方面，会影响对浮点数据操作的程序如何被映射到机器上
- 如何存储和访问浮点数值，通常是通过 某种寄存器方式 来完成的
- 向浮点数据操作的指令
- 向函数 传递浮点数参数，返回浮点数结果的规则
- 函数调用过程中保存寄存器的规则，例如 一些寄存器被指定为 调用者保存，而其他指定为 被调用者保存

我们的讲述基于 AVX2，即 AVX的第二个版本，它是 2013年 在 Core i7 Haswell 处理器 中引入的。
当 给定 命令行参数 -mavx2 时， GCC 会生成 AVX2 代码。

AVX 浮点体系结构 允许 数据存储在 16个 YMM 寄存器中，它们的名字是 ==%ymm0 - %ymm15==， 每个 ymm寄存器都是 256bit (32字节)。
当对标量数据操作时，这些寄存器只保存浮点数，而且只使用低 32 位(对于 float)或 64 位(对于 double)。
汇编代码用寄存器的 SSE XMM 寄存器名字 %xmm0 - %xmml5 来引用它们，每个 XMM 寄存器都是对应的 YMM 寄存器的低 128 位（16 字节）。


### 3.11.1 浮点传送和转换操作

vmovss
vmovsd
vmovaps
vmovapd

s: single
d: double

。。跳，太多了，

3.11.5 在浮点代码中使用位级操作



# ch4 处理器体系结构

一个处理器支持的 指令和指令的字节级编码 称为它的指令集体系结构(Instruction-Set Architecture ISA)

本章将简要介绍处理器硬件的设计


深度 讲到， 自建指令集， 逻辑门。 硬件结构， 指令的硬件处理过程。

RISC 非常适合 流水线
CISC 也利用高性能流水线，它读取CISC指令，并动态翻译为 比较简单的，像RISC那样的操作的序列。

4.2 逻辑设计和硬件控制语言 HCL

在硬件设计中，用电子电路来计算对位进行运算的函数
大多数现代电路技术都是用信号线上的髙电压或低电压来表示不同的位值
要实现一个数字系统需要三个主要的组成部分：
- 计算对位进行操作的函数的组合逻辑、
- 存储位的存储器单元，以及
- 控制存储器单元更新的时钟信号。

。。操作，存储，更新时钟

HCL (Hardware Control Language 硬件控制语言)，用这种语言来描述不同处理器设计的控制逻辑

HCL 中 最常用的语言是 Verilog，语法类似于C， 另一种是 VHDL，语法类似 Ada

逻辑门，与 或 非
逻辑门总是活动的，一旦一个门的输入变化了，在很短的时间内，输出就会变化。

将 很多逻辑门 组合成一个网，就能 构建 计算块，称为 组合电路。

例如，一个组合电路，有2个输入a,b，有唯一的输出eq，当a和b都是1 或 都是0 时，输出为1。用HCL 来写就是
`bool eq = (a && b) || (!a && !b);`

对应的电路图如下：

![6dded8c9b35ad72357ea4cb458e70b6a.png](../_resources/6dded8c9b35ad72357ea4cb458e70b6a.png)

---

多路复用器(multiplexor, 通常称为 MUX)， 根据输入的控制信号值，从2个数据信号中选出一个。
`bool out = (s && a) || (!s && b);`

对应的电路图：

![78816634b3f949b969fa44e0ee4de13a.png](../_resources/78816634b3f949b969fa44e0ee4de13a.png)


---

4.2.3 字级的组合电路和 HCL 整数表达式

字级的相等判断

![0ba6601f907cfdb4ccc370a1bb608e2f.png](../_resources/0ba6601f907cfdb4ccc370a1bb608e2f.png)

---

字级的多路复用器

![f5ef9e880db98d3f84f74884ebe39e2d.png](../_resources/f5ef9e880db98d3f84f74884ebe39e2d.png)

---

四路复用器

![7fb5f9763e08360d15bcbf343d2ce982.png](../_resources/7fb5f9763e08360d15bcbf343d2ce982.png)

---

算术/逻辑单元(ALU)是一种很重要的组合电路

![af945c60daf2e0e5eec9ca622d98899b.png](../_resources/af945c60daf2e0e5eec9ca622d98899b.png)


---

4.2.5 存储器和时钟

组合电路从本质上讲，不存储任何信息。相反，它们只是简单地响应输人信号，产生等于输人的某个函数的输出。

为了产生时序电路(sequential circuit), 也就是有状态并且在这个状态上进行计算的系统，我们必须引入按位存储信息的设备。
存储设备都是由同一个时钟控制的，时钟是一个周期性信号，决定什么时候要把新值加载到设备中。
考虑两类存储器设备
- 时钟寄存器(简称寄存器)，存储单个位或字，时钟信号控制寄存器加载输入值
- 随机访问存储器(简称内存)，存储多个字，用地址来选择读/写哪个字。 包括了 内存和寄存器文件(%rax 等)

硬件 和 编程 对 寄存器的定义不同。 为了避免歧义，称为 硬件寄存器，程序寄存器。


4.3 Y86-64 的顺序实现

各阶段执行的操作
- 取指，fetch
  从内存读取指令字节，地址为 程序计数器PC的值。
  从指令中获得 指令指示符字节的 2个 4位部分，称为 指令代码 icode 和 指令功能 ifun。
- 译码，decode
  译码阶段从寄存器文件读入最多2个操作数。
- 执行，execute
  算术/逻辑单元(ALU) 要么执行 指令指明的操作(根据ifun)，要么增加/减少栈指针
- 访存，memory
  读写内存
- 写回，write back
  将 最多2个结果 写到 寄存器文件
- 更新PC，PC update
  设置PC为下一条指令的地址



## 4.4 流水线的通用原理



![5bc40ef134c1854dad7c763daac087b9.png](../_resources/5bc40ef134c1854dad7c763daac087b9.png)



流水线的局限性

1. 不一致的划分

运行时钟的速率 被 最慢的阶段 限制

下面只有 阶段B 会一直活动， A 和C 都存在空闲时间。

![70171c4ac61303d7ac3cd0f51d641641.png](../_resources/70171c4ac61303d7ac3cd0f51d641641.png)


2. 流水线过深，收益反而下降

当组合逻辑被分为很小的块时，更新硬件寄存器的消耗 占比就上来了，次数也增加了。

。。原先的逻辑是 50,50,50,50,50,20(寄存器)， 流水线后变成了 50,20,50,20,50,20,50,20,50,20


4.4.4 带反馈的流水线系统

当下一条语句 需要 上一条语句的 输出时， 无法进行流水线。


4.5 Y86-64 的流水线实现

4.5.1 SEQ+: 重新安排计算阶段

4.5.2 插入流水线寄存器

4.5.3 对信号进行重新排列和标号

4.5.4 预测下一个 PC

猜测分支方向并根据猜测开始取指的技术称为分支预测

4.5.5 流水线冒险

冒险也可以分为两类：
数据冒险(data hazard)
控制冒险(control hazard)


4.5.6 异常处理




---

# ch5 优化程序性能

编写高效程序需要：
- 选择适当的算法和数据结构
- 编写出 能被编译器 有效优化的 源码
- 把 计算密集型的任务 分成多个部分，多核并发 。。。IO密集型也可以多核， 任何情况都可以多核。

妨碍优化的因素就是程序行为中那些严重依赖于执行环境的方面。


程序优化的第一步就是 消除不必要的工作。
第二步，了解处理器的运作，利用CPU的 指令集并行 能力，同时执行多条指令。

通过确认关键路径 来确定 循环所需要的时间



## 5.1 优化编译器的能力和局限性

`-Og -O1 -O2 -O3`

编译器 必须小心地 对代码 使用 安全的优化
比如
```C
void fun1(long *xp, long *yp)
{
    *xp += *yp;
    *xp += *yp;
}

void fun2(long *xp, long *yp)
{
    *xp += 2 * *yp;
}
```

当 xp == yp 的时候，这2个方法的 结果不同。

2个指针可能指向同一个内存位置的情况 称为 ==内存别名引用== (memory aliasing)

```C
x = 1000; y = 3000;
*q = y;
*p = x;
t1 = *q;   // 1000 or 3000
```
t1的值取决于 q 和 p 是不是 同一个位置。


用内联函数 来优化函数调用。
。。因为 编译器知道的东西多了，所以 它可以 确保 它的优化没有问题。

在各种编译器中，就优化能力来说，GCC 被认为是胜任的，但是并不是特别突出。
它完成基本的优化，但是它不会对程序进行更加“有进取心的”编译器所做的那种激进变换。
因此，使用 GCC的程序员必须花费更多的精力，以一种简化编译器生成高效代码的任务的方式来编写程序。


## 5.2 表示程序性能

我们引人度量标准每元素的周期数(Cycles Per Element, CPE), 作为一种表示程序性能并指导我们改进代码的方法

2个计算前缀和的方法
```C
void psum1(float a[], float p[], long n)
{
    long i;
    p[0] = a[0];
    for (i = 1; i < n; i++)
        p[i] = p[i - 1] + a[i];
}

void psum2(float a[], float p[], long n)
{
    long i;
    p[0] = a[0];
    for (i = 1; i < n-1; i += 2)
    {
        float mid = p[i - 1] + a[i];
        p[i] = mid;
        p[i + 1] = mid + a[i + 1];
    }
    if (i < n)
        p[i] = p[i - 1] + a[i];
}
```

psum2 使用了 ==循环展开== (loop unrolling)

![02a4e5410a2b55ca1ed6d4b4f1124253.png](../_resources/02a4e5410a2b55ca1ed6d4b4f1124253.png)

使用==最小二乘拟合==，发现 psum1,psum2 的运行时间，近似于 368 + 9n, 368 + 6n

![5dc830dcf6e0b6cbe699d1aefcb6a431.png](../_resources/5dc830dcf6e0b6cbe699d1aefcb6a431.png)



### 5.3 !!!程序示例

。到 5.10 的代码，gcc -O3，反编译查看 汇编， 寻找 关键路径

```C
typedef long data_t;

typedef struct {
    long len;
    data_t *data;
} vec_rec, *vec_ptr;

#define IDENT 0
#define OP +

// #define IDENT 1
// #define OP *

void combine1(vec_ptr v, data_t *dest)
{
    long i;
    *dest = IDENT;
    for (i = 0; i < vec_length(v); i++)
    {
        data_t val;
        get_vec_element(v, i, &val);
        *dest = *dest OP val;
    }
}
```



## 5.4 消除循环的低效率


将 5.3 的 vec_length(v) 移除循环
```C
void combine2(vec_ptr v, data_t *dest)
{
    long i;
    long length = vec_length(v);
    *dest = IDENT;
    for (i = 0; i < length; i++)
    {
        data_t val;
        get_vec_element(v, i, &val);
        *dest = *dest OP val;
    }
}
```

这是 常见的优化， 称为 ==代码移动== (code motion)。
识别 需要执行多次，但 计算结果不会变的 计算。

注意，strlen() 需要遍历 `char *` 才能知道长度。



## 5.5 减少过程调用

在原先的 get_vec_element 中，会先判断 i 是否越界。
现在直接 数组进行操作

```C
*data = get_vec_start(v);
for () {
    *dst = *dst OP data[i];
}
```

令人吃惊的是，性能没有明显的提升。
事实上，整数求和的性能还略有下降。
显然，内循环中的其他操作形成了瓶颈，限制性能超过调用 get_vec_element

。。我在想，是不是原来的 get_vec_element 会被 内联？


## 5.6 消除不必要的内存引用

。。5.5 的代码中，==每次都需要 反引用 dst， dst有地址，说明必须是 内存。==

我们可以消除这种 不必要的 内存读写

```C
void combine4(vec_ptr v, data_t *dest)
{
    long i;
    long length = vec_length(v);
    data_t *data = get_vec_start(v);
    data_t acc = IDENT;
    for (i = 0; i < length; i++)
    {
        acc = acc OP data[i];
    }
    *dest = acc;
}
```

对比 5.4， 减少了 50% - 80% 的时间



## 5.7 理解现代处理器

随着试图进一步提高性能，必须考虑利用处理器微体系结构的优化，也就是处理器用来执行指令的底层系统设计。

处理器的实际操作与通过观察机器级程序所察觉到的大相径庭。

在代码级上，看上去似乎是一次执行一条指令，每条指令都包括从寄存器或内存取值，执行一个操作，并把结果存回到一个寄存器或内存位置。
在实际的处理器中，是==同时==对多条指令求值的，这个现象称为指令级并行


超标量(superscalar)，每个时钟周期可以 执行多个操作，并且是 乱序的。

整个设计有2个主要部分
- 指令控制单元，instruction control unit, ICU
  从内存中读取指令序列，并根据这些指令序列生成一组针对程序数据的基本操作
- 执行单元，execution unit，EU
  执行 ICU 生成 的操作

乱序CPU 需要更大，更复杂的硬件，但是 能更好地达到 更高的 指令级并行度

---

![09bc86a480e5680ce0cadfb0f6883879.png](../_resources/09bc86a480e5680ce0cadfb0f6883879.png)

ICU 从 L1 cache 中读取指令。
当程序遇到分支时，程序有 2个可能的前进方向。 现在CPU 使用了 ==分支预测== (branch prediction)，CPU会猜测 走哪个分支。
使用 ==投机执行==(speculative execution) 的技术，CPU 会 ==拉取== 位于它 预测的分支 的 ==指令，并 译码( 。。但应该不会执行吧，会的。下面有)==。 如果之后 确定 分支预测错误，会将状态 重新设置到 分支点的状态，并开始 取 正确分支的指令。

取指控制 的块 进行 分支预测

指令译码 接收 实际的程序指令，并转换成一组 基本操作 (有时称为 ==微操作==)，每个 这样的操作 都完成 某个简单的 计算任务。

在典型的 x86 实现中， 一条 只对 寄存器操作的指令，会被转化为一个操作
一条包括 一个或多个 内存 引用的指令，会产生多个操作，把 内存引用 和 算术运算 分开。

EU接收来自 取指单元的操作，通常，每个时钟周期 会接收多个操作，这些操作 被分派到 一组功能单元中。

==使用投机执行技术对操作求值，但 最终结果不会存放到 程序寄存器 或内存中，==知道处理器 能确定应该 实际执行这些指令。
分支操作 被送到 EU，不是确定分支 该往哪里去，而是 确定分支预测 是否正确。

在ICU中，退役单元(retirement unit) 记录正在进行的处理，并确保它 遵守 机器级程序的 顺序语义。

控制操作数 在执行单元间 传送的最常见的机制称为==寄存器重命名==(register renaming)
当一条更新寄存器 r 的指令译码时，产生标记 t 得到一个指向该操作结果的唯一的标识符。
条目(r，t)被加人到一张表中，该表维护着每个程序寄存器 r 与会更新该寄存器的操作的标记 t 之间的关联。
当随后以寄存器 r 作为操作数的指令译码时，发送到执行单元的操作会包含 t 作为操作数源的值。
有了寄存器重命名，即使只有在处理器确定了分支结果之后才能更新寄存器，也可以预测着执行操作的整个序列



### 5.7.2 功能单元的性能

下图是 Intel i7 Haswell 的一些性能
每个运算都是通过 以下数值来刻画
- 延迟 latency
  完成运算所需要的总时间
- 发射时间 issue time
  开始 2个连续的 同类型运算之间 需要的最小时钟周期数
- 容量 capacity
  能执行该运算的 功能单元数量

![5c9ac3f30d62e2f32ce8f6ea1d0d0495.png](../_resources/5c9ac3f30d62e2f32ce8f6ea1d0d0495.png)


可以看到加法和乘法运算的发射时间都为 1，意思是说在每个时钟周期，处理器都可以开始一条新的这样的运算。
这种很短的发射时间是通过使用流水线实现的。

一个典型的 浮点加法器 实现为 3个阶段，处理指数，小数相加，对结果进行舍入。

算术运算可以连续地通过各个阶段，爾不用等待一个操作完成后再开始下一个。
只有当要执行的运算是连续的、逻辑上独立的时候，才能利用这种功能。
发射时间为1 的功能单元被称为==完全流水线化==的(fully pipelined): 每个时钟周期可以开始一个新的运算。出现容量大于 1 的运算是由于有多个功能单元

除法器(用于整数和浮点除法，还用来计算浮点平方根)不是完全流水线化的——它的发射时间等于它的延迟

表达发射时间的一种更常见的方法是指明这个功能单元的最大呑吐量，定义为发射时间的倒数。
一个完全流水线化的功能单元有最大的吞吐量

---

我们使用CPE的界限来描述这种影响

|界限|整数+|整数*|浮点+|浮点*|
|--|--|--|--|--|
|延迟|1|3|3|5|
|吞吐量|0.5|1|1|0.5|

有4个功能单元可以执行整数加法，处理器可以 在一个周期 执行 4个操作，但是，因为需要 从内存 读数据，这是 另一个吞吐量限制， 2个加载单元 限制了 处理器 每个 时钟周期 最多只能读取 2个数据值，从而使得 吞吐量 界限为 0.5
。。为什么 是0.5 ？  一个加法 需要2个操作数，1个写出， 那也应该是 0.6666 啊。



### !!! 5.7.3 处理器操作的抽象模型

398, 362

寻找关键路径



## 5.8 循环展开

循环展开是一种程序变换，通过增加每次迭代计算的元素的数量，减少循环的迭代次数

循环展开能够从两个方面改进程序的性能。
- 首先，它减少了不直接有助于程序结果的操作的数量，例如循环索引计算和条件分支。
- 第二，它提供了一些方法，可以进一步变化代码，减少整个计算中关键路径上的操作数量。


要理解为什么 K * 1 循环展开不能将性能改进到超过延迟界限




## 5.9 提局并行性

程序的性能是受运算单元的延迟限制的

执行加法和乘法的功能单元是完全流水线化的，这意味着它们可以每个时钟周期开始一个新操作，并且有些操作可以被多个功能单元执行。

==但是代码不能利用这种能力，即使是使用循环展开也不能，这是因为我们将累积值放在一个单独的变量 acc 中。==

### 5.9.1 多个累积变量

对于一个可结合和可交换的合并运算来说，比如说整数加法或乘法，我们可以通过将一组合并运算==分割成两个或更多的部分==，并在最后合并结果来提高性能

```C
// 2 * 2 loop unrolling
void combine6(vec_ptr v, data_t *dest)
{
    long i;
    long length = vec_length(v);
    long limit = length - 1;
    data_t *data = get_vec_start(v);
    data_t acc0 = IDENT;
    data_t acc1 = IDENT;

    for (i = 0; i < limit; i += 2) 
    {
        acc0 = accp OP data[i];
        acc1 = acc1 OP data[i + 1];
    }

    for (; i < length; i++)
    {
        acc0 = acc0 OP data[i];
    }
    *dest = acc0 OP acc1;
}
```

浮点乘法和加法不是可结合的


### 5.9.2 重新结合变换

`acc = (acc OP data[i]) OP data[i + 1]`
改为
`acc = acc OP (data[i] OP data[i + 1])`




---

用向量指令达到更高的并行度
SIMD

AVX


GCC 支持对 C 语言的扩展，能够让程序员在程序中使用向量操作，这些操作能够被编译成 AVX 的向量指令（以及基于早前的 SSE 指令的代码）。 
这种代码风格比直接用汇编语言写代码要好，因为 GCC 还可以为其他处理器上的向量指令产生代码。



## 5.10 优化合并代码的结果小结

![07238b5b6ffecb0e111bac9c06bb2ce0.png](../_resources/07238b5b6ffecb0e111bac9c06bb2ce0.png)


使用多项优化技术，我们获得的 CPE 已经接近于 0.50 和 1.00 的吞吐量界限，只受限于功能单元的容量。
与原始代码相比提升了 10-20 倍，且使用普通的 C 代码和标准编译器就获得了所有这些改进。
重写代码利用较新的 SIMD 指令得到了将近 4 倍或 8 倍的性能提升。比如单精度乘法，CPE 从初值 11.14 降到了 0.06, 整体性能提升超过 180 倍



## 5.11 一些限制因素

- 关键路径指明了执行该程序所需时间的一个基本的下界。
如果程序中有某条数据相关链，这条链上的所有延迟之和等于 T， 那么这个程序至少需要 T 个周期才能执行完。


- 功能单元的吞吐量界限也是程序执行时间的一个下界
假设一个程序一共需要 N 个某种运算的计算，而微处理器只有 C 个能执行这个操作的功能单元,并且这些单元的发射时间为 I。那么，这个程序的执行至少需要 N*I/C 个周期。


### 5.11.1 寄存器溢出

循环并行性的好处受汇编代码描述计算的能力限制。
如果我们的并行度 p 超过了可用的寄存器数量，那么编译器会诉诸溢出(spilling)，将某些临时值存放到内存中，通常是在运行时堆栈上分配空间。

将 combine6 的多累积模式 扩展到 k=10, k=20， 性能并没有改善，甚至还出现了下降。

累积变量保存为栈上的一个局部变量，其位置距离栈指针偏移量为 40。
程序必须从内存中读取两个数值：累积变量的值和 data[i] 的值，将两者相乘后，将结果保存回内存。



### 5.11.2 分支预测和预测错误处罚

分支预测没有简单的答案，但是下面的通用原则是可用的

1. 不要过分关心 可预测的分支

现代处理器中的分支预测逻辑非常善于辨别不同的分支指令的有规律的模式和长期的趋势

2. 书写适合用条件传送实现的代码
。。这个太难了。



## 5.12 理解内存性能


5.12.1 加载的性能


5.12.2 存储的性能



## 5.13 应用：性能提高技术

我们已经描述了许多优化程序性能的基本策略
- 高级设计
  为遇到的问题选择合适的算法和数据结构
- 基本编码原则
  避免限制优化的因素，让编译器产生高效的代码
  - 消除连续的函数调用。将计算移到循环外
  - 消除不必要的内存引用。引入临时变量保存中间结果
- 低级优先
  结构化代码以利用硬件功能
  - 展开循环
  - 使用 多个累计变量 和 重新结合。
  - 用功能性风格重写条件操作，使得编译采用条件数据传送。

一个忠告，要警惕，在为了提高效率重写程序时避免引入错误。


## 5.14 确认和消除性能瓶颈(gprof)

大程序时，很难知道应该优化什么地方。

Unix 有一个 程序 GPROF，它产生2种形式的信息。
1. 确定程序中每个函数花费了多少CPU时间
2. 计算每个函数被调用的次数

`gcc -Og -pg prog.c -o prog`
`./prog file.txt`
`gprof prog`

GPROF有些属性值得注意
- 计时不是很准确
- 如果没有内联替换，那么 调用信息 相当可靠
- 默认情况下，不会显示 对库函数的 计时


5.14.2 使用剖析程序来指导优化



---

# ch6 存储器层次结构

数据在 CPU 寄存器中，那么在指令的 执行期间，0个周期内就可以访问到它们
在高速缓存中，需要 4-75个周期
主存，上百个周期
磁盘，大约几千万个周期
。。几千万？ 这本书 前面也提到过，也是 几千万。 所以我记得。不可能几千万吧。
。。是千万，《深入理解软件性能》 中是 1千万ns (10ms)， L1 是0.5ns。 主存是100ns。  和这里是 匹配的。
。。不过 ssd应该会快一点吧。

局部性原理。


6.1 存储技术

6.1.1 随机访问存储器
RAM，random access memory，分为2类， 静态，动态

静态SRAM更快，用于 高速缓存
动态DRAM，用于 主存和 图形系统的帧缓冲区

DRAM 的访问时间 是 SRAM 的10倍


DRAM中的单位被 分为 d个 ==超单元== (supercell)
每个 超单元 由 w个 DRAM 单元组成
超单元被组织成 r行 c列 的 长方形矩阵。

每个DRAM芯片 被连接到 称为 ==内存控制器==(memory controller) 的电路
这个电路 可以一次 传输 w 位 到 每个 DRAM芯片，或 一次从每个DRAM芯片 传出 w 位。



内存模块


增强的DRAM
- 快页模式DRAM
- 扩展数据输出DRAM
- 同步DRAM
- 双倍数据速率同步DRAM， Double Data-Rate Sync DRAM, DDR SDRAM 
- 视频RAM

。。DDR4, DDR5


非易失性存储器
ROM 只读存储器
programmable ROM, PROM，能被编程一次
erasable PROM, EPROM，可以擦除1000次
electrically EPROM, EEPROM，可以擦除10^5
flash memory, 闪存，基于 EEPROM
SSD，基于闪存


访问主存
数据流通过 称为 总线(bus) 的共享电子电路 在处理器 和 DRAM之间 来回。

。。跳

访问磁盘

CPU使用 称为 内存映射IO (memory mapped IO) 的技术 来向 IO设备 发射命令。
在使用 内存映射 IO 的 系统中，地址空间中 有一块 地址 是为了 与 IO 设备通信 而保留的。 每个这样的地址 称为 一个 IO端口。

假设 硬盘控制器 映射到 端口 0xa0，随后，CPU 可能通过 执行 3个 对地址 0xa0 的存储指令，发起磁盘读： 
- 第一条指令 是发送一个命令字，告诉磁盘 发起一个读，同时还发送了其他参数，例如当读完成时，是否中断CPU
- 第二条指令 指明 应该读的 逻辑块号
- 第三条指令 指明 应该存储 磁盘内容的 主存地址

。。==所以 第三条的 主存地址 就是 内核缓冲区？==

磁盘控制器 收到 来自 CPU的 读命令后， 将 逻辑块号 翻译成 一个 扇区地址，读该扇区的内容，然后 将这些内容 直接传送到 主存，不需要 CPU干涉。
设备可以自己执行 读或写 总线事务 而不需要 CPU干涉的过程，称为 ==直接内存访问 (DMA)==

在DMA传送完成，磁盘内容已经 安全地存储到 主存后，磁盘控制器 通过 给 CPU 发送一个 中断信号 来通知 CPU。



固态硬盘 SSD
读取很快
随机写很慢，写之前要擦除。

比HDD 快

缺点是，反复写之后，闪存块会磨损， SSD试图将 擦除 平均分布 来 最大化每个块的寿命


![9a41fd14e5cd2d47ae3cbdd77f0afa60.png](../_resources/9a41fd14e5cd2d47ae3cbdd77f0afa60.png)



## 6.2 局部性

一个编写良好的计算机程序常常具有良好的局部性(locality)。
也就是，它们倾向于引用邻近于其他最近引用过的数据项的数据项，或者最近引用过的数据项本身。
这种倾向性，被称为局部性原理(principle of locality)

时间局部性，空间局部性。



对于引用多维数组的程序来说，步长也是一个很重要的问题
先循环外层，然后循环访问内层，能保证 良好的 局部性
即 `for (i) { for (j) { x = arr[i][j] }}` 比
`for (j) { for (i) { x = arr[i][j] }}` 要好



6.2.2 取指令的局部性

循环中的指令 按照 连续的内存顺序读取，因此有 好的 空间局部性
循环体 被多次执行，有很好的 时间局部性

6.2.3 局部性小结

量化 局部性的一些 简单原则
- 重复引用相同变量的程序有良好的时间局部性
- 对于 步长 k 的引用模式， k 越小，空间局部性越好
- 对于 取指令来说， 循环有 好的 时间 和空间 局部性。 循环体越小，循环次数越多，局部性越好


## 6.3 存储器层次结构

![00ae96647a6b552018ae9555a0af12c8.png](../_resources/00ae96647a6b552018ae9555a0af12c8.png)


---

![dc0eb65461d6d64be79d799bffaac9cd.png](../_resources/dc0eb65461d6d64be79d799bffaac9cd.png)



## 6.4 高速缓存存储器

6.4.1 通用的高速缓存存储器组织结构

6.4.2 直接映射高速缓存

6.4.3 组相联高速缓存

6.4.4 全相联高速缓存


## 6.5 编写高速缓存友好的代码

1. 让最常见的情况运行得快
2. 尽量减小每个循环内部的缓存不命中数量
   1. 对局部变量的反复引用是好的，因为编译器能够将它们缓存到 寄存器中(时间局部性)
   2. 步长为1的引用模式是好的，因为 存储器层次结构中 所有层次上的 缓存 都是将 数据存储为 连续的块 (空间局部性)




## 6.6 综合：高速缓存对程序性能的影响


![5941a6cd6a8c00993251b3e00d0b9fc9.png](../_resources/5941a6cd6a8c00993251b3e00d0b9fc9.png)


---
![3f6fdf08216fbb5f1f2bfffa510d3d02.png](../_resources/3f6fdf08216fbb5f1f2bfffa510d3d02.png)

---

![011f8419382f3d5a10adec089debef6e.png](../_resources/011f8419382f3d5a10adec089debef6e.png)


---

有一项很有趣的技术，称为分块(blocking), 它可以提高内循环的时间局部性。
分块的大致思想是将一个程序中的数据结构组织成的大的片(chunk), 称为块(block)。(在这个上下文中，“块”指的是一个应用级的数据组块，而 不是高速缓存块。)
这样构造程序，使得能够将一个片加载到 L1 高速缓存中，并在这个片中进行所需的所有的读和写，然后丢掉这个片，加载下一个片 ，依此类推


---

推荐
- 将注意力集中在 内循环上，大部分计算和内存访问都发生在这里
- 按照 数据 在 内存中 存储的顺序，以步长1 来 读取，以 最大化 空间局部性
- 一旦从 存储器 读入了一个 数据对象，就尽可能多使用它，以最大化 时间局部性




---

# 第二部分 在系统上运行程序

# ch7 链接

链接(linking)是将各种 代码和数据片段 收集并组合成为一个单一文件的过程

链接可以执行于编译时 (compile time) 也就是在源代码被翻译成机器代码时；
也可以执行于加载时(load time), 也就是在程序被加载器(loader)加载到内存并处理时；
甚至执行于运行时(runtime)，也就是由应用程序来执行。

链接器在软件开发中扮演着一个关键的角色，因为它们使得 ==分离编译==(separate compilation)成为可能


- 理解链接器将帮助你构造大型程序
- 理解链接器将帮助你避免一些危险的编程错误
- 理解链接将帮助你理解语言的 作用域 规则是如何实现的
- 理解链接将帮助你理解其他重要的系统概念。
- 理解链接将使你能够利用 共享库


我们的讨论是基于这样的环境：一个运行 Linux 的 x86-64 系统，使用标准的 ELF-64 (此后称为ELF)目标文件格式

## 7.1 编译器驱动程序

下面的2个 C文件 将贯穿本章。

```C
// main.c
int sum(int *a, int n);

int array[2] = {1,2};

int main()
{
    int val = sum(array, 2);
    return val;
}
```

```C
// sum.c
int sum(int *a, int n)
{
    int i, s = 0;
    for (i = 0; i < n; ++i) {
        s += a[i];
    }
    return s;
}
```


---

`gcc -Og -o prog main.c sum.c`

![10a641148498cbe71e7804ca2063a61e.png](../_resources/10a641148498cbe71e7804ca2063a61e.png)


如果要看 步骤的具体过程，使用 `-v`

上面的命令可以分解为
- `cpp main.c /tmp/main.i`
- `cc1 /tmp/main.i -Og -o /tmp/main.s`
- `as -o /tmp.main.o /tmp/main.s`
- 相同的 3条命令 生成 sum.i, sum.s, sum.o
- `ld -o prog /tmp/main.o /tmp/sum.o`


## 7.2 静态链接

linux 的 LD 是 静态链接器， 以 一组可重定位目标文件 和命令参数 作为输入，生成一个完全链接的，可以加载，运行 的 可执行目标文件 作为输出。

输入的 可重定位目标文件 由 各种不同的==代码== 和==数据节==(section)组成，每一节都是 连续的 字节序列。 指令在一节中， 初始化了的 全局变量 在另一节中， 未初始化的变量 又在 另一节中。

链接器 要完成2个任务
- 符号解析
  目标文件 定义和 引用符号，每个符号 对应一个 函数，全局变量或 静态变量
  符号解析的目的是 将每个 符号引用 ==正好== 和一个 符号定义 关联起来
- 重定位
  编译器和汇编器 生成 从地址0开始的 代码和数据节。
  链接器通过把 每个符号定义 与一个内存位置 关联起来，从而 重定位 这些节，然后修改 所有 对这些符号的 引用，使得它们指向这个内存位置。


## 7.3 目标文件

目标文件有3种形式
- 可重定位目标文件
- 可执行目标文件
- 共享目标文件 (。。共享库)

编译器和 汇编器 生成 可重定位目标文件 (包括 共享目标文件)。
链接器 生成 可执行目标文件。

目标模块 是 字节序列
目标文件 是 文件形式的 存放于磁盘的 目标模块。


## 7.4 !!! 可重定位目标文件

![8cac3fa81d08bbc441152e1f78581952.png](../_resources/8cac3fa81d08bbc441152e1f78581952.png)

executable and linkable format, ELF

ELF 头(ELF header)以一个 16 字节的序列开始，这个序列描述了生成该文件的系统的字的大小和字节顺序。

ELF 头剩下的部分包含帮助链接器语法分析和解释目标文件的信息。
其中包括 
- ELF 头的大小、
- 目标文件的类型(如可重定位、可执行或者共享的)、 
- 机器类型(如 X86-64) 
- 节头部表(section header table)的文件偏移，以及
- 节头部表中条目的大小和数量。

不同节的位置和大小是由节头部表描述的，其中目标文件中每个节都有一个固定大小的条目(entry)

夹在 ELF 头和节头部表之间的都是节。
一个典型的 ELF 可重定位目标文件包含下面几个节
- .text
  已编译程序的 机器代码
- .rodata
  只读数据，如 printf中的格式串 和 switch的跳转表
- .data
  已初始化的 全局 和 静态 C 变量
- .bss
  未初始化的全局和静态C 变量， 及 所有被初始化为0 的全局 或静态变量
- .symtab
  符号表，保存程序中 定义 和 引用的 函数的 和全局变量的 信息
- .rel.text
  .text节中位置的列表，
  链接器 把这个目标文件 和其他文件 组合时 需要修改这些位置。
- .rel.data
  被模块引用 或定义的 所有全局变量的 重定位信息
- .debug
  调试符号表，保存了 程序中定义的 局部变量和类型定义， 程序中定义和引用的全局变量，以及原始的 C 源文件。 
  只有 -g 时才会生成这张表
- .line
  原始 C源文件中的 行号 和 .text 中 机器指令之间的映射。
  只有 -g 才生成
- .strtab
  一个字符串表，包含 .symtab, .debug 中的 符号表，以及 节头部中的 节名字。


## !! 7.5 符号和符号表

每个 可重定位目标模块 m 都有一个 符号表，包含了 m 定义和引用的 符号的信息。
在链接器的上下文中，有 3种 不同的符号
- m定义 并能被 其他模块ref 的 全局符号， 即 非静态的 C函数 和 全局变量
- 有其他模块定义，并被 m ref 的全局符号，即 其他模块中定义的 非静态的 C函数 和全局变量
- 只能被 m 定义和ref 的 局部符号， 即 带 static 属性的 C函数 和 全局变量。这些符号 在 m 的任何位置 可见， 但不能被其他 模块ref

.symtab 的 符号表 不包含 本地非静态变量 的任何符号。 这些符号 在运行时 在 栈中管理。

带有static 的 本地过程变量 不在 栈中管理， 而是在 .data, .bss 中为每个定义 分配空间，并在 符号表中 创建一个 具有 唯一名字的 本地链接器符号。
```C
int f() {
    static int x = 0;
    return x;
}
int g() {
    static int x = 1;
    return x;
}
```
这2个 x 的 局部链接器符号 是不同的。

符号表是由汇编器构造的，使用编译器输出到汇编语言.s 文件中的符号。
.symtab 节中包含 ELF 符号表。
这张符号表包含 条目的数组
下图是每个条目的格式
```C
typedef struct {
    int name;   /* String table offset */   // 字符串表中的偏移
    char type:4,/* Function or data (4 bits) */ // 通常 要么是数据，要么是函数
        binding:4; /* Local or global (4 bits) */  // 符号是 本地的，还是全局的
    char reserved; /* Unused */
    short section; /* Section header index */  // 符号 被分配到的 节
    long value;/* Section offset or absolute address */ // 符号的地址, 对于可重定位的模块来说，是 距定义目标的节的起始位置的偏移；对于可执行文件，是一个绝对运行时地址
    long size; /* Object size in bytes */  // 目标的大小(以字节为单位)
} Elf64_Symbol;
```

有 3个特殊的 伪节，它们在 节头部表 中 没有条目
- ABS，不该被重定位的符号
- UNDEF，未定义的符号，即 在本目标模块 中ref，但在 其他地方定义
- COMMON，还未分配位置的 未初始化的数据目标。  value 给出 对齐要求， size 给出最小的大小

COMMON 和 .bss 的区别很细微
- COMMON 未初始化的全局变量
- .bss 未初始化的静态变量，及 初始化为0 的全局 或 静态变量

Gnu ==readelf== 可以查看 目标文件内容。

对 main.o 使用 readelf，可以得到
![54835762bf541b571e4d7016d8f233ee.png](../_resources/54835762bf541b571e4d7016d8f233ee.png)


我们看到全局符号 main 定义的条目，它是一个位于.text 节中偏移量为 0(即value 值)处的 24 字节函数。
其后跟随着的是全局符号 array 的定义，它是一个位于.data 节中偏移量为 0 处的 8 字节目标。
最后一个条目来自对外部符号 sum 的ref。
READELF 用一个整数索引来标识每个节。
Ndx=l 表示 .text 节，而 Ndx=3 表示 .data 节。



## 7.6 符号解析

链接器解析符号引用的方法是将每个 引用 与 它输入的可重定位目标文件的符号表中的一个确定的 符号定义 关联起来。

对那些和引用定义在相同模块中的局部符号的引用，符号解析是非常简单明了的。

对全局符号的引用解析就棘手得多。
当编译器遇到一个不是在当前模块中定义的符号(变量或函数名)时，会假设该符号是在其他某个模块中定义的，生成一个链接器符号表条目，并把它交给链接器处理。
如果链接器在它的任何输入模块中都找不到这个被引用符号的定义，就输出一条(通常很难阅读的)错误信息并终止。

对全局符号的符号解析很棘手，还因为==多个目标文件==可能会==定义相同名字的全局符号==。
在这种情况中，链接器必须要么标志一个错误，要么以某种方法选出一个定义并抛弃其他定义。

C++，java 都允许 重载方法，因为 它们把 参数 编入了 符号中。
。。==因为 C 没有把 参数 编入 符号中，所以它无法重载==


### 7.6.1 链接器如何解析 多重定义 的全局符号

如果多个模块定义同名的全局符号，会发生什么呢？
下面是 Linux 编译系统采用的方法。

编译时，编译器 向 汇编器 输出的 每个全局符号，要么是 ==强strong 要么是 弱weak==
汇编器 将这个 信息 隐含地 编码在 可重定位目标文件的 符号表中。
- 函数 和 已初始化的 全局变量 是 ==强符号==
- 未初始化的 全局变量 是 ==弱符号==

linux 链接器 使用下面的规则来处理 多重定义的 符号名
1. 不允许有多个 同名的 强符号
2. 如果有 一个强符号，多个弱符号，选择 强符号
3. 如果 有多个 弱符号，任意选一个

规则 2 和规则 3 的应用会造成一些不易察觉的运行时错误，尤其是如果重复的符号定义还有不同的类型时

当你怀疑有此类错误时，用 gcc的 ==-fno-common==, 这个选项会告诉链接器，在遇到多重定义的全局符号时，触发一个错误。
或者使用 ==-Werror== 选项，它会把所有的警告都变为错误


### 7.6.2 与静态库链接 (。。-static)

`gcc main.c /usr/lib/libm.a /usr/lib/libc.a`

在 Linux 系统中，静态库以一种称为存档(archive)的特殊文件格式存放在磁盘中。
存档文件是一组连接起来的可重定位目标文件的集合，有一个头部用来描述每个成员目标文件的大小和位置。
存档文件名由后缀.a 标识。

```text
gcc -c addvec.c multvec.c
ar rcs libvector.a addvec.o multvec.o
```

```text
gcc -c main2.c
gcc -static -o prog2c main2.o ./libvector.a
```
。。static 又出现了。

或等价于
```text
gcc -c main2.c
gcc -static -o prog2c main2.o -L. -lvector
```


### 7.6.3 链接器如何使用静态库来解析引用

虽然静态库很有用，但是它们同时也是一个程序员迷惑的源头，原因在于 Linux 链接器使用它们解析外部引用的方式。
在符号解析阶段，链接器==从左到右==按照它们在编译器驱动程序==命令行上出现的顺序==来扫描可重定位目标文件和存档文件。
(驱动程序自动将命令行中所有的.c 文件翻译为 .o文件)。
在这次扫描中，链接器维护
- 一个可重定位目标文件的集合 E(这个集合中的文件会被合并起来形成可执行文件）
- 一个未解析的符号（即引用了但是尚未定义的符号)集合 U 以及
- 一个在前面输人文件中已定义的符号集合 D 
- 初始时，E, U 和 D 均为空。

---

- 对于 命令行上的每个输入文件 f，链接器会判断 f 是一个 目标文件 还是 存档文件。 如果是 目标文件，那么 链接器 把 f 添加到 E， 修改 U，D 来 反应 f 中的 符号定义和 引用，并继续下一个输入文件
- 如果f 是存档文件，链接器 就尝试匹配 U 中未解析的符号 和 由 存档文件成员 定义的 符号。如果某个存档文件成员m 定义了一个 符号 来解析 U 中的 一个ref，那么把 m 加入到 E，并修改U 和 D 来 反应 m中的 符号定义和引用。
- 链接器对 命令行的 输入文件 扫描完后， U如果 非空，则 链接器 抛出错误 并终止； 否则，它会 合并 和 重定位 E 中的目标文件， 构建 可执行文件 作为 输出结果。

这种算法会导致一些令人困扰的链接时错误，因为==命令行上的库和目标文件的顺序非常重要==

关于库的一般准则是将它们放在命令行的==结尾==。
如果各个库的成员是==相互独立==的(也就是说没有成员引用另一个成员定义的符号)， 那么这些库就可以以任何顺序放置在命令行的结尾处。
另一方面，如果库不是相互独立的，那么必须对它们==排序==，使得对于每个被存档文件的成员外部引用的符号 S, 在命令行中至少有一个 S 的定义是在对 S 的引用之后的。

。。也是 特殊的 包 越放前面， 就是， 公司的包 要在 libc.a 之前。


## 7.7 重定位

一旦链接器完成了符号解析这一步，就把代码中的每个符号引用和正好一个符号定义(即它的一个输入目标模块中的一个符号表条目)关联起来。
此时，链接器就知道它的输人目标模块中的==代码节和数据节==的确切大小。
现在就可以开始重定位步骤了，在这个步骤中，将合并输人模块，并为每个符号==分配运行时地址==。
重定位由两步组成
- 重定位 节和符号定义
  链接器将 所有相同类型的 节 合并为 同一类型的 新的 聚合节。
  链接器 将运行时内存 地址 赋给 新的 聚合节，赋给 输入模块定义的 每个节，赋给输入模块定义的 每个符号。
  这步完成后，程序中 每条指令 和 全局变量 都有 ==唯一的 运行时内存地址==
- 重定位 节中的符号引用
  链接器 修改  代码节 和 数据节 中 对每个符号的 引用，使 它们指向正确的运行时地址。
  执行这一步时， 链接器 依赖于 可重定位目标模块中 称为 重定位条目的 数据结构。


7.7.1 重定位条目

```C
typedef struct {
    long offset; // 需要被修改的 ref 的 节偏移
    long type:32,    // 告知 链接器 如何修改 新的ref
        symbol:32; // 标识 被修改引用 应该指向的 符号
    long addend; // 常数， 一些类型的 重定位 要使用它 对 被修改引用的 值 做 偏移调整。
} Elf64_Rela;
```

ELF 有 32种不同的 重定位类型
我们只关心 2种 最基本的
- R_X86_64_PC32
  重定位一个使用32位PC相对地址的 引用
- R_X86_64_32
  重定位一个使用 32位 绝对地址ide引用

小型代码模型 < 2g
中型代码模型 `-mcmodel=medium`
大型代码模型 `-mcmodel=large`



7.7.2 重定位符号引用




## !!!! 7.8 可执行目标文件

下面是 一个典型的 ELF 可执行文件中的各类信息

![a8795b8e6d47117c04289c799bfa834d.png](../_resources/a8795b8e6d47117c04289c799bfa834d.png)

ELF 头描述文件的总体格式。它还包括程序的入口点(entry point)
.init 节定义了一个小函数，叫做_init 程序的初始化代码会调用它
可执行文件是完全链接的（已被重定位）， 所以它不再需要.rel 节。

ELF 可执行文件被设计得很容易加载到内存，可执行文件的连续的片(chunk)被映射
到连续的内存段。
程序头部表(program header table)描述了这种映射关系


## 7.9 加载可执行目标文件

每个 Linux 程序都有一个运行时内存映像，类似于图 7-15 中所示。
在 Linux X86-64系统中，代码段总是从地址 0x400加0 处开始，后面是数据段。
运行时堆在数据段之后，通过调用 malloc 库往上增长。
堆后面的区域是为共享模块保留的。
用户栈总是从最大的合法用户地址(2^48 —1)开始，向较小内存地址增长。
栈上的区域，从地址 2^48 开始，是为内核(kernel)中的代码和数据保留的，所谓内核就是操作系统驻留在内存的部分。

实际上，由于 .data 段有对齐要求(见 7.8 节)， 所以代码段和数据段之间是有间隙的。

![10a67e947ae3ab3041ed4cc3819b75d6.png](../_resources/10a67e947ae3ab3041ed4cc3819b75d6.png)

当加载器运行时，它创建类似于图 7-15 所示的内存映像。在程序头部表的引导下,加载器将可执行文件的片(chunk)复制到代码段和数据段。
接下来，加载器跳转到程序的人口点，也就 函数的地址。这个函数是在系统目标文件 ctrl.o 中定义的，对所有的 C 程序都是一样的。
`_start` 函数调用系统启动函数 `__libc_start_main`，该函数定义在 libc.so 中。
它初始化执行环境，调用用户层的 main 函数，处理 main 函数的返回值，并且在需要的时候把控制返回给内核。


## !! 7.10 动态链接共享库

静态库仍然有一些明显的缺点。
静态库和所有的软件一样，需要定期维护和更新。
如果应用程序员想要使用一个==库的最新版本==，他们必须以某种方式了解到该库的更新情况，然后显式地将他们的程序与更新了的库重新链接

另一个问题是几乎每个 C 程序都使用标准 I/O 函数，比如 printf 和 scanf。在运行时，这些函数的代码会被复制到每个运行进程的文本段中。
在一个运行上百个进程的典型系统上，这将是对稀缺的内存系统资源的极大浪费。

共享库(shared library)是致力于==解决静态库缺陷==的一个现代创新产物。
共享库是一个目标模块，在运行或加载时，可以加载到任意的内存地址，并和一个在内存中的程序链接起来。
这个过程称为动态链接(dynamic linking) 是由一个叫做动态链接器(dynamic linker) 的程序来执行的。
共享库也称为共享目标(shared object) 在 Linux 系统中通常用 ==.so==后缀来表示。
微软的操作系统大量地使用了共享库，它们称为 ==DLL==(动态链接库)。

共享库是以两种不同的方式来“共享”的。
- 首先，在任何给定的文件系统中，对于一个库只有一个.so 文件。所有引用该库的可执行目标文件共享这个.so 文件中的代码和数据；而静态库是复制内容嵌套到可执行文件
- 在内存中，一个共享库的 .text 节的一个副本可以被不同的正在运行的进程共享

。。内存中，.text 可能有多个副本吗？


创建共享库
`gcc -shared -fpic -o libvector.so addvec.c multivec.c`

`gcc -o prog21 main2.c ./libvector.so`

可执行文件 prog21 会包含一个 ==.interp 节，包含 链接器的路径名==
动态链接器 通过以下重定位 完成链接
- 重定位 libc.so 的文本和数据 到 某个内存段
- 重定位 libvector.so 的文本和数据 到另一个内存段
- 重定位 prog21 中所有 对由 libc.so 和 libvector.so 定义的符号和引用

。。所以 libc.so 是默认 会链接的？



## ! 7.11 从应用程序中加载和链接共享库

动态链接 是一项强大有用的技术。下面是一些 现实中的例子
- 分发软件
  windows应用的开发者 常常利用 共享库 来分发软件更新。
  他们生成一个共享库的新版本，然后用户可以下载，并替换当前的版本，下一次 用户运行应用时，应用会自动链接和加载新的共享库
- 构建高性能web服务器
  许多web服务器生成动态内容，比如个性化的web页面，账户余额，广告标语。
  早期的web 服务器通过 fork 和 execve 创建一个子进程，在子进程中运行 CGI程序来生成 动态内容。
  现代高性能web服务器可以使用基于动态链接的 更有效，完善的方法来生成 动态内容。

。。cgi，common gateway interface，公共网关接口。
。。cgi程序 能与 浏览器交互，还可以通过数据 api 与数据库服务器 等外部数据源 进行通信。
。。是外部扩展应用程序与 Web 服务器交互的一个标准接口。它可以使外部程序处理www上客户端送来的表单数据并对此作出反应


思路是将每个生成动态内容的函数 打包到 共享库，当一个来自 web 浏览器的请求到达时，服务器动态地加载 和链接 适当的函数，然后直接调用它， 而不是 fork execve。 函数会一直缓存在 服务器的地址空间中，所以只要一个 简单的 函数调用的开销 就可以处理随后的请求了。

Linux 为动态链接器 提供了一个 简单的接口，允许应用在运行时加载 和 链接共享库
```C
#include <dlfcn.h>
void *dlopen(const char *filename, int flag);
```
返回指向句柄的指针，或 NULL

dlopen 加载 和链接 共享库filename。
flag可以：
- RTLD_GLOBAL，可以使用全局符号
- RTLD_NOW，立即解析
- RTLD_LAZY，延迟解析

---

```C
#include <dlfcn.h>
void *dlsym(void *handle, char *symbol);
```
handle 是 dlopen 打开的句柄，如果 symbol 存在，就返回符号的地址，否则NULL

---

```C
// dlfcn.h
int dlclose(void *handle);
```
如果没有其他共享库在使用这个共享库，就卸载，并返回0， 否则返回-1

---

```C
// dlfcn.h
const char *dlerror(void);
```
返回字符串，描述的是 调用dlopen，dlsym，dlclose 函数时 发生的 最近的错误。如果没有错误，就NULL

---

### 动态加载代码

编译使用： `gcc -rdynamic -o prog2r dll.c -ldl`

```C
#include <stdio.h>
#include <stdlib.h>
#include <dlfcn.h>

int x[2] = {1,2};
int y[2] = {3,4};
int z[2];

int main()
{
  void *handle;
  void (*addvec)(int *, int *, int *, int);
  char *error;

  handle = dlopen("./libvector.so", RTLD_LAZY);
  if (!handle) {
    fprintf(stderr, "%s\n", dlerror());
    exit(1);
  }

  addevc = dlsym(handle, "addvec");
  if ((error = dlerror()) != NULL) {
    fprintf(stderr, "%s\n", error);
    exit(1);
  }

  addvec(x, y, z, 2);
  printf("z = [%d, %d]\n", z[0], z[1]);

  if (dlclose(handle) < 0) {
    fprintf(stderr, "%s\n", dlerror());
    exit(1);
  }
  return 0;
}
```


Java Native Interface, JNI，可以使得 java 调用 c，c++函数。
jni的基本思想是 将 本地C函数 编译到 一个共享库中。 当一个正在运行的 java 程序 试图调用 函数时， java解释器 使用 dlopen 加载 和链接 共享库，然后调用。


## 7.12 位置无关代码

多个进程如何共享 共享库的一个副本呢？
一种方法是 给每个共享库 分配一个 事先准备好的 专用的 地址空间片，然后 要求加载器 总是 在这个地址加载 共享库， 这个方法 简单，但有 严重的问题： 它对地址空间的使用率 不高，因为 即使一个进程 不使用这个库，那部分空间还是会分配。 也难以管理，必须保证 空间片 不会重叠，在修改库后，必须确认 已分配的 空间片 是否合适。

现代 系统以这样的方式 编译共享模块的 代码段，使得 可以把 它们加载到内存的 任何位置 而无需链接器修改。
可以加载 而 无需重定位的代码 称为 位置无关代码 (position independent code, ==PIC==)。 ==gcc -fpic 生成 PIC代码， 共享库 必须有这个选项==

在一个 x86_64 系统中，对同一个目标模块中符号的引用是不需要特殊处理使之成为PIC，可以用 PC 相对寻址来编译这些引用，构造目标文件时由静态链接器重定位。
然而，对共享模块定义的外部过程和对全局变量的引用需要一些特殊的技巧，接下来我们会谈到

1. PIC数据引用
无论我们在内存中 何处加载 一个 目标模块，数据段 与 代码段的距离总是不变的。因此 代码中 任何指令 和 数据段中 任何变量之间的 距离都是 一个 运行时常量。

在数据段开始的地方创建 一个 ==全局偏移量表(GOT,global offset table)。==
在GOT中，这个目标模块 ref的所有全局变量 都有一个 8字节条目。 编译器还为 GOT中每个条目生成一个 重定位记录。
在加载时，动态链接器会重定位 GOT 中的每个条目，使得它包含 目标的 正确的 绝对地址。


2. PIC函数调用

编译器无法预测 函数的运行时地址。
正常的方法是 为该引用生成一条重定位记录，然后动态链接器在程序加载的时候 再解析它。不过这种方法并不是 PIC，因为它需要 链接器修改 调用模块的 代码段。

GNU 使用 ==延迟绑定==，将函数地址的 绑定推迟到第一次调用该函数时。

延迟绑定 需要 2个数据结构， GOT 和 过程链接表 (PLT, procedure linkage table)。

。。跳


## 7.13 库打桩机制

Linux 链接器支持一个很强大的技术，称为库打桩(library interpositioning), 它允许你截获对共享库函数的调用，取而代之执行自己的代码

。。。it's very spring  >.<

使用打桩机制，你可以追踪对某个特殊库函数的调用次数，验证和追踪它的输人和输出值，或者甚至把它替换成一个完全不同的实现。

给定一个需要打桩的目标函数，创建一个包装函数，它的原型与目标函数完全一样。
使用某种特殊的打桩机制，你就可以欺骗系统调用包装函数而不是目标函数了。
包装函数通常会执行它自己的逻辑，然后调用目标函数，再将目标函数的返回值传递给调用者


7.13.1 编译时打桩

mymalloc.c 中的 包装函数 调用目标函数，打印追踪记录，并返回。
本地的 malloc.h 头文件 指示 预处理器 用 相应的 包装函数 的调用 替换掉 对目标函数的调用。
编译和链接：
`gcc -DCOMPILETIME -c mymalloc.c`
`gcc -I. -o intc int.c mymalloc.o`

`./intc`

由于有 `-I.` 所以会进行打桩。 它告诉 C编译器 在 搜索 系统目录之前，先在当前 目录中 寻找 malloc.h。 
注意 mymalloc.c 中的 包装函数 是使用 标准的 malloc.h 头文件编译的。


```C
// int.c
#include <stdio.h>
#include <malloc.h>
int main()
{
  int *p = malloc(32);
  free(p);
  return(0);
}

// malloc.h
#define malloc(size) mymalloc(size)
#define free(ptr) myfree(ptr)
void *mymalloc(size_t size);
void myfree(void *ptr);

// mymalloc.c
#ifdef COMPILETIME
#include <stdio.h>
#include <malloc.h>

void *mymalloc(size_t size)
{
  void *ptr = malloc(size);
  printf("malloc(%d)=%p\n", (int)size, ptr);
  return ptr;
}
void myfree(void *ptr)
{
  free(ptr);
  printf("free(%p)\n", ptr);
}
#endif
```


---

7.13.2 链接时打桩

linxu静态链接器 支持 `--wrap f` 进行链接时打桩。 这个选项是告诉 链接器，把 对 符号 f 的引用 解析为 __wrap_f， 还要把 对 符号 __real_f 的引用 解析为 f

`gcc -DLINKTIME -c mymalloc.c`
`gcc -c int.c`

`gcc -W1,--wrap,malloc -W1,--wrap,free -o intl int.o mymalloc.o`

`./intl`

`-W1,option` 把 option 传递给链接器， ==option中 每个 , 都替换为 空格。==
所以 `-W1,--wrap,malloc` 就是把 `--wrap malloc` 传递给链接器

```C
// mymalloc.c
#ifdef LINKTIME
#include <stdio.h>
void *__real_malloc(size_t size);
void __real_free(void *ptr);

void *__wrap_malloc(size_t size)
{
  void *ptr = __real_malloc(size);
  printf("malloc(%d) = %p\n", (int)size, ptr);
  return ptr;
}
void __wrap_free(void *ptr)
{
  __real_free(ptr);
  printf("free(%p)\n", ptr);
}
#endif
```

---
7.13.3 运行时打桩

在运行时打桩，它只需要能够访问可执行目标文件。
这个很厉害的机制基于动态链接器的 LD_PRELOAD 环境变量。

如果LD_PRELOAD 环境变量被设置为一个共享库路径名的列表(以空格或分号分隔),那么当你加载和执行一个程序，需要解析未定义的引用时，动态链接器(LD-LINUX.SO)会先搜索 LD_PRELOAD 库，然后才搜索任何其他的库。
有了这个机制，当你加载和执行任意可执行文件时，可以对任何共享库中的任何函数打桩，包括 libc.so.

`gcc -DRUNTIME -shared -fpic -o mymalloc.so mymalloc.c -ldl`
`gcc -o intr int.c`

printenv SHELL 查看 是哪种shell
bash shell: `LD_PRELOAD="./mymalloc.so" ./intr`
csh/tcsh: `(setenv LD_PRELOAD "./mymalloc.so"; ./intr; unsetenv LD_PRELOAD)`

可以使用 LD_PRELOAD 对任何可执行程序的库函数调用打桩
`LD_PRELOAD="./mymalloc.so" /usr/bin/uptime`



```C
#ifdef RUNTIME
#define _GNU_SOURCE
#include <stdio.h>
#include <stdlib.h>
#include <dlfcn.h>

void *malloc(size_t size)
{
  void *(*mallocp)(size_t size);
  char *error;

  mallocp = dlsym(RTLD_NEXT, "malloc");
  if ((error = dlerror()) != NULL) 
  {
    fputs(error, stderr);
    exit(1);
  }
  char *ptr = mallocp(size);
  printf("malloc(%d) = %p\n", (int)size, ptr);
  return ptr;
}

void free(void *ptr)
{
  void (*freep)(void *) = NULL;
  char *error;
  if (!ptr)
    return;
  
  freep = dlsym(RTLD_NEXT, "free");
  if ((error = dlerror()) != NULL) {
    fputs(error, stderr);
    exit(1);
  }
  freep(ptr);
  printf("free(%p)\n", ptr);
}
#endif
```

## 7.14 处理目标文件的工具

linux中有大量工具可以帮助你 理解和处理目标文件
==GNU binutils== 包尤其有帮助
- AR，创建静态库，插入，删除，列出，提取 成员
- STRINGS，列出目标文件中所有可打印的字符串
- STRIP，从目标文件删除符号表信息
- NM，列出一个目标文件的符号表中定义的符号
- SIZE，列出目标文件中 节的名字和大小
- READELF，显示目标文件的完整结构
- OBJDUMP，所有二进制工具之母，显示目标文件中的所有信息。最大的作用是 反汇编 .text 中的二进制指令
- LDD，列出一个可执行文件 在运行时 需要的 共享库。



# ch8 异常控制流

现代系统通过使控制流发生突变来对这些情况做出反应。一般而言，我们把这些突变称为==异常控制流(ECF==，exception control flow)。

理解ECF很重要，因为
- 理解ECF将帮助你理解重要的系统概念
  ECF是 OS用来实现 IO，进程，虚拟内存的 ==基本机制==，理解这些概念前，必须理解 ECF
- 理解ECF将帮你理解 app 如何与 OS 交互
  app 使用 陷阱(trap) 或 系统调用 的 ECF形式， 向 OS请求服务。
- 帮你编写应用
  OS 为 app 提供了强大的 ECF机制，用来创建 新进程，等待进程终止，通知其他进程 系统中的 异常事件，及 检测和响应这些事件。
- 帮你==理解并发==
  ECF是OS实现并发的基本机制
- 理解 软件异常如何工作
  C++，Java 通过 try，catch，throw 提供 ==软件异常机制==， 软件异常 允许程序 进行 非本地跳转 来响应错误情况， 非本地跳转是一种 app层 ECF，在C中通过 setjmp，longjmp 实现。



## 8.1 异常

异常是异常控制流的一种形式，一部分由硬件实现，一部分由OS实现。

异常就是控制流中的突变，用来响应处理器状态中的 某些变化。

![bbf7c4b3a4fbdf87f37716bae30fc4c5.png](../_resources/bbf7c4b3a4fbdf87f37716bae30fc4c5.png)


当处理器状态中发生一个重要的变化时，处理器正在执行某个当前指令Icurr。
在CPU中，状态被编码为不同的位和信号。
状态变化 称为 事件。事件可能和当前指令的 执行直接相关(如 虚拟内存缺页，算术溢出，除0)，也可能无关(系统定时器产生信号 或 一个IO请求完成)。

任何情况下，CPU检测到 有事件发生时，它就会通过 一张 ==异常表(exception table) 的跳转表==，进行一个间接过程调用，到一个专门设计用来处理 这类事件的 操作系统 子程序(异常处理程序(exception handler))。 
当异常处理程序 完成处理后，根据引起异常的事件的类型，会发生以下3种情况中的一种
- 处理程序程序将控制返回给当前指令 Icurr，即当事件发生时正在执行的指令
- 返回给 Inext，即 如果没有异常将会执行的下一条指令
- 处理程序终止被中断的程序。


### 8.1.1 异常处理

异常可能会难以理解，因为处理异常 需要硬件和软件紧密合作。

系统 为 每种类型的异常 都分配了一个 唯一的 非负整数的 异常号(exception number)。 一些号码是由处理器的设计者分配的，其他是由 OS 的设计者分配的。 前者包括了 /0，缺页，内存访问违例，断电，算术运算溢出。 后者包括 系统调用 和 来自外部IO设备的信号
OS启动时，分配 和初始化一张 异常表，包含了 异常的处理程序地址。
在运行时，处理器检测到 发生了一个事件，并且确定了 相应的异常后，跳转到 间接过程调用，通过异常表的地址 跳转到 相应的处理程序

异常表的起始地址 放在 异常表基址寄存器 的 特殊 CPU寄存器中。

异常类似 过程调用，也有一些不同
- 过程调用时，在跳转到 处理程序之前，处理器将 返回地址 压栈。
  然而 根据 异常类型，返回地址 要么是 当前执行，要么是下一条指令
- CPU 也把一些 额外的处理器状态 压栈，在 处理程序返回时，重新开始执行 被中断的程序 会需要这些状态。
- 如果控制 从 用户程序转到 内核，所有这些项目都被压倒 内核栈， 而不是 用户站。
- 异常处理程序 ==运行在 内核模式下==，这意味着 它们对所有的 系统资源 都有 完全的 访问权限。

一旦硬件触发异常，剩下的工作就是 由 异常处理程序 在 软件中完成。
异常处理程序 处理完事件后，通过 执行一条 特殊的  从中断返回 指令，可选地 返回 被中断的程序，该指令将适当的状态 弹回到 CPU的控制 和数据 寄存器中，如果异常中断的 是一个 用户程序，就将 状态恢复到 用户模式。

### 8.1.2 异常的类别

4类，中断interrupt，陷阱trap，故障fault，终止abort

|类型|原因|异步/同步|返回行为|
|--|--|--|--|
|中断|来自IO设备的信号|异步|总是返回到下一条指令|
|陷阱|有意的异常|同步|总是返回到下一条指令|
|故障|潜在可恢复的错误|同步|==可能==返回到==当前==指令(。。能修复就返回当前(如缺页)，不能就abort)|
|终止|不可恢复的错误|同步|不会返回|



1. 中断

中断是异步发生的，是来自 CPU外部的IO设备的信号的结果。
硬件中断不是由 指令造成的， 从这个意义上讲 它是异步的。
硬件中断的异常处理程序常常被称为 中断处理程序 interrupt handler。

IO设备(如 网络适配器，磁盘控制器，定时器) 通过向 处理器芯片上的一个 引脚发信号，并将异常号 放到 系统总线上，来触发中断，这个异常号 标识了 引起中断的设备。
当前指令处理完后， CPU 注意到 中断 引脚 的电压 变高了，就从 BUS 读取异常号，然后调用 适当的 中断处理程序。 当处理程序返回时，将控制 返回给 下一条 指令，继续执行

其他的异常类型(trap,fault,abort) 是同步的，是执行 当前指令的结果。 我们把这类指令 叫做 故障指令 (faulting instruction)

2. 陷阱和故障调用

陷阱是有意的异常，是执行一条指令的结果。
和中断处理程序一样， 陷阱处理程序 将控制 返回 下一条指令。
陷阱 最重要的用途是 在 ==用户程序 和 内核之间 提供一个 将 过程一样的接口，叫做系统调用==

app经常向 OS 请求服务，如 读文件 read，创建新进程 fork，加载新程序 execve，终止当前进程 exit。
为了允许 对这些内核服务的受控的访问，处理器(。。OS？)提供了一条特殊的 `syscall n` 指令，当用户程序想要请求服务 n 时，可以执行这条指令。
执行 `syscall n` 会 ==导致一个 到异常处理程序的 陷阱，这个处理程序 解析参数，并调用适当的内核程序==。

从程序员的角度，系统调用 和 普通的函数调用 是一样的。然而，它们的实现非常不同。
普通函数 运行在 ==用户模式==中，用户模式 ==限制==了函数可以 执行的==指令的类型==，而且 它们==只能访问 与 调用函数 相同的栈==。
系统调用运行在 ==内核模式==中，内核模式 运行 系统调用，执行 ==特权指令==，访问 ==内核中的栈==


3. 故障

故障由错误情况引起，它可能被 故障处理程序修正。
故障发生时，CPU 将控制转移给 故障处理程序。
如果处理程序 ==可以修正== 这个错误，就将 ==控制返回 引起 故障的指令，重新执行它==。 
不能修正，就返回到 内核中的 abort例程， 它会 终止 引起故障的 app。

一个经典的故障 是 缺页异常。

4. 终止

终止是 不可恢复的 致命错误 造成的 结果，通常是 一些 硬件错误，比如 DRAM 或 SRAM 位被损坏 是发生的 ==奇偶错误==。
终止处理程序 会调用 abort， 终止app



### 8. 1 . 3 Linux/x86-64 系统中的异常

为 X86-64 系统定义的一些异常。有高达 256 种不同的异常类型
0-31 是由 Intel 架构师定义的异常
32-255 是 OS定义的 中断和陷阱

每个==系统调用都有一个唯一的整数号，对应于一个到内核中跳转表的偏移量==。（注意：这个跳转表和异常表不一样。）



## 8.2 进程

异常是允许操作系统内核提供进程(process)概念的基本构造块，进程是计算机科学中最深刻、最成功的概念之一。

在现代系统上运行一个程序时，我们会得到一个假象，就好像我们的程序是系统中当前运行的唯一的程序一样。

进程的经典定义就是一个执行中程序的实例。系统中的每个程序都运行在某个进程的上下文(context)中。
==上下文==是由程序正确运行==所需的状态==组成的。
这个状态包括存放在==内存中的程序的代码和数据，它的栈、通用目的寄存器的内容、程序计数器、环境变量以及打开文件描述符==的集合。

关于操作系统如何实现进程的细节的讨论超出了本书的范围。反之，我们将关注进程提供给应用程序的关键抽象：
- 一个独立的逻辑控制流，它提供一个假象，好像我们的程序==独占==地使用==处理器==。
- 一个私有的地址空间，它提供一个假象，好像我们的程序==独占==地使用==内存系统==。


8.2.1 逻辑控制流

每个进程执行它的流的一部分，然后被抢占(preempted)(暂时挂起)， 然后轮到其他进程。


8.2.2 并发流

==单核的并发，非 多核的 并行

流 X 和 Y 互相并发，当且仅当 X 在 Y 开始之后和 Y 结束之前开始，或者 Y 在 X 开始之后和 X 结束之前开始。
。。就是 2个流的  开始-结束 有重叠。

多个流并发地执行的一般现象被称为并发(concurrency)。
一个进程和其他进程轮流运行的概念称为多任务(multitasking)。
一个进程执行它的控制流的一部分的每一时间段叫做时间片(time slics).
因此，多任务也叫做时间分片(time slicing)


如果两个流并发地运行在不同的处理器核或者计算机上，那么我们称它们为并行流(parallel flow), 它们并行地运行(running in parallel) 且并行地执行(parallel execution)


8.2.3 私有地址空间

进程也为每个程序提供一种假象，好像它独占地使用系统地址空间。


### 8.2.4 用户模式和内核模式

为了使操作系统内核提供一个无懈可击的==进程==抽象，处理器必须提供一种机制，==限制==一个应用==可以执行的指令==以及它==可以访问的地址空间范围==。
。。不然就看到 别人(内核)了。。

处理器通常是用某个控制==寄存器中的一个模式位==(mode bit)来提供这种功能的，该寄存器描述了进程当前享有的特权。
当设置了模式位时，进程就运行在内核模式中（有时叫做超级用户模式）

没有设置模式位时，进程就运行在用户模式中。
用户模式中的进程不允许执行特权指令(privileged instruction), 比如停止处理器、改变模式位，或者发起一个 I/O 操作。
也不允许用户模式中的进程直接引用地址空间中 内核区 内的代码和数据。
任何这样的尝试都会导致致命的保护故障。
反之，用户程序必须通过系统调用接口间接地访问内核代码和数据。

进程从用户模式变为==内核模式的唯一方法==是通过诸如中断、故障或者陷人系统调用这样的==异常==。
异常发生时，控制传递到 异常处理程序，处理器 将模式 从 用户模式 变为 内核模式。
异常处理程序运行在内核模式中，当它返回到应用程序代码时，处理器就把模式从内核模式改回到用户模式。

Linux 提供了一种聪明的机制，叫做 `/proc` 文件系统，它允许用户模式进程访问内核数据结构的内容。
/proc 文件系统将许多内核数据结构的内容输出为一个用户程序可以读的文本文件的层次结构



8.2.5 上下文切换

操作系统内核使用一种称为==上下文切换==(context switch)的较高层形式的==异常==控制流来实现==多任务==。

内核为每个进程维持一个上下文(context)。
上下文就是内核==重新启动==一个被抢占的进程所需的状态。
它由一些对象的值组成，这些对象包括
- 通用目的寄存器、
- 浮点寄存器、
- 程序计数器、
- 用户栈、
- 状态寄存器、
- 内核栈和各种内核数据结构，比如
  - 描述地址空间的页表、包含
  - 有关当前进程信息的进程表，以及包含
  - 进程已打开文件的信息的文件表。

在进程执行的某些时刻，内核可以决定==抢占当前进程==，并重新开始一个先前被抢占了的进程。
这种决策就叫做调度(scheduling), 是由内核中称为调度器(scheduler)的代码处理的。

上下文切换
1. 保存当前进程的上下文，
2. 恢复某个先前被抢占的进程被保存的上下文，
3. 将控制传递给这个新恢复的进程。

当内核代表用户执行系统调用时，可能会发生上下文切换。
如果系统调用因为等待某个事件发生而阻塞，那么内核可以让当前进程休眠，切换到另一个进程。

中断也可能引发上下文切换。
比如，所有的系统都有某种产生==周期性定时器中断==的机制，通常为每 1 毫秒或每 10 毫秒。
每次发生定时器中断时，内核就能判定当前进程已经运行了足够长的时间，并切换到一个新的进程


## 8.3 系统调用错误处理

当 Unix 系统级函数遇到错误时，它们通常会返回一1，并设置全局整数变量 errno 来表示什么出错了。
但是不幸的是，许多人都忽略了错误检查，因为它使代码变得臃肿，而且难以读懂。

通过使用错误处理包装函数，我们可以更进一步地简化代码
对于一个给定的基本函数 foo, 我们定义一个具有相同参数的包装函数Foo, 但是第一个字母大写了。==包装函数调用基本函数==，检查错误，如果有任何问题就终止
。。就是 DBUtils.close, closeQuite ...

关于 Unix 错误处理以及本书中使用的错误处理包装函数的讨论，请参见附录 A。
包装函数定义在一个叫做 csapp.c 的文件中，它们的原型定义在一个叫做 csapp.h 的头文件中；可以从 CS:APP 网站上在线地得到这些代码。


## 8.4 进程控制

Unix 提供了大量从 C 程序中操作进程的系统调用

。。下面的方法 是unix 还是 linux 的？ 一样的？

### 8.4.1 获取进程ID

```C
#include <sys/types.h>
#include <unistd.h>

pid_t getpid(void);
pid_t getppid(void);
```

### 8.4.2 创建和终止进程

从程序员的角度，我们可以认为 进程 总是 下面3种状态之一
- 运行，要么CPU上执行，要么在等待被执行且最终会被内核调度
- 停止，被挂起，且不会被调度。
- 终止，永远停止了。

```C
#include <stdlib.h>

void exit(int status);
```

父进程通过 fork 创建 一个 新的子进程
```C
#include <sys/types.h>
#include <unistd.h>

pid_t fork(void);
```
新创建的子进程 和 父进程 几乎相同。
子进程得到 父进程的 用户级 ==虚拟地址空间 的一份 副本，包括== 代码和数据段，堆，共享库，用户栈。 还获得了 父进程 打开的 ==所有文件描述符 的副本==，子进程可以读写 父进程 打开的任何文件。
父进程 和 子进程 最大的区别 是 pid 不同。

fork 只被调用一次，但是会返回2次，一次在 父进程中，一次在 新创建的 子进程中。
父进程中，fork 返回 子进程的 pid， 在子进程中，fork返回0。 这样可以==区分== 进程是 父进程还是 子进程


### 8.4.3 回收子进程

进程终止时，内核并不是 立即把它 从系统中清除。
进程保持在 一种 已终止的 状态中，直到 被它的 父进程 回收(reaped)。

当父进程 回收 已终止的子进程时， ==内核将 子进程的 退出状态传递给 父进程==，然后 抛弃已终止的 进程。

如果一个父进程终止了，内核 会安排 init进程 成为 它的 孤儿进程 的养父。
init进程的 pid 为 1， 是系统启动时 内核创建的，它不会终止，是所有进程的祖先。

等待子进程的终止或停止
```C
#include <sys/types.h>
#include <sys/wait.h>

pid_t waitpid(pid_t pid, int *statusp, int options);
// 下面还有个 wait
```
默认情况下(options=0时)， 方法会挂起 调用进程，直到 它等待集合中的一个 子进程 终止。 如果等待集合中 一个进程 在 调用时 就已经终止了，则立刻返回。

pid > 0，等待集合就是一个 单独的子进程， 它的进程id 等于 pid
pid=-1, 等待集合 就是 父进程的 所有子进程

waitpid 还支持 其他的等待集合，如 进程组。


修改默认行为
options 设置为 WNOHANG，WUNTRACED，WCONTINUED
- WNOHANG, 如果等待集合中 任何子进程 都没有终止，就立刻返回(返回0)
- WUNTRACED，挂起调用进程，直到 等待集合中有进程 变成已终止 或 被停止。返回的PID是 导致 返回的已终止或 被停止 子进程的 PID， 默认是返回 已终止的子进程。
- WCONTINUED，挂起调用进程的执行，直到 等待集中中 一个 正在运行的 进程 终止 或等待集合中 一个被停止的 进程收到 SIGCONT 重新开始执行

可以 或运算符 组合这些选项


---

检查已回收子进程的退出状态

如果 statusp 的参数 非空，那么 waitpid 会在 status 上存放 关于 导致返回的 子进程的 状态信息。
wait.h 定义了 解释 status 参数的 几个宏
- WIFEXITED
- WEXITSTATUS
- WIFSIGNALED
- WTERMSIG
- WIFSTOPPED
- WSTOPSIG
- WIFCONTINUED


如果调用进程 没有子进程，那么 waitpid 返回 -1， 设置 errno 为 ECHILD。
如果 waitpid 被 信号中断，那么返回-1， errnor 为 EINTR。


wait函数 是 waitpid 的简单版本
```C
#include <sys/types.h>
#include <sys/wait.h>

pid_t wait(int *statusp);
```
wait(&status) 等价于 waitpid(-1, &status, 0);



### 8.4.4 让进程休眠

将进程挂起一段时间
```C
#include <unistd.h>

unsigned int sleep(unsigned int secs);
// 返回 还要休眠的秒数
```
sleep 可能被 信号中断 而过早地返回，所以可能返回 还需要休眠的秒数


休眠，直到进程 收到一个信号
```C
#include <unistd.h>
int pause(void);
// 总是返回 -1
```


### 8.4.5 加载并运行程序

execve 在当前进程的 上下文中加载并运行 一个新程序
```C
#include <unistd.h>

int execve(const char *filename, const char **argv[], const char *envp[]);
// 成功不返回，失败返回-1
```
fork 调用一次，返回2次。
evecve 调用一次，成功则 不返回


```C
#include <stdlib.h>

char *getenv(const char *name);
```

```C
#include <stdlib.h>

int setenv(const char *name, const char *newvalue, int overwrite);
void unsetenv(const char *name);
```


### 8.4.6 利用 fork 和 execve 运行程序

像 Unix shell 和 Web 服务器这样的程序大量使用了 fork 和 evecve


## 8.5 信号

更高层的 软件形式的异常， 称为 linux 信号， 它允许进程 和 内核 中断其他进程。

信号 就是 一条小消息。
每种 信号类型 都对应于 某种 系统事件。 低层的硬件异常 是由 内核异常处理程序处理的。正常情况下，对用户进程 而言是 可不见的。 信号 提供了一种机制，通知 用户 进程 发生了这些异常。
比如，如果一个进程 试图除以0，那么 内核 就发送给它 一个 SIGFPE 信号。
如果进程 执行一条非法指令，那么 内核就发送给它 一个 SIGILL 信号
如果进程 进行 非法内存引用，内核就给它 SIGSEGV 信号
如果进程在 前台运行， 输入 ctrl+c ，内核就给这个前台进程组中的所有进程 SIGINT信号
一个进程 可以 向 另一个进程 SIGKILL 来终止它
当 一个子进程 终止 或者 停止时， 内核会发送一个 SIGCHLD 信号 给 父进程

![c5c3eb9b69efc8d9a52c0c1e403c0401.png](../_resources/c5c3eb9b69efc8d9a52c0c1e403c0401.png)



8.5.1 信号术语

传送一个信号 到目的进程  是由 2个步骤组成的
- 发送信号
  内核通过更新目的进程 上下文中的 某个状态，==发送== 一个信号 给目的进程
  发送信号 有2个原因
  - 内核检测到一个 系统事件，如 /0， 子进程终止
  - 一个进程调用了 kill函数
- 接收信号
  当目的进程 被 内核强迫以某种方式 对 信号的 发送 做出反应时，它就接收了信号。
  进程可以忽略这个信号，终止，或通过执行 信号处理程序 的用户层函数 捕获这个信号。

一个发出 而没有被接收的信号 叫做待处理信号。
任何时候，一种类型 最多只会有 一个 待处理信号。 后续来的 信号被丢弃。(。。只是 bit位，所以应该没有丢弃的说法)
进程可以 选择性地 阻塞 接收某种信号。当 一种信号被阻塞时，它仍然可以被发送，但是 产生的信号 不会被 接收，直到 进程 取消 对这种 信号的阻塞。

一个待处理信号 最多只能被 接收一次。
内核为 每个进程 在 ==pending 位向量==中 维护者 待处理信号的集合，在 ==blocked 位向量==中 维护者 被阻塞的 信号集合。


8.5.2 发送信号。

提供了大量向进程发送信号的机制
所有的机制 都是基于 ==进程组== 这个概念的

==进程组==
每个进程 都只属于 一个进程组，
进程组是由一个 正整数 来标识的。
```C
#include <unistd.h>

pid_t getpgrp(void);
```

默认下，子进程 和 它的父进程 属于同一个进程组。
通过setpgid改变自己 或 其他进程 的 进程组
```C
#include <unistd.h>

int setpgid(pid_t pid, pid_t pgid);
// 成功0，失败-1
// pid为0，则使用当前进程的pid
// pgid为0，则使用 当前进程的pid 作为进程组 id
```

`setpgid(0,0)`, 如果当前进程是 1234， 那么 会创建 一个新的进程组 1234， 并把 进程 1234 放到这个组里。

---

/bin/kill 发送信号
`/bin/kill -9 1234`
负数pid 则发送到 进程组

---

通过 kill函数 发送信号给其它进程(或自己)

```C
#include <sys/types.h>
#include <signal.h>

int kill(pid_t pid, int sig);
```
pid 大于0，发送给 该pid 的进程
=0，发送给 调用进程 所在 进程组 中的 所有进程，包括 调用进程自己
小于0，发送给 进程组 -pid


---
alarm 向它自己发送 SIGALRM 信号

```C
#include <unistd.h>

unsigned int alarm(unsigned int secs);
```

alarm 安排 内核 在 secs 秒后 发送 一个 SIGALRM信号 给 调用进程。
如果secs 为0 ，不会 调度 安排新的 闹钟。
任何情况下，对 alarm 的调用 都将 取消 任何待处理的 闹钟，并且 返回 待处理闹钟 在被 发送前 还剩下 的秒数， 如果没有任何 待处理的闹钟，就返回0。


### 8.5.3 接收信号

当内核把进程 P 从内核模式切换到用户模式时（例如，从系统调用返回或是完成了一次上下文切换）， 它会检査进程的 未被阻塞的待处理信号的集合(pending &~blocked)。
如果这个集合为空（通常情况下），那么内核将控制传递到 P 的逻辑控制流中的下一条指令。
然而，如果集合是非空的，那么内核选择集合中的某个信号 k (通常是最小的k)，并且强制 P 接收信号 k。 收到这个信号会触发进程采取某种行为。一旦进程完成了这个行
为，那么控制就传递回p 的逻辑控制流中的下一条指令。
每个信号类型都有一个预定义的默认行为 ，是下面中的一种：
- 进程终止
- 进程终止并转储内容
- 进程停止(挂起)直到 被 SIGCONT 信号重启
- 进程忽略该信号

SIGSTOP，SIGKILL  的默认行为不能修改。

```C
#include <signal.h>
typedef void (*sighandler_t)(int);

sighandler_t signal(int signum, sighandler_t handler);
```

---

### 8.5.4 阻塞和解除阻塞信号

隐式阻塞机制
内核 默认 阻塞任何 当前处理程序 正在处理的 信号类型的待处理的信号

显示阻塞机制
app使用 sigprocmask 明确 阻塞和 解阻塞 选定的信号

```C
#include <signal.h>

int sigprocmask(int how, const sigset_t *set, sigset_t *oldset);
int sigemptyset(sigset_t *set);
int sigfillset(sigset_t *set);
int sigaddset(sigset_t *set);
int sigdelset(sigset_t *set, int signum);
int sigismember(sigset_t *set, int signum);
```

how
- SIG_BLOCK
  添加到 blocked 中， blocked = blocked | set
- SIG_UNBLOCK
  从blocked 中移除 set中 信号, blocked = blocked & ~set
- SIG_SETMASK, blocked = set


### 8.5.5 编写信号处理程序

信号处理 是 linux 系统编程中 最棘手的一个问题。

处理程序的几个属性 使得它们很难推理分析
- 处理程序 与 主程序并发，共享同样的 全局变量，因此可能和 主程序 和其他处理程序 相互干扰
- 如何 以及 何时 接收信号的 规则 常常 违背直觉
- 不同的系统 有不同的 信号处理语义

1. 安全的信号处理。

![1586a6803390bd14cbed8facea023b67.png](../_resources/1586a6803390bd14cbed8facea023b67.png)


。。跳

8.5.6 同步流以避免讨厌的并发错误


8.5.7 显式地等待信号


## !! 8.6 非本地跳转 setjmp, longjmp

C 语言提供了一种用户级 异常控制流形式，称为 ==非本地跳转==(nonlocal jump), 它将控制直接从一个函数转移到另一个当前正在执行的函数，而不需要经过正常的调用-返回序列。
非本地跳转是通过 ==setjmp 和 longjmp== 函数来提供的。

```C
#include <setjmp.h>

int setjmp(jmp_buf env);
int sigsetjmp(sigjmp_buf env, int savesigs);
```

```C
#include <setjmp.h>

void longjmp(jmp_buf env, int retval);
void siglongjmp(sigjmp_buf env, int retval);
```



## 8.7 操作进程的工具

- strace，打印正在运行的程序和它的子进程调用的 每个系统调用的轨迹
- ps，列出当前系统中的进程(包括 僵死进程)
- top，打印当前进程资源使用的情况
- pmap，线程进程的内存映射
- /proc，虚拟文件系统，以ASCII文本格式 输出 大量 内核数据结构的内容。




# ch9 虚拟内存

为了更加有效地管理内存 并减少出错，现代系统 提供了 对主存的抽象，叫做 虚拟内存(VM)。
虚拟内存是 硬件异常，硬件地址翻译，主存，磁盘文件，内核文件的 完美交互。
它为每个进程提供一个==大的，一致的，私有的== 地址空间
通过一个很清晰的机制，虚拟内存提供3个重要的能力
- 它将主存看成是一个存储在磁盘上的地址空间的高速缓存，在主存中只保存活动区域，并根据需要在磁盘和主存之间来回传送数据，通过这种方式，它高效地使用了主存
- 它为每个进程提供了一致的地址空间，从而简化了内存管理
- 它保护了每个进程的地址空间不被其他进程破坏。

虚拟内存是计算机系统最重要的概念之一。它成功的一个主要原因就是因为它是沉默地、自动地工作的


## 9.1 物理和虚拟寻址

计算机系统的主存被组织成一个由 M 个连续的字节大小的单元组成的数组。
每字节都有一个唯一的物理地址(Physical Address PA)。
第一个字节的地址为 0, 接下来的字节地址为 1，再下一个为 2, 依此类推。
给定这种简单的结构，CPU 访问内存的最自然的方式就是使用物理地址。
我们把这种方式称为物理寻址(physical addressing)

早期的 PC 使用物理寻址

现代处理器使用的是一种称为虚拟寻址(virtual addressing)的寻址形式

![2da3df7eacdc3cf64bf3adba59d00978.png](../_resources/2da3df7eacdc3cf64bf3adba59d00978.png)

CPU 通过生成一个虚拟地址(Virtual Address, VA)来访问主存，这个虚拟地址在被送到内存之前先转换成适当的物理地址
CPU 芯片上叫做内存管理单元(Memory Management Unit,MMU)的专用硬件，利用存放在主存中的查询表来动态翻译虚拟地址，该表的内容由操作系统管理。



## 9.2 地址空间

地址空间(address space)是一个非负整数地址的有序集合

如果地址空间中的整数是连续的，那么我们说它是一个 线性地址空间(linear address space)

我们总是假设使用的是线性地址空间

地址空间的概念是很重要的，因为它清楚地区分了数据对象（字节）和它们的属性（地址）


## 9.3 虚拟内存作为缓存的工具

VM系统将 虚拟内存分割为 虚拟页 (virtual page, VP) ，大小固定的块。
物理内存也被 分割为 物理页 (physical page, PP，也称为 页帧 page frame), 大小和 虚拟页 一样。

在任何时候，虚拟页的集合都被分为 3个不想交的子集
- 未分配的
- 缓存的，当前已缓存在 物理内存中的 已分配页
- 未缓存的，未缓存在 物理内存中的已分配页

。。虚拟内存 可以大于物理内存，所以 有一部分页 可能 放在磁盘上，这些就是 未缓存的。


9.3.1 DRAM 缓存的组织结构


因为大的不命中处罚和访问第一个字节的开销，虚拟页往往很大，通常是 4KB - 2MB



### 9.3.2 页表

同任何缓存一样，虚拟内存系统必须有某种方法来判定一个虚拟页是否缓存在DRAM 中的某个地方。
如果是，系统还必须确定这个虚拟页存放在哪个物理页中。
如果不命中，系统必须判断这个虚拟页存放在磁盘的哪个位置，在物理内存中选择一个牺牲页，并将虚拟页从磁盘复制到 DRAM 中，替换这个牺牲页。

这些功能是由软硬件联合提供的，包括操作系统软件、MMU(内存管理单元）中的地址翻译硬件和一个存放在物理内存中叫做页表（page table)的数据结构

页表将虚拟页映射到物理页。
每次地址翻译硬件将一个虚拟地址转换为物理地址时，都会读取页表


页表就是一个页表条目(Page Table Entry PTE)的数组
我们将假设每个 PTE 是由一个有效位(valid bit)和一个 n 位地址字段组成的。
有效位表明了该虚拟页当前是否被缓存在 DRAM 中。
如果设置了==有效==位，那么地址字段就表示 DRAM 中相应的==物理页的起始位置==，这个物理页中缓存了该虚拟页。
如果==没有设置有效位==，那么一个==空地址==表示这个虚拟页还==未被分配==。
否则，这个地址就指向该虚拟页在==磁盘上的起始位置==



### 9.3.3 页命中




### 9.3.4 缺页

在虚拟内存中， DRAM 缓存 不命中 被称为 ==缺页==(page fault)

地址翻译硬件从内存中读取 PTE 3, 从有效位推断出 VP 3 未被缓存，并且触发一个缺页异常。缺页异常调用内核中的缺页异常处理程序
该程序会选择一个牺牲页，在此例中就是存放在 PP 3 中的 VP 4。如果 VP 4 已经被修改了，那么内核就会将它复制回磁盘

内核从磁盘复制 VP 3 到内存中的 PP 3, 更新 PTE 3，随后返回。
当异常处理程序返回时，它会重新启动导致缺页的指令，该指令会把导致缺页的虚拟地址重发送到地址翻译硬件。
但是现在，VP 3 已经缓存在主存中了，那么页命中也能由地址翻译硬件正常处理了。


9.3.5 分配页面

malloc


### 9.3.6 又是局部性救了我们

当我们中的许多人都了解了虚拟内存的概念之后，我们的第一印象通常是它的效率应该是非常低

实际上，虚拟内存工作得相当好，这主要归功于我们的老朋友局部性(locality),


如果工作集的大小超出了物理内存的大小，那么程序将产生一种不幸的状态，叫做抖动(thrashing), 这时==页面将不断地换进换出==。
虽然虚拟内存通常是有效的，但是如果一个程序==性能慢==得像爬一样，那么聪明的程序员会==考虑是不是发生了抖动==。


可以使用 linux 的 getrusage 函数 监测 缺页的数量 (及 许多其他信息)


## 9.4 虚拟内存作为内存管理的工具


到目前为止，我们都假设有一个单独的页表，将一个虚拟地址空间映射到物理地址空间。
实际上，操作系统为==每个进程提供了一个独立的页表==，因而也就是一个独立的虚拟地址空间。

按需页面调度和独立的虚拟地址空间的结合，对系统中内存的使用和管理造成了深远的影响。
特别地,VM 简化了链接和加载、代码和数据共享，以及应用程序的内存分配



## 9.5 虚拟内存作为内存保护的工具 (segment fault)

任何现代计算机系统必须为操作系统提供手段来 ==控制对内存系统的访问==

提供独立的地址空间使得区分不同进程的私有内存变得容易。
但是，地址翻译机制可以以一种自然的方式扩展到提供更好的访问控制。
因为每次 CPU 生成一个地址时，地址翻译硬件都会读一个 PTE, 所以通过在 PTE 上添加一些额外的==许可位==来控制对一个虚拟页面内容的访问十分简单

如果一条指令违反了这些许可条件，那么 CPU 就触发一个一般保护故障，将控制传递给一个内核中的异常处理程序。
Linux shell 一般将这种异常报告为 ==段错误==(segmentation fault)



## 9.6 地址翻译

地址翻译是一个 N 元素的虚拟地址空间(VAS)中的元素和一个 M 元素的物理地址空间(PAS)中元素之间的映射

下图展示了 MMU 如何利用页表来实现这种映射。

![f6b4a54306b25c4dd292f0df10ba9530.png](../_resources/f6b4a54306b25c4dd292f0df10ba9530.png)



---

![6e2dce42152501b1bc6d4c38bc83b77e.png](../_resources/6e2dce42152501b1bc6d4c38bc83b77e.png)


在页面命中时，CPU硬件执行的步骤
1. 处理器生成一个 虚拟地址，并传给 MMU
2. MMU生成 PTE 地址，并从 高速缓存/主存 请求它
3. 高速缓存/主存 向 MMU返回 PTE
4. MMU构造物理地址，并把它传送给 高速缓存/主存
5. 高速缓存/主存 返回 请求的数据字 给 CPU

。。page table entry 页表条目

页面命中 完全由 硬件处理。
处理缺页 需要 硬件 和 OS 协作
1-3 和 页面命中一样
4. PTE 中有效位为 0，所以 MMU 触发 异常，传递 CPU中的 控制 到 OS的 缺页异常处理程序
5. 缺页处理程序 确定 物理内存中的 牺牲页，如果这个页 已经被修改了，则把它换出到 磁盘
6. 缺页处理程序 调入新的页，并更新内存中的 PTE
7. 缺页处理程序 返回到原来的进程， 再次执行 导致 缺页的指令。 然后 走页面命中的 第一步。


9.6.1 结合高速缓存和虚拟内存

在任何既使用虚拟内存又使用 SRAM 髙速缓存的系统中，都有应该使用虚拟地址还是使用物理地址来访问 SRAM 高速缓存的问题。
尽管关于这个折中的详细讨论已经超出了我们的讨论范围，但是==大多数系统是选择物理寻址==的。
使用物理寻址，==多个进程同时==在高速缓存中有存储块和共享来自相同虚拟页面的块成为很简单的事情。   。。。？
而且，高速缓存无需处理保护问题，因为访问权限的检査是地址翻译过程的一部分。


### !!! 9.6.2 利用 TLB 加速地址翻译

正如我们看到的，每次 CPU 产生一个虚拟地址，MMU 就必须查阅一个 PTE, 以便将虚拟地址翻译为物理地址

许多系统都试图消除这样的开销，它们在 MMU 中包括了一个关于 PTE 的小的缓存，称为翻译后备缓冲器(Translation Lookaside Buffer, TLB)。

TLB 是一个小的、虚拟寻址的缓存，其中每一行都保存着一个由单个 PTE 组成的块。
TLB 通常有高度的相联度。

。。==原先==是， 虚拟地址 到 MMU，MMU 生成 PTE 地址， 从 高速缓存/主存 中获得 PTE，然后 构造 物理地址，
。。==现在== 在 TLB 中保存 PTE， 不需要 访问 高速缓存/主存 ， TLB在MMU中，所以很快。




### 9.6.3 多级页表

用来压缩页表的常用方法是使用层次结构的页表。

`4k -> 4m -> 4g`

。。我记得是 4层， 但是 基本用不到4层， 但是 还是会维持 4层的样子 (中间某层 直接 1比1， 而不是 1比1024)。


9.6.4 综合：端到端的地址翻译


## 9.7 案例研究：丨ntel Core i7/Linux 内存系统



## !!! 9.8 内存映射

Linux 通过将一个==虚拟内存==区域与一个==磁盘上的对象==(object)关联起来，以初始化这个虚拟内存区域的内容，这个过程称为==内存映射==(memory mapping)

虚拟内存区域可以映射到两种类型的对象中的一种：
1. linux文件系统中的普通文件
2. 匿名文件， 匿名文件由内核创建，驻留在内存中。  磁盘和内存 没有实际的 数据发送。


9.8.1 再看共享对象

内存映射的概念来源于一个聪明的发现：如果虚拟内存系统可以集成到传统的文件系统中，那么就能提供一种简单而高效的把程序和数据加载到内存中的方法。

一个对象可以被映射到虚拟内存的一个区域，要么作为共享对象，要么作为私有对象。

如果一个进程将一个==共享对象==映射到它的虚拟地址空间的一个区域内，那么这个进程对这个区域的任何写操作，对于那些也把这个共享对象映射到它们虚拟内存的其他进程而言，也是可见的。
而且，这些变化也会反映在磁盘上的原始对象中。

对于一个映射到==私有对象==的区域做的改变，对于其他进程来说是不可见的，并且进程对这个区域所做的任何写操作都不会反映在磁盘上的对象中。

一个映射到共享对象的虚拟内存区域叫做共享区域。类似地，也有私有区域。

私有对象使用一种叫做 ==写时复制==(copy-on-write)的巧妙技术被映射到虚拟内存中。


### 9.8.2 再看 fork 函数

当 fork 函数被当前进程调用时，内核为新进程创建各种数据结构，并分配给它一个唯一的 PID.
为了给这个新进程创建虚拟内存，它创建了当前进程的 mm_struct, 区域结构和页表的原样副本。
它将两个进程中的每个页面都标记为只读，并将两个进程中的每个区域结构都标记为私有的写时复制

### 9.8.3 再看 execve 函数

虚拟内存和内存映射在将程序加载到内存的过程中也扮演着关键的角色。

`execve("a.out", NULL, NULL);`

execve 函数在当前进程中加载并运行包含在可执行目标文件a.out 中的程序，用 a.out 程序有效地替代了当前程序
加载并运行 a.out 需要以下几个步骤:
1. 删除已存在的用户区域
2. 映射私有区域
3. 映射共享区域
4. 设置程序计数器PC


### !!!! 9.8.4 使用 mmap 函数的用户级内存映射

使用 mmap 函数来创建新的虚拟内存区域，并将对象映射到这些区域中。

```C
#include <unistd.h>
#include <sys/mman.h>

void *mmap(void *start, size_t length, int prot, int flags, int fd, off_t offset);
```

mmap 函数要求==内核==创建一个新的虚拟内存区域，==最好==是从地址 start 开始的一个区域，并将文件描述符 fd 指定的对象的一个连续的片(chunk)映射到这个新的区域。
连续的对象片大小为 length 字节，从距文件开始处偏移量为 offset 字节的地方开始。start地址仅仅是一个暗示，通常被定义为 NULL

参数 prot 包含描述新映射的虚拟内存区域的访问权限位(即在相应区域结构中的 vm_prot 位)
- PROT_EXEC，这个区域内的页面可以被 CPU 执行的指令组成
- PROT_READ，可读
- PROT_WRITE，可写
- PROT_NONE，不能被访问

参数 flags 由描述被映射对象类型的位组成。
如果设置了 ==MAP_ANON== 标记位，那么被映射的对象就是一个匿名对象
MAP_RPIVATE 表示被映射的对象是一个私有的、写时复制的对象
MAP_SHARED 表示是一个共享对象。

munmap 函数删除虚拟内存的区域
```C
#include <unistd.h>
#include <sys/mman.h>

int munmap(void *start, size_t length);
```
munmap 函数删除从虚拟地址 start 开始的，由接下来 length 字节组成的区域。
接下来对已删除区域的引用会导致 ==段错误==。


## !!! 9.9 动态内存分配

动态内存分配器(dynamic memory allocator)

动态内存分配器维护着一个进程的虚拟内存区域，称为堆(heap)(见图 9-33)。
系统之间细节不同，但是不失通用性，假设堆是一个请求二进制零的区域，它紧接在未初始化的数据区域后开始，并向上生长（向更高的地址）。 
对于每个进程，内核维护着一个变量 ==brk== (读做break), 它指向堆的顶部.


![8860a618135f743815b6911fae3db33b.png](../_resources/8860a618135f743815b6911fae3db33b.png)


分配器有2种风格
- 显示分配器， malloc/free， new/delete
- 隐式分配器， 要求分配器检测一个已分配块何时不再被程序所使用，那么就释放这个块。隐式分配器也叫垃圾收集器，如Lisp，Java

本节剩下的部分讨论的是显式分配器的设计和实现。


### 9.9.1 malloc, free

```C
#include <stdlib.h>

void *malloc(size_t size);
```

malloc 函数返回一个指针，指向大小为至少 size 字节的内存块，这个块会为可能包含在这个块内的任何数据对象类型做对齐，32位是8的倍数，64为是16的倍数。

malloc失败，则返回 NULL，设置 errno

malloc ==不初始化== 返回的内存。

==calloc== 初始化 返回的内存， 是 malloc 的一个 瘦 包装函数，将 分配的内存初始化为 0

==realloc==，改变一个 已分配块的 大小。


动态内存分配器，例如 malloc，可以通过使用 mmap 和 munmap 函数，显式地分配和释放堆内存，或者还可以使用 sbrk 函数：
```C
#include <unistd.h>

void *sbrk(intptr_t incr);
```

sbrk 函数通过将内核的 brk 指针增加 incr 来==扩展和收缩堆==。
如果成功，它就返回 brk 的旧值，否则，它就返回 -1，并将 errno设置为 ENOMEN


---

调用 free 函数来释放已分配的堆块。
```C
#include <stdlib.h>

void free(void *ptr);
```
ptr 参数必须指向一个从 malloc,calloc或者realloc 获得的已分配块的起始位置。
如果不是，那么 free 的行为就是==未定义==的。


9.9.2 为什么要使用动态内存分配

程序使用动态内存分配的最重要的原因是经常直到程序实际运行时，才知道某些数据结构的大小。




9.9.3 分配器的要求和目


### 9.9.4 碎片

造成堆利用率很低的主要原因是一种称为碎片(fragmentation)的现象，当虽然有未使用的内存但不能用来满足分配请求时，就发生这种现象。
有两种形式的碎片：内部碎片(internal fragmentation)和 外部碎片(external fragmentation)

内部碎片 是在一个已分配块 比 有效载荷 大 时发生的

外部碎片是当空闲内存合计起来足够满足一个分配请求，但是没有一个单独的空闲块足够大可以来处理这个请求时发生的

分配器通常采用启发式策略来试图维持少量的大空闲块，而不是维持大量的小空闲块


9.9.5 实现问题

。。跳，我相信 linux 的开发者 能处理碎片， 至少 肯定比我处理的好。。

9.9.6 隐式空闲链表

9.9.7 放置已分配的块
9.9.8 分割空闲块
9.9.9 获取额外的堆内存
9.9.10 合并空闲块

### 9.9.11 带边界标记的合并

==Knuth== 提出了一种聪明而通用的技术，叫做边界标记(boundary tag), 允许在常数时间内进行对前面块的合并

在每个块的结尾处添加一个脚部（footer，边界标记）， 其中脚部就是头部的一个副本。
如果每个块包括这样一个脚部，那么分配器就可以通过检查它的脚部，判断前面一个块的起始位置和状态，这个脚部总是在距当前块开始位置一个字的距离。



9.9.12 综合：实现一个简单的分配器

9.9.13 显式空闲链表

9.9.14 分离的空闲链表


## 9.10 垃圾收集

9.10.2 Mark & Sweep 垃圾收集器



## !! 9.11 C 程序中常见的与内存有关的错误


### 9.11.1 间接引用坏指针

使用 scanf 从 stdin 读一个整数到一个变量。
正确的方法
`scanf("%d", %val);`

错误的方法
`scanf("%d", val);`


### 9.11.2 读未初始化的内存

虽然 bss 内存位置（诸如未初始化的全局 C 变量）总是被加载器初始化为零，
但是对于==堆内存==却并不是这样的。
一个常见的==错误==就是==假设堆内存被初始化为零==：

```C
int *matvec(int **A, int *x, int n)
{
  int i, j;
  int *y = (int *) malloc(n * sizeof(int));

  for (i..)
    for (j..)
      y[i] += A[i][j] * x[j];
}
```

正确的方法是 显式设置为0， 或 calloc。



### 9.11.3 允许栈缓冲区溢出

如果一个程序不检查输入串的大小就写入栈中的目标缓冲区，那么这个程序就会有缓冲区溢出错误(buffer overflow bug)


```C
void buf_overflow()
{
  char buf[64];
  gets(buf);
  return;
}
```
gets 函数复制一个任意长度的串到缓冲区

我们必须使用 fgets 函数，这个函数限制了输入串的大小


### 9.11.4 假设指针和它们指向的对象是相同大小的

```C
int **makeArray1(int n, int m)
{
  int i;
  int **A = (int **) malloc(n * sizeof(int));  // ---error---

  for (i = 0; i < n; ++i)
    A[i] = (int *) malloc(m * sizeof(int));
  
  return A;
}
```

这里的目的是创建一个由 n 个指针组成的数组，每个指针都指向一个包含 m 个 int 的数组。
然而，因为程序员在第 5 行将 sizeof(int*)写成了 sizeof(int) 代码实际上创建
的是一个 int 的数组。

这是 在远处起作用(action at distance) 的一个阴险的示例，这类“在远处起作用”是与内存有关的编程错误的典型情况。


### 9.11.5 造成错位错误

错位(off-by-one)错误是另一种很常见的造成覆盖错误的来源

```C
int **makeArray2(int n, int m)
{
  int i;
  int **A = (int **) malloc(n * sizeof(int *));

  for (int i = 0; i <= n; ++i)    // == n
    A[i] = (int *) malloc(m * sizeof(int));
  
  return A;
}
```

试图初始化这个数组的 n+1 个元素，在这个过程中覆盖了 A数组后面的某个内存位置。


### 9.11.6 引用指针，而不是它所指向的对象

如果不太注意 C 操作符的优先级和结合性，我们就会错误地操作指针，而不是指针所指向的对象。

`*size--`     指针--， 取值
`(*size)--`   取值， 值--



### 9.11.7 误解指针运算

另一种常见的错误是忘记了指针的算术操作是以它们指向的对象的大小为单位来进行的，而这种大小单位并不一定是字节。

```C
while (*p && *p != val)
  p += sizeof(int);   // 应该是 p++
```


### 9.11.8 引用不存在的变量

```C
int *stackref()
{
  int val;
  return &val;
}
```
P 仍然指向一个合法的内存地址，但是它已经不再指向一个合法的变量了


### 9.11.9 引用空闲堆块中的数据

free 后，又 * 反引用


### 9.11.10 引起内存泄漏

内存泄漏是缓慢、隐性的杀手

```C
void leak(int n)
{
  int *x = (int *) malloc(n * sizeof(int));

  return;
}
```







# 第三部分 程序间的交互和通信

# ch10 系统级IO

输人操作是从 I/O 设备复制数据到 主存，
输出操作是从 主存 复制数据到 I/O 设备。



## 10.1 Unix I/O

linux文件就是 m个字节的序列
所有的 IO设备 (如 网络，磁盘，终端) 都被 模型化为 文件，所有的 输入输出 都被当做 对 相应文件的读写 来执行。

linux内核引出一个 简单，低级的 应用接口，称为 Unix IO，这使得 所有输入输出 都能 以一种 统一 且一致的方式 进行

- 打开文件
  app 要求 内核打开相应文件。 内核返回一个 小的 非负整数，称为 描述符。app的所有操作 都需要 标识 一个 描述符。 内核中记录了这个描述符的 所有信息。app只需要知道这个描述符即可
- linux shell 创建的 每个进程 都默认打开3个文件，
  标准输入(fd为0)，标准输出(1)，标准错误(2)。头文件 unistd.h 中常量 STDIN_FILNO，STDOUT_FILENO，STDERR_FILENO，可以用来 代替 显式的 0,1,2
- 改变当前的文件位置，
  对于每个打开的文件，内核保持一个文件位置k，初始为0。这个文件位置就是 从文件开头起始的 字节偏移量。
  app 可以使用 seek， 显式 设置文件的当前位置为 k
- 读写文件
  读操作就是 从文件 复制 n 个字节到内存，从当前文件位置 k 开始，然后将 k 增加到 k+n。 
  给定一个大小为 m 字节的文件， 当k >= m 时，执行 读操作 会触发 EOF (end of file)。
  写操作 就是 从内存复制 n 个字节到 文件，从 当前文件位置 k 开始，然后 更新 k
- 关闭文件
  app完成对文件的访问后，通知内核 关闭这个文件。
  内核释放 打开文件时 创建的 数据结构，并将 这个 fd 恢复到 可用的描述符池。
  进程终止(无论什么原因)时，内核会关闭所有打开的文件 并释放它们的内存资源。


## 10.2 文件

每个 linux 文件都有一个类型(type) 来表明它在系统中的角色
- 普通文件
  包含任意数据。app常常要区分 文件文件 和 二进制文件。 对于内核而言，这2者没有区别。
- 目录
  包含一组 链接 的文件，每个链接 都将一个 文件名 映射到 一个文件，这个文件可能是 另一个目录。
  每个目录至少有2个条目：`.`, `..`
- 套接字socket
  用于与另一个进程 进行跨网络通信的文件

其他文件类型，如 命名通道 named pipe，符号链接 symbolic link，字符和块设备 character and block device， 不在本书的范畴

每个进程都有一个 当前工作目录 来确定目录结构中的 当前位置

路径名 分为 绝对路径名(以 / 开始)，相对路径名(以 文件名 开始)


## 10.3 打开和关闭文件

```C
#include <sys/types.h>
#include <sys/stat.h>
#include <fcntl.h>

int open(char *filename, int flags, mode_t mode);
// 文件描述符 or -1
```

open 函数将 filename 装换为 一个文件描述符，并返回 文件描述符 数字。
返回的 fd 是 进程中 最小可用的 fd

flags指明 如何访问 文件
- O_RDONLY
- O_WRONLY
- O_RDWR

flags 还可以 通过 `或` 来 提供一些提示
- O_CREAT， 文件不存在，就创建一个新的
- O_TRUNC， 文件已存在，就截断它(。应该就是 从头写入)
- O_APPEND， 追加

`fd = open("foo.txt", O_WRONLY | O_APPEND, 0);`

mode参数指定了 ==新== 文件的 访问权限位。

每个进程都有 umask ， 它是通过 umask 函数 来设置的。
当进程通过 带 某个 mode 参数的 open 函数 创建 一个 新 文件时，文件的访问权限被设置为 `mode & ~umask`


```C
#include <unistd.h>
int close(int fd);
```


## 10.4 读和写文件

```C
#include <unistd.h>

ssize_t read(int fd, void *buf, size_t n);  // 返回读取的字节数 或 -1 // 返回0 表示 EOF
ssize_t write(int fd, const void *buf, size_t); // 返回写入的字节数 或 -1

// lseek 函数可以修改 文件位置
```

size_t 是 unsigned long
ssize_t 是 long， 即 signed size_t


## 10.5 用 RIO包健壮地读写

robust IO

有2类不同的函数
- 无缓冲的输入输出函数
- 带缓冲的输入函数


无缓冲的输入输出函数
```C
#include "csapp.h"
// 这是他自己的库。 跳
```

。。还有个 apue.h (和本书无关) unix环境高级编程的
。。不过 工程中 肯定有更合适的包的。 虽然我不知道在哪，但 估计 boost 肯定有。
。。有2个 boost.iostreams, boost.io
。还看到 Boost.Circular Buffer

。。10.11 ：  标准 IO 函数提供了 Unix I/O 函数的一个更加完整的带缓冲的替代品


## 10.6 读取文件元数据

```C
#include <unistd.h>
#include <sys/stat.h>

int stat(const char *filename, struct stat *buf);
int fstat(int fd, struct stat *buf);
// 0 or -1
```

```C
struct stat {
  dev_t st_dev; // device
  ino_t st_ino; // inode
  mode_t st_mode; // protection and file type
  nlink_t st_nlink; // hard link 数量
  uid_t st_uid; // owner 的 user id
  gid_t st_gid; // owner 的 group id
  dev_t st_rdev; // device tpye
  off_t st_size // total size, in bytes
  unsigned long st_blksize; // block size for filesystem IO
  unsigned long st_blocks; // number of blocks allocated
  time_t st_atime; // last access
  time_t st_mtime; // last modify
  time_t st_ctime; // last change
};
```

sys/stat.h 中提供了 宏 来判断 st_mode 的文件类型
S_ISREF(mode)
S_ISDIR(mode)
S_ISDOCK(mode)



## 10.7 读取目录内容


。。 不理解，这个是 dfs 还是什么。 主要是 下一个目录项。 很奇怪的说法。
。。应该是 这样的， 上面说过 目录 也是一个文件，里面保存了 文件名与链接， 所以 这里的 readdir 就是在 遍历 这个 目录中的 文件。  不涉及 更深层的。 
。而且 dirent 保存了 string 的 filename，  这个 需要自己 open ，然后判断 这个 filename 对应了什么东西。
。。DIR 是一个 流， 所以可以当做 iterator。 所以 readdir 返回 + 移动指针


```C
#include <sys/types.h>
#include <dirent.h>

DIR *opendir(const char *name);
// 指针 或 NULL
```

```C
#include <dirent.h>

struct dirent *readdir(DIR *dirp);
// 指针 或 NULL

struct dirent {
  ino_t d_ino; // inode number
  char d_name[256]; // filename
};
```

每次调用 readdir ，返回指向 流dirp 下一个 目录项的指针。

```C
#include <dirent.h>

int closedir(DIR *dirp);
```



## !! 10.8 共享文件

有多种方式 共享linux文件。

除非你很清楚内核是如何表示打开的文件，否则文件共享的概念相当难懂。
内核用三个相关的数据结构来表示打开的文件：
- 描述符表，descriptor table
  每个进程有 它独立的 描述符表
  表项 由 进程打开的 fd 来索引，指向 文件表 中的一个表项
- 文件表，file table
  所有进程共享。
  打开的文件集合。
  每个表项 包含 当前的 文件位置，引用计数，指向 v-node 项 的 指针。
  关闭 fd ，会减少 引用计数， 为0时，内核 删除 这个文件表项。
- v-node表，v-node table
  所有进程共享
  每个表项 包含了 stat 结构中的 大部分信息，包括 st_mode, st_size
  。。不会被删除


这是一种典型的情况，没有共享文件，并且每个描述符对应一个不同的文件。


![f27d90588a51d221940358afb6806739.png](../_resources/f27d90588a51d221940358afb6806739.png)


---


多个描述符也可以通过 不同的文件表 表项来 引用 同一个文件

如果以同一个 filename 调用 函数两次，就会发生这种情况

![24eb7dfd1a0b9f425136f4f565430d9e.png](../_resources/24eb7dfd1a0b9f425136f4f565430d9e.png)


---

父子进程共享相同的打开文件表集合，因此共享相同的文件位置。
一个很重要的结果就是，在内核删除相应文件表表项之前，父子进程必须都关闭了它们的描述符

![3a27a8d3016ab31ef3bb939cfb359c06.png](../_resources/3a27a8d3016ab31ef3bb939cfb359c06.png)



## 10.9 I/O 重定向

`ls > foo.txt`

将在 11.5节中看到，当一个web服务器 代表客户端 运行 CGI程序时， 它就执行 一种 相似类型的 重定向

一种实现 IO 重定向的方式是 dup2

```C
#include <unistd.h>

int dup2(int oldfd, int newfd);
// 非负描述符 或 -1
```

dup2 复制 oldfd 到 newfd， 覆盖 newfd 之前的内容。 如果 newfd 已经打开，dup2 会在 复制 之前 关闭 newfd。

`dup2(4, 1)`

。。把4复制给1， 不是 1给4。 
。所以是 关闭1 (可能导致 refcnt 为0，内核删除 文件表项 )， 1指向4

![19f4fdf65447d2ac32282f81fb85c171.png](../_resources/19f4fdf65447d2ac32282f81fb85c171.png)




## 10.10 标准 I/O

C 语言定义了一组高级输人输出函数，称为标准 I/O 库，为程序员提供了 Unix I/O 的较髙级别的替代

这个库(libc)提供了
- 打开和关闭文件的函数(fopen 和 fclose)
- 读和写字节的函数(fread 和 fwrite)
- 读和写字符串的函数(fgets 和 fputs)以及
- 复杂的格式化的 I/O 函数(scanf 和 printf)

标准 I/O 库将一个打开的文件模型化为一个流。
对于程序员而言，一个流就是一个指向 ==FILE== 类型的结构的指针

每个 ANSIC 程序开始时都有三个打开的流 stdin,stdout和 stderr分别对应于标准输人、标准输出和标准错误：
```C
#include <stdio.h>

extern FILE *stdin;
extern FILE *stdout;
extern FILE *stderr;
```

类型为 FILE 的流是对文件描述符和流缓冲区的抽象。
流缓冲区的目的和 RIO 读缓冲区的一样：就是使开销较高的 Linux I/O 系统调用的数量尽可能得小。


## !!! 10.11 综合：我该使用哪些 I/O 函数？

![a5381b340574352e9335796980fe3de3.png](../_resources/a5381b340574352e9335796980fe3de3.png)

标准 IO函数提供了 Unix I/O 函数的一个更加完整的带缓冲的替代品


在你的程序中该使用这些函数中的哪一个呢？下面是一些基本的指导原则
1. C的标准IO是首选，大多数C程序员 在整个职业生涯中 只使用 标准IO
2. 不要使用 scanf 来读 二进制文件。 scanf 是 专门用来 读取 文本文件的
3. socket IO 使用 RIO。 标准IO 用于 网络IO时，会出现一些问题。

标准IO流，某种意义上而言 是 全双工的，因为 程序能在 一个流上 执行 输入 和输出。
但是，对流的限制 和 对 socket的限制，有时 会互相冲突：
- 在输出函数 之后的 输入函数
  如果中间没有 fflush,fseek,fsetpos,rewind，输入函数不能跟在 一个输出函数之后。
- 在输入函数 之后的 输出函数
  如果中间没有 fseek,fsetpos,rewind，输出函数不能 跟在 输入函数之后，除非 该输入函数 遇到了 EOF

这些限制 给 网络应用 带来了 问题， 因为 对socket 使用 lseek 是 非法的。
- 对于第一个限制，可以使用 fflush
- 对于第二个限制，只能 对 一个打开的socket fd 打开2个 流，分别用来 读，写

```C
FILE *fpin, *fpout;
fpin = fdopen(sockfd, "r");
fpout = fdopen(sockfd, "w");
```
这种方法需要 在 2个 流上 都 调用 fclose 才能释放 每个流相关的 内存资源。
这些操作中的每一个都试图关闭同一个底层的套接字描述符，所以第二个 close 操作就会==失败==。
对顺序的程序来说，这并不是问题，但是在一个线程化的程序中关闭一个已经关闭了的描述符是会导致灾难的

因此，我们建议你在网络套接字上不要使用标准 I/O 函数来进行输人和输出


# ch11 网络编程

所有的网络app 都基于相同的基本编程模型，有相似的整体逻辑结构，依赖相同的编程接口。

网络app 依赖于很多 之前的概念，如 进程，信号，字节顺序，内存映射，动态内存分配。


## 11.1 客户端-服务器编程模型

每个网络应用都是基于 客户端-服务器模型的。
。。B-S呢。。B也可以算是C

一个应用是由一个服务器进程 和 一个或多个客户端进程 组成。
服务器管理某种资源，通过操作这种资源 来为 它的客户端 提供某种服务。

C-S 模型中 基本操作 是 事务， 一个 C-S事务由以下4步组成
- 客户端需要服务时，向服务器发送一个 请求，发起一个事务。
- 服务器收到请求后，解释它，并以适当的方式操作它的资源。
- 服务器给 客户端发送一个响应，并等待下一个请求
- 客户端收到 响应，并处理它

认识到客户端和服务器是进程，而不是常提到的机器或者主机，这是很重要的

## 11.2 网络

客户端和服务器通常运行在不同的主机上，并且通过计算机网络的硬件和软件资源来通信。

对主机而言，网络只是又一种 I/O 设备，是数据源和数据接收方

一个插到 I/O 总线扩展槽的适配器提供了到网络的物理接口。
从网络上接收到的数据从适配器经过 I/O 和内存总线复制到内存，通常是通过 ==DMA== 传送。
相似地，数据也能从内存复制到网络

![518a5f204ea7f892092c4da48245cdff.png](../_resources/518a5f204ea7f892092c4da48245cdff.png)


---

下图展示了主机和路由器如何使用互联网络协议在不兼容的局域网间传送数据的一个示例

1. 运行在主机A上的客户端进行一个系统调用，从客户端的虚拟地址空间复制数据到内核缓冲区中。
2. 主机A上的协议软件 在数据前 附加 互联网包头 和 LAN1 帧头，创建一个 LAN1 帧。互联网络包头寻址到互联网络主机B。LAN1 帧头寻址到路由器。然后它传送此帧到适配器。
3. LAN1 适配器复制该帧到网络上。
4. 当此帧到达路由器时，路由器的 LAN1 适配器从电缆上读取它，并把它传送到协议软件。
5. 路由器从互联网络包头中提取出目的互联网络地址，并用它作为路由表的索引，确定向哪里转发这个包。在本例中是 LAN2 路由器剥落旧的 LAN1 的帧头，加上寻址到主机 B 的新的 LAN2 帧头，并把得到的帧传送到适配器。
6. 路由器的 LAN2 适配器复制该帧到网络上
7. 当此帧到达主机 B 时，它的适配器从电缆上读到此帧，并将它传送到协议软件
8. 最后，主机 B 上的协议软件剥落包头和帧头。当服务器进行一个读取这些数据的系统调用时，协议软件最终将得到的数据复制到服务器的虚拟地址空间。

![201dd0078741e7cebbadc2577885647e.png](../_resources/201dd0078741e7cebbadc2577885647e.png)


## 11.3 全球 IP 因特网

TCP/IP

### 11.3.1 IP 地址

```C
struct in_addr {
  uint32_t s_addr; // 网络字节序(大端) 的地址
};
```

在网络和主机字节顺序间实现转换。
```C
#include <arpa/inet.h>

uint32_t htonl(uint32_t hostlong);
uint16_t htons(uint16_t hostshort);

uint32_t ntohl(uint32_t netlong);
uint16_t ntohs(uint16_t netshort);
// n: network, h: host
```

```shell
> hostname -i
123.123.123.123
```

ip地址， uint32_t 和 字符串之间的转换
```C
#include <arpa/inet.h>

int inet_pton(AF_INET, const char *src, void *dst);
// 成功返回1，src非法返回0，出错-1

const char *inet_ntop(AF_INET, const void *src, char *dst, socklen_t size);
// 字符串 或 NULL
```


### 11.3.2 因特网域名

```shell
nslookup localhost

hostname

nslookup whaleshark.ics.cs.cmu.edu

nslookup cs.mit.edu

nslookup eecs.mit.edu

nslookup www.twitter.com

nslookup twitter.com
```

### 11.3.3 因特网连接

—个连接是由它两端的套接字地址唯一确定的。这对套接字地址叫做==套接字对==(socket pair), 由下列元组来表示：
`(cliaddr:cliport, servaddr:servport)`




## !!! 11.4 套接字接口

套接字接口(socket interface)是一组函数，它们和 Unix I/O 函数结合起来，用以创建网络应用。

![621b353436e2f83e6f4320265b60ae53.png](../_resources/621b353436e2f83e6f4320265b60ae53.png)


### 11.4.1 套接字地址结构

```C
// 大端序
// IP socket address
struct sockaddr_in {
  uint16_t sin_family;  // 协议簇(总是 AF_INET)
  uint16_t sin_port; // 大端序的 端口
  struct in_addr sin_addr; // 大端序的 IP地址
  unsigned char sin_zero[8]; // pad of sizeof(struct sockaddr)
};

// generic socket address (for connect, bind, accept)
struct sockaddr {
  uint16_t sa_family; // 协议簇
  char sa_data[14]; // address data
};
```

`_in` 是 internet 的缩写。

connect,bind 和 accept 函数要求一个指向与协议相关的套接字地址结构的指针。
套接字接口的设计者面临的问题是，如何定义这些函数，使之能接受各种类型的套接字地址结构。
今天我们可以使用通用的 void* 指针，但是那时在 C 中并不存在这种类型的指针。
解决办法是定义套接字函数要求一个指向通用 sockaddr 结构的指针，然后要求应用程序将与协议特定的结构的指针强制转换成这个通用结构


### 11.4.2 socket 函数

使用socket函数 创建 socket descriptor

```C
#include <sys/types.h>
#include <sys/socket.h>

int socket(int domain, int type, int protocol);
// 非负描述符 或 -1
```

如果想要使套接字成为连接的一个端点，就用如下硬编码的参数来调用 socket 函数
`clientfd = socket(AF_INET, SOCK_STREAM, 0);`

AF_INET 表明正在使用 32位 IP地址， SOCK_STREAM表示 这个套接字 是 连接的一个端点。
不过最好的方法是 getaddrinfo 函数 来自动生成 这些参数，这样代码 就与 协议无关了。

socket返回的 clientfd 描述符 仅是部分打开的，还不能用于读写。
如何完成打开 套接字的工作，取决于 我们是 客户端还是 服务器。


### 11.4.3 connect 函数

客户端通过调用 connect 函数 来建立 和服务器的 连接

```C
#include <sys/socket.h>

int connect(int clientfd, const struct sockaddr *addr, socklen_t addrlen);
// 成功0， 出错-1
```

connect 函数 试图 与 套接字地址为 addr 的服务器 建立一个 因特网连接，其中 addrlen 是 sizeof(sockaddr_in)。 

connect 函数会阻塞，一直到 连接成功建立 或 发生错误。

如果成功， clientfd 可以开始读写，并且得到的 连接 是由 套接字对
`(x:y, addr.sin_addr:addr.sin_port)` 描述的
x是客户端的 IP地址， y表示 临时端口。

对于socket，最好的方法是 用 getaddrinfo 来为 connect 提供参数

### 11.4.4 bind函数

bind,listen,accept，服务器使用它们 来和 客户端建立连接

```C
#include <sys/socket.h>

int bind(int sockfd, const struct sockaddr *addr, socklen_t addrlen);
```

bind 告诉内核 将 addr 中的 服务器套接字地址 和套接字描述符 sockfd 联系起来。参数 addrlen 就是 sizeof(sockaddr_in)。
对于 socket 和 connect，最好的方法是 用 getaddrinfo 来为 bind 提供参数


### !!! 11.4.5 listen 函数

客户端是主动发起请求的 ==主动==实体
服务器是等待来自客户端的连接请求的 被动实体

默认情况下，内核会认为 socket 函数创建的 描述符 对应于 ==主动==套接字，它存在于 一个 连接的客户端。
服务器调用listen 函数 告诉内核，描述符 是被 服务器使用，而不是客户端。

```C
#include <sys/socket.h>

int listen(int sockfd, int backlog);
```

listen 将 sockfd 从 主动套接字 转换为 监听套接字 ， 该套接字可以 接收 来自 客户端的 连接请求。
==backlog== 暗示 内核 在 开始 拒绝 连接请求前， 队列中要排队的 未完成的 连接请求的数量。 backlog 的确切含义 需要对 TCP/IP 有一定的理解，这超出了我们讨论的范围。 通常会设置为一个==较大值，比如 1024==。


### 11.4.6 accept函数

服务器通过 accept 来等待 来自客户端的连接请求

```C
#include <sys/socket.h>

int accept(int listenfd, struct sockaddr *addr, int *addrlen);
// 非负连接描述符 或 -1
```

等待 来自客户端的连接请求到达侦听描述符 listenfd，然后在 ==addr 中填写 客户端的== 套接字地址，并返回 一个 已连接描述符(connected descriptor)， 这个描述符 用来 通过Unix IO 与客户端通信

。。accept 默认阻塞， 可以设置为 非阻塞



### !! 11.4.7 主机和服务的转换

Linux 提供了一些强大的函数(称为 ==getaddrinfo 和 getnameinfo==)实现二进制套接字地址结构和主机名、主机地址、服务名和端口号的字符串表示之间的相互转化。
当和套接字接口一起使用时，这些函数能使我们编写独立于任何特定版本的 IP 协议的网络程序

getaddrinfo 将主机名，主机地址，服务名，端口号 的==字符串==表示 ==转成== 套接字地址==结构==。
它是 已废弃的 gethostbyname, getservbyname 的替代品

这个函数时可重入的(12.7.2)，适用于任何协议

```C
#include <sys/types.h>
#include <sys/socket.h>
#include <netdb.h>

int getaddrinfo(const char *host, const char *service, const struct addrinfo *hints, struct addrinfo **result);
// 成功0，错误 非0

void freeaddrinfo(struct addrinfo *result);

const char *gai_strerror(int errcode);
```

给定 host 和 service，getaddrinfo 返回 result, result 指向 addrinfo结构的链表，每个结构 指向 一个 对应与 host 和 service 的套接字地址结构

![1a515a128cf6aa3996ca07193c58f64b.png](../_resources/1a515a128cf6aa3996ca07193c58f64b.png)


在客户端调用 getaddrinfo 之后，会遍历这个列表，==依次尝试==每个套接字地址，直到调用 socket 的 connect 成功，建立起连接。
。。这个依次尝试 是 谁做的？ 系统 还是 程序员？
。。程序员，就是 IPv4, IPv6, 多个网卡，127.0.0.1， 192.168.1.123，这种，有好多种，所以 会返回 列表。 需要自己遍历， 哪个能成功，就 用哪个。
。不需要自己 生成 addrinfo。
。。而且 我们操作的是 socket descriptor ，底层是 什么，并不关心。 但是这个会 绑到 不需要的 网卡/地址(127.0.0.1) 上吗？

类似地，服务器会尝试遍历列表中的每个套接字地址，直到调用 socket 和 bind 成功， 描述符 会被绑定到 一个合法的 套接字地址。

host 可以是 域名，也可以是 数字地址(127.0.0.1)
service 可以是 服务名(http)， 也可以是 十进制端口号。
如果不想把 主机名转换成 地址，可以把 host 设置为 NULL， 对service来说也是一样。 但是必须指定 2者中的 一个。

可选参数 hints 是一个 addrinfo 结构， 可以对 getaddrinfo 的返回的 套接字地址 列表 进行更好的 控制。 hints 只能设置 ai_family, ai_socktype, ai_protocol, ai_flags。 其他必须设置为 0 或 NULL。

getaddrinfo 默认返回 IPv4， IPv6 套接字地址， ai_family 设置为 AF_INET 会将列表限制为 IPv4， AF_INET6 限制为 IPv5

对于 host 关联的 每个地址， getaddrinfo 默认 最多返回 3个 addrinfo 结构，每个 的 ai_socktype 不同，一个是 连接，一个是 数据报，一个是 原始套接字。 ai_socktype 设置为 SOCK_STREAM 将列表限制为 每个地址 最多一个 addrinfo，该结构的套接字地址 可以作为 连接的一个端点。

ai_flags 字段是一个 位掩码，可以把各种值用 或 组合。一些有用的值：
- AI_ADDRCONFIG，如果在使用连接，就推荐这个标志。它要求只有当本地主机被配置为 IPv4 时，getaddrinfo 返回 IPv4 地址。对 IPv6 也是类似 。。。 什么？
- AI_CANONNAME，如果设置，就告诉 getaddrinfo 将列表的 第一个 addrinfo 的 ai_canonname 字段设置为 host 的名字
- AI_NUMERICSERV，强制参数 service 为端口号
- AI_PASSIVE，告诉getaddrinfo，返回的 套接字地址 可能用作 监听套接字，这周给你情况下 参数 host 应该是 NULL。


```C
struct addrinfo {
  int ai_flags;
  int ai_family;
  int ai_socktype;
  int ai_protocol;
  char *ai_canonname;
  size_t ai_addrlen;
  struct sockaddr *ai_addr;
  struct addrinfo *ai_next;
};
```
getaddrinfo 会 填写每个字段， 除了 ai_flags。



---

getnameinfo
和 getaddrinfo 想法，将一个 套接字地址结构 转为 主机和服务名
是 已启用的 gethostbyaddr, getservbyport 的替代品
可重入的，协议无关的

```C
#include <sys/socket.h>
#include <netdb.h>

int getnameinfo(const struct sockaddr *sa, socklen_t salen, char *host, size_t hostlen, char *service, size_t servlen, int flags);
```


### 11.4.8 套接字接口的辅助函数

。。csapp.h 的

`int open_clientfd(char *hostname, char *port)`

调用 getaddrinfo
然后遍历该列表，依次尝试列表中的每个条目，直到调用 socket 和 connect 成功。
如果 connect 失败，在尝试下一个条目之前，要小心地关闭套接字描述符。
如果 connect 成功，我们会释放列表内存，并把套接字描述符返回给客户端，客户端可以立即开始用Unix I/O 与服务器通信了。

所有的代码都与任何 版本的 IP 无关。
socket 和 connect 的参数都是用getaddrinfo 自动产生的，这使得我们的代码干净可移植。


`int open_listenfd(char *port);`


11.4.9 echo 客户端和服务器的示

csapp 的


## 11.5 Web 服务器

11.5.1 Web 基础

web客户端 和 服务器 之间的交互 用的是 一个 基于文本的应用级协议，叫做 HTTP。


### 11.5.2 Web 内容

对于 Web 客户端和服务器而言，内容是与一个 MIME(Multipurpose Internet Mail Extensions 多用途的网际邮件扩充协议)类型相关的字节序列。

Web 服务器以两种不同的方式向客户端提供内容
- 取一个磁盘==文件==，将它的内容返回给 客户端， 磁盘内容称为 静态内容，返回文件的过程将 服务静态内容
- 运行一个可执行==文件==，将它的输出 返回给客户端。 动态内容。


每条由 Web 服务器返回的内容都是和它管理的某个==文件==相关联的。这些文件中的每一个都有一个唯一的名字，叫做 URL (Universal Resource Locator, 通用资源定位符)。

服务器如何解释 URL后缀，有几点需要理解
- 没有标准的规则 用来 确定URL 指向的内容 是 静态还是 动态
- 后缀中 最开始的 / 不表示linux 的根目录。表示的是 被请求内容类型的 主目录
- 最小的URL后缀是 /，所有服务器都将其扩展为 某个默认主页，如 /index.html


### 11.5.3 HTTP事务

因为 HTTP 是基于在因特网连接上传送的文本行的，我们可以使用 Linux 的 TELNET 程序来和因特网上的任何 Web 服务器执行事务。

telnet 发出 HTTP 请求
`method URI version`

HTTP响应
`version statud-code status-message`


```text
telnet www.aol.com 80   // 。。登录

GET / HTTP/1.1      // 。。 请求

HTTP/1.0 200 OK   // 。。响应
```

### 11.5.4 服务动态内容

如果我们停下来考虑一下，一个服务器是如何向客户端提供动态内容的，就会发现一些问题。
例如，
- 客户端如何将程序参数传递给服务器？
- 服务器如何将这些参数传递给它所创建的子进程？
- 服务器如何将子进程生成内容所需要的其他信息传递给子进程？
- 子进程将它的输出发送到哪里？

一个称为 CGI (Common Gateway Interface, 通用网关接口) 的实际标准的出现解决了这些问题。

。。cgi 基本已经淘汰了。
。。跳



# ch12 并发编程

应用级并发 在下面的常见也是很有用的
- 访问慢速IO设备
- 与人交互
- 通过推迟工作以降低延迟
- 服务多个网络客户端
- 在多核机器上并行计算

现代OS 提供了 3种基本的 构造并发程序的方法
- 进程。
  每个逻辑控制流 都是一个进程，进程有独立的虚拟地址空间，要和其他 流 通信，必须使用某种显式的 进程间通信(IPC) 机制
- IO多路复用。
  app在一个进程的上下文中 显式地 调度它们自己的逻辑流。逻辑流被模型化为 状态机，数据到达 fd 后，主程序显式地 从一个状态转为 另一个状态。因为 程序是一个单独的进程，所以所有的流都共享同一个地址空间
- 线程。
  运行在一个单一进程上下文中的逻辑流，由内核进行调度。你可以把 线程看出是其他2种方式的混合体，像进程流一样 由内核进行调度，向IO多路复用流一样共享一个虚拟地址空间



## 12.1 基于进程的并发编程

并发 最简单的方式就是 用进程。
fork,exec,waitpid

构造 并发服务器的自然方法就是，在父进程中接收 客户端连接请求，然后创建一个 新的子进程 来为 每个新客户端提供服务。

1. 服务器正在监听一个监听描述符
2. 客户端发送连接请求
3. 服务器接收请求，并返回一个 已连接描述符
4. 在接收请求之后，服务器派生 一个 子进程，这个子进程 获得 服务器描述符表 的完整副本。 子进程关闭 它的副本中的 监听描述符， 父进程关闭 它的 已连接描述符。

因为 父子进程的 已连接描述符 都指向 同一个 文件表项，所以 父进程 关闭 它的 已连接描述符副本 至关重要。否则 永远不会释放 已连接描述符的 文件表条目。


### 12.1.1 基于进程的并发服务器

有几点重要内容需要说明
1. 服务器会运行很长时间，所以我们必须包括一个 SIGCHLD 处理程序，来回收 僵死 子进程 的资源。 由于 SIGCHLD 不排队，所以 必须回收 多个僵死子进程。
2. 父子进程必须关闭 它们各自的 connfd 副本。
3. 由于套接字的文件表表项中的 引用计数，直到父子进程的 connfd 都关闭了，到客户端的连接才终止

。。代码跳， csapp


### 12.1.2 进程的优劣

父子进程 共享文件表，不共享 用户地址空间。

进程有独立的 地址空间 既是优点也是 缺点。
优点，不会覆盖 其他进程的 虚拟内存。
缺点，独立的地址空间 使得 进程共享状态 变得更加困难； 基于进程 的速度 往往比较慢，因为 进程控制，IPC 的开销很高。



### 12.2 基于 I/O 多路复用的并发编程

加入要编写一个 echo 服务器，它也能对 用户从 标准输入 输入的交互命令做出响应。
这种情况下，服务器必须 响应 2个独立的 IO事件
- 网络客户端发起的 连接请求
- 用户在键盘上 输入的命令行

先等待哪个事件？

一种解决方法是 IO多路复用
基本思路就是使用 select 函数，==要求 内核挂起进程，只有在 一个或多个 IO事件发生后，才将 控制返回给 app==

多种场景：
- 当集合 {2,5} 中任意描述符准备好 读时 返回
- 当集合 {1,3,5} 中任意描述符准备好 写时 返回
- 如果在等待 IO事件 已等待 123.12 秒，就超时

select 是一个复杂的函数，我们只讨论第一种场景

```C
#include <sys/select.h>

// int select(int n, fd_set *fdset, NULL, NULL, NULL);
int select(int max_fd, fd_set *readset, fd_set *writeset, fs_set *exceptset, struct timeval *timeout);

FD_ZERO(fs_set *fdset);   // clear all bit
FD_CLR(int fd, fd_set *fdset); // clear bit fd
FD_SET(int fd, fd_set *fdset); // tuen on bit fd
FS_ISSET(int fd, fd_set *fdset); // is bit fd on ?
```

select 函数处理类型为 fd_set 的集合， 也叫做 描述符集合。
逻辑上，我们将 描述符集合看出一个 大小 n 的位向量。
每个位 bk 对应 一个描述符 k

针对我们的目的，select 函数有两个输入：一个称为读集合的描述符集合(fdset)和该读集合的基数(n)(实际上是任何描述符集合的最大基数)。 
select 函数会一直阻塞，直到读集合中至少有一个描述符准备好可以读。

select 有一个副作用， 它修改 参数 fdset 指向的 fs_set， 指明读集合的一个子集。 称为 ready set， 这个集合 有 读集合中 准备好可以读了的 描述符 组成。
由于这个副作用，我们必须在 每次调用 select 是 都 更新 读集合。

返回值 指明了 ready set 的 基数。


### 12.2.1 基于 I/O 多路复用的并发事件驱动服务器

I/O 多路复用可以用做并发事件驱动(event-driven)程序的基础

借助select 检测 输入事件的发生。

。。代码

### 12.2.2 I/O 多路复用技术的优劣

优点
- 比基于进程的设计 给了程序员更多的 对程序行为的 控制
- 基于IO多路复用的事件驱动服务器是运行在 单一进程上下文中的，因此，每个逻辑流都能访问该进程的 全部地址空间。 这使得 在流之间 共享数据 变得很容易。
- 单进程还有一个优点，调试简单。
- 事件驱动设计 常常比 基于进程的设计 要高效得多。因为它们不需要 进程上下文切换 来调度新的流。

缺点
- 编码复杂，事件驱动的并发echo 需要的代码 比 基于进程服务器 多3倍， 并且 随着 并发粒度的减小，复杂性还会上升。
- 不能充分利用 多核处理器


## !!! 12.3 基于线程的并发编程

之前，第一种方法，每个流 单独的进程。每个进程有 私有的地址空间，使得 流之间共享数据很难。
第二种方法，创建自己的逻辑流，利用 IO多路复用 来显式调度流。因为只有一个进程，所有的流共享整个地址空间。
本节介绍第三种，基于线程，它是这2种方法的混合

线程就是运行在 进程上下文中的 逻辑流。

现代OS 允许我们编写 一个进程中 同时运行多个 线程的 程序。
线程由内核自动调度。每个线程都有它自己的==线程上下文==，包括
- 线程id
- 栈
- 栈指针
- 程序计数器PC
- 通用目的寄存器
- 条件码

所有运行在一个进程中的线程 共享该进程的 整个虚拟地址空间。

基于线程的逻辑流 结合了 基于进程 和 基于IO多路复用的 流的 特性。
- 同进程一样，线程 由 内核自动调度，并且 内核 通过 一个 整数ID 来识别 线程。
- 同基于IO多路复用的流一样，多个线程运行在单一进程的上下文中，因此共享这个进程虚拟地址空间的所有内容，包括它的==代码，数据，堆，共享库，打开的文件。==


### 12.3.1 线程执行模型

每个进程开始生命周期时都是单一线程，这个线程称为主线程(main thread).
在某一时刻，主线程 创建一个 对等线程(peer thread), 从这个时间点开始，两个线程就并发地运行


在一些重要的方面，线程执行是不同于进程的。
因为一个线程的上下文要比一个进程的上下文小得多，线程的上下文切换要比进程的上下文切换快得多。
另一个不同就是线程不像进程那样，不是按照严格的父子层次来组织的。和一个进程相关的线程组成一个对等(线程)池，独立于其他线程创建的线程。


### 12.3.2 Posix 线程

Posix 线程(Pthreads)是在 C 程序中处理线程的一个标准接口

Pthreads 定义了大约 60 个函数，允许程序创建、杀死和回收线程，与对等线程安全地共享数据，还可以通知对等线程系统状态的变化。


### 12.3.3 创建线程

```C
#include <pthread.h>
typedef void *(func)(void *);

int pthread_create(pthread_t *tid, pthread_attr_t *attr, func *f, void *arg);
// 成功0，出错非0
```

pthreacLcreate 函数创建一个新的线程，并带着一个输入变量 arg。
在新线程的上下文中运行线程例程 f。
attr 用于改变 新线程的 默认属性(超出本书范围，所以本书中总是NULL)

tid 是新线程的 ID

新线程可以通过 `pthread_self` 来获得 它自己的 线程ID
```C
#include <pthread.h>

pthread_t pthread_self(void);
```

### 12.3.4 终止线程

线程通过以下方式来终止
- 顶层的线程 返回时，线程会 隐式终止
- 通过 pthread_exit 函数， 显式终止。 如果主线程调用 pthread_exit，它会等待 所有 其他对等线程终止，然后再终止 主线程 和 整个进程。
- 某个对等线程调用 Linux 的 exit函数，该函数 会终止 进程 以及 该进程所有 的线程。
- 另一个对等线程 通过 当前线程的ID 作为参数 调用 pthread_cancel 来终止 当前线程

```C
#include <pthread.h>

void pthread_exit(void *thread_return);
```

```C
#include <pthread.h>

int pthread_cancel(pthread_t tid);
```


### 12.3.5 回收已终止线程的资源

等待其他线程终止

```C
#include <pthread.h>

int pthread_join(pthread_t tid, void **thread_return);
```
pthreadjoin 函数会阻塞，直到线程 tid 终止
将线程例程返回的通用(void*)指针赋值为 thread_return 指向的位置，然后回收已终止线程占用的所有内存资源。
。。thread_return 里有什么东西？ 回收 是程序员 手动回收？

pthread_join 函数只能等待一个指定的线程终止。没有办法让 pthread_join 等待任意一个线程终止

。。所以 C++的thread1.join()， 是 本线程 等待 thread1 终止。  本现场 和 thread1 的 线程ID 都是 确定的。


### 12.3.6 分离线程

任何一个时间点，线程 是 可结合的(joinable)，或 分离的(detached)。
一个可结合的线程 可以被其他线程 收回 和杀死。 在被其他线程回收之前，它的内存资源(如 栈) 是==不释放的==。
一个分离的线程 不能被 其他线程 回收 或杀死。 它的内存资源 在它 终止时 由 系统==自动释放==

默认情况下，线程 是 可结合的。
为了避免内存泄漏，每个可结合线程 都应该要么被 其他线程 显示回收，要么 通过 pthread_detach 函数 被分离

```C
#include <pthread.h>

int pthread_detach(pthread_t tid);
```

pthread_detach 函数分离可结合线程 tid。
线程能够通过以 pthread_self()为参数的 pthread_detac.h 调用来分离它们自己。
。。可以把别人 设置为 detach。。



### 12.3.7 初始化线程

pthread_once 函数允许你初始化与线程例程相关的状态

```C
#include <pthread.h>

pthread_once_t once_control = PTHREAD_ONCE_INIT;

int pthread_once(pthread_once_t *once_control, void (*init_routine)(void));
```

once_control 变量是一个==全局或者静态==变量，总是被初始化为 PTHREAD_ONCE_INIT。
当你第一次用参数 once_control 调用 pthread_once 时，它调用 init_routine。
后续 再以 once_control 为参数 调用 pthread_once， 不会做任何事情。

无论何时，当你需要动态初始化多个线程共享的全局变量时， pthread_once 函数是很有用的。

。。所以 这个 pthread_once 是什么时候调用的？ 看 once_control ，那么 全局 只能调用一次，所以 是 main 调用的？ 但是 不同的 thread 应该可能有不同的 状态啊。
。。最开始的 那段 "初始化与线程例程相关的状态" 是错的。 
。。baidu：用于初始化那些在多线程环境中只应进行一次的操作



### 12.3.8 基于线程的并发服务器

主线程不断地等待连接请求，然后创建一个对等线程处理该请求

第一个问题是当我们调用 pthread_create 时，如何将已连接描述符传递给对等线程。
最明显的方法就是传递一个指向这个描述符的指针，就像下面这样

```C
connfd = accept(listenfd, (SA *) &clientaddr, &clientlen);
pthread_create(&tid, NULL, thread_fun, &connfd);
```

然后 让对等线程 间接 引用这个指针，并赋值给 一个局部变量
```C
void *thread(void *vargp) {
  int connfd = *((int *) varpg);
  // ...
}
```

然而， 这样可能会出错，因为 它在 对等线程 的赋值语句 和 主线程的 accept 语句间 引入了 ==竞争==
。。确实， connfd 是 父线程的，  子线程读取的话， 可能 读取到 被下一次 accept 的值。
必须为 connfd 设置 它自己的 动态内存块
```C
connfdp = malloc(sizeof(int));
*connfdp = accept(xx,xx,xx,xx);
pthread_create(&tid, NULL, thread_fun, connfdp);
```

另一个问题是 在线程 中避免 内存泄漏。 既然不显示回收 线程，就必须分离每个线程，使得 它们在 终止时 内存资源能被回收。 我们也需要 小心释放 主线程分配的 内存块

```C
void *thread_fun(void *vargp)
{
  int connfd = *((int *) varpg);
  pthread_detach(pthread_self());
  free(vargp);    // .
  echo(connfd);
  close(connfd);
  return NULL;
}
```

## 12.4 多线程程序中的共享变量

线程很有吸引力的一个方面是多个线程很容易共享相同的程序变量

然而，这种共享也是很棘手的。为了编写正确的多线程程序，我们必须对所谓的共享以及它是如何工作的有很清楚的了解


为了理解 C 程序中的一个变量是否是共享的，有一些基本的问题要解答：
- 线程的基础内存模型是什么？
- 根据这个模型，变量实例是如何映射到内存的？
- 最后，有多少线程引用这些实例？

一个变量是共享的，当且仅当多个线程引用这个变量的某个实例。


### 12.4.1 线程内存模型

一组并发线程 运行在 一个进程的上下文中，每个线程都有它自己独立的 线程上下文，包括 ==线程ID，栈，栈指针，程序计数器，条件码，通用目的寄存器==
每个线程 和其他线程 共享 进程上下文的 剩余部分，这包括 整个用户虚拟地址空间，它是由 ==只读文本(代码), 读/写数据，堆，所有的共享库代码 和 数据区域== 组成的。 线程 也共享 相同的 ==打开文件的 集合==。



### 12.4.2 将变量映射到内存

多线程的 C 程序中变量根据它们的存储类型被映射到虚拟内存：
- 全局变量
  全局变量 是定义在 函数之外的变量
  运行时，虚拟内存的 读/写区域 只包含 每个全局变量的 一个实例，任何线程都可以引用。
- 本地自动变量
  定义在 函数内部，且 没有 static 的变量
  每个线程的 栈 包含 它的 所有 本地自动变量的实例。 (。栈是独立的)
- 本地静态变量
  定义在 函数内部，且 static 的变量
  和全局变量一样，虚拟内存的 读写区域 只包含 本地静态变量的 一个实例


### 12.4.3 共享变量

我们说一个变量是共享的，当且仅当它的一个实例被一个以上的线程引用




## 12.5 用信号量同步线程

共享变量是十分方便，但是它们也引入了同步错误(synchronization error)的可能性

一般而言，你没有办法预测操作 系统是否将为 你的线程选择一个正确的顺序。


### 12.5.1 进度图

多处理器的工作方式是进度图==不能==解释的。

进度图(progress graph)将 n 个并发线程的执行模型化为一条 n 维笛卡儿空间中的轨迹线。
每条轴 k 对应于线程k 的进度。每个点(I1,I2,I3..In) 代表线程 k 已经完成了指令 Ik这一状态。
图的原点对应于没有任何线程完成一条指令的初始状态。

两个临界区的交集形成的状态空间区域称为不安全区(unsafe region)


绕开不安全区的轨迹线叫做安全轨迹线(safe trajectory)

接触到任何不安全区的轨迹线就叫做不安全轨迹线(unsafe trajectory)

![da1902bdf0f280d4c1aafdf8998d7f07.png](../_resources/da1902bdf0f280d4c1aafdf8998d7f07.png)



### !! 12.5.2 信号量

Edsger Dijkstra 并发编程领域的先锋人物，提出了一种经典的解决同步不同执行线程问题的方法，这种方法是基于一种叫做信号量(semaphore)的特殊类型变量。

信号量s 是具有 非负整数值的 全局变量，只能有 2种特殊的操作，P 和 V
- P(s)
  如果 s 非0，那么 减1，并 立即返回。
  如果 s 是0，那么就挂起 线程，直到 s变成非0， V操作会唤醒这个线程。
- V(s)
  将s 加1。
  如果有 任何线程 阻塞在 P操作，那么 V操作 会唤醒这些线程中的 一个。


P中测试 和 减1 是不可分割的，
V中 加1 也是不可分割的(加载，+1，存储)。


Posix 标准定义了许多操作信号量的函数。

```C
#include <semaphore.h>

int sem_init(sem_t *sem, 0, unsigned int value);
int sem_wait(sem_t *sem); // P(s)
int sem_post(sem_t *sem); // V(s)
```

P 和 V 来源 于荷兰语单词 Proberen(测试)和 Verhogen(增加)。


### 12.5.3 使用信号量来实现互斥

保护共享变量的信号量叫做==二元信号量==(binary semaphore), 因为它的值总是 0 或者 1。
以提供互斥为目的的二元信号量常常也称为==互斥锁==(mutex)。
在一个互斥锁上执行 P 操作称为对互斥锁加锁。类似地，执行 V 操作称为对互斥锁解锁。

一个被用作一组可用资源的计数器的信号量被称为==计数信号量==。


![8aaa4005023623d0c615a6fc49f5dbba.png](../_resources/8aaa4005023623d0c615a6fc49f5dbba.png)



### 12.5.4 利用信号量来调度共享资源


生产者-消费者问题


读者-写者问题
。。读写锁



### 12.5.5 综合：基于预线程化的并发服务器




## 12.6 使用线程提高并行性

同步开销巨大，要尽可能避免。如果无可避免，必须要用尽可能多的有用计算弥补这个开销。

强扩展
绝对加速比
相对加速比

弱扩展


## 12.7 其他并发问题

一旦我们要求同步对共享数据的访问，那么事情就变得复杂得多了。


### 12.7.1 线程安全

必须小心地编写那些具有称为线程安全性(thread safety)属性的函数
一个函数被称为线程安全的(thread-safe), 当且仅当被多个并发线程反复地调用时，它会一直产生正确的结果

四个(不相交的)线程 不安全 函数类：
- 不保护共享变量的函数
- 保持跨越多个调用的状态的函数
- 返回指向静态变量的指针的函数
- 调用线程不安全的函数的函数


### 12.7.2 可重入性

有一类重要的线程安全函数，叫做可重入函数(reentrant function), 其特点在于它们具有这样一种属性：当它们被多个线程调用时，不会引用任何共享数据

可重入函数通常要比不可重入的线程安全的函数高效一些，因为它们不需要同步操作。

。。线程安全，一种是 天生就线程安全的， 一种是 需要 mutex 才线程安全的。  可重入 应该就是 前一种。



### 12.7.3 在线程化的程序中使用已存在的库函数

大多数 Linux 函数，包括定义在标准 C 库中的函数(例如 malloc，free，realloc，printf和 scanf)都是线程安全的，只有一小部分是例外。

下图列出了常见的例外。
![71670b32a072c2f78d280392336b92f6.png](../_resources/71670b32a072c2f78d280392336b92f6.png)



### 12.7.4 竞争

当一个程序的正确性依赖于一个线程要在另一个线程到达y 点之前到达它的控制流中的 x点时，就会发生竞争(race)。

多线程的程序必须对任何可行的轨迹线都正确工作。





### 12.7.5 死锁

一组线程被阻塞了，等待一个永远也不会为真的条件

![67cbbcafb57b07fdfb124c95fbf503f9.png](../_resources/67cbbcafb57b07fdfb124c95fbf503f9.png)


- 使用 P，V 操作顺序不当，以至于 2个 信号量的禁止区域重叠
- 重叠的禁止区域引起了一组称为 死锁区域的 状态
- 死锁 无法预测，无法复现。


避免死锁
- 互斥锁加锁顺序规则，给定所有互斥操作的一个全序，如果每个线程都是以一种顺序获得互斥锁并以相反的顺序释放，那么这个程序就是无死锁的。

---

2024-05-20 20:03

---















