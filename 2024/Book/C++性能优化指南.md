
2025-02-15 11:31

[[toc]]

---



# ch1 优化概述

本书中 一些优化技术 对C++特别有效，但是可能对其他编程语言无效。

本书关注的是如何对体现 C++ 设计最佳实践的正确代码进行优化，使之不仅可以体现出优秀的 C++ 设计，而且还可以在绝大多数计算机上更快速、更低耗地运行

本书不会涉及编写汇编语言子程序、计算时钟周期，或者学习英特尔最新的芯片可以同时分发多少个指令

要想优化成功，需要先观察程序行为，然后基于这些程序行为作出可测试的推测，再进行==实验==得出测试结果

即使是经验丰富的团队在时间充裕的情况下编写出的代码，运行速度通常也可以提高 30% 至 100%。
我见过对在时间很紧张的情况下或是欠缺经验的团队编写出的代码进行优化后，程序运行速度提高了 3 至 10 倍的情况。
不过，通过微调代码让程序的运行速度提升 10 多倍几乎是不可能的。但是选择一种==更好的算法或是数据结构==，则可以将程序的某个特性的性能从慢到无法忍受提升至可发布的状态。

常识可能是性能改善最大的敌人

基数排序 `O(n * logn / logr)`， `r` 是 基数 或用于排序的 桶的数量

对于随机分布的数据，flashsort O(n)

。。timsort 最快， O(n) - O(nlogn),  flashsort会降低到 O(n^2)


## 1.5 C++代码优化策略总结

C++的一些热点代码是性能惯犯，包括 函数调用，内存分配，循环。

下面是 改善C++性能的方法的总结，也是本书的大纲。这些优化建议非常简单。

### 用好的编译器 并用好编译器

如果打算为代码做最后一点性能提升，那么可以尝试下 各种不同的编译器，看看是否有一种编译器可以生成更快的可执行文件。

编译器必须支持 C++11，因为11有 右值引用，move

用好编译器: 编译器的各种选项。 

### 使用更好的算法

大部分优化手段 只能使得程序 性能呈现 线性提升。
许多优化手段可以将 性能提升 30% - 100%， 如果足够幸运，可以提升3倍。

但是除非找到 更高效的算法，否则 要让 性能呈现 指数增长 是不太可能的。

对于代码优化而言，学习和使用 ==查找和排序==的 最优算法 才是 康庄大道。
一个低效的查找或排序算法的代码可以 完全 占用一个程序的运行时间。

修改代码可以将程序运行时间 减少一半。
但替换一种更优的算法，数据集越大，可以缩小的 运行时间就越多。

5.5 讲解几个改善程序性能的重要技巧: 预计算(将计算移动到 链接，编译，设计时)， 延迟计算， 缓存。

### 使用更好的库

C++编译器提供的 标准C++模板库 和 运行时库 是 可维护的，全面的，健壮的。 我们无序对这些库 进行调优。

对于进行性能优化的 开发人员来说， 掌握标准C++模板库 是必须的技能。
ch9: 查找和排序算法
ch10: 容器类的最优惯用法
ch11: IO
ch12: 并发
ch13: 内存管理

一些开源库实现了 非常重要的功能，如内存管理(13.2)

Boost Project 和 Google Code 公开了很多可以使用的库，一些用于 IO，窗口，处理字符串(4.3.3), 并发(12.5)

还可以开发 适合自己项目的库，通过 放松标准库中 某些安全性和健壮性约束 来换取更快的 运行速度。 ch8

### 减少内存分配和复制

减少对内存管理器的调用是一种非常有效的优化手段，以至于开发人员只要掌握了这一个技巧就可以变为成功的性能优化人员

ch4: 字符串处理的优化
ch6: 如何减少 动态内存分配的性能开销

减少复制 也是一种优化方式。

### 移除计算

绝大多数程序都会有一个或多个主要的事件处理循环和一个或多个处理字符的函数。找出并优化这些循环几乎总是可以让性能优化硕果累累
ch7 如何找到频繁执行的语句
ch3 如何确定程序中哪部分会频繁执行

达夫设备，稍微了解，不要推广  ch7

### 使用更好的数据结构

ch10: 探索C++标准库 提供的数据结构的性能，行为和权衡。
ch9: 使用标准库算法 实现 简单矢量 和 C数据的表数据结构

### 提高并发


### 优化内存管理

ch13 展示一些改善内存管理效率的技术


# ch2 影响优化的计算机行为

内存被分为 word， word由若干 bit组成。

## 2.1 C++所相信的计算机谎言

- C++程序只需要表现得好像 语句是顺序执行的。C++编译器和 计算机 只需要确保每次计算的含义都不变，就可以 改变执行顺序 使得程序更快
- 从C++11开始，C++不再认为只有一个执行地址。C++标准库支持 启动和终止线程 以及同步线程间的内存访问。
- 某些内存地址可能是 寄存器。 这些设备的值 可能在 同一个线程 对该地址的 2次连续 读的间隔中 发生变化。 C++中使用 volatile 定义这些地址。volatile 要求 编译器在每次使用该变量时 都获取它的 最新副本，而不用 通过该 将变量的值 保存在一个 寄存器中 并复用它 来优化程序。 另外，也可以声明指向 volatile 内存的指针
- C++11 提供了 `std::atomic<>`， 可以让 内存在一段 短暂的时间内 表现得 仿佛是 字节的 简单线性存储一样，这样可以远离现代CPU的复杂性，包括 多线程执行，多层高速缓存等。


## 2.2 计算机的真相

只有最简单的 微处理器 和 某些具有悠久历史的 大型机 才直接和 C++模型相符。


### 2.2.1 内存很慢

处理器访问内存的开销 远大于 其他开销 (包括 执行的开销)

冯 诺依曼瓶颈

### 2.2.2 内存访问 并非以字节为单位

计算机 通过一次性获得更大块的数据 来 补偿 缓慢的内存速度

最小型的处理器可以每次从 主内存获得 1字节
桌面级处理器 获得 64字节
一些超级计算机 和 图形处理器 可以获得 更多。

当C++获取一个 多字节类型的数据时，构成数据的 字节可能跨越2个物理内存word，这种被称为==非对齐的内存访问==。 一次访问需要消耗2倍的时间。
编译器会帮助我们 对齐结构体。
但是 结构体的 洞 包含了无用的数据， 在定义结构体时 要注意 字段的 顺序。


### 2.2.3 某些内存访问会比其他的更慢

为了进一步补偿 主内存的缓慢速度，许多计算机中都有 高速缓存。

高速缓存 会让 执行的执行时间 变得难以确定。

读取一个不在 高速缓存中的 字节 会导致 许多临近的字节 也被 缓存起来。
所以 访问内存中 相邻位置的字节 要比 访问远离的字节 更快。

### 大端小端

int: 0x01234567 存储在 1000-1003 中。
如果小端: 1000中存储 0x01， 1003中存储0x67

问题出在 数据 由一台计算机 通过网络传输给 另一台计算机时。

字节序(大端/小端) 是C++不能指定 int中bit的存储方式  或 设置 联合体中 一个字段 如何影响其他字段的 原因之一。

### 内存容量是有限的

为了维持内存容量无限的假象，OS 可以将 没有放入物理内存中的数据 作为文件存储在 磁盘上。 称为 虚拟内存。

但是从 磁盘读取 很慢。

### 指令执行缓慢

微处理器 被设计为 执行指令的速度 和 从内存中获取指令 一样快。

桌面级CPU 执行指令的速度 比 从主内存获取指令快很多倍。

多数时候，执行单元 等待 高速缓存的数据。 这意味着 ==内存访问 决定了 计算开销==

处理器中包含一条 指令流水线，它支持并发执行指令。
指令 在流水线中 被解码，获取参数，执行计算，最后保存处理结果。
CPU性能越强，这条流水线 越复杂。 它会将指令分解为 若干个阶段，这样就可以 并发处理更多指令。

如果指令B 需要指令A的结果，那么在A处理完之前 B是无法执行的，这导致 指令执行过程中发生 ==流水线停滞==，因为2个指令无法完全同时执行。 
如果A需要从  内存中取值，那么 流水线停滞 时间会特别长。
流水线停滞 会拖累 高性能CPU


### 计算机难以作决定

执行完一条指令后，CPU会获取 下一条指令 继续执行。
多数情况下，下一条指令 已经在 高速缓存中了。

但 控制指令不同， 跳转指令 或跳转子例程指令 会将 执行地址变为一个新的值，在执行跳转指令一段时间后，执行地址才会被更新。
新的执行地址的内存word 可能不在 高速缓存中。
会发生 流水线停滞


### 程序执行中的 多个流

OS中 后台也有很多程序在运行。

当许多程序一起开始运行的时候，会 竞争 内存和磁盘。

切换上下文 (将一个线程 切换为 同一个程序的 另外一个线程) 的成本很高

当OS 从一个程序 切换为 另一个程序时，这个过程的 开销 更大。
- 所有脏的高速缓存页面 都必须被刷新到 物理内存中
- 所有CPU 寄存器 都要被保存
- 内存管理器中的 "物理地址到虚拟地址" 的内存页寄存器也要被保存
- 新线程的 "物理地址到虚拟地址" 的 内存页寄存器和 处理器寄存器 被载入
- 高速缓存是 空白的， 因此在填满之前，还有一段 缓慢 且 激烈竞争的 内存初始化阶段

执行单元 写值时， 先进入 高速缓存， 最终写入主内存。
计算机有多个执行单元时，一个单元 可能要很久之后才能看到 另一个执行单元 所写的值 被反映到 主内存中。
执行单元看到的 值 很可能是旧的，所以必须 使用 特殊的同步指令 来确保 不同线程看到的 内存中的值 是一样的
访问线程间的共享数据 比访问 非共享数据 要慢得多


### 调用OS的开销是昂贵的


---

2.3 C++也会说谎

并非所有语句的性能开销都相同

语句并非按照顺序执行


# ch3 测量性能

2种测量性能的工具软件: 分析器 和 计时器软件 (profiler, software timer)


## 3.1 优化思路

### 必须测量性能

优秀的优化人员会
- 他们做出的预测都是 可预测的，而且他们会记录下预测
- 他们保留代码变更记录
- 他们使用可以使用的 最优秀的工具进行测量
- 他们会保留实验结果的详细笔记

### 优化器是王牌猎人

修改代码可能引入bug，所以 只有能 显著提升性能时 才值得修改代码。

1% 不值得

20% 会消除所有反对

### 90/10 规则

一个程序 花费 90%的时间 执行 10%的代码。

某些代码块是 热点

优化一小部分代码已经足够了。

识别出 10%的热点代码 是值得花费时间的。


### 阿姆达尔定律

`St = 1 / (1-P + P/Sp)`
其中
St 是优化导致 程序整体性能提升的比率
P 是被优化部分的运行时间 占 原来程序整体运行时间的 比例
Sp 是被优化部分 P的性能改善的比率

假设 一个程序 运行时间是 100s，花费80秒调用函数f， 现在进行修改使得 f 提升30%，那么对 程序整体提升有多大?
St = 1 / (1-0.8 + 0.8/1.3) = 1/(0.2+0.62) = 1.22

整体提升了 22%


## 3.2 进行实验

- 为什么这些代码是热的?
- 为什么某个函数 出现在 分析器的 最差性能列表的 最前面?
  - 是因为这个函数 浪费了很多时间在冗余处理上吗?
  - 有其他更快的方法进行相同的计算吗?
  - 这个函数 使用了 紧缺的计算机资源吗?
  - 函数已经足够快，但是被调用次数太多，还有优化的余地吗?

修改后的代码可能 由于某些原因运行更快，但和你的修改无关
- 测量运行时间时，计算机正在接收邮件 或 检查 Java是否有版本更新
- 重新编译之前，有同事使用了 性能更高的库
- 你的修改使得运行更快，但是 逻辑不正确。

优秀的科学家是怀疑论者。 如果没有出现 期待的 实验结果，或 实验结果太好了， 那么怀疑论者 会再进行一次实验 或 质疑他的假设， 或检查 是否由bug


---

3.2.1 记实验笔记

可重复性。

可对比性。


---

### 3.2.2 测量基准性能并设定目标

优化工作受 2个数字主导: 优化前的性能基准测量值 和 性能目标值。

启动时间
用户按下回车 到 程序进入主输入处理循环所需的时间。
通常是 进入main() 到 进入主循环的时间 来得到 启动时间

退出时间
用户点击关闭图标 或 输入退出命令 直至 程序实际完全退出所经过的时间。
通常 测量 主窗口收到关闭命令 到 程序退出main 的时间 来的到 退出时间。

响应时间
执行一个命令的平均时间 或最长时间。
- 低于0.1s，用户在直接控制。 如果响应时间低于0.1s，用户会感觉他们在直接控制用户界面。
- 0.1-1s，用户在控制命令。 短暂的延迟 会被用户理解为 计算机执行了一条命令 导致 UI发生变化
- 1-10s，计算机在控制。  用户满意度 急剧下降
- 高于10s，喝杯咖啡休息一下。

吞吐量
适合于 评估 批处理程序。


### 3.2.3 你只能改善你能够测量的


## 3.3 分析程序执行

profiler 是一个可以生成另外一个程序的 执行时间的 统计结果的程序
profiler 可以输出一份包含每个语句 或函数的 执行频度，每个函数的积累执行时间的报表。

许多编译器套件，如 window的 visual studio 和 linux的 GCC 都带有 profiler。

有几种方式 可以实现一个分析器。一种同时支持 window 和 linux的方法如下:
1. 设置一个特殊的 可以分析程序中所有函数的 编译选项，重新编译， 让程序变为 可分析的状态。这涉及在 每个函数的开始 和结束处 添加一些额外的 汇编语言指令
2. 将可分析的程序链接到分析库上
3. 每次这个 可分析的程序运行时 都会在 磁盘上 生成一张分析表
4. 分析器读取分析表，然后 生成 可阅读的问题 或 图形报告

另一种分析方法
1. 将 优化前的程序 链接到 分析库上 使其变为 可分析状态。 分析库的例程 会 非常高的频率 中断程序的执行，记录 指令指针的值
2. 每次运行时 都会在磁盘上生成 分析表
3. 分析器读取分析表，然后生成 可阅读的文字 或图形报告

profiler的输出 有多种形式。
- 标记有 每行代码执行次数的 源代码清单
- 由 函数名 和 该函数被调用次数 组成的清单
- 记录每个函数的 累计执行时间 和 每个函数中进行的 函数调用的 函数清单

分析器的 消耗很小，只会导致 程序 降低几个百分点。

以个人经验来说，对 debug build 和 release build 的 分析结果 是一样的。
debug build 更容易分析，因为 它包含所有函数，包括内联函数。

windows的分析器 会进行额外的 对内存管理器函数的测试， 这会显著增加 某些函数的 开销。 设置一个环境变量 可以让 调试器不要使用 调试内存管理器: 控制面板-系统属性-高级系统设置-环境变量-系统变量，添加一个 `_NO_DEBUG_HEAP` 的变量 并设置为 1


分析器也有缺点
- 无法告诉你 有更高效的算法可以解决当前计算性能问题。 去优化一个低效的算法 只是浪费时间
- 对于执行许多不同任务的 程序，分析器无法给出明确的结果。 因此，想要找到最热点的函数，尽量一次仅优化一个任务。 但是，仅优化一个任务 不一定能改善程序的 整体性能。
- IO密集型 或 多线程程序，分析器的结果 可能包含 误导信息， 因为分析器减去了 系统调用的时间 和 等待事件的时间。


## 3.4 测量长时间运行的代码

如果只运行一个 计算密集型任务，那么分析器会自动告诉我们 程序中的 热点在哪里。
。。当年 CMS 如果用这个，应该很快就可以搞定吧。

如果程序做许多不同的处理，可能在分析器看来，没有一个函数是热点。
这种情况下，我们要测量程序 中各个部分的时间，然后尝试 减少 低效部分的运行时间

### 3.4.1 一些关于测量时间的知识

测量实验 必须能 应对 可变性

可变性分为2种:
- 随机的，对每次测量的影响都不同
- 系统的，对每次测量的影响都相似

衡量一次测量过程中的 可变性的 属性 被称为 精确性 precision 和 正确性 trueness， 这2种属性 合并为 准确性 accuracy

如果测量不受 随机可变性的影响，它就是 精确的。 即 反复测量，结果非常接近。   (。。但是这个结果可能是错误的，即 离正确结果有点远， 但是每次都是 这个方向 这么远)

如果测量不受 系统可变性的 影响，它就是正确的。 即可以反复测量，测量的结果 的 平均值接近实际值。

---

测量时间
要么测量 持续时间，要么测量 速率

---

测量分辨率

指 测量所呈现的单位的大小


---

3.4.2 用计算机测量时间

。。C++有 high_resolution_clock, 其他的(OS提供的时间) 没有什么意义了。

延迟
非确定性行为

---

3.4.3 克服测量障碍

别为小事烦恼
测量误差在 几个百分比， 就足够指引 我们进行 性能优化了。

测量相对性能
优化后代码的运行时间 与 优化前代码的运行时间的 比率 称为 相对性能
相对性能 抵消了 系统可变性。

通过测试模块测试 改善可重复性

根据指标优化性能
根据指标优化性能时可能遇到的一些问题
- 代码统计必须基于 大量事件 才有效
- 相比于 分析代码 和测量运行时间， 收集指标 需要 更完善的 基础设施。通常需要持久化的存储设备来存放统计数据。
- 统计 本身就有的 复杂性

通过多次迭代的平均值 来提高准确性

通过提高进程的优先级 来减少OS的 非确定性行为

非确定性行为 发生了就克服它

---

### 3.4.4 创建stopwatch类

使用 stopwatch类 来测量 程序中的 部分代码的 执行时间 并分析代码。


stopwatch 用到了 ==RAII==。 初始化时 默认开始计时， 出作用域，析构时 输出最终的计时结果。


```C++
template <typename T> 
class basic_stopwatch : T {
    typedef typename T BaseTimer;
public:
    // 创建一个秒表，开始计时一项程序活动（可选）
    explicit basic_stopwatch(bool start);
    explicit basic_stopwatch(char const* activity = "Stopwatch",
                             bool start=true);
    basic_stopwatch(std::ostream& log,
                    char const* activity="Stopwatch",
                    bool start=true);

    // 停止并销毁秒表
    ~basic_stopwatch();

    // 得到上一次计时时间（上一次停止时的时间）
    unsigned LapGet() const;

    // 判断：如果秒表正在运行，则返回true
    bool IsStarted() const;

    // 显示累计时间，一直运行，设置/返回上次计时时间
    unsigned Show(char const* event="show");

    // 启动（重启）秒表， 设置/返回上次计时时间
    unsigned Start(char const* event_namee="start");

    // 停止正在计时的秒表， 设置/返回上次计时时间
    unsigned Stop(char const* event_name="stop");

private:   //  成员变量
    char const*    m_activity;  // "activity"字符串
    unsigned       m_lap;       // 上次计时时间（上一次停止时的时间）
    std::ostream&  m_log;       // 用于记录事件的流
};
```

为了使性能最佳，成员函数将会被 内联展开。

stopwatch 的类型模板参数 T 的值的类是一个更加简单的计时器，它提供了依赖于操作系统和 C++ 标准


下面是 C++11 的 chrono
```C++
# include <chrono>
using namespace std::chrono;
class TimerBase {
public:
    // 清除计时器
    TimerBase() : m_start(system_clock::time_point::min()) { }

    // 清除计时器
    void Clear() {
        m_start = system_clock::time_point::min();
    }

    // 如果计时器正在计时，则返回true
    bool IsStarted() const {
        return (m_start.time_since_epoch() != system_clock::duration(0));
    }

    // 启动计时器
    void Start() {
        m_start = system_clock::now();
    }

    // 得到自计时开始后的毫秒值
    unsigned long GetMs() {
        if (IsStarted()) {
            system_clock::duration diff;
            diff = system_clock::now() - m_start;
            return (unsigned)(duration_cast<milliseconds>(diff).count());
        }
        return 0;
    }
    private:
        system_clock::time_point m_start;
};
```


使用 window和linux都有的 clock() 函数
```C++
class TimerBaseClock {
public:
    // 清除计时器
    TimerBaseClock()       { m_start = -1; }

    // 清除计时器
    void Clear()           { m_start = -1; }

    // 如果计时器正在计时，则返回true
    bool IsStarted() const { return (m_start != -1); }

    // 启动计时器
    void Start()           { m_start = clock(); }

    // 得到自计时开始后的毫秒值
    unsigned long GetMs() {
        clock_t now;
        if (IsStarted()) {
            now = clock();
            clock_t dt = (now - m_start);
            return (unsigned long)(dt * 1000 / CLOCKS_PER_SEC);
        }
        return 0;
    }
private:
    clock_t m_start;
};
```

window的 gettimeofday() 函数
```C++
//。。懒
```




### 3.4.5 使用测试套件测量热点函数

一旦通过分析器 或 运行时分析 找到一个 候选的 待优化函数， 一种简单的改善它的方法就是 构建一个 测试套件，在其中 ==多次调用==该函数。
这样可以将 该函数的 运行时间 增大为 一个可测量的值， 同时还可以 抵消 后台任务，上下文切换 等 带来的 对运行时间的 影响。

```C++
typedef unsigned counter_t;
counter_t const iterations = 10000;
    ...
{
    Stopwatch sw("function_to_be_timed()");
    for (counter_t i = 0; i < iterations; ++i) {
        result = function_to_be_timed();
    }
}
```


## 3.5 评估代码开销来找到热点代码

通过 分析器 和 测量运行时间 是找出 需要优化的代码的好方法。

但是 它们不能直接告诉你 哪个 具体的 C++语句可以优化。

开发人员下一步需要做的是，对找到的代码块中的 每条语句的 开销进行评估。 不需要太精确

### 3.5.1 评估独立的C++语句的开销

评估C++语句的开销的 有效的==规则==: 该语句对内存的读写次数

`a=b+c`，abc都是整数，b,c的值必须从 内存中读取，+后必须写入内存，所以 3次内存访问。
`r=*p+a[i]`，读取i，读取`a[i]`，读取p，读取*p，写入r， 所以5次访问。


### 3.5.2 评估循环的开销

评估嵌套循环中的 循环次数

```C++
for (int i=0; i<100; ++i) {
    for (int j=0; j<50; ++j) {
        fiddle(a[i][j]);
    }
}
```
这里循环次数是 100*50 = 5000

上面的循环很简答，但是
- 有时 代码编写非常糟糕，需要花费很大力气才可以看清 嵌套循环的 轮廓
- 循环中 调用方法A， 方法A内部 又循环调用另一个方法B
- 内存循环可能被嵌入在 标准库函数中，特别是 处理字符串 或字符的 IO函数。


评估 循环次数为 变量的 循环的 开销
需要大致估算下 变量的 平均值


识别出 隐式循环
响应事件的程序 (如 windows UI程序) 在最外层 都会有一个 隐式循环。

识别假循环
不是所有的 while，do-while 都是 循环语句。

```C++
do {
    if (!operation1())
        break;
    if (!operation2(x,y,z))
        break;
} while(0);   // while(false)
```
这种惯用法 就是将 几条语句 打包为 C风格的 宏


## 3.6 其他找出热点代码的方法

如果熟悉代码的话，凭直觉 推测。 不建议。



# ch4 优化字符串的使用: 案例研究

C++的 std::string 是 C++标准库中 使用最广泛的特性之一。

## 4.1 为什么字符串很麻烦

字符串概念上很简单，但是 要高效实现 很难。
C++标准 对std::string 有一定的要求。

字符串的某些行为会增加它们的开销

字符串需要大量的复制操作

### 字符串是动态分配的

std::string 之所以用起来方便，是因为它们会为了保存内容 而自动增长 (即 ==动态分配==)。 C的库函数(strcat,strcpy等) 工作于固定长度的 字符数组上。

动态分配 耗时耗力， 因此无论如何，字符串都是 性能优化热点。

当string变量超出 定义范围 或 被赋予一个新的值后， 动态分配的 存储空间会被立刻释放。

string内部的 字符缓冲区的大小是 固定的。任何使得 string变长的操作，都可能 使字符串的长度 超出它内部的 缓冲区的大小。 此时，操作 会从 内存管理器中 获取一块新的 缓冲区，并将字符串复制到 新的缓冲区中。

string 向 内存管理器 申请的 字符缓冲区的 大小 比 string存储的字符数 大。 有些实现 是 申请 实际字符数的 2倍的 空间。

### 字符串就是值

string的行为 和 值一样。 可以将一个 新值 赋予 一个变量，但是 改变这个变量 并不会改变这个值。
就好像 每个字符串变量 都拥有一份 私有副本一样
```C++
std::string s1, s2;
s1 = "hot"; // s1是"hot"
s2 = s1; // s2是"hot"
s1[0] = 'n'; // s2仍然是"hot"，但s1变为了"not"
```

所以 string就是值，因此 string表达式 的结果也是值。
如果使用 `s1=s2+s3+s4`，那么 s2+s3 的结果 会存放到 新分配的 临时string中， +s4 后的结果 会保存到 另一个 临时string中。这个值 会取代 s1之前的 值。 然后 第一个临时string 和 s1之前的值 的 内存将被 释放，这会多次调用 内存管理器

### 字符串会进行大量复制

由于string的行为 与值类似， 所以 修改字符串 不能 改变 其他字符串的值。

但是 字符串 有 改变其内容的 操作， 因为这些操作的存在，每个字符串 变量 必须表现得 好像 它们拥有一份 私有副本一样。
实现这种行为最简单的方式 是 ==创建，复制，传递== string的时候 进行 复制。 但是这种方式 会使得 赋值，传参 的开销很大，变值函数和 非常量引用的 开销很小。

==写时复制(COW)== 是著名的 编程惯用法。 它可以让 对象 与 值具有同样的表现，但是会使得 复制的开销变得非常大。
在COW的 string中，动态分配的内存 可以在 字符串间==共享==。 每个string 都可以通过 ==引用计数== 知道 它们是否使用了 共享内存。 
当一个 字符串被 ==赋值==给另一个 字符串时，==只需要== 复制指针 以及增加 引用计数。
任何==改变==string值得操作 都会先 检查 是否只有一个指针 指向 该string的内存。如果 有多个string指向了该内存，所有的 变值操作 都会在 改变string值之前 先分配新的内存空间 并复制 字符串。

```
COWstring s1, s2;
s1 = "hot"; // s1是"hot"
s2 = s1;    // s2是"hot"（s1和s2指向相同的内存）
s1[0] = 'n';// s1会在改变它的内容之前将当前内存空间中的内容复制一份
            // s2仍然是"hot"，但s1变为了"not"
```

但 实际上，==COW不符合C++11标准==
COW 实现string，那么 赋值 传参 的开销很小。
但是一旦 string被共享， 非常量引用 和 任何变值操作 都需要 昂贵的 分配和 复制操作。 在并发代码中，COW的开销同样很大，COW的 引用计数 必须是 线程安全的。

。。string_view, span 算不算 手动COW

随着 C++11 的 ==右值引用，移动语义==， 使用它们可以 减轻复制的负担。
如果 函数的 形参是 右值ref， 当 实参是 右值表达式时， string可以进行 轻量级的 指针复制，从而==节省一次复制==操作。


## 4.2 第一次尝试优化字符串

假设下面的函数是 性能瓶颈
函数的功能时 从一个 由 ASCII字符组成的 字符串中 移除控制字符。

```C++
std::string remove_ctrl(std::string s) {
    std::string result;
    for (int i=0; i<s.length(); ++i) {
        if(s[i] >= 0x20)
            result = result + s[i];
    }
    return result;
}
```
。。按照之前所说，这里 每次 `+ s[i]` 都会生成一个 新的 string。
。。应该使用 append? 不， string没有办法 设置 capacity。 只能看capacity。 。。 有的 ==reserve==
。。所以应该 创建 长度 s.size() 的 result，或 result.resize(s.size())。 然后 双指针， 修改 result的 某个字符， 最后 resize到 指针的位置 ?  `result[i] = 'a'` 应该不会触发 复制吧。
。。当然可以 for一下，计算下 有多少 非控制字符，但是 有点太浪费了。
。。
。。md，有的，下面会 提到 ==reserve()==，来 预留空间

字符串连接运算符的开销是很大的。
它会调用内存管理器去构建一个新的临时字符串对象来保存连接后的字符串
对于由100个 非控制字符组成的 string，会导致  调用 100次 内存管理器 来==分配==内存， 100次 内存管理器 来 ==释放==内存

将 连接完的 值 赋给 result 时 可能还会分配额外的字符串，这取决于 string如何实现
- 如果 string是 COW的，那么 赋值运算符 会执行一次 高效的 指针复制 并增加 refCount
- 如果string是 非共享缓冲区方式 实现的，那么 赋值运算符 必须 复制 临时字符串的内容。
  - 如果实现是原生的，那么赋值运算符 还必须分配一块 新的缓冲区 用于 复制连接结果。这会导致 100次复制 和 100次额外的内存分配
- 如果编译器 实现了 右值ref，move，那么 连接表达式的结果是一个 右值，编译器可以 调用 result的 移动构造函数，无需复制构造函数。因此 会执行一次 高效的 指针复制


每次连接运算符 还需要 将 之前处理过的 所有字符 复制到 临时string中， 是 `O(n^2)`。

测试套件，平均每次调用 花费 24.8微秒， 这是基准值


### 4.2.1 使用+=避免临时字符串

。。`operator+=()`
。。复合赋值操作符

`result = result + s[i]` 变成 `result += s[i]`

每次调用花费 1.72 微秒。 提升 13倍。

这次改善源于 ==移除==了
- 所有 为了分配临时string对象 来保存 连接结果 而对内存管理器的 调用
- 相关的复制和删除临时字符串的操作。 
- 赋值时的 分配和复制操作 也可以被移除，不过这取决于 string的实现方式


### 4.2.2 通过预留空间减少内存的重新分配

4.2.1 优化后，方法依然会 执行一个 导致 result 变长的操作， 这意味着 result 被反复 复制到 一个更大的 内部动态缓冲区中。
正如之前讨论的，每次string的字符缓冲区溢出时，string的一种可能的实现方式 会 申请 2倍 内存空间。如果 string以这种方式实现，那么 100个字符 需要申请8次。

假设 字符串中 大多是 可打印字符，只有几个 需要被移除的 控制字符。那么 result 的最终长度 和 s 的长度 非常接近。
下面代码 通过 reserve() 成员函数 来预先分配足够的内存。
使用 reserve() 不仅==移除==了 字符串==缓冲区的重新分配==，还==改善==了 函数所读取的 ==数据的缓存局部性==

```C++
std::string result;
result.reserve(s.length());
// for () {}
```
。。第一次知道 还有 length。 看了cppreference， length 和 size是一起的，所以 完全相同。

每次耗时 1.47微秒，比 4.2.1 提高了 17%

### 4.2.3 消除对参数字符串的复制

方法被调用时，形参 会通过 复制构造函数 被初始化，这可能导致 复制操作。这取决于 string的实现方式
- 如果COW，那么 复制构造器，执行一次 高效的 指针复制 并增加 ref_count
- 如果 非共享缓存区， 那么 复制构造器必须 分配新的 缓冲区 并复制 实参的内容
- 如果编译器实现了C++11的 右值ref，move，而且 ==实参是 表达式==，那么 就调用 ==移动==构造器，执行一次 高效的 指针复制。 如果==实参是变量==，那么调用 构造器，导致一次 内存分配和复制。

由于方法中不会修改 s的值，所以 复制实参 毫无意义。
```C++
std::string remove_ctrl_ref_args(std::string const& s) {
    // ...
}
```

每次调用耗时 1.6 微秒，增加了 8% 的时间。

由于 引用是通过 指针实现的，所以 方法中每次调用s时，都需要 解引用。 推测 这些开销导致了 性能下降。


### 4.2.4 ==使用迭代器消除指针引用==

解决方法是 在string上使用迭代器。
string迭代器 是 指向 字符==缓冲区==的 简单指针。
与 在循环中 不使用迭代器相比，这样可以 节约 2次 解引用操作

```C++
std::string remove_ctrl_ref_args_it(std::string const& s) {
    std::string result;
    result.reserve(s.length());
    for (auto it=s.begin(),end=s.end(); it != end; ++it) {
        if (*it >= 0x20)
            result += *it;
    }
    return result;
}
```

每次调用 耗时 1.04微秒。


### 4.2.5 消除对返回的字符串的复制

```C++
void remove_ctrl_ref_result_it (
    std::string& result,
    std::string const& s)
{
    result.clear();
    result.reserve(s.length());
    for (auto it=s.begin(),end=s.end(); it != end; ++it) {
        if (*it >= 0x20)
            result += *it;
    }
}
```

1.02 微秒，快了 2%

但是这个方法容易被误用

下面会导致 foo 变成空字符串
```C++
std::string foo("this is a string");
remove_ctrl_ref_result_it(foo, foo);
```

### 4.2.6 使用==C风格==字符数组代替字符串

当程序有 ==极其严格的性能要求== 时， 不使用C++标准库，而是使用 C风格的字符串函数

比起std::string，C风格字符串函数 难以使用，但是 有显著的 性能提升。

```C++
void remove_ctrl_cstrings(char* destp, char const* srcp, size_t size) {
    for (size_t i=0; i<size; ++i) {
        if (srcp[i] >= 0x20)
            *destp++ = srcp[i];
    }
    *destp = 0;
}
```

==0.15微秒==， 比上一个版本 ==快了 6倍==， 比最初版本 快了 ==170倍==

。。真滴恐怖!!!

获得这种改善效果的 原因之一是 移除了 若干函数调用 及 改善了缓存局部性。

不过 ==优秀的缓存局部性 可能误导性能测量==。 通常 方法的2次调用 之间 还有其他操作，会 刷新缓存。 但是在 测试套件中 循环地 调用方法，指令和数据可能 驻留在 缓存中。


---

在性能优化时，要注意权衡简单性、安全性与所获得的性能提升效果。
相比 remove_ctrl() ，remove_ctrl_ref_result_it() 需要==改变函数签名==，这可能会==引入潜在的错误==。
remove_ctrl_cstrings() 的性能改善代价是==手动管理临时存储空间==。对于某些开发团队来说，这个==代价太大==了。

C++ 为开发人员提供了很多选择，从编写简单、安全但效率低下的代码，到编写高效但必须谨慎使用的代码


## 4.3 第二次尝试优化字符串

### 4.3.1 使用更好的算法

初始版本 一次复制一个字符。

```C++
std::string remove_ctrl_block(std::string s) {
    std::string result;
    for (size_t b=0, i=b, e=s.length(); b < e; b = i+1) {
        for (i=b; i<e; ++i) {
            if (s[i] < 0x20)
                break;
        }
        result = result + s.substr(b,i-b);
    }
    return result;
}
```

每次 2.91微秒， 比 初始版本 快 7倍。

这个函数 还可以 通过 operator+= 来优化。 优化后是 1.27 微秒

但是 substr() 依然会生成 临时字符串。
由于这个函数 将字符 添加到 result的末尾， 所以可以 重载 std::string 的 append() 来 复制 substring， 而 无需创建 临时string。

`result.append(s, b, i-b);`
每次耗时 0.65微秒。  比 迭代器的 1.02 更快。  比最初的版本 快了 36倍。

还可以 预留 result的 存储空间 和 移除参数复制， 每次耗时 0.55 微秒
还可以 移除返回值的复制， 每次 0.51 微秒
还可以使用 迭代器，每次 0.43微秒


---

另一种改善性能的方法是， std::string 的 ==erase()== 来移除 控制字符。

```C++
std::string remove_ctrl_erase(std::string s) {
    for (size_t i = 0; i < s.length（);)
        if (s[i] < 0x20)
            s.erase(i,1);
        else ++i;
    return s;
}
```

由于s 在变短，所以不会触发 内存分配。 除了 返回 值时 会发生 内存分配外，其他情况下 不会再发生 内存分配。

每次调用 耗时 0.81微秒， 比 初始版本快了 30倍。


### 4.3.2 使用更好的编译器

使用 VS2013 进行了同样的测试， VS2013 实现了move。 
。。之前是 VS2010

但是结果并不符合猜测。 在 debug模式下， 2013比 2010 快了 5%-15%。 但是 命令行运行 2013 慢了 5%-20%。

使用 VS2015RC ，更慢。

这可能与 容器类的 改变有关。

一个新版的 编译器 可能会改善性能，不过 需要 通过测试 验证，而不是 想当然。

### 4.3.3 使用更好的字符串库

Boost 字符串库

C++字符串工具包 StrTK

使用 std::stringstream 避免值语义

C++有多种string实现
- 模板化的，支持迭代器访问的，可变长度的 std::string
- 简单的，基于迭代器的 `std::vector<char>`
- 老式的，C风格的 以 `\0`结尾的 固定长度的 字符数组
- std::stringstream， stringstream 之于 字符串，就如同 std::ostream 之于 输出文件。 stringstream 以一种不同的方式 封装了 一块动态大小的 缓冲区 ( 事实上，通常就是一个 std::string)。

```C++
std::stringstream s;
for (int i=0; i<10; ++i) {
    s.clear();
    s << "The square of " << i << " is " << i*i << std::endl;
    log(s.str());
}
```

上面进行的优化:
- 由于 s 是实体，插入表达式 不会创建 临时字符串，因此不会发生 内存分配 和 复制操作
- s内部的 缓存将被复用， 第一次循环时，随着字符的添加，可能会重新分配 几次 缓冲区，但是 后续的迭代中，由于s的缓冲区已经够大了，所以不太可能 重新分配缓冲区。  如果将 s定义在 循环内部，则每次循环都要 分配一块空的缓冲区，而且 插入时，还会触发 重新分配缓冲区


如果 std::stringstream 是 std::string 实现的，那么它 的性能永远无法 超过 std::string。 优点是，可以放置 某些降低 程序性能的 编程实践。


---

==std::string_view==， 包含指向 字符串数据的 无主指针 和一个 表示字符串长度的 值， 所以它可以表示为 std::string 或 字面字符串的substr， 和 std::string的返回值的成员函数相比，它的 substring 和 trim 等操作更高效 。。。但是 没有trim() 啊。
string_view的主要问题是 指针是无主的，程序员必须保证 每个 string_view 的生命周期 不会比 它指向的 std::string的 生命周期 长。


---

`folly::fbstring`

folly是一个完整的 代码库，它被 facebook使用。

---

字符串类的工具包
http://johnpanzer.com/tsc_cuj/ToolboxOfStrings.html       。。还在

这篇2000年的文章 和代码 描述了一个 模板化的 字符串类型。

---

C++03 表达式模板
http://craighenderson.co.uk/papers/exptempl/      。。这个没了

2005年的一篇论文， 用于解决字符串连接问题的 模板代码。

表达式模板 重写了 +运算符。 这样可以创建 一个表示 2个字符串的连接 或 一个字符串 和一个字符串表达式 的连接的 中间类型。 当表达式模板 被赋给一个 字符串时，表达式模板 将内存分配 和 复制 推迟到 表达式结束， 只执行一次 内存分配。

---

Better String库
http://bstring.sourceforge.net/
。2015年最后更新。  https://github.com/websnarf/bstrlib

bstring 允许通过 相对一个字符串的 偏移量 和 长度 来组成一个 新的字符串。
在C++中有一个 称为 CBString 的 bstring库的 包装类。

---

rope

https://www.sgi.com/tech/stl/Rope.html  。进去后，跳了好几层，然后 要登录。。


---

Boost字符串

http://www.boost.org/doc/libs/1_60_0/doc/html/string_algo.html

https://www.boost.org/doc/libs/1_87_0/doc/html/string_algo.html

但是感觉没有修改过。因为 只有 2002-2004 有人。

它是对 std::string 的成员函数的补充。 这个库是基于 查找和替换 的概念构建起来的。


### 4.3.4 使用更好的内存分配器

std::string 是 通用模板的 一种特化

```C++
template<
    class CharT,
    class Traits = std::char_traits<CharT>,
    class Allocator = std::allocator<CharT>
> class basic_string;

// C++17开始
namespace pmr {
template<
    class CharT,
    class Traits = std::char_traits<CharT>
> using basic_string =
    std::basic_string<CharT, Traits, std::pmr::polymorphic_allocator<CharT>>;
}
```

第三个参数 是 分配器。 一个访问 C++内存管理器的专用接口。
默认情况下，是 std::allocator， 它会调用 `::operator new()` 和 `::operator delete()` ，这2个 全局的 C++内存分配器函数

ch13中详细讲解 ::operator new, ::operator delete 及其分配器对象的行为。
现在 只能说   ::operator new， ::operator delete 会做 非常复杂 和 困难的 工作， 为各种 动态变量分配存储空间。 它们需要为 大大小小的对象， 单线程，多线程 程序工作。 为了 通用性，它在设计上做了一些妥协。


我编写了一个 极其简单的 分配器， 它可以管理 几个固定大小的 内存块。
下面的代码，使用这种分配器，使用 最初始的 代码

```C++
typedef std::basic_string<
    char,
    std::char_traits<char>,
    block_allocator<char, 10>> fixed_block_string;

fixed_block_string remove_ctrl_fixed_block(std::string s) {
    fixed_block_string result;
    for (size_t i=0; i<s.length(); ++i) {
        if (s[i] >= 0x20)
            result = result + s[i];
    }
    return result;
}
```

运行时间是 13636毫秒， 比最初版本 快了 7.7倍。

。。估计这个时间是 测试套件的 时间，不是 每次调用的 时间。

修改分配器并不适用于怯懦的开发人员。
你==无法==将基于不同分配器的字符串赋值给另外一个字符串。
可以将示例代码修改为 `result = s.c_str();`

将所有 std::string 都改为 fixed_block_string 会有很大的影响。
因此，如果 团队认为 需要对他们 使用的字符串 做些修改，那么最好在 设计阶段 定义 全工程范围的 typedef， `typedef std::string MyProjString;`



## 4.4 消除字符串转换

### 4.4.1 将C字符串转为std::string

将C风格字符串 转为 std::string 这种 无谓转换，是浪费CPU时间的 原因之一。 例如
```C++
std::string MyClass::Name() const {
    return "MyClass";
}
```

这个函数需要将 字符串常量 "MyClass" 转为一个 std::string， 分配内存和复制字符到 std::string中。 C++会自动进行这种转换，因为 std::string 有一个 参数为char* 的构造器

当Name() 的返回值 被赋给一个 字符串 或 作为参数 传递给 另外一个函数时，会 自动进行转换。所以上面的函数 可以简单地 写为
```C++
char const* MyClass::Name() const {
    return "MyClass";
}
```
这样，返回值的 转换 被推迟到 真正使用时。
当它被使用时，通常不需要转换
```C++
char const* p = myInstance->Name(); // 没有转换
std::string s = myInstance->Name(); // 转换为'std::string'
std::cout << myInstance->Name();    // 没有转换
```

如果收到 std::string，但是 下一层需要 char*，那么需要转换
```C++
void HighLevelFunc(std::string s) {
    LowLevelFunc(s.c_str());
}
```


### 4.4.2 不同字符集间的转换

C++需要将 C的字母字符串(ASCII) 与来自 浏览器的 UTF-8 进行比较
或是将 生成 UTF-16的字流 的xml解析器输出的字符串 转为 utf-8

移除转换的 最佳方式 是为所有字符串 选择一种固定的格式， 并将 所有字符串都存储为这种格式。

个人比较喜欢 UTF-8，因为它可以表示 所有的 Unicode代码点， 可以直接和 C风格的字符串进行比较。


# ch5 优化算法

当程序 需要在 数秒内执行完毕，但是 实际上花费 数小时时， 唯一可以成功的 优化方法是 选择一种更高效的算法。

多数优化方法的性能改善是 线性的， 但是使用更高效的 算法 可以 指数级。

将介绍 常用的 查找和排序算法。 然后介绍一个 可以用在 现有程序中 优化查找 和排序的 工具。

## 5.1 算法的时间开销

logn 是 logn/log2

每次操作1纳秒

|操作次数|logn|n|nlogn|n^2|2^n|
|--|--|--|--|--|--|
|10|<1 微秒|<1 微秒|<1 微秒|<1 微秒	|1 微秒|
|20|<1 微秒|<1 微秒|<1 微秒|<1 微秒	|1 微秒|
|30|<1 微秒|<1 微秒|<1 微秒|<1 微秒	|1 秒|
|40|<1 微秒|<1 微秒|<1 微秒|1.6 微秒|18 分|
|50|<1 微秒|<1 微秒|<1 微秒|2.5 微秒|1013 年|
|100|<1 微秒|<1 微秒|<1 微秒|10 微秒|∞|
|1000|<1 微秒|1 微秒|10 微秒|1 毫秒|∞|
|10 000|<1 微秒|10 微秒|130 微秒|100 毫秒|∞|
|100 000|<1 微秒|100 微秒|2 毫秒|10 秒|∞|
|1 000 000|<1 微秒|1 毫秒|>20 毫秒|17 分|∞|


5.1.1 最优情况，平均情况，最差情况的时间开销

### 5.1.2 摊销时间开销

摊销 时间开销表示在大量输入数据上的平均时间开销。
例如，向堆中==插入==一个元素的时间复杂度是 ==O (log2 n )==，那么如果每次插入一个元素，构建整个堆的时间就是 O (n log2 n )。
不过，构建堆的最高效方法的时间开销是 O (n )，这意味着该方法==插入==每个元素的摊销时间复杂度是 ==O (1)==。但是最高效的算法并不会每次只插入一个元素。它会使用分治法算法 （divide-and-conquer algorithm）将所有数据插入到依次增大的子堆中。

最显著的摊销时间开销，发生在当某些独立的操作很快而其他操作很慢时。
例如，将一个字符添加到 std::string 中的摊销时间开销是一个常量，但这其中包含了一次对内存管理器的调用所占用的部分时间。
如果这个字符串很短，那么可能几乎每次在添加字符的时候都需要调用内存管理器。只有当程序再添加了数千个或是数百万个字符后，摊销时间开销才会变小。

5.1.3 其他开销

存储开销


## 5.2 优化查找和排序的工具箱

只有3个工具
- 用平均时间开销更低的 算法 替换 现有算法
- 加深对数据的理解 (例如，知道数据是已排序 或 几乎已排序)， 然后根据数据的特性 选择 具有 最优时间开销的 算法
- 调整算法 来线性地提高其性能

ch9 讲 如何使用 这些工具


## 5.3 高效查找算法

- 线性查找
- 二分查找
- 插补查找，和二分类似，也是将 有序表分为2部分，不过 它用 查找关键字的 一些其他特性来改善分块性能。 当查找关键字均匀分布时，O(loglogn)
- 散列法 O(1)


当n很小时，所有算法的 时间开销 都一样。

## 5.4 高效排序算法

维基百科上有 对 排序算法的 全面总结。

一些排序算法的时间开销

|排序算法|最好|平均|最差|空间|最好/差的注意点|
|--|--|--|--|--|--|
|插入排序|n|n^2|n^2|1|最好情况出现在当数据集已经排序完成或是几乎排序完成时|
|快速排序|nlog2 n|n log2 n|n^2|log2 n|最差情况出现在数据集已经排序完成或是支点元素的原生选择（第一个 / 最后一个）|
|归并排序|nlog2 n|nlog2 n|nlog2 n|1|-|
|树形排序|nlog2 n|nlog2 n|nlog2 n|n|-|
|堆排序|nlog2 n|n log2 n|n log2 n|1|-|
|Timsort|n|nlog2 n|n log2 n|n|最好情况出现在当数据集已经排序完成时|
|内省排序|nlog2 n|nlog2 n|nlog2 n|1|-|

Timsort 是一个对 归并排序做了大量优化的 版本

内省排序 (intro sort)， 是快速排序 和 堆排序的 混合。  先以 快速排序 开始，但当 输入数据集 导致 快速排序的 递归深度太深时，切换为 堆排序。 C++11以来，内省排序是 std::sort() 的优先实现。

最近非常流行的 FlashSort，对于 抽取自 某种概率分布的 数据，它的性能非常棒，O(n)。

5.4.2 替换在最差情况下 性能较差的排序算法。

如果你对输入数据集一无所知，那么 归并排序，树形排序，堆排序 都可以 确保 最差情况是 nlogn

5.4.3 利用输入数据集的 已知特性

如果 输入数据集 是已经有序，或 几乎有序，那么 平均性能为 n^2 的插入排序 可以做到 最优的 O(n)。

Timsort 在数据集 已经有序 或接近有序时， 也是 O(n)

Flash Sort 对于抽取自某种概率分布的数据，它的性能非常棒，达到了 O (n )。


## 5.5 优化模式

- 预计算， 在 设计，编译，链接时 计算
- 延迟计算， 在真正需要执行计算时 计算
- 批量处理， 每次对多个元素一起计算   。。。 duff
- 缓存
- 特化，移除未使用的共性来减少计算量
- 提高处理量，一次处理一大组数据 来减少 循环处理的开销
- 提示， 在代码中加入 可能会改善性能的提示 来减少计算量
- 优化期待路径
- 散列法
- 双重检查， 先进行一项 开销不大的 检查，然后 只在必要时 进行另一项 开销昂贵的检查 来减少计算量


### 5.5.1 预计算

当计算不依赖上下文时 才适用。 如 `int sec_per_day = 60 * 60 * 24;`

下面不行，因为依赖了 变量
`int sec_per_weekend = (date_end - date_beginning + 1) * 60 * 60 * 24;`


### 延迟计算

目的在于 将计算推迟至 更接近真正需要进行计算的地方。

好处: 如果没有必要在 函数的 所有执行路径 (if-else 的所有分支) 上都进行计算，那就只需要在 需要结果的 分支上进行计算。

延迟计算的例子
-  两段构建， 实例能被静态创建时，经常会缺少构建对象所需的信息。 在构建对象时，构造器中 编写建立 空对象的最低限度的代码， 稍候，程序再调用 该对象的 初始化成员函数 来完成构建。 将初始化 推迟至 有足够的额外数据时，意味着 建立的对象 总是高效的，扁平的 数据结构
-  写时复制


### 批量处理

目标是 收集多份工作，然后一起处理它们。

批量处理 用来移除 重复的函数调用 或是每次只处理一个项目时 会发生的 其他计算。

处理输入数据时，也可以使用 批量处理 将计算==推迟到 有更多的计算资源可用==时，如
- 缓存输出是批处理的一个典型例子。 输出字符会一直缓存，直到 缓存慢 或 程序遇到 行尾(EOL) 或 文件末尾 (EOF)。
- 将一个未排序的数组转换为 堆 的最优方法 是通过 批处理 使用更高效算法的 一个例子。 将n个元素 一个个插入到 堆中，开销是 nlogn，一次性构建整个堆是 n
- 多线程的任务队列是通过 批处理高效地利用计算资源的 一个例子
- 在后台保存 或更新 也是一个 批处理的例子

。。所以 批量处理 还有 缓冲的意思， 就是 线程池的队列 缓冲， 后台 也算是 缓冲吧。


### 缓存

保存 和 复用 昂贵计算的 结果 来 减少 计算量。

- 编译器会缓存 短小的，重复的 代码块的结果，如 `a[i][j] = a[i][j] + c;`，编译器会生成 `auto p = &a[i][j]; *p = *p + c;`
- CPU的 高速缓存
- std::string 会缓存 字符串长度。 C风格的字符串的长度 每次都需要计算。
- 线程池 缓存线程
- 动态规划


### 特化

特化 与 泛化相对。

特化的目的是 ==移除==在某种情况下 不需要执行的 昂贵的计算。

通过==移除==那些 导致 计算变得昂贵的 特性 可以简化操作 或 数据结构。

可以通过 放松问题的限制 或 对实现附加限制 来实现。 例如，使 动态变为 静态，限制不受限制的条件 等，如
- 模板函数 std::swap() 的默认实现可能会复制它的参数。C++11的使用 move来提高效率
- std::string 可以动态改变长度。 如果只需要 比较 固定的 字符串，那么使用 C风格的数组 或 指向字面字符串的 指针 会更高效


### 提高处理量

目的是 减少重复操作的 迭代次数， 减少 重复操作带来的 开销

- 向OS 请求大量输入数据 或发送 大量输出数据， 来减少 为少量内存块 或独立的数据项 调用内存 而产生开销。  副作用时，程序崩溃时，丢失的数据更多。       。。就是之前的 cout会 合并数据。  还有 申请内存 应该也算吧。
- 在移动缓存 或清除缓存时，不要以 byte 为单位， 而是以 word，long word 为单位。 这个优化仅在 两块内存对齐至 相同大小的边界时 才能改善性能
- 以 word 或 long word 来比较字符串。 这个优化 仅适用于 大端计算机， 不适用于 小端的 x86计算机。  不可移植的
- 在唤醒线程时 执行更多的工作。 唤醒线程后，不要只让处理器执行一个工作单元就 就放弃它，应该让它 处理多个 工作单元，这样可以节约 重复唤醒线程的 开销
- 不要在每次循环中 都执行 维护任务，而是应该 每循环10次或 100次 再执行一次维护任务

### 提示

使用提示来减少计算量

如，std::map 有一个重载的 insert() 函数，它有一个 表示最优插入位置的 可选参数。 最优提示 可以让 插入 变成 O(1)， 不使用最优提示，insert是 O(logn)

。。确实有 这么一个 重载，但是 有用? 有序 应该使用了 红黑树吧，  ok 知道了。 不提示，那么需要从 root 一路往下 找。 提示后，就直接在这个地方 insert。  一般是 lower_bound 找到位置，然后 insert。   。。 如果给的 位置 是错的， 会发生什么?

### 优化期待路径

if 有多个 else 分支， 把 最可能发生的 分支 写最上面。

### ==散列法==

大型数据结构 或 长字符串 可以处理为 hash值。

比较是否相同时， 先比较 hash值， 如果hash不同，则绝对不同。 hash相同，则 可能相同

hash 一般和 双重检查 一起使用。

### 双重检查

先使用一种开销不大的 检查 来 排除部分可能性，  必要时 再使用一个 开销很大的 检查来 测试 剩余的 可能性

- 双重检查 经常和 缓存同时使用。 CPU需要某个值时，会先检查 是否在 缓存中，如果不在，则从 内存中获取该值 或 计算
- 比较2个字符是否相等时 先判断 长度是否相同
- 用于散列法中。 先判断2个值得 hash。



# ch6 优化动态分配的内存的变量

除了 使用非最优算法 外，乱用动态分配内存的变量 就是 C++ 最大的 性能杀手了。

C++ 中的一些特性使用标准库容器、智能指针和字符串等动态分配内存的变量。这些特性可以提高 C++ 程序的编写效率。 但是 当发生性能问题时， new 就不再是你的好朋友了。

优化内存管理 的目标 不是 避免使用 动态分配内存的 变量。 而是 通过 巧妙地使用这些特性 移除对 内存管理器的 无谓的，降低性能的 调用。

以我的经验来看， 从循环处理中 或 被频繁调用的 函数中 移除 哪怕一次 对内存管理器的 调用，就可以 显著改善性能。

## 6.1 C++变量回顾

每个C++变量 在内存中的 布局都是固定的，它们的大小在 编译时就已经确定了。
C++允许程序 获得 变量的 字节单位的大小 和 指向该变量的 指针， 但不允许指定变量的每一位的布局。
C++的规则 允许 开发人员 调整 结构体成员变量的 顺序 和内存布局， C++也提供了 多个变量 共享同一内存块的 联合类型，但是 程序 所看到的 联合 是依赖于实现的。

### 6.1.1 变量的存储期

每个变量都有 存储期，也称为生命周期。 在这段时间内，变量所占用的 内存空间 的值 才是有意义的。

C++既要与C兼容，又要添加新概念，所以 C++ 中的变量声明语法有时会让人感到困惑

C++无法直接 指定变量的 存储期，但是可以通过 变量声明 来推导。

#### ==静态存储期==

在 命名空间作用域 内定义的变量 以及 被声明为 static 或是 extern 的变量 具有 静态存储期

具有静态存储期的变量 被分配在 编译器预留的 内存空间中。
编译器编译时，会为每个 静态变量 分配一个 固定位置 和 固定大小的 内存空间。
静态变量的 内存空间 在整个生命周期中都会 一直保留。
所有的 ==全局静态==变量 在 进入main之前 构建， 退出main之后 销毁。
==函数内声明的静态==变量 在 程序第一次进入函数前 创建， 这意味着 它 可能和 全局静态变量 一起被构建 也可以 直到第一次调用时 才构建。
C++为 全局静态变量 指定了 构建 和 销毁的 顺序。 但规则太复杂，实际使用时，更像 警告。

为 静态变量 创建 存储空间 没有运行时开销。 不过 无法再利用这段 存储空间。 因此 静态变量 适用于那些 在整个程序的生命周期 中都会被使用的数据


#### ==线程局部存储期==

C++11 开始，用 thread_local 存储类型指示符关键字声明的变量具有线程局部存储期。

线程局部变量 在 ==进入线程==时被构建，在==退出线程==时 被析构。 所以 和 线程的 生命周期 一样。

每个线程都有一份 该变量的 独立的副本

访问 线程局部变量 可能比 访问 静态变量 开销更大， 这取决于 OS 和编译器。 
某些系统中，线程局部存储空间 是由 线程分配的，所以访问 线程局部变量 的开销 比 访问全部变量 的开销 多一次指令。
其他系统中，必须通过 线程ID 索引一张 全局表 来访问 线程局部变量。 尽管开销是 常量时间，但是会发生一次 函数调用 和一些计算 导致  访问 线程局部变量的 开销变得更大。


#### ==自动存储期==

函数的==形参变量== 具有自动存储期。 除非使用 特殊的关键字，那些 ==声明在可执行代码块内部==的 变量 也有自动存储期

具有自动存储期的变量 被分配在 编译器在 函数调用栈上预留的 内存空间中。
编译时，编译器 会计算出 距离 栈指针的 偏移量，自动变量 以该offset为起点，占用一段固定大小的内存， 但是 自动变量的 绝对地址 直到 程序执行 进入 变量的作用域内时 才确定下来。

程序 运行至 声明自动变量的位置时， 会构建 自动变量， 当程序离开 大括号 括起来的 代码块时， 自动变量 会被析构。

和静态变量一样， 为自动变量分配 存储空间==不会发生 运行时开销==。
和静态变量 不同的是，自动变量 每次可以占用的 总的存储空间 是有限的。 当 递归不收敛 或 发生 深度函数嵌套调用 导致 自动变量 占据的存储空间 大小 超过 最大值时，发生 ==栈溢出==。

自动变量 适合于那些只在代码块中 被使用的 对象。



#### ==动态存储期==

new 表达式返回的变量 具有 动态存储期

动态存储期的变量 被保存在 程序 请 求 的 内存中

程序会调用 ==内存管理器，即== C++运行时系统函数 和 代表程序管理内存的 数据结构的集合。

程序在 ==new== 表达式中 显式 为 动态变量 申请 存储空间 并构建 动态变量。
稍候，程序在 ==delete==表达式 中 显式 析构动态变量， 并将 内存 返回给 内存管理器。

和自动变量类似，但是和 静态变量不同，  动态变量的 地址 是在 运行时确定的。

不同于 静态变量，线程局部变量，自动变量 的是， 数据的 声明语法被扩展了，这样可以在 运行时 通过一个 (非常量) ==表达式== 来指定 动态数据变量的 ==最高==维度。   。。不是全部的维度?

动态变量 ==没有自己的名字==。 构建后，C++内存管理器 会返回 指向该动态变量的 指针。 程序必须将 这个指针 赋值给 一个变量，这样就可以在 最后一个指向该变量的 指针 被析构之前，将 动态变量 返回给 内存管理器， 否则，不断创建动态变量 会 耗尽内存。

不同于 静态变量 和 线程局部变量的是，动态变量的 数量 和类型 可以随着时间改变， 而不受 它们所消耗的 内存总量的限制。    。。。?how

与 静态变量和 自动变量不同的是，管理动态变量使用的内存时会发生显著的运行时开销。


---

### 6.1.2 变量所有权

变量的所有者 决定了 变量 什么时候创建， 什么时候析构。

#### ==全局所有权==

具有 静态存储期 的变量 整体上被程序所有。
程序会在进入 main() 前构建它们，并在从 main() 返回后销毁它们。


#### ==词法作用域所有权==

具有 自动 存储期 的变量被一段 由大括号 括起来的 代码块 构成的 词法作用域所拥有

词法作用域 可能是 函数体，if,while,for,do,try,catch, {}

这些变量在程序进入词法作用域时会被构建，在程序退出词法作用域时会被销毁。

#### ==成员所有权==

类 和 结构体 的 成员变量 由定义它们的类实例所有。

当类的实例被 构建 时，它们会被类的 构造函数 构建；
当类的实例被 销毁 时，它们也会随之被销毁。

#### ==动态变量所有权==

动态变量 没有 预定义的 所有者

new 表达式 创建 动态变量 并返回一个 必须由程序显式管理的 指针。

动态变量 必须 在最后一个指向它的指针被销毁之前，通过 delete 表达式返回给内存管理器销毁。

动态变量的 生命周期 是可以 完全通过 编程控制 的，它是一个强大且危险的工具

动态变量的 所有权 必须由 程序员 执行并编写在程序逻辑中。它不受编译器控制，也不由 C++ 定义。

动态变量所有权对于性能优化非常重要。具有 强定义所有权 的程序会比 所有权 分散的 程序更高效。


### 6.1.3 ==值对象与实体对象==

有些变量通过它们的 ==内容== 体现出它们在程序中的意义，这些变量被称为==值对象== 。
其他变量通过在程序中 所扮演的 ==角色== 体现出它们的意义，这些变量被称为==实体 或实体对象== 。

通过实体对象的下列共通特性 识别 出它们


#### 实体是独一无二的

程序中的有些对象在概念上有唯一的标识符，
典型的例子有：守护某个特定临界区的 互斥锁 和有许多表元素的 符号表。


#### 实体是可变的

程序可以 对互斥锁 加锁，解锁，但是 它们仍然是同一个互斥锁

实体作为整体才是有意义的。改变实体的状态并不会改变它对于程序的基本意义。


#### 实体是不可复制的

实体不是通过复制得到的。它们的本质来源于使用它们的方式，而不是来自它们内部的每个位。

你可以将系统符号表中的所有位复制到另外一个数据结构中，但它不会成为系统的符号表。程序依然会去原来的地址查找符号表，而不会使用那份副本。


#### 实体是不可比较的

比较 是否相等 是没有意义的。

对两个实体的比较必须永远返回 false 。


---

对象 具有与 实体对象 相反的 下列 共通特性

#### 值是可互换和可比较的

数字 4 和 字符串"hi,world" 都是值。  
表达式 2+2 和 值4 的比较结果是相等。
"hi" + ",world" 和 "hi,world" 是相等的。

值的意义来自于它内部的每个位，而不是它在程序中的使用方法。


#### 值是不可变的

没有任何一种运算可以将 4 变为 5

#### 值是可以复制的

一个变量是实体对象还是值对象决定了复制以及比较相等是否有意义。
实体不应当被复制和比较。
一个类的成员变量是实体还是值决定了应该如何编写该类的构造函数。
类实例可以共享实体的所有权，但是无法有效地复制实体。



## 6.2 ==C++动态变量API回顾==

C++ 有一个完善的工具箱用于管理动态变量，这些工具允许对内存管理和动态分配内存的 C++ 变量的构建

---

指针和引用

C++中 动态变量 是没有名字的， 我们可以通过 C风格的 指针变量 或 引用变量 来访问它们。

指针 保存的值 并不是 一直是一个 有效的 内存地址，  可能是 nullptr。 C++11前，0代表 nullptr，C++11开始 0可以转为 nullptr。

未初始化的 C风格的指针 没有 预定义值。

---

new 和 delete 表达式

C++中 动态变量 通过 new表达式创建。

new 表达式会分配存储变量所需的空间，在存储空间中构建指定类型的变量，并返回一个指向新构建的变量的带类型的指针

用于创建数组的 new 表达式与用于创建 单实例的 new 表达式 不同，但都会返回相同类型的指针。
。。就是 `new int[1]` 返回 int*,  `new int(1)` 也是返回 int*

用于释放数组的 delete 表达式与用于销毁单实例的 delete 表达式不同
。。 `delete p`  ， `delete[] p`



==placement new==

```C++
{
    int n = 100;
    char* cp;             // 没有指定cp的值
    Book* bp = nullptr;   // bp指向无效地址

//     ...

    cp = new char[n];                // cp指向一个新的动态数组
    bp = new Book("Optimized C++"); // 新的动态类的实例

//     ...

    char array[sizeof(Book)];
    Book* bp2 = new(array) Book("Moby Dick"); // placement new操作符

//     ...

    delete[] cp;   // 在改变指针之前删除动态数组
    cp = new char; // cp现在指向一个动态char

//     ...

    delete bp;      // 类实例使用完毕
    delete cp;      // 动态分配的char使用完毕
    bp2->~Book();  // placement new操作符创建出的类实例使用完毕
}
// 在指针超出作用域前删除动态变量
```


---

内存管理函数

new 和delete 表达式 会调用 C++标准库的 内存管理函数， 在C++标准中 称为 "自由存储区"的内存池 中 分配 和归还内存。

这些函数是 new() 运算符 的重载， 对数组的 new[]() 运算符的重载， delete()， delete[]() 的重载。

C++还提供 C的内存管理函数， 如 malloc(), free()


---

类构造函数 和析构函数

构造器，析构器， 提供了放置 new 和delete 表达式的 场地，这样 所有的动态成员变量 都可以在 类的实例中 被自动管理起来。

---

智能指针

行为和 原始指针 类似，但是 它们在超出作用域后 还会删除 它们指向的 变量。

智能指针 可以记住 分配的 存储空间是 数组 还是 单实例。 能调用 正确的 delete 表达式

---

分配器模板

分配器模板 是 new 和 delete 表达式的 泛化形式， 可以和 标准容器 一起使用。 13.4介绍。


### 6.2.1 使用智能指针实现动态变量所有权的自动化

动态变量的 所有权不受 编译器控制，也不由 C++定义。 导致 可以在 某个地方声明 变量指针，然后在另一个地方 使用new 进行赋值， 再在 另一个地方 复制这个指针， 再在 另一个地方 delete销毁 动态变量。
这样的程序 难以测试和调试，因为 所有权太分散了。
每行代码都可能 创建 销毁 动态变量，还可能 复制指针， 开发人员 必须追踪 所有的 执行路径， 确保 动态变量 被正确地 返回给 内存管理器。

RAII
指针 是 类的私有成员变量， 在构造器中 初始化指针， 析构器中 释放指针 指向的内容。 还要实现 operator->(), operator*() 。 这种类 被称为 智能指针

C++提供了 `std::unique_ptr<T>`

---

动态变量所有权的自动化

智能指针 通过 耦合动态变量的 生命周期 与 拥有该动态变量的 智能指针的 生命周期，来实现动态变量所有权的 自动化。

---

共享动态变量的所有权的开销更大

`std::shared_ptr<T>` 可以在 所有权被共享时 管理 被共享的 所有权。

需要调整 引用计数，所以 开销更大。 。。。而且为了多线程安全，引用计数是线程安全的。就需要 临界区。

不能将 C风格的指针 赋给 智能指针。


### 6.2.2 动态变量有运行时开销

大多数C++语句的 开销是 几次内存访问。

但 为动态变量分配内存的开销 是 数千次内存访问。

分配内存的函数 会从 内存块集合中 寻找一块 可以使用的 内存 来满足请求。
如果找到 正好符合大小的内存，那么 从 集合中移除 并返回
如果找到一块 稍大的内存，它可以 选择 拆分内存，返回

如果没有可用的内存块，那么 分配函数 会调用 OS，从系统的 可用内存池中 请求 额外的 大块内存，这次调用的 开销非常大。  内核返回的内存 可能会(也可能不会) 缓存在 物理RAM中，可能导致 初次访问时 发生更大的延迟。

遍历可使用的内存块列表，这一操作的 开销也是 昂贵的。

多线程 并发 调用内存管理器分配内存，那么 内存管理器 也是一种资源。 导致 处一个线程外，其他线程都必须等待。

释放内存， 实际的实现 很复杂。 绝大多数实现 都会尝试 将 刚释放的内存 与 临近的 未使用的内存块 合并。
多线程并发 也会 竞争。

## 6.3 减少动态变量的使用

静态创建的变量 常常可以用于 替代 动态变量

### 静态地创建类实例

java可以
```java
MyClass myInstance = new MyClass("hello", 123);
```

C++会报错: 无法从 MyClass* 转为 MyClass， 所以C++需要
```C++
MyClass* myInstance = new MyClass("hello", 123);
```

不过上面的方法太低效，应该:
```C++
MyClass myInstance("hello", 123);

// 或
MyClass anotherMC = MyClass("hello", 123); // 可能稍微低效
```

如果 myInstance 声明在一个 可执行代码块中，那么它具有 自动存储期。
如果希望 它的存储器更长，那么 可以将 myInstance 定义在 更外层的 作用域中， 或定义在 一个 具有 较长存储期的 对象中，当需要时 传递指针。
如果希望 myInstance 的 生命周期 和 整个程序一样，那么 将声明 移到 文件作用域

---

静态地创建类的成员变量

当类的成员变量 也是类时， 我们可以在创建类时 静态地创建这些 成员变量。

有时，似乎必须动态创建类实例，因为 在创建 外层类时，还没有足够的资源来创建 成员变量 ，所以 该成员变量 需要动态创建。

可以使用 两段初始化来规避

还有一个好处， 初始化成员函数 可以返回错误代码 或其他信息，而 构造函数 则不行。


### 6.3.2 使用静态数据结构

std::string, std::vector, std::map, std::list 是几乎每天必用的容器。
如果使用得当，效率还是比较高的。 当它们不是 唯一选择，当向容器中 添加新的 元素时，std::string,std::vector 偶尔会重新分配它们的 存储空间。  std::map,std::list 会为每个 新添加的 元素分配一个 新节点。  有时，这种开销很贵。

让我们来看看 一些其他选择

==std::array替代std::vector==

如果编译时 能知道 数组的大小，或最大的大小，那么可以使用 std::array ，使 数组大小固定 且不会 调用 内存管理器。

。。不过 resize() 一次 也不是大问题，或者 vector(10, 0) 也可以。

std::array 支持复制构造，且提供了 标准库风格的 随机访问迭代器 和 下标运算符[]， size()返回数组的 固定大小。

从性能角度看，std::array 几乎和 C风格的数组 不分伯仲， 从编程角度看，std::array 与标准库容器有 相似性。

---

==在栈上创建大块缓冲区==

往std::string插入字符 的开销 会非常昂贵。
如果开发人员能够知道 字符串 可能的 最大长度，或 一个 合理的 最大长度，那么就可以使用 自动存储期 的 C风格的字符数组 作为临时字符串， 使用这个 临时字符串 进行 字符串连接操作，最后 再从 临时字符串中 复制出 结果。

担心数组溢出的话，可以先检查 字符串或数组的 长度。 太长了，就使用 动态构建的数组。

---

==静态地创建链式数据结构==

使用静态初始化的 方式构建具有 链式数据结构的数据

```C++
struct treenode {
    char const* name;
    treenode* left;
    treenode* right;
} tree[] = {
    { "D", &tree[1], &tree[2] }   // ......!!!  &tree[1] ...
    { "B", &tree[3], &tree[4] },
    { "F", &tree[5], nullptr },
    { "A", nullptr, nullptr },
    { "C", nullptr, nullptr },
    { "E", nullptr, nullptr },
};
```

能正常工作，是因为 数组元素的地址 是 常量表达式。 我们可以使用这种标记法定义 任何链式结构， 但是 编码 容易出错。

另一种方式 是为 结构中每个元素 初始化一个变量。
容易记忆，但是需要 前向声明

```C++
struct cyclenode {
    char const* name;
    cyclenode* next;
}
extern cyclenode first; // 前向引用
cyclenode fourth = { "4", &first );
cyclenode third  = { "3", &fourth };
cyclenode second = { "2", &third };
cyclenode first  = { "1", &second };
```

---

==在数组中创建二叉树==

利用数组索引 计算 上级，下级。

---

==用环形缓冲区替代双端队列==

std::deque, std::list 经常被用于 FIFO缓冲区， 以至于 标准库中有一个 std::queue 的容器适配器。

其实，还可以在 环形缓冲区上 实现双端队列。 环形缓冲区 是一个 数组型的 数据结构。 通过 取模 来确定 实际位置。

环形缓冲区 和 双端队列 有相似的特性，包括 都有 常量时间的 push_bakc，pop_front， 都有 随机访问迭代器。
不过 只要 消费者 跟得上 生产者，环形缓冲区 就不用 重新分配内存。

Boost的环形缓冲区: http://www.boost.org/doc/libs/1_58_0/doc/html/circular_buffer.html


### 6.3.3 使用std::make_shared代替new表达式

std::shared_ptr 包含2个指针，一个 指向对象，一个指向引用计数

下面的语句 会调用 2次 内存管理器，一次 创建MyClass对象，一次创建 引用计数。
`std::shared_ptr<MyClass> p(new MyClass("hello", 123));`

C++11开始，std::make_shared 模板函数 可以 一次性 分配一块独立内存 用来保存 引用计数 和 对象实例。
`std::shared_ptr<MyClass> p = std::make_shared<MyClass>("hello", 123);`
更简单的:
`auto p = std::make_shared<MyClass>("hello", 123);`


### 6.3.4 不要无谓地共享所有权

shared_ptr 修改 引用计数 需要 完整的 内存屏障， 进行一次 昂贵的 atomic操作。

如果 一个shared_ptr 的生命周期 完全包含 另一个shared_ptr，那么 第二个 shared_ptr 是无意义的。
```C++
void fiddle(std::shared_ptr<Foo> f);
   ...
shared_ptr<Foo> myFoo = make_shared<Foo>();
   ...
fiddle(myFoo);
```

myFoo 拥有 动态变量的实例Foo。 
程序调用 fiddle时， 会创建 第二个 指向Foo实例的 shared_ptr， 并增加 引用计数。
fiddle返回时，释放一次所有权

可以将 fiddle 的形参修改为 指针
```C++
void fiddle(Foo* f);
   ...
shared_ptr<Foo> myFoo = make_shared<Foo>();
   ...
fiddle(myFoo.get());
```

C++世界中有一个常识: 永远不要使用C风格的指针。
所以可以改为 引用
```C++
void fiddle(Foo& f);
   ...
shared_ptr<Foo> myFoo = make_shared<Foo>();
   ...
if (myFoo)
    fiddle(*myFoo.get());
```

解引用运算符 * 将 get()返回的 指针 转为 Foo的引用

C++的世界中，引用表示 无主且非空的指针


### 6.3.5 使用"主指针"拥有动态变量

shared_ptr 使用简单，自动管理动态变量。
但是 开销昂贵，许多情况下 没有必要。

经常出现的一种情况是，一个单独的数据结构在它的整个生命周期内拥有动态变量。
指向动态变量的引用或是指针可能会被传递给函数和被函数返回，或是被赋值给变量，等等。
但是在这些引用中，没有哪个的寿命比“主引用”长。

如果存在主引用，那么我们可以使用 std::unique_ptr 高效地实现它。
然后，我们可以在函数调用过程中，用普通的 C 风格的指针或是 C++ 引用来引用该对象。
如果在程序中贯彻了这种方针，那么普通指针和引用就会被记录为“无主”指针

。。就是可以确定 一个指针 是 实例的 创建者 和 销毁者， 那么 这个指针变为 unique_ptr 来 RAII，消除 忘记释放 的 风险。  但是 使用这个 实例的时候，还是 使用了 实例的 指针。


## 6.4 减少动态变量的重新分配。

### 6.4.1 预分配动态变量 以防止重新分配

std::string,vector 都有 reserve(size_t n)， 让 string，vector 确保至少可以存储 n个元素。

```C++
std::string errmsg;
errmsg.reserve(100); // 下面这些字符串连接操作中只会发生一次内存分配
errmsg += "Error 1234: variable ";
errmsg += varname;
errmsg += " was used before set. Undefined behavior.";
```

reserve 后计算， 计算完以后 shrink_to_fit() 归还 未使用的空间 给 内存管理器

std::unordered_map 也有 reserve()
但 std::deque 没有

在设计自己的 数据结构时，如果 能有一个 reserve，那么就 帮了 使用者 一个大忙。


### 在循环外创建动态变量

下面的代码，每次循环 都会创建 字符串 config，而且 随着 config的增加，会重新分配内存， 离开作用域后， 会销毁 config。

```C++
for (auto& filename : namelist) {
    std::string config;
    ReadFileXML(filename, config);
    ProcessXML(config);
}
```

提高性能的一种方式 是 将 config移到循环外部

```C++
std::string config;
for (auto& filename : namelist) {
    config.clear();
    ReadFileXML(filename, config);
    ProcessXML(config);
}
```

。。clear()，cppreference: C++标准 没有规定 是否要清空 string的 capacity。 现在的实现 都是 不修改 capacity。

另外一种变化形式是将 config 声明为 类的成员变量， 对于某些开发人员来说，这种修改 像是 滥用全局变量。 不过 延迟 动态分配内存的 变量的 生命周期 可以显著 提升性能

这种技巧还 适合与 std::vector 等 任何拥有动态大小 的 数据结构。


## 6.5 移除无谓的复制

`a=b;` 如果 b内部有一个非常大的 map，那么这个赋值语句的 开销会很大。

复制可能发生在:
- 构造器
- 赋值
- 函数参数
- 函数返回
- 插入一个元素到 标准库容器中

### 6.5.1 在类定义中 禁止不希望发生的复制

如果复制类实例 过于昂贵 或不希望这么做，那么 一种有效的方法是 禁止复制。
C++11前，将 复制构造器，赋值运算符 的可见性 声明为 private
```C++
// 在C++11之前禁止复制的方法
class BigClass {
private:
    BigClass(BigClass const&);
    BigClass& operator=(BigClass const&);
public:
    ...
};
```

C++11开始，使用delete

```C++
// 在C++11中禁止复制的方法
class BigClass {
public:
    BigClass(BigClass const&) = delete;
    BigClass& operator=(BigClass const&) = delete;
    ...
};
```

任何企图对以这种方式声明的类的实例赋值——或通过传值方式传递给函数，或通过传值方式返回，或是将它用作标准库容器的值时——都会导致发生 编 译 错 误 。


### 6.5.2 移除函数调用上的复制

程序调用函数时，会计算每个参数表达式，并以 参数表达式的 值 作为初始化器 创建每个 形参。
创建意味着 调用 形参的 构造器，对于 int，double，char* 等基本类型， 由于 基本类型的 构造器 只是概念上的 而非实际的函数，因此 程序只是 简单地 将 值 复制到 形参的存储空间中。

当形参是一个 类的实例 时，程序将调用 这个类的 复制构造器 来初始化实例。 对于一个 大且复杂的参数，复制所花的 时间足以 引起 开发人员的注意。 但是 如果测试时 参数中只有几个元素，那么恐怕直到生产大规模应用 才会被发现，导致其成为 提高程序可扩展性的 绊脚石

考虑下面的代码
```C++
int Sum(std::list<int> v) {
    int sum = 0;
    for (auto it : v)
        sum += *it;
    return sum;
}
```
调用 Sum 会复制 list ( 也会复制 list中的元素)。

为了避免这种开销，我们可以将 形参定义为 带有==平凡(trivial)构造器==的类型。
为了将 类实例 传递给 函数， 指针和引用 具有 普通构造器。例如 上面的例子中可以使用 `std::list<int> const &` , 该引用会被 指向实参的 引用初始化，而不会使用 复制构造器。

当一个 类和 标准库容器 一起使用时，或是 这个类包含了 一个必须要复制的数组，又或者是它有许多局部变量，那么通过复制构造函数创建它的实例可能会调用内存管理器来复制它内部的数据，而传递指向类实例的引用可以改善程序性能。

通过引用访问实例也会产生开销：每次访问实例时，都必须解引实现该引用的指针
如果函数很大，且 函数体中 多次使用了 形参，那么 解引用的 开销 可能超过 复制的开销。
但对于小型函数， 除了特别小的类外，通过引用传递参数 总是能获得更好的性能。

引用参数 在函数内部的修改 会导致 引用的实例 也发生改变， 将 ref 声明为 const 可以防止 不小心修改 所ref的实例。

ref参数 还是引入别名，可能导致 意料之外的 影响， 即 如果函数签名是
`void func(Foo& a, Foo& b);`
函数调用 `func(x,x)` 如果 func中 修改了 a，那么 你会发现 b 也被修改 了。


### 6.5.3 移除函数返回上的复制

如果函数返回一个值，那么这个值 会被 复制构造到 一个 未命名的 与 函数返回值类型 相同的 临时变量中。

```C++
std::vector<int> scalar_product(std::vector<int> const& v, int c) {
    std::vector<int> result;
    result.reserve(v.size());
    for (auto val : v)
        result.push_back(val * c);
    return result;
}
```

通常 函数的返回值 会被赋给变量，所以还会发生一次 复制构造器 或 赋值运算符。

早期，这2次复制构造 是性能杀手。
C++编译器找到了 移除 额外的 复制构造函数 调用 的方法，称为 ==复制省略(copy elision) 或 返回值优化 (return value optimization RVO)==。

只有某些特殊的情况，编译器才能 RVO。 
- 函数必须返回一个 局部对象。 
- 编译器必须能确定在所有的 控制路径上 返回的 都是 相同的 对象。 ( 。最简单的就是 只有一个return)
- 返回对象的类型 必须与所声明的 函数返回值的类型相同


一种移除函数内部的 类实例的构造 以及 从函数返回时发生的 2次复制构造 (或是等价于 复制构造器的 赋值运算符):  使用 ==输出参数==

```C++
void scalar_product(
    std::vector<int> const& v,
    int c,
    vector<int>& result) {   // <<<<

    result.clear();
    result.reserve(v.size());
    for (auto val : v)
        result.push_back(val * c);
}
```

这种机制有以下优点
- 函数被调用时，对象已经被构建。有时，该对象必须被 清除 或重新初始化，但是这些操作的开销 都小于 构造器的开销
- 在函数内 被更新的对象无序在 return语句中 被复制到 无名的临时变量中
- 由于实际结果 通过参数返回，所以函数 返回值 可以是 void 或 返回错误码/状态码
- 由于 函数中被 更新的对象 也是 外部的 对象，所以 函数返回时 不再需要 复制 或 赋值

C++中 有一种情况 只能通过值返回对象: 运算符函数。


### 6.5.4 免复制库

当需要 填充的 缓冲区，结构体，或其他数据结构 是函数参数时， 传递 引用 穿越多层库调用的 开销很小。

有种叫做 "免复制" 的库 实现了这样的行为。
例如C++标准库的 `istream::read()`的 签名如下
`istream& read(char* s, streamsize n);`

这个函数 读取 n个字节 到 s指向的 存储空间。 这个s 是一个 输出参数。

但是 istream::read 自身并不会从 OS获取数据。它会调用另外一个函数。 某些实现中，它可能调用 C的库函数 fread
`size_t fread(void* ptr, size_t size, size_t nmemb, FILE* stream);`

fread 会读取 size * nmemb 个字节的数据 并保存到 ptr 指向的内存中。
fread 的ptr 和 read中的 s 相同。

但 fread 不是终点， linux上，fread 会调用 标准Unix函数read()， windows上会调用 win32的 Readfile(). 这2个函数的签名类似
`ssize_t read(int fd, void *buf, size_t count);`
`BOOL ReadFile(HANDLE hFile, void* buf, DWORD n, DWORD* bytesread, OVERLAPPED* pOverlapped);`

2个函数都接收 一个指向需要填充的缓冲区的 void* 以及一个 要读取的 最大字节数。


### 6.5.5 实现写时复制惯用法

COW，copy on write， 用于高效复制 那些 含有 昂贵复制开销的 动态变量的 类实例。

当 带有动态变量的 对象被复制时，也必须复制 该动态变量，这种是 ==深复制==
通过复制 指针，而不是 复制 指针指向的变量， 称为 ==浅复制==

现代C++ 的 COW 的实现方式中， 任何引用 动态变量的 类成员 都是 用 如 std::shared_ptr 这样的具有 共享所有权的 智能指针实现的。

COW中使用 std::make_shared() 构建动态变量 非常重要。

### 6.5.6 切割数据结构

slice 是一种编程惯用法， 它指的是 一个变量 指向 另一个变量的 一部分。

C++17 的 string_view 就是 指向 了 字符串的子字符串。 它包含 一个指向 子字符串开始位置的 char*指针 以及 子字符串的长度。


## 6.6 实现==移动语义==

就性能优化而言，C++11的 移动语义 具有非常重要的意义。

C++11前，C++没有提供任何标准的方式 来 高效地将 一个变量的内容 移动到 另一个变量中。


6.6.1 非标准复制语义:痛苦的实现

。。移动语义之前的 做法。


### 6.6.2 std::swap(): "穷人"的移动语义

```C++
std::vector<int> a(1000000,0);
   ...
std::vector<int> b; // b是空的
std::swap(a,b);     // 现在b有100万个元素
```

std::swap() 可以特化。


6.6.3 共享所有权的实体

让 shared_ptr 指向实体

### 6.6.4 移动语义的移动部分

为了实现 移动语义，编译器 需要能够 识别 一个变量 在什么时候 只是临时值。 这样的实例 是没有名字的。
例如，函数返回的对象或 new 表达式的结果就没有名字。
不可能会有其他引用指向该对象。
该对象可以被初始化、赋值给一个变量或是作为表达式或函数的参数。
但是接下来它会立即被销毁。
这样的无名值被称为==右值==

==左值== 是指通过变量命名的值。

当一个对象是右值时，它的内容可以被转换为左值

C++ 的类型系统被扩展了，它能够从函数调用上的左值中识别出右值。
如果 T 是一个类型，那么声明 `T&&` 就是指向 T 的右值引用

函数重载的解析规则也被扩展了，这样当右值是一个实参时，优先右值引用重载；而当左值是实参时，则需要左值引用重载。

特殊成员函数的列表被扩展了，现在它包含了 移动构造 函数和一个 移动赋值 运算符

编译器只会在当程序 没有 指定 复制构造函数、赋值运算符 或是 析构函数 ，而且 父类或是 任何类成员都 没有 禁用 移动运算符 的简单情况下，才会 自动 生成 移动构造函数和移动赋值运算符。


6.6.5 更新代码以使用移动语义

### 6.6.6 ==移动语义的微秒之处==

==移动实例到std::vector==

如果希望 对象在 vector 中高效移动，那么 仅编写 移动构造，移动赋值 是==不够的==。 必须将 移动构造 和 移动复制 声明为 ==noexcept==。
因为 vector 提供了 强异常安全保证: 当一个 vector 执行某个操作时，如果发生了异常，那么 该 vector 的 状态 会和 执行操作之前 一样。  复制构造器 不会 修改 源对象， 但是 移动构造器 会销毁它。  任何在 移动构造中 发生的异常 都会和 强异常安全保证 相冲突。

如果没有将移动构造函数和移动赋值运算符声明为  noexcept ，std::vector 会使用比较低效的复制构造函数。

noexcept 是一种强承诺。
使用 noexcept 意味着不会调用内存管理器、I/O 或是其他任何可能会抛出异常的函数


==右值引用参数是左值==

当一个函数接收一个右值引用作为参数时，它会使用右值引用来构建形参。
因为形参是有名字的，所以尽管它构建于一个右值引用，它仍然是一个左值。


幸运的是，开发人员可以显式地将左值转换为右值引用。
`<utility>` 中的模板函数 std::move() 来完成这项任务

```C++
std::string MoveExample(std::string&& s) {
    std::string tmp(std::move(s));
//  注意！现在s是空的
    return tmp;
}
   ...
std::string s1 = "hello";
std::string s2 = "everyone";
std::string s3 = MoveExample(s1 + s2);
```

```C++
template <typename T> void std::swap(T& a, T& b) {
{
  T tmp(std::move(a));
  a = std::move(b);
  b = std::move(tmp);
}
```


==不要返回右值引用==

返回右值引用会妨碍返回值优化

#### ==移动父类和类成员==

要为一个类 实现 移动语义，你==必须== 为 所有的 父类 和 类成员 也实现 move语义。 否则 父类 和 类成员 将被 复制，而不是move

```C++
class Base {...};
class Derived : Base {
    ...
    std::unique_ptr<Foo> member_;
    Bar* barmember_;
};
　
Derived::Derived(Derived&& rhs)
  : Base(std::move(rhs)),             // move
    member_(std::move(rhs.member_)),
    barmember_(nullptr) {
　
    std::swap(this->barmember_, rhs.barmember_);
}
```

假设 Base 有移动构造函数，那么它只有在通过调用 std::move() 将左值 rhs 转换为右值引用后才会被调用


在实现移动赋值运算符时，==std::swap() 可能会引起麻烦==。
麻烦在于 this 可能会指向一个已经分配了内存的对象。
std::swap() 不会销毁那些不再需要的内存。
它会将它们保存在 rhs 中，直至 rhs 被销毁前这块内存都无法被重新利用。
如果在一个类成员中有一个含有 100 万个字符的字符串或是包含一张 100 万个元素的表，这可能会是一个潜在的大问题。
在这种情况下，最好先显式地复制 barmember_ 指针，然后在 rhs 中删除它，以防止 rhs 的析构函数删除释放它：

```C++
void Derived::operator=(Derived&& rhs) {
    Base::operator=(std::move(rhs));
    delete(this->barmember_);
    this->barmember_ = rhs.barmember_;
    rhs.barmember_ = nullptr;
}
```


## 6.7 扁平数据结构

当一个数据结构中的元素被存储在 连 续 的 存储空间中 时，我们称这个数据结构为扁平的 。
相比于通过指针链接在一起的数据结构，扁平数据结构具有 显著的 性能优势。

- 相比通过指针链接， 创建扁平数据结构实例时 调用内存管理器的 开销更小。有些数据结构(list,deque,map,unordered_map) 会创建许多 动态变量， 而其他 数据结构(vector) 则较少。
- 以前常常需要用到的技巧，诸如用智能指针组成 vector 或是 map 来存储不可复制的对象，在 C++11 中的移动语义出现后已经不再需要了



# ch7 优化热点语句

语句级别的优化 可以被 模式化为 ==从执行流中移除指令== 的过程

语句级别的优化 的问题在于， 除了函数调用外，没有那条C++语句会消耗 许多条 机器指令。
通常，集中精力在这些微小的性能点上是无法获得与开发人员所付出的努力相应的性能回报的

除非开发人员找到了 `放大` 这些语句的开销、使得它们成为值得优化的热点代码的因素。
这些因素包括以下几个
- 循环， 分析器可以找出 包含热点循环的 函数，但不会指出 那个循环是 热点循环。
- 频繁被调用的函数
- 贯穿整个程序的惯用法

## 7.1 从循环中移除代码

循环 由2部分组成: 控制语句 和 循环代码。

```C++
char s[] = "This string has many space (0x20) chars. ";
    ...

for (size_t i = 0; i < strlen(s); ++i)
    if (s[i] == ' ')
       s[i] = '*';
```

strlen 是 O(n)的，使得代码 整体是 O(n^2)


### 7.1.1 缓存循环结束条件值

```C++
for (size_t i = 0, len = strlen(s); i < len; ++i)
    if (s[i] == ' ')
        s[i] = '*';
```

1000万次迭代 快 20倍。

### 7.1.2 使用更高效的循环语句


`for (初始化表达式 ; 循环条件 ; 继续表达式 ) 语句`
会被编译为

```
    初始化表达式 ;
L1: if ( ! 循环条件 ) goto L2;
    语句 ;
    继续表达式 ;
    goto L1;
L2:
```

for循环中 有2次 jump指令 (。即2个goto)。 jump 会降低执行速度


`do 语句 while ( 循环条件 ) ;`
编译为
```
L1: 控制语句
    if ( 循环条件 ) goto L1;
```

因此 将 for 修改为 do 可以提高速度。    。。但是 for 的2次goto 又不是同时发生的啊。

```C++
size_t i = 0, len = strlen(s); // for循环初始化表达式
do {
    if (s[i] == ' ')
        s[i] = ' ';
    ++i;                       // for循环继续表达式
} while (i < len);             // for循环条件
```

VS2010 性能提高了 12%， VS2015 降低了25%。


### 7.1.3 用--代替++

```C++
for (int i = (int)strlen(s)-1; i >= 0; --i)
    if (s[i] == ' ')
        s[i] = '*';
```
这里不能用 size_t， 会 死循环。 因为 size_t 始终 >= 0

测试下来，没有显著提升。


### 7.1.4 从循环中移除不变性代码

含有 循环不变性代码的循环。
```C++
int i,j,x,a[10];
   ...
for (i=0; i<10; ++i) {
    j = 100;        // 不变的
    a[i] = i + j * x * x;  // j*x*x 也不变
}
```

改为
```C++
int i,j,x,a[10];
   ...
j = 100;
int tmp = j * x * x;
for (i=0; i<10; ++i) {
    a[i] = i + tmp;
}
```

### 7.1.5 从循环中移除无谓的函数调用

```C++
char* s = "sample data with spaces";
    ...
size_t end = strlen(s);
for (size_t i = 0; i < end; ++i)
    if (s[i] == ' ')
        s[i] = '*'; // 将' '改为'*'
```
。。这个和 7.1.1 一样吧。

上面是替换，所以 s的 size 不会变。 下面的代码 就无法将 strlen 拿出来

```C++
char* s = "sample data with spaces";
size_t i;
    ...
for (i = 0; i < strlen(s); ++i)
    if (s[i] == ' ')
        strcpy(&s[i], &s[i+1]); // 移除空格，导致strlen变化。
s[i] = '\0';
```

。。不过 可以手动 sz1-- 啊。
。。而且 看书上说， strlen并非唯一的问题，那说明 strcpy 也有问题。 确实，最后一个字符，每次遇到 空格，都会移动一次。 所以 strcpy是 O(n)， 整个for 就是 O(n^2) 的。 。。这个时候 应该是 双指针了吧。

有一种函数永远都可以被移动到循环外部，那就是返回值只依赖于函数参数而且没有副作用的 纯函数

```C++
void rotate(std::vector<Point>& v, double theta) {
    for (size_t i = 0; i < v.size(); ++i) {
        double x = v[i].x_, y = v[i].y_;
        v[i].x_ = cos(theta)*x - sin(theta)*y;
        v[i].y_ = sin(theta)*x + cos(theta)*y;
    }
}
```

将 具有 循环不变性的 纯函数 移动到 循环外后
```C++
void rotate_invariant(std::vector<Point>& v, double theta) {
    double sin_theta = sin(theta);
    double cos_theta = cos(theta);
    for (size_t i = 0; i < v.size(); ++i) {
        double x = v[i].x_, y = v[i].y_;
        v[i].x_ = cos_theta*x - sin_theta*y;
        v[i].y_ = sin_theta*x + cos_theta*y;
    }
}
```

性能大约提高了 3%。
。。这么少的吗。。你 sin cos 不会是 查表的吧。。


### 7.1.6 从循环中移除隐含的函数调用

普通的函数调用很容易识别。

C++还有隐式的函数调用。 当一个变量是以下之一时 就会发生这种情况
- 声明一个类实例， 调用构造器
- 初始化一个类实例， 构造器
- 赋值给一个类实例， 赋值运算符
- 设计类实例的计算表达式， 运算符成员函数
- 退出作用域， 析构器
- 函数参数， 复制构造
- 函数返回一个类的实例， 复制构造，可能2次
- 向标准库容器中插入元素， 移动构造 或复制构造
- 向vector中插入元素， 如果vector重新分配内存，那么所有元素都要 移动构造 或 复制构造


```C++
for (...) {
    std::string s("<p>");
    ...
    s += "</p>";
}
```

改成
```C++
std::string s;
for (...) {
    s.clear();
    s += "<p>";
    ...
    s += "</p>";
}
```

### 7.1.7 从循环中移除昂贵的，缓慢改变的调用

有些函数调用不具备 循环不变性，但是也可能变得 具有循环不变性。

一个典型的例子就是 日志应用程序中 调用 获得当前时间的函数。

```C++
# include <ctime>

char* timetoa(char *buf, size_t bufsz) {
    if (buf == 0 || bufsz < 9)
        return nullptr; // 无效参数
    time_t t = std::time(nullptr); // 从操作系统中获取时间
    tm     tm = *std::localtime(&t); // 将时间分解为时分秒
    size_t sz = std::strftime(buf, bufsz, "%c", &tm); // 格式化到缓存中
    if (sz == 0) strcpy(buf, "XX:XX:XX"); // 错误
    return buf;
}
```

在性能测试实验中，timetoa() 花费了大约 700 纳秒完成了获取和格式化时间的处理

```C++
out << "Fri Jan 01 00:00:00 2016"
    << " Test log line test log line test log line\n";
```
只花了 372纳秒

```C++
out << timetoa(buf, sizeof(buf))
    << " Test log line test log line test log line\n";
```
花了 1042纳秒


修改为 10行日志 获取一次 时间，耗时 376ns

### 7.1.8 将循环放入函数以减少调用开销

如果程序 在遍历 字符串，数组 或其他数据结构时， 会在每次迭代中 都调用一个函数，那么可以通过  循环倒置 (loop inversion) 来提高性能

循环倒置是指将在循环中调用函数变为在函数中进行循环。这需要改变函数的接口

```C++
# include <ctype>

void replace_nonprinting(char& c) {
    if (!isprint(c))
        c = '.';
}
```
```C++
for (unsigned i = 0, e = str.size(); i < e; ++i)
    replace_nonprinting(str[i]);
```
如果编译器无法对 replace_nonprinting() 内联展开，那么当需要处理的字符串是“Ring the carriage bell\x07\x07!!”时，它会调用这个函数 26 次。

库的设计者可以重载 replace_nonprinting() 函数来处理整个字符串
```C++
void replace_nonprinting(std::string& str) {
    for (unsigned i = 0, e = str.size(); i < e; ++i)
        if (!isprint(str[i]))
            c = '.';
}
```


### 7.1.9 不要频繁地进行操作

现在有一个问题: 在一个程序的主循环中每秒处理约 1000 个事务，那么它应当每隔多长时间检测一次是否有终止命令呢？

答案当然是“视情况而定”。
事实上，这取决于两件事情：
- 程序需要以多快的速度响应终止请求，以及
- 程序检查终止命令的开销

如果程序的响应目标是需要在一秒内停止程序，而且在检测到停止命令后需要平均 500 ± 100 毫秒来停止程序，那么它需要每 400 毫秒（1000 - (500 + 100) = 400 毫秒）检测一次。更频繁地检测只会是浪费

另一个因素是检测终止命令的开销。
如果主循环是 Windows 消息循环，那么终止命令就是 Windows 的 WM_CLOSE 消息。
由于此时开销包含在了事件分发中，因此不会发生额外的检测开销。
如果信号处理函数会设置一个 bool 标识位，那么每次在循环中检测这个标识位的开销非常微小。


## 7.2 从函数中移除代码

和循环一样，函数也包含2部分: 
- 函数体
- 参数列表 和 返回值类型 组成的 函数头。

这2部分也可以独立优化

函数的开销可能很大，但是调用函数的开销 和 大多数C++语句的开销一样， 是非常小的


### ==函数调用的开销==

调用函数时，会发生下面的处理
1. 执行代码 将 一个栈帧 push到 调用栈中 来保存函数的 参数 和局部变量
2. 计算每个 参数表达式 并复制到 栈帧中
3. 执行地址 被复制到 栈帧中 并生成 返回地址
4. 执行代码 将执行地址 更新为 函数体的 第一条语句
5. 执行函数体中的 指令
6. 返回地址 从 栈帧中复制到 指令地址中，将控制权交给 函数调用后的语句
7. 栈帧被 pop

函数开销 也有一些好消息。 带有函数的 程序通常比 带有被内联展开的大型函数的 程序 更加紧凑， 这有利于 提高缓存 和 虚拟内存的 性能

---

==函数调用的基本开销==

- 函数参数， 除了计算参数表达式的开销外，复制每个参数的值 到栈中也会发生开销。
- 成员函数调用(与函数调用)， 每个成员函数都有一个额外的 隐藏参数: 一个指向 自己的 this指针
- 调用和返回， 可以通过内联来消除

---

==虚函数的开销==

C++中可以将 任何 成员函数定义为 虚函数。继承类能通过定义一个 具有相同函数前面的 成员函数 来重写 基类的虚成员函数。
每个带有 虚成员函数的 实例 都有一个 无名指针指向 ==虚函数表== vtable。 虚函数表 指针通常是 类实例的 第一个字段，这样 解引用的开销更小

调用虚函数的代码会解引用指向类实例的指针，来获得指向虚函数表的指针。
这里会为所有的虚函数调用额外加载2次非连续的内存，每次都会增加高速缓存未命中的几率和发生流水线停顿的几率

虚函数的另一个问题是编译器难以内联它们

---

==继承中的成员函数调用==

当一个类继承另一个类时，继承类的成员函数可能需要进行一些额外的工作。

---

==继承类中定义的虚成员函数==

如果继承关系 最顶端的 基类 ==没有== 虚成员函数，那么代码必须要给 this 类实例指针加上一个==偏移量==，来得到继承类的虚函数表，接着会遍历虚函数表来获取函数执行地址

---

==多重继承的继承类中定义的成员函数调用==

代码必须向 this 类实例指针中加上一个偏移量来组成指向多重继承类实例的指针。

---

==多重继承的继承类中定义的虚成员函数调用==

对于继承类中的虚成员函数调用，如果继承关系最顶端的基类没有虚成员函数，那么代码必须要给 this 类实例指针加上一个偏移量来得到继承类的虚函数表，接着会遍历虚函数表来获取函数执行地址。

---

==虚多重继承==

为了组成虚多重继承类的实例的指针，代码必须解引类实例中的表，来确定要得到指向虚多重继承类的实例的指针时需要加在类实例指针上的偏移量。
如前所述，当被调用的函数是虚函数时，这里也会产生额外的间接开销

---

==函数指针的开销==

C++ 提供了函数指针，这样当通过函数指针调用函数时，代码可以在 运行时 选择要执行的函数体。
除了基本的函数调用和返回开销外，这种机制还会产生其他额外的开销。

函数指针（指向非成员函数和静态成员函数的指针）

C++ 允许在程序中定义指向函数的指针。
程序员可以通过函数指针显式地选择一个具有特定签名（由参数列表和返回类型组成）的非成员函数。
当函数指针被解引后，这个函数将会在运行时会被调用。
通过将一个函数赋值给函数指针，程序可以显式地通过函数指针选择要调用的函数。

代码必须解引指针来获取函数的执行地址。编译器也 不太可能 会 内联 这些函数。


成员函数指针

成员函数指针声明同时指定了 `函数签名` 和解释函数调用的上下文中的`类`。
程序通过将函数赋值给函数指针，显式地选择通过成员函数指针调用哪个函数

成员函数指针有多种表现形式，一个成员函数只能有一种表现形式。
它必须足够通用才能够在以上列举的各种复杂的场景下调用任意的成员函数。
我们有理由认为一个成员函数指针会出现最差情况的性能。


---

==函数调用开销总结==

C 风格的不带参数的 void 函数的调用开销是`最小`的。
如果能够内联它的话，就没有开销；即使不能内联，开销也仅仅是两次内存读取加上两次程序执行的非局部转移

如果基类没有虚函数，而虚函数在多重虚拟继承的继承类中，那么这是`最坏`的情况。
不过幸运的是，这种情况非常罕见。
在这种情况下，代码必须解引类实例中的函数表来确定加到类实例指针上的偏移量，构成虚拟多重继承函数的实例的指针，接着解引该实例来获取虚函数表，最后索引虚函数表得到函数执行地址。


### 7.2.2 简短地声明内联函数

移除函数调用开销的一种有效方式是内联函数

要想内联函数，==编译器必须能够在函数调用点访问函数定义==

那些函数体在==类定义中的函数==会被==隐式==地声明为内联函数。
通过将在==类定义外部定义==的函数==声明为存储类内联==，也可以明确地将它们声明为内联函数

如果==函数定义出现在==它们在某个编译单元中==第一次被使用之前==，那么编译器还可能会自己选择内联较短的函数

当编译器内联一个函数时，那么它还有可能会改善代码，包括移除调用和返回语句。
有些数学计算可能会在编译时完成。
如果编译器能够确定当参数为某个特定值时有些分支永远不会执行，那么编译器会==移除这些分支==。
因此，内联是一种通过在编译时进行计算来==移除多余计算==的改善性能的手段

函数内联可能是最强力的代码优化武器

### 7.2.3 在使用之前定义函数

在第一次调用函数之前定义函数（提供函数体）给了编译器优化函数调用的机会，编译器能够自主选择==内联==这次函数调用

如果编译器能够同时找到==函数体==，以及实例化那些发生虚函数调用的==类变量、指针或是引用==的代码，那么这也同样适用于==虚函数==。


### 7.2.4 移除未使用的多态性

虚成员函数多用来实现 运行时 多态性

当程序必须在 运行时 从多种实现中选择一种执行时，虚函数表是一种非常高效的机制，它的间接开销只有两次额外的==内存读取==以及与这两次内存读取相关的==流水线停顿==

多态仍然可能会带来不必要的性能开销

当不会使用多态时，移除 父类的 方法的 virtual

### ==放弃不使用的接口==

在 C++ 中可以使用==虚成员函数==实现接口: 一组通用函数的声明。
这些函数描述了对象行为，而且它们在不同的情况下有不同的实现方式。

基类通过声明一组==纯==虚函数（有函数声明，但没有函数体的函数）定义接口。
由于纯虚函数没有函数体，因此 C++ 不允许实例化接口基类

C++ 中接口惯用法的优点在于，继承类==必须实现==接口中声明的==所有==函数，否则编译器将不会允许程序创建继承类的实例。

开发人员可以使用接口类来隔离操作系统依赖性，特别是当设计人员预计需要为多个操作系统实现程序时
我们可以通过下面的接口类 file 来定义读写文件的类。
这个 file 被称为抽象基类 ，因为它无法被实例化：
```C++
// file.h——接口
class File {
public:
    virtual ~File() {}
    virtual bool Open(Path& p) = 0;
    virtual bool Close() = 0;
    virtual int GetChar() = 0;
    virtual unsigned GetErrorCode() = 0;
};
```
在其他代码中定义的 Windowsfile 继承类提供了这些函数在 Windows 操作系统上的实现。
C++11 中的关键字 override 是可选关键字，它告诉编译器当前的声明会重写基类中虚函数的声明。
```C++
// Windowsfile.h——接口

# include "File.h"
class WindowsFile : public File { // C++11风格的声明
public:
    ~File() {}
    bool Open(Path& p) override;
    bool Close() override;
    int GetChar() override;
    unsigned GetErrorCode() override;
};
```
除了头文件外，还有一个包含了这些重写函数的 Windows 版实现的 windowsfile.cpp 文件：
```C++
// windowsfile.cpp——Windows版的实现
# include "WindowsFile.h"
bool WindowsFile::Open(Path& p) {
    
}
bool WindowsFile::Close() {
    
}
```

有时，一个程序虽然定义了接口，但是只提供了一种实现。
在这种情况下，通过==移除接口==，即==移除== file.h 类定义中的 ==virtual 关键字==并==提供== file 的成员函数的==实现==，可以==节省虚函数调用==（特别是频繁地对 GetChar() 的调用）的开销。


---

==在链接时选择接口实现==

虚函数允许程序在`运行时`从多个实现中选择一种
使用 C++ 虚函数实现接口惯用法的问题在于，虚函数为设计时问题提供的是一个带有`运行时开销`的运行时解决方案。

如果要将上面的 file.h 移植到 Linux 上，那么还需要给这段代码加上一个 file 接口的继承类 Linuxfile ，但是 Windowsfile 和 Linuxfile 永远不会在同一个程序中被实例化。
它们使得`底层调用` `只会`被实现在一种操作系统上。这样就`不会发生`虚函数的调用开销

如果无需在运行时做出选择的话，那么开发人员可以使用`链接器`来从多个实现中选择一种。
具体做法是不声明 C++ 接口，而是在头文件中直接声明（但不实现）成员函数，就像它们是标准库函数一样
```C++
// file.h——接口
class File {
public:
    File();
    bool Open(Path& p);
    bool Close();
    int GetChar();
    unsigned GetErrorCode();
};
```

windows.cpp    // 没有 windowfile.h 了
```C++
// windowsfile.cpp——Windows的实现代码
# include "File.h"
　
bool File::Open(Path& p) {
   ...
}
　
bool File::Close() {
   ...
}
...
```

linuxfile.cpp 的相似文件中包含了 Linux 的实现。

Visual Studio 工程文件引用 windowsfile.cpp，Linux 的 makefile 则引用 linuxfile.cpp。
选择哪个实现会由链接器根据`参数列表`来做出决定
。。应该就是 把哪个cpp 引入到 编译环境中。

在链接时选择实现的优点是使得程序具有通用性，而缺点则是部分决定被放在了 .cpp 文件中，部分决定被放在了 makefile 或是工程文件中。
。。可以通过前缀来区分吧。 windows的全部用 win作为前缀，  cmake应该可以 通过 判断目标操作系统 拉取 不同前缀的 cpp 到 编译环境中吧?


---

==在编译时选择接口实现==

如果对于两种 file 实现使用不同的编译器（例如对 Window 版本使用 Visual Studio，对 Linux 版本使用 GCC），那么可以在编译时使用 #ifdef 来选择实现。
头文件不需要做任何改变。

下面是一个名为 file.cpp 的源文件，其中预处理宏会选择实现：

。。这样 可以在cmake中 根据目标OS 放出 不同的 #define 啊。 有这功能吧?

```C++
// file.cpp——实现
# include "File.h"
# ifdef _WIN32
    bool File::Open(Path& p) {
       ...
    }
    bool File::Close() {
       ...
    }
   ...
# else // Linux
    bool File::Open(Path& p) {
       ...
    }
　
    bool File::Close() {
       ...
    }
   ...
# endif
```

有些开发人员喜欢这种方法，因为可以在 .cpp 文件中做更多决定。
另外一些开发人员则认为在一个文件中编写两种实现方式是凌乱且非面向对象的。


### 7.2.6 ==用模板在编译时选择实现==

C++ 模板特化是另外一种在 ==编译时选择实现== 的方法

利用模板，开发人员可以创建具有 通用接口的类群，但是它们的==行为取决于模板的类型参数==。

模板参数可以是任意类型——具有自己的一组成员函数的类类型或是具有内建运算符的基本类型。

因此，存在两种接口：模板类的 public 成员，以及由在模板参数上被调用的运算符和函数所定义的接口。
抽象基类中定义的接口是非常`严格`的，继承类`必须实现`在抽象基类中定义的所有函数。
而通过模板定义的接口就没有这么严格了。只有参数中那些`实际`会被模板的某种特化所调用的函数`才需要`被定义。

模板的特性是一把双刃剑：
一方面，即使开发人员在某个模板特化中忘记实现接口了，编译器也不会立即报出错误消息；
但另一方面，开发人员也能够选择不去实现那些在上下文中没被用到的函数。

从性能优化的角度看，`多态类层次 与 模板实例`之间的==最重要的区别是，通常在编译时整个模板都是可用的==。
在大多数用例下，C++ 都会==内联==函数调用，用多种方法改善程序性能

模板编程提供了一种强力的优化手段。
对于那些不熟悉模板的开发人员来说，需要学习如何高效地使用 C++ 的这个特性

。。。没例子啊。

### 7.2.7 避免使用 PIMPL 惯用法

PIMPL 是“Pointer to IMPLementation”的缩写，它是一种用作编译防火墙 ——一种防止修改一个头文件会触发许多源文件被重编译的机制——的编程惯用法

20 世纪 90 年代是 C++ 的快速成长期，在那时使用 PIMPL 是合理的，因为在那个年代，大型程序的编译时间是以小时为单位计算的。

下面是 PIMPL 的工作原理。

假设 BigClass 是一个被其他类广泛使用的类，它有一些内联函数，而且使用了 Foo 类、Bar 类和 Baz 类。
一般情况下，bigclass.h、foo.h、bar.h 或是 baz.h 的任何改动，哪怕只是代码注释中的一个字符发生了变化，都会触发许多引用了 bigclass.h 的文件被重编译。

。。是因为 #include 导致的?

```C++
// bigclass.h
# include "foo.h"
# include "bar.h"
# include "baz.h"
class BigClass {
public:
    BigClass();
    void f1(int a) { ... }
    void f2(float f) { ... }
    Foo foo_;
    Bar bar_;
    Baz baz_;
};
```

要实现 PIMPL，开发人员要定义一个新的类，在本例中，我们将其命名为 Impl 。
bigclass.h 如下
```C++
class Impl;
class BigClass {
public:
    BigClass();
    void f1(int a);
    char f2(float f);
    Impl* impl;
};
```

C++ 允许声明一个指向未完成类型，即一个还没有定义的对象的指针。
在本例中，Impl 就是一个未完成类型。
在实现 PIMPL 后，BigClass 的对外可见的定义不再依赖 foo.h、bar.h 或 baz.h 了

bigclass.cpp
```C++
# include "foo.h"
# include "bar.h"
# include "baz.h"
# include "bigclass.h"

class Impl {
    void g1(int a);
    void g2(float f);
    Foo foo_;
    Bar bar_;
    Baz baz_;
};

void Impl::g1(int a) {
   ...
}
char Impl::g2(float f) {
   ...
}
void BigClass::BigClass() {
    impl_ = new Impl;
}
void BigClass::f1(int a) {
    impl_ -> g1(a);
}
char BigClass::f2(float f) {
    return impl_ -> g2(f)
}
```

实现了 PIMPL 后，在编译时，对 foo.h、bar.h 或 baz.h，或者是对 Impl 的实现的改动都会导致 bigclass.cpp 被重编译，但是 bigclass.h 不会改变，这样就限制了重编译的范围。

。。.h中保存的是 指针，指针没有发生变化。

在运行时情况就不同了。
PIMPL 给程序==带来了延迟==。
==之前== BigClass 中的成员函数可能会被==内联==，而==现在==则会发生一次==成员函数调用==。

每次成员函数调用 都要调用 Impl的成员函数， 而且 这里使用了 PIMPL 意味着 工程中其他地方 也使用了 PIMPL， 这样 函数的调用的 栈 会 深一倍。  调试也更难了。

2016 年，PIMPL 已经不是必需的了，因为编译时间可能已经减少至了 20 世纪 90 年代的 1%。
而且，即使是在 20 世纪 90 年代，也只有当 BigClass 是一个非常大的类，依赖于许多头文件时，才需要使用 PIMPL。这样的类违背了许多面向对象编程原则。
采用将 BigClass 分解，使接口功能更加集中的方法，可能与 PIMPL 同样有效。


### 移除对 DDL 的调用

在 Windows 上，当 DLL 被按需加载后在程序中显式地设置函数指针，或是在程序启动时自动地加载 DLL 时隐式地设置函数指针，然后通过这个函数指针调用动态链接库 （dynamic link library，DDL）。
Linux 上也有动态链接库，实现也是相同的。

有些 DLL 调用是必需的。
例如，应用程序可能需要实现第三方插件库。

其他情况下，DLL 则不是必需的。
例如，有时之所以使用 DLL 仅仅是因为它们修复了一些 bug。经验证明 bug 修复通常都是批量的，一次性覆盖了程序中的各个地方。这限制了在一个 DLL 中修复所有 bug 的可能性，破坏了 DLL 的用途。

另外一种改善函数调用性能的方式是不使用 DLL，而是使用对象代码库并将其链接到可执行程序上。


### 使用静态成员函数取代成员函数

每次对成员函数的调用都有一个额外的隐式参数：指向成员函数被调用的类实例的 this 指针
通过对 this 指针加上偏移量可以获取类成员数据。
虚成员函数必须解引 this 指针来获得虚函数表指针。

。。调用的时候 要 通过this 找到 函数表。

有时，一个成员函数中的处理仅仅使用了它的参数，而不用访问成员数据，也不用调用其他的虚成员函数。
在这种情况下，this 指针没有任何作用。

我们应当将这样的成员函数声明为静态函数。
静态成员函数不会计算隐式 this 指针，可以通过普通函数指针，而不是开销更加昂贵的成员函数指针找到它们


### 将虚析构函数移至基类中

任何有继承类的类的析构函数都应当被声明为虚函数。

这是有必要的，这样 delete 表达式将会引用一个指向基类的指针，继承类和基类的析构函数都会被调用。

另外一个在继承层次关系顶端的基类中声明虚函数的理由是：确保在基类中有虚函数表指针。

继承层次关系中的基类处于一个特殊的位置。
如果在这个基类中有虚成员函数声明，那么虚函数表指针在其他继承类中的==偏移量是 0==；
如果这个基类声明了成员变量且没有声明任何虚成员函数，但是有些继承类却声明了虚成员函数，那么每个虚成员函数调用都会在 this 指针上加上一个偏移量来得到虚函数表指针的地址。
确保在这个基类中至少有一个成员函数，可以强制虚函数表指针出现在偏移量为 0 的位置上，这有助于产生更高效的代码。

析构函数则是最佳候选


## 7.3 优化表达式

在语句级别下面是涉及基本数据类型（整数、浮点类型和指针）的数学计算。这也是最后的优化机会。如果一个热点函数中只有一条表达式，那么它可能是唯一的优化机会。

### 简化表达式 ==多项式霍纳法则==

用于计算多项式的霍纳法则（Horner Rule）证明了以一种更高效的形式重写表达式有多么厉害

多项式 `y = ax^3 + bx^2 + cx + d` 可以写为
`y = a*x*x*x + b*x*x + c*x + d;`
执行 6 次乘法运算和 3 次加法运算

根据霍纳法则 重复地使用 分配律 来重写
`y = (((a*x + b)*x) + c)*x + d;`
执行 3 次乘法运算和 3 次加法运算


通常，霍纳法则可以将表达式的 乘法 运算次数从 n*(n -1) 减少为 n ，其中 n 是多项式的维数。


### 将常量组合在一起

`seconds = 24 * 60 * 60 * days;`
编译器会计算表达式中的常量部分，产生类似下面的表达式：
`seconds = 86400 * days;`

但写成
`seconds = 24 * days * 60 * 60;`
编译器只能在运行时进行乘法计算了。

我们应当总是用括号将常量表达式组合在一起，或是将它们放在表达式的左端，或者更好的一种的做法是，将它们独立出来初始化给一个常量，或者将它们放在一个常量表达式（constexpr）函数中


### 使用更高效的运算符

乘法 变 位移
`x*4`  ->  `x<<2`

乘法 变 位移+加法
`x*9` -> `(x<<3) + x`


### 使用整数计算替代浮点型计算

浮点型计算的开销是昂贵的

下面是 将2个整数 相除，然后 四舍五入到 整数。
`unsigned q = (unsigned)round((double)n / (double)d));`

```C++
inline unsigned div0(unsigned n, unsigned d) {
    auto r = ldiv(n, d);
    return (r.rem >= (d >> 1)) ? r.quot + 1 : r.quot;
}
```

第二个方法比 第一个方法 快6倍。

```C++
inline unsigned div1(unsigned n, unsigned d) {
    unsigned q = n / d;
    unsigned r = n % d;
    return r >= (d >> 1) ? q + 1 : q;
}
```
比第一个 快22倍

```C++
inline unsigned div2(unsigned n, unsigned d) {
    return (n + (d >> 1)) / d;
}
```
比第一个快30倍。  这个要注意 + 可能溢出 21.49亿


### 7.3.5 双精度类型可能会比浮点型更快


```C++
float d, t, a = -9.8f, v0 = 0.0f, d0 = 100.0f;
for (t = 0.0; t < 3.01f; t += 0.1f) {
    d = a*t*t + v0*t + d0;
```

```C++
double d, t, a = -9.8, v0 = 0.0, d0 = 100.0;
for (t = 0.0; t < 3.01; t += 0.1) {
    d = a*t*t + v0*t + d0;
```

执行1000万次，第一个1889ms， 第二个989ms，第二个快一倍。

Visual C++ 生成的浮 点型指令 会引 用老式 的“x87 FPU coprocessor”寄存器栈。
在这种情况下，所有的浮点计算都会以 80 位格式进行。当单精度 float 和双精度 double 值被移动到 FPU 寄存器中时，它们都会被加长。对 float 进行转换的时间可能比对 double 进行转换的时间更长。

有多种编译浮点型计算的方式。在 x86 平台上，使用 SSE 寄存器允许直接以四种不同大小完成计算。使用了 SSE 指令的编译器的行为可能会与为非 x86 处理器进行编译的编译器不同。


### 用闭形式替代迭代计算

判断一个数是不是2的幂

```C++
inline bool is_power_2_iterative(unsigned n) {
    for (unsigned one_bits = 0; n != 0; n >>= 1)
        if ((n & 1) == 1)
            if (one_bits != 0)
                return false;
            else
                one_bits += 1;
    return true;
}
```

```C++
inline bool is_power_2_closed(unsigned n) {
    return ((n != 0) && !(n & (n - 1)));
}
```
第二个快2.3倍。

推荐书籍: Hacker's Delight


## 7.4 优化控制流程惯用法

如在 2.2.7 节中所讲过的，由于当指令指针必须被更新为 `非连续地址`时在处理器中会发生 `流水线停顿`，因此计算比控制流程更快。
C++ 编译器会努力地减少指令指针更新的次数。

### 使用switch代替if-else

if-else 是线性的，判断分支需要 O(n)

switch 语句也会测试一个变量是否等于这 n 个值，但是由于 switch 语句的形式比较特殊，它用 switch 的值与一系列常量进行比较，这样编译器可以进行一系列有效的优化。

switch会被编译为 jump指令， 如果 case的范围很小，那么直接 通过下标索引， O(1)
如果case的范围很大，那么 二分搜索， O(nlogn)

任何情况下，switch的速度 >= if-else的速度
如果 if-else的 某个分支 可能性很大，且 这个分支 是第一个分支，那么 性能 可能和 switch 接近，即 O(1) 判断 分支。


### 用虚函数替代 switch 或 if

C++出现之前，如果要 多态，那么他们必须编写一个带有标识变量的结构体或是联合体，然后通过这个标识变量来辨别出当前使用的是哪个结构体或是联合体。
程序中应该会有很多类似下面的代码：
```C++
if (p->animalType == TIGER) {
    tiger_pounce(p->tiger);
}
else if (p->animalType == RABBIT) {
    rabit_hop(p->rabbit);
}
else if (...)
```

从性能优化的角度看，这段代码的`问题在于`使用了 if 语句来识别对象的继承类型。
C++ 类已经包含了一种机制来实现此功能：虚成员函数和作为识别器的虚函数表指针。


### 使用无开销的异常处理

异常处理是应当在`设计阶段`就进行优化的项目之一。
错误传播方法的设计会影响程序中的每一行代码，因此`改造`程序的异常处理的代价可能会非常昂贵。

如果程序不使用异常处理，那么关闭编译器的异常处理开关可以使得程序变得更小，而且可能更快。测量到性能差距在 1.4% 和 4% 之间。

但是 C++ 标准库中的所有容器都使用 new 表达式来抛出异常。
许多其他库，包括本书中会讲解的流 I/O 和并发库（请参见第 12 章）都会抛出异常。
dynamic_cast 运算符也会抛出异常。
如果关掉了异常处理，无法确定当程序遇到异常被抛出的情况时会如何。

如果程序不抛出异常，它可能会`完全忽略错误码`。那么在这种情况下，开发人员就会得到报应了。

另外一种情况是，程序必须在各层函数调用之间耐心地、小心地传递错误码，然后在调用库函数的地方将错误码从一种形式转换为另一种形式并相应地释放资源。而且，无论每次运算是成功还是失败，都不能遗漏这些处理。

如果有异常，`处理错误的部分开销`就被从程序执行的正常路径`转移至错误处理路径`上。
除此之外，编译器会通过调用在抛出异常和 try/catch 代码块之间的执行路径上的所有自动变量的析构函数，自动地回收资源。这`简化`了程序执行的正常路径的逻辑，从而提升性能。

在 C++ 的早期，每个栈帧都包含一个异常上下文：一个指向包含所有被构建的对象的链表的指针，因此当异常穿过栈帧被抛出时，这些对象也必须被销毁。
随着程序的执行，这个上下文会被动态地更新。
这并非大家所希望看到的，因为这导致了在程序执行的`正常路径`上增加了`运行时开销`。
这可能会是高开销的异常处理之源。

后来出现了一种==新的实现方式==，它的原理是将那些需要被销毁的对象映射到指令指针值上。除非抛出了异常，否则这种机制`不会`发生任何`运行时开销`。


---

==不要使用异常规范==

异常规范是对函数声明的修饰，指出函数可能会抛出什么异常。

不带有异常规范的函数抛出异常可能不会有任何惩罚。

而带有异常规范的函数可能`只会`抛出在规范中列出的异常。但是如果它抛出了`其他`异常，那么程序会被 terminate() 无条件地`立即终止`。

一个问题是开发人员很难知道被调用的函数可能会抛出什么异常，特别是在使用不熟悉的库时。这使得使用了异常规范的程序变得脆弱且可能会突然停止。

第二个问题是异常规范对性能有负面影响。程序必须要检查被抛出的异常，就像是每次对带有异常规范的函数的调用都进入了一个 try/catch 代码块一样。


C++11 ==弃用==了传统的异常规范。

在 C++11 中引入了一种新的异常规范，称为 ==noexcept== 。
声明一个函数为 noexcept 会告诉编译器这个函数不可能抛出任何异常。
如果这个函数抛出了异常，那么如同在 throw() 规范中一样，terminate() 将会被调用。

编译器要求将`移动构造`函数和`移动赋值`语句声明为 noexcept 来实现移动语义



# ch8 使用更好的库

库函数和类常常被用在嵌套循环的最底层，因此通常它们都是热点代码。

## 8.1 优化标准库的使用

C++为以下功能提供了 一个简洁的标准库
- 确定那些依赖于实现的行为，如每种数值类型的最大值和最小值。
- 最好不要在 C++ 中编写的函数，如 strcpy() 和  memmove() 。
- 易于使用但是编写和验证都很繁琐的可移植的超越函数（transcendental function），如正弦函数和余弦函数、对数函数和幂函数、随机数函数，等等。
- 除了内存分配外，不依赖于操作系统的可移植的通用数据结构，如字符串、链表和表。
- 可移植的通用数据查找算法、数据排序算法和数据转换算法。
- 以一种独立于操作系统的方式与操作系统的基础服务相联系的执行内存分配、操作线程、管理和维护时间以及流 I/O 等任务的函数。考虑到兼容性，这其中包含了一个继承自 C 编程语言的函数库。


### C++标准库的哲学

C++ 标准库之所以提供这些函数和类，是因为要么无法以其他方式提供这些函数和类，要么这些函数和类会被广泛地用于多种操作系统上 。

C++ 的这种实现方法的优点包括 C++ 程序能够运行于没有提供任何操作系统的硬件之上

相比之下，包括 C# 和 Java 在内的部分编程语言提供了包括视窗用户接口框架、Web 服务器、套接字网络和其他大型子系统等在内的大量标准库。
提供整体标准库的优点在于，开发人员只需学习如何在所有支持的平台上让一套库高效运行就可以了。
但是这样的库都对操作系统有要求（有时是厂商有意为之）。
随着编程语言提供的这些库还代表着一个最小共通功能的集合，它们没有原生视窗系统或是任何特定操作系统的联网能力那么强大。
因此它们会在某种程度上限制习惯了某种特定操作系统的原生能力的程序员。


### 使用C++标准库的注意事项

尽管下面的讨论是针对 C++ 标准库的，但它同样适用于标准 Linux 库、POSIX 库或是其他任何被广泛使用的跨平台库。
在使用上的问题包括如下这些。

---

- 标准库的实现中有bug
- 标准库的实现可能不符合 C++ 标准
- 对标准库开发人员来说，性能并非最重要的事情。 他们追求 简单和可维护，可移植
- 库的实现可能会让一些优化手段无效
- 并非 C++ 标准库中的所有部分都同样有用
- 标准库不如最好的原生函数高效


## 8.2 优化现有库

最容易优化的库是设计良好、低耦合和带有优秀测试用例的库。不幸的是，这类库通常都已经被优化过了

现实情况是，如果你被要求去优化一个库，那么它可能是一堆功能耦合在了函数或类中，而这些函数或类要么做了太多事情，要么什么都没做。


### 改动越少越好

不要向类或函数中添加或移除功能，也不要改变函数签名。
这类改动几乎肯定会破坏修改后的库与使用库的程序之间的兼容性。

### 添加函数，不要改动功能

在优化现有库的黑暗世界中也有一丝希望，那就是在现有库中加入新函数和类是相对安全的。

当然，这也存在着一种风险，因为该库`以后的版本`中可能会出现一个与我们新加入的类或函数`同名`的类或者函数。
当然，只要谨慎地选择名字，这种风险就是可控的，而且即使发生了重名问题，也可以`编写宏来解决`。
。。宏 怎么解决?。。

以下是一些安全地修改现有库来提高性能的方法。
- 向现有库中添加函数，将循环处理移动到这个新函数内，在你的代码中使用编程惯用法。
- 通过向现有库中添加接收右值引用作为参数的新函数，重载现有库中的旧函数来在老版本的库中实现移动语义

。。第一个就是 原先是 for() { lib.fun() } ,改成 lib.fun_all(vector) { 复制fun的函数体 } 。 就是变成 内联。 。 库函数没有办法内联，只有 link的时候才知道， 所以 只能 在 库中增加 fun的 多元素版本。


## 8.3 设计优化库

库已经完成，那么很难优化

设计库时，优化是比较简单的。

### 草率编码后悔多

接口的稳定性是设计可持续交付的库的核心

设计优化库与设计其他 C++ 代码是一样的，不过风险更高 

### 在库的设计上，简约是一种美德

SOLID
单一职责
开闭
里氏替换
接口隔离
依赖倒置

### 不要在库内分配内存

将内存分配移动到库函数外部，可以允许`调用方`实现第 6 章中介绍过的性能优化方法——在每次调用函数时尽可能地`重用内存`，而不是分配新的存储空间。

将内存分配移动到库外部，还可以减少在函数之间传递数据时保存数据的存储空间被复制的次数。

如果有必要，可以将内存分配放到继承类中，然后在基类中仅仅保存一个指向已分配内存的指针。这种方式可以让继承类以不同的方式分配内存。

### 若有疑问，以速度为准

对于库类或是库函数，优秀的性能特别重要

### 函数比框架更容易优化

库可以分为两种：函数库和框架。

框架在概念上是一个非常庞大的类，它实现了一个完整程序的骨架，例如一个视窗应用程序或是一个 Web 服务器。

第二种库是函数和类等组件的集合，可以将它们组合起来实现程序，例如 Web 服务器中的 URI 解析或是视窗应用程序中的文本绘制。

函数的优势在于我们可以独立地测量和优化它们的性能。
调用一个框架会牵扯到它内部的所有类和函数，使得修改变得难以隔离和测试

### 扁平继承层次关系

多数抽象都不会有超过三层类继承层次 ：
一个具有通用函数的基类，
一个或多个实现多态的继承类，
一个在非常复杂的情况下可能会引入的多重继承混合层。

一旦继承层次超过了三层，这就是一个信号，表明类的层次结构不够清晰，其引入的复杂性会导致性能下降。

从性能优化的角度看，继承层次越深，在成员函数被调用时引入额外计算的风险就越高


### 扁平调用链

与继承类一样，绝大多数抽象的实现都不会超过三层嵌套函数调用 ：
一种非成员函数或是成员函数实现策略，
调用某个类的成员函数，
调用某个实现了抽象或是访问数据的公有或私有的成员函数。


### 扁平分层设计


### 避免动态查找

大型程序包往往含大量的配置信息或是注册表项

少量信息，直接用 struct保存 (。。struct的一个属性名 就是key)
信息多了以后，就 会保存为map
如果信息是组合为 json或xml的，那么不会动，因为 json xml 库有很多。

- 动态查找天生低效，有些库查找Json，Xml的性能是 O(n)， 基于map的查询 可能是 O(nlogn)， struct是 O(1)
- 库的设计人员可能对库需要访问的元数据不太了解。
- 一致性。对于一个给定的变换，表中包含了所有所需的元数据吗？必须成对出现的命令行参数真的成对出现了吗
- 基于结构体的数据仓库在某种程度上可以说是自描述的，因为所有可能的元数据都是立即可见的。相比之下，符号表则是一个不透明的大包包，里面装满了未命名的值。


### 留意"上帝函数"

“上帝函数”是指实现了高级策略的函数。

如果在程序中使用这种函数，会导致链接器向可执行文件中添加许多库函数


```C++
# include <stdio.h>
int main(int, char**) {
    printf("Hello, World!\n");
    return 0;
}
```

上面的编译完 8kb，下面的100字节。
因为 printf 自身就是一个大函数， 而且 引入了格式化各种基本类型的标准库函数

```C++
# include <stdio.h>
int main(int, char**) {
    puts("Hello, World!");
    return 0;
}
```


# ch9 优化查找和排序

## 9.1 使用std::map 和 std::string的键值对表

我们通常会使用这样的表 (。。指 `std::map<std::string, xxxx>`) 来解析初始化配置、命令行、XML 文件、数据库表以及其他需要有限组键的应用程序

除非有一个非常大的值会影响高速缓存性能，否则值的类型对查找操作的性能不会有影响

这里使用 unsigned 作为 value

如果使用的是支持 C++11 的编译器，开发人员可以如下这样使用初始化列表
```C++
std::map<std::string, unsigned> const table {
    { "alpha",   1 },   { "bravo",   2 },
    { "charlie", 3 },   { "delta",   4 },
    { "echo",    5 },   { "foxtrot", 6 },
    { "golf",    7 },   { "hotel",   8 },
    { "india",   9 },   { "juliet", 10 },
    { "kilo",   11 },   { "lima",   12 },
    { "mike",   13 },   { "november",14 },
    { "oscar",  15 },   { "papa",   16 },
    { "quebec", 17 },   { "romeo",  18 },
    { "sierra", 19 },   { "tango",  20 },
    { "uniform",21 },   { "victor", 22 },
    { "whiskey",23 },   { "x-ray",  24 },
    { "yankee", 25 },   { "zulu",   26 }
};
```


使用 std::map 创建表是一个例子，它向我们展示了 C++ 标准库提供了多么强大的抽象能力，让我们无需太多思考和编码即可实现不错的大 O 性能


## 9.2 改善查找性能的工具箱

假如分析器指出一个包含查找表操作的函数是程序中最热点的函数之一，应该怎么办呢？
例如下面这个函数

```C++
void HotFunction(std::string const& key) {
    ...
    auto it = table.find(key);
    if (it == table.end()) {
    // 没有在表中找到元素时的活动
        ...
    }
    else {
    // 在表中找到元素时的活动
        ...
    }
    ...
}
```
。。unordered_map。 而且 问题应该不是 find 的吧， 应该是 if else 里的内容。

经验丰富的 直接看出来，然后改。
另外一种较好的做法是，开发人员有条理地推进性能优化工作。
- 测量当前的实现方式的性能来得到比较基准。
- 识别出待优化的抽象活动。
- 将待优化的活动分解为组件算法和数据结构。
- 修改或是替换那些可能并非最优的算法和数据结构，然后进行性能测试以确定修改是否有效果。

。。。讲了很多。但是。。

## 9.3 优化std::map的查找

### 以固定长度字符数组作为 std::map的键

如果key的最大长度不是特别大
`std::map<char[10],unsigned> table` 不过无法使用，因为 C++数组 没有内置比较运算符

```C++
template <unsigned N=10, typename T=char> struct charbuf {
    charbuf();
    charbuf(charbuf const& cb);
    charbuf(T const* p);
    charbuf& operator=(charbuf const& rhs);
    charbuf& operator=(T const* rhs);

    bool operator==(charbuf const& that) const;
    bool operator<(charbuf const& that) const;

private:
    T data_[N];
};
```

C++ 标准库通常只会使用  == 运算符和 < 运算符。其他四种运算符可以从这两种中合成出来。
运算符的定义可以是非成员函数：
```C++
template <unsigned N=10, typename T=char>
    bool operator<(charbuf<N,T> const& cb1, charbuf<N,T> const& cb2);
```

只有那些独立的设计团队才能`洞察`出这种改动的`收益`是否大于`风险`，权威专家的凭空判断不可信。

使用与之前相同的 53个名字 进行了 100万次测试，耗时 1331， 是 std::string 的一半。

### 9.3.2 以 C 风格的字符串组作为键使用 std::map

以 char* 作为键类型也有一个问题。虽然在 char* 中也定义了 < 运算符，但它比较的却是指针，而不是指针所指向的字符串。

比较算法是通过 std::map 的第三个模板参数提供的。
比较算法的默认值是函数对象 `std::less<Key>` 。std::less 定义了一个成员函数 bool operator()(Key const& k1, Key const& k2) ，它会通过返回表达式 key1 < key2 的结果来比较两个键的大小。

```C++
bool less_free(char const* p1, char const* p2) {
    return strcmp(p1,p2)<0;
}
   ...

std::map<char const*,
        unsigned,
        bool(*)(char const*,char const*)> table(less_free);
```
。。可以lambda吧?

测试结果是 1450 毫秒，与使用以 std::string 为键的版本相比有了显著的性能提
。。根据之前的 1331 是 一半 -> std::string 是2662ms

---

程序还可以创建一个函数对象来封装比较操作
```C++
struct less_for_c_strings {
    bool operator()(char const* p1, char const* p2) {
        return strcmp(p1,p2)<0;
    }
};

   ...

std::map<char const*,
        unsigned,
        less_for_c_strings> table;
```

测试结果是 820 毫秒，它的速度几乎是初始版本的三倍，是 char* 和非成员函数版本的两倍。

---

lambda

```C++
auto comp = [](char const* p1, char const* p2) {
    return strcmp(p1,p2)<0;
};
std::map<char const*,
        unsigned,
        decltype(comp)> table(comp);
```

改善后的最佳性能约是初始版本的三倍，即使与使用固定长度的字符数组为键的版本相比也提高了 55%。


### 9.3.3 当键就是值时，使用std::set



## 9.4 使用 algorithm 优化算法

C++ 标准库还提供了一组算法，其中就包括查找和排序算法。标准库算法接收迭代器 作为参数。

迭代器抽象了指针的行为，从包含这些值的数据结构中分离出值的遍历


### 使用序列容器代替键值对表

序列容器消耗的内存比 map 少，它们的启动开销也更小。

```C++
struct kv { // （键，值）对
    char const* key;
    unsigned    value; // 可以是任何类型
};
```

```C++
kv names[] = {// 以字母顺序排序
    { "alpha",   1 },   { "bravo",    2 },
    { "charlie", 3 },   { "delta",    4 },
    { "echo",    5 },   { "foxtrot",  6 },
    { "golf",    7 },   { "hotel",    8 },
    { "india",   9 },   { "juliet",  10 },
    { "kilo",   11 },   { "lima",    12 },
    { "mike",   13 },   { "november",14 },
    { "oscar",  15 },   { "papa",    16 },
    { "quebec", 17 },   { "romeo",   18 },
    { "sierra", 19 },   { "tango",   20 },
    { "uniform",21 },   { "victor",  22 },
    { "whiskey",23 },   { "x-ray",   24 },
    { "yankee", 25 },   { "zulu",    26 }
};
```

names 数组的初始化是静态集合初始化。


标准库容器类提供了 begin() 和 end() 成员函数，这样程序就能够得到一个指向待查找范围的迭代器。
C 风格的数组更加简单，通常没有提供这些函数。可以通过用一点模板“魔法”提供类型安全的模板函数来实现这个需求。由于它们接收一个数组类型作为参数，数组并不会像通常那样退化为一个指针

在 C++11 中，我们可以在头文件中的命名空间 std 中，找到使用相同的模板“魔法”实现的更复杂的 begin() 和 end() 的定义。
```C++
// 得到C风格数组的大小和起始或终止位置
template <typename T, int N> size_t size(T (&a)[N]) {
    return N;
}
template <typename T, int N> T* begin(T (&a)[N]) {
    return &a[0];
}
template <typename T, int N> T* end(T (&a)[N]) {
    return &a[N];
}
```

### std::find(), O(n)开销

algorithm中有 一个模板函数find:
`template <class It, class T> It find(It first, It last, const T& key)`

find是线性查找。返回第一个和待查找key相等的元素的迭代器

`kv* result=std::find(std::begin(names), std::end(names), key);`

### std::binary_search(): 不返回值

返回一个 bool 值，表示键是否存在于有序表中。


### 使用std::equal_range()的二分查找

```C++
template <class ForwardIt, class T>
    std::pair<ForwardIt,ForwardIt>
        equal_range(ForwardIt first, ForwardIt last, const T& value);
```

equal_range() 会返回一对迭代器，它们确定的是范围是有序序列中包含要查找的元素的子序列 `[first, last)` 。
如果没有找到元素，equal_range() 会返回一对指向`相等值`的迭代器，这表示这个范围是空的。

如果返回的两个迭代器不等，表示至少找到了一条元素

```C++
auto res = std::equal_range(std::begin(names), std::end(names), key);
kv* result = (res.first == res.second) ? std::end(names) : res.first;
```

测试结果表明这个比 find 更慢

### 9.4.4 使用 std::lower_bound() 的二分查找

尽管 equal_range() 所承诺的时间开销是 O (logn )，但除了表查找以外，它还有其他不必要的功能。
equal_range() 的一种可能实现方式看起来像下面这样

```C++
template <class It, class T>
    std::pair<It,It>
        equal_range(It first, It last, const T& value) {
    return std::make_pair(std::lower_bound(first, last, value),
                          std::upper_bound(first, last, value));
}
```

其实我们可以使用 lower_bound() 和一次额外的比较运算来进行查找就足够了

```C++
kv* result = std::lower_bound(std::begin(names), std::end(names), key);
if (result != std::end(names) && key < *result.key)
    result = std::end(names);
```

比 equal_range 快了 86%
和 binary_search 一样快，但是 binary_search返回 bool


### 自己编写二分查找法

```C++
kv* find_binary_lessthan(kv* start, kv* end, char const* key) {
    kv* stop = end;
    while (start < stop) {
        auto mid = start + (stop-start)/2;
        if (*mid < key) {// 查找右半部分[mid+1,stop)
            start = mid + 1;
        }
        else {// 查找左半部分[start,mid)
            stop = mid;
        }
    }
    return (start == end || key < *start) ? end : start;
}
```

时间和lower_bound 一样。

### 使用strcmp自己编写二分查找法

如果注意到 < 运算符可以用 strcmp() 替换，那么还可以进一步提高性能。
与 < 运算符一样，strcmp() 也会对两个键进行比较，但是 strcmp() 的输出结果包含的信息更多：如果第一个键小于、等于、大于第二个键，那么其返回结果就小于、等于、大于 0。

```C++
kv* find_binary_3(kv* start, kv* end, char const* key) {
    auto stop = end;
    while (start < stop) {
        auto mid = start + (stop-start)/2;
        auto rc = strcmp(mid->key, key);
        if (rc > 0) {
            stop = mid;
        }
        else if (rc < 0) {
            start = mid + 1;
        }
        else {
            return mid;
        }
    }
    return end;
}
```

比 lower_bound 快 26%

。。有这么快吗。就多了一个 rc = 0 的分支 啊。


## 9.5 优化键值对散列表中的查找

C++ 定义了一个称为 std::hash 的标准散列函数对象。
std::hash 是一个模板，为整数、浮点数据、指针和 std::string 都提供了特化实现。
同样适用于指针的未特化的 std::hash 的定义会将散列类型转换为 size_t ，然后随机设置它的各个位的值。

### std::unordered_map 进行散列

std::unordered_map 无法与上一节示例程序中自己编写的静态表一起使用。
我们必须将元素插入到散列表中，这会增加构建散列表的性能开销。

不计算构建时间，只计算查找时间， unordered_map 比使用 std::string的map 快 56%

这并不是理想的结果。

### 对固定长度字符数组的键进行散列

下面这个模板继承了 charbuf ，提供了对字符串进行散列的方法以及在发生冲突的情况下可以比较键的 == 运算符

```C++
template <unsigned N=10, typename T=char> struct charbuf {
    charbuf();
    charbuf(charbuf const& cb);
    charbuf(T const* p);
    charbuf& operator=(charbuf const& rhs);
    charbuf& operator=(T const* rhs);

    operator size_t() const;

    bool operator==(charbuf const& that) const;
    bool operator<(charbuf const& that) const;
private:
    T data_[N];
};
```

散列函数是运算符 size_t() 。这有一点不直观，还有一点不纯净。std::hash() 的默认特化实现会将参数转换为 size_t 。

`std::unordered_map<charbuf<>, unsigned> table;`

比 `map<string, usigned>` 更差。


### 以\0结尾的字符串为key 进行散列

如果能够用如 C++ 字符串字面常量这样的存储期很长的以空字符结尾的字符串来初始化散列表，那么就可以用指向这些字符串的指针来构造基于散列值的键值对表。
以 char* 为键配合 std::unordered_map 一起使用是一座值得挖掘的性能金矿

std::unordered_map 的完整定义是
```C++
template<
    typename Key,
    typename Value,
    typename Hash = std::hash<Key>,
    typename KeyEqual = std::equal_to<Key>,
    typename Allocator = std::allocator<std::pair<const Key, Value>>
> class unordered_map;
```

如果key是指针，可以用，但是 逻辑是错误的， 因为 指针的hash 是 指针地址的hash，而不是指针指向的对象的hash

```C++
struct hash_c_string {
    void hash_combine(size_t& seed, T const& v) {
        seed ^= v + 0x9e3779b9 + (seed << 6) + (seed >> 2);
    }

    std::size_t operator() (char const* p) const {
        size_t hash = 0;
        for (; *p; ++p)
            hash_combine(hash, *p);
        return hash;
    }
};

// 这种解决方法是不完整的，理由请往下看
std::unordered_map<char const*, unsigned, hash_c_string> table;
```
问题出在 std::unordered_map 模板的第四个参数 KeyEqual 上。
这个参数的默认值是  std::equal_to ，一个使用 == 比较两个运算对象的函数对象。
虽然指针定义了 == 运算符，但它比较的是指针在计算机内存空间中的顺序，而不是指针所指向的字符串。

解决方式是提供另外一个非默认的函数对象替代 KeyEqual 模板参数。
完整的解决方案代码如下
```C++
struct hash_c_string {
    void hash_combine(size_t& seed, T const& v) {
        seed ^= v + 0x9e3779b9 + (seed << 6) + (seed >> 2);
    }

    std::size_t operator() (char const* p) const {
        size_t hash = 0;
        for (; *p; ++p)
            hash_combine(hash, *p);
        return hash;
    }
};

struct comp_c_string {
    bool operator()(char const* p1, char const* p2) const {
        return strcmp(p1,p2) == 0;
    }
};

std::unordered_map<
    char const*,
    unsigned,
    hash_c_string,
    comp_c_string
> table;
```

比 `unordered_map<string, xx>` 快了 73%
比 `map<char*, xx>` 快了 9%

而且无法 二分。

还是不理想


### 9.5.4 用自定义的散列表进行散列

```C++
unsigned hash(char const* key) {
    if (key[0] < 'a' || key[0] > 'z')
        return 0;
    return (key[0]-'a');
}

kv* find_hash(kv* first, kv* last, char const* key) {
    unsigned i = hash(key);
    return strcmp(first[i].key, key) ? last : first + i;
}
```

find_hash 的性能非常出色。

GNU 计划（还有其他项目）构建了一个称为 gperf（http://www.gnu.org/software/gperf/ ）的命令行工具，它所生成的完美散列函数通常也是最小散列函数。


## 9.6 斯特潘诺夫的抽象惩罚

C++ 标准库提供了一组直接可用且经过调试的算法和数据结构，它们能够适用于许多情况。C++ 标准定义了最差情况下的大 O 时间开销，来证明这些算法和数据结构是能够被广泛地使用的。

但是使用标准库的这种极其强大和通用的机制是有开销的。
即使标准库算法具有优秀的性能，它也往往无法与最佳手工编码的算法匹敌

这个存在于标准算法和手工编写的优秀算法之间的鸿沟被称为“斯特潘诺夫的抽象惩罚”，它是以亚历山大 • 斯特潘诺夫的名字命名的

。。但是绝大多数的人应该不会遇到这个鸿沟吧

## 9.7 使用C++标准库优化排序

std::sort, std::stable_sort

稳定排序 （stable sort）的==价值==是程序能够==按照若干个条件==（例如首先是姓，接着是名）对某个范围内的记录进行==排序==，并==先==将记录按照第二个条件进行排序，==然后==在这个基础上按照第一个条件排序（如首先是对名字排序，接着是在名字的基础上对姓氏排序）

algorithm 还提供了一些其他排序
- std::heap_sort，将具有堆属性的 范围转为 有序范围
- std::partition，执行快速排序的基本操作
- std::merge，执行归并排序的基本操作
- 序列容器的insert，执行插入排序


# ch10 优化数据结构

## 序列容器

序列容器: std::string, vector, deque, list, forward_list
除了 forward_list，所有容器 都能 常量时间 将 元素 推入到 序列容器的末尾。
只有 deque，list，forward_list 能高效地 将元素 推入到 序列容器的 头部

string,vector,deque 的元素的  索引是 0 - size-1， 能通过下标 快速访问

list，forward_list 没有下标运算符

## 关联容器

所有的关联容器 都会按照元素的==某种属性上的顺序==关系，而不是按照插入的顺序来保存元素

map,set,multimap,multiset

所有的四种关联容器都是基于相同的 平衡二叉树数据结构实现的

---

C++11 带来了4种 无序关联容器
std::unordered_map, unordered_multimap, unordered_set, unordered_multiset

无序关联容器只要求对键（std::unordered_map ）或是元素（std::unordered_set ）==定义了相等关系即可==

---


虽然==查找==操作的时间开销为 O (1) 的 unordered_map 比 map 更快，但差距其实并==没有==我预想的那么大。
而且为了达到这种性能，它所==消耗的内存量非常大==。

---

高效地使用 std::vector 的一个秘诀是，通过调用 void ==reserve==(size_t n) 预留出足够多的 capacity ，这样可以防止发生不必要的重新分配和复制的开销。

高效地使用 std::vector 的另外一个秘诀是，即使其中的元素被移除了，它也==不会==自动将内存返回给内存管理器
当开发人员在存储空间极度有限的环境中使用 std::vector 时，必须时刻注意这一点。

void clear() 会设置容器的大小为 0，但并`不一定`会重新分配内部存储空间来减小 vector 的容量。

void shrink_to_fit() 可以提示  vector 将容量缩减至当前的大小，但并不强制进行重新分配。

要想确保在所有版本的 C++ 中都能释放 vector 的内存，可以使用以下技巧
```C++
std::vector<Foo> x;
    // 许多insert 到 x
vector<Foo>().swap(x);
```

---

### vector的插入与删除

1. 复制
`v1=v2;` 复制最快，因为知道size， 复制10万个元素的vector， 0.445ms

2. insert range
`v1.insert(v1.end(), v2.begin(), v2.end())` 10万个元素， 0.696ms

3. push_back
```C++
for (auto it=random_vector.begin(); it!=random_vector.end(); ++it)
    test_container.push_back(*it);
```
或
```C++
for (unsigned i = 0; i < nelts; ++i)
    test_container.push_back(random_vector.at(i));
```
或
```C++
for (unsigned i = 0; i < nelts; ++i)
    test_container.push_back(random_vector[i]);
```
10万元素，分别是 2.26,2.05,1.99ms 。 是 赋值语句的 6倍。

reserve 预分配空间
```C++
test_container.reserve(nelts);
for (auto it=random_vector.begin(); it != random_vector.end(); ++it)
    test_container.push_back(*it);
```
0.674ms


`test_container.insert(test_container.end(), *it);`  insert到 end() 比 push_back 更慢。
使用迭代器，at()，下标，都是 2.7ms
reserve 是 1.45ms

---

vector的 超级弱点: 在前端插入元素

```C++
for (auto it=random_vector.begin(); it != random_vector.end(); ++it)
    test_container.insert(test_container.begin(), *it);
```

8065ms， 是 push_back的 4000倍，  insert(end()) 的 3000倍。

。。push_back + reverse 应该更快吧。


### 遍历vector

3种方法
- 迭代器
- at()
- 下标

累加所有元素， 迭代器0.236ms，  at 0.23ms，   下标 0.129ms

下标 只需要 其他2种方法的 一半时间。

。。at 带 越界检查，而且是 函数调用，  不过不知道 会不会 内联
。。迭代器 是 指针，需要 反引用，而且 迭代器需要调用 operator++， 每次比较时 调用 end() 方法。
。。下标 无敌。

---

排序

std::sort, stable_sort

差不多， 10万元素， 
无序 ， sort 18.61ms  unstable_sort 16.08ms
已有序，  sort 3.77ms  unstable_sort 5.01ms


---

查找

```C++
std::vector<kvstruct> sorted_container, random_vector;
   ...
for (auto it=random_vector.begin(); it!=random_vector.end(); ++it) {
    kp = std::lower_bound(
                sorted_container.begin(),
                sorted_container.end(),
                *it);
    if (kp != sorted_container.end() && *it < *kp)
        kp = sorted_container.end();
}
```

对每个元素都进行一次 二分查找 一共 28.92ms


## 10.3 std::deque

专门用于创建 FIFO 队列的容器

deque的 操作(插入，移除) 时间复杂度是 常量， 但它的常量 比 vector的常量 要大。

deque的操作 比 vector的慢 3-10倍
迭代，排序，查找，慢 30%

典型实现 ==数组的数组==
获取 deque中的元素 需要 2次 间接引用， 降低 缓存局部性
调用 内存管理器 也更频繁。   。。 估计是指 vector 是 1-2-4-8-16..  deque是 1-2-4-8，子数组满，新建数组 1-2-4-8，满了 再新建数组 继续 1-2-4-8

将一个元素加入到 deque 的任何一端都会导致最多调用内存分配器两次：一次是为新元素分配另一块存储元素的区域；另一次则可能没那么频繁，那就是扩展 deque 的内部数组。 

deque 没有 reserve

---

插入 删除

deque的 接口和 vector 一样，而且 还多了一个 push_front

deque赋值 `a=b;` 需要 5.7ms
`insert(a.end(), b.begin(), b.end());` 5.28ms
。。。vector 都是 0.6ms 左右
。。而且，这里 书上描述是 deque 赋值给另一个deque，但是 代码是 vector 赋值给 deque。。 2个都是 描述 deque -> deque, 但代码是 vector -> deque

3种方式 从vector push_back() 到 deque
迭代器 4.33ms
at 4.76ms
下标 5.01ms

push_front()
迭代器 5.19
下标 5.55

push_front 比 push_back 慢了 20%


insert 在 头 和尾 插入元素， 开销是 push_back push_front 的 2倍。

现在让我们来对比一下 std::vector 和 std::deque 的性能。
对于相同数量的元素，
vector 的赋值操作的性能是 deque 的 13 倍，
删除操作的性能是 deque 的 22 倍，
基于迭代器的插入操作的性能是 deque 的 9 倍，
push_back() 操作的性能是 deque 的 2 倍，
使用  insert() 在末尾插入元素的性能则是 deque 的 3 倍。


Note:
在调试模式下链接到 C++ 运行时库时会带有额外的调试检查
由于诊断代码被加入到了内存分配例程中，调试模式下的 std::deque 的性能开销变得格外昂贵。


---

==遍历==

下标 0.828ms
迭代器 0.45ms

deque的 迭代器(最优) 耗时 是 vector的下标(最优) 的 2倍

---

==排序==

sort 10万数据， 24.82ms  比 vector 慢33%
stable_sort  17.76ms  比vector 慢 10%

---

==查找==

查找所有的10万个键，35ms， 比vector 慢 20%

## 10.4 std::list

list太低效，不使用它 已经成为常识。

但是经过测试， 和 deque 有竞争力。 对于测试的大部分操作， list 都比 deque 快。

另一个常识是，对于它提供的特性而言，前向遍历、反向遍历和具有常量时间开销的 size() 方法都太过于昂贵。这种认识导致最终在 C++11 中引入了 std::forward_list 

不过，经过测试我发现，至少在 PC 硬件上，std::list 的各种操作的性能与 std::forward_list 几乎相同。

由于 std::list 没有可能会导致内存重新分配的内部骨架数组，插入操作永远不会使迭代器和引用失效。仅当它们所指向的链表元素被删除了时，它们才会失效

std::list 的一个`优点是在拼接`（O (1) 时间开销）和合并时无需复制链表元素。即使是像 splice 和 sort 这种操作也不会使 std::list 的迭代器失效。
在 list `中间插入`元素的时间开销是常数时间。 但是你得先知道 插入的位置。

std::list 能够以一种简单且可预测的方式与内存管理器交互。
当有需要时，list 中的每个元素会被分别分配存储空间。
在 list 中`不存在未使用`的额外的存储空间

list 中的每个元素所分配到的存储空间大小是相同的。
这有助于提高复杂的内存管理器的工作效率，也降低了出现内存碎片的风险。
我们还能够为 std::list 自定义简单的内存分配器，利用这个特性使其更高效地工作

。。甚至可以用 数组来完成 list ? 不，删除还是有问题的，会很多 空隙。 没有意义。  要用数组 为什么不用 vector 呢?


list 无法二分查找


## 10.5 std::forward_list

std::forward_list 是一种性能被优化到极限的序列容器。
它有一个指向链表头部节点的指针。
它的设计经过了深思熟虑，标准库的设计人员希望使它尽量贴近手动编码实现的单向链表。
它没有 back() 和 rbegin() 成员函数。

在我的 PC 上，std::forward_list 并没有比 std::list 快很多。
导致 std::list 性能变差的原因（为每个元素单独分配内存以及差劲的缓存局部性）也同样困扰着 std::forward_list 。
在`内存使用非常严格`的小型处理器上，std::forward_list `可能有用武之地`，但是在`桌面级和手持级处理器`上则`不建议`使用它。


## 10.6 std::map, std::multimap

map 的内部实现是一棵带有便于使用迭代器遍历的额外链接的平衡二叉树

std::map 没有内部骨干数组，不会重新分配存储空间，因此在插入元素后，指向元素的迭代器和引用永远不会失效。
只有当它们被删除后，迭代器和引用才会失效。
。。? 不对的， 迭代器会失效的， 毕竟  it = map2.erase(it) 。


---

如果只要知道是否找到了键即可，那么可以使用返回 pair 的版本的 insert()   。。。但是 无论如何 都会 insert的。
```C++
std::pair<value_t, bool> result = table.insert(key, value);
if (result.second) {
    // k找到key的分支
}
else {
    // 没有找到key的分支
}
```

使用lower_bound 找到位置

```C++
iterator it = table.lower_bound(key);
if (it == table.end() || key < it->first) {
    // 没有找到key的分支
    table.insert(it, key, value);
}
else {
    // 找到key的分支
    it->second = value;
}
```

---

遍历

10万元素，1.34ms， 是 vector的迭代器遍历的  10倍

---

排序

必须复制到 另一个map 才能重排序

---

查找

10万个元素，每个都查找一次， 42.3ms ，  对vector，deque进行二分 是 28.9ms 和 35.1ms


## 10.7 std::set, std::multiset

set 和 map的结构相同。

## std::unordered_map, std::unordered_multimap

尽管有多种方式能够实现散列表，但是只有采用了动态分配内存的骨干数组，然后在其中保存指向动态分配内存的节点组成的链表的`桶` 的设计，才有可能符合标准定义。

构造是昂贵的

![13bd8183ed6261a5e4f4680aad3e6bb1.png](../_resources/13bd8183ed6261a5e4f4680aad3e6bb1.png)

### ==load factor==Q

元素数量就是 unordered_map的 `size`
size/buckets 就是 ==负载系数 load factor==
负载系数大于1，表明 有些桶 有 一条多个元素链接而成的 元素链，降低了查询这些键的性能 (换言之，==非完美散列==)

。。不清楚了， 这。。百度了。。 发现 不同语言 对 load factor 的定义不同。。
。。golang， load factor 是 键值对数量 / hash桶的数量  。。 根据上下文， 应该是 已使用的 hash桶的 数量。   golang 中 load factor 阈值 是 ==6.5==
。。C++ 应该和 golang 的定义一样， 但不知道 阈值是多少
。。 https://en.cppreference.com/w/cpp/container/unordered_map/load_factor 。==C++提供了 方法 来获得 load_factor==。 不过 里面的描述 是 桶的数量， 没有说是 已使用的 桶的数量， 而且用的 是 bucket_count。  所以。。 我为什么认为 是 使用的 桶的数量呢?   。。。。
。。所以  ==桶的数量 就是 总共多少个桶， 而不是 使用了 多少个桶==
。。C++还==提供了 load factor阈值== https://en.cppreference.com/w/cpp/container/unordered_map/max_load_factor

。。java的 load factor 是 ==0.75==， 而且它的定义是  键值对数量 / 容量 。 容量，挺奇怪的，拉链，哪有容量的说法，无限。  看了下 ，感觉是 桶的数量，但是 0.75 也太小了吧。
。。难道 java想要一个 完美hash ?


负载系数 是一个 因变数，可以观测，但是无法设置 或预测
当最大负载系数 大于==1.0 这个默认值==时，插入 和 查找 会显著降低。
通过将最大负载系数降低到 1.0 以下能够适度地提高程序性能。

。。为什么 go 是6.5 ...

。。unordered_map 有 ==rehash==(unsigned bucket_count)， ==reserve==(unsigned bucket_count).

通过 unordered_map 的==构造函数==的参数==指定桶的初始数量==
调用 ==rehash==(size_t n) 将桶的数量的最小值设置为 n 
调用 ==reserve==(size_t n) 可以确保在重新分配骨干数组之前预留出足够的空间来保存 n 条元素。这等价于调用 rehash(ceil(n/max_load_factor())) 。 。。使得，cppreference上也是这样写的。
==clear()== 成员函数会`清除`所有的元素，并将所有存储==空间返回==给内存管理器

```
begin(size_type)cbegin(size_type)  // 真有。
	returns an iterator to the beginning of the specified bucket
```

std::unordered_map 通过为遍历桶和为遍历桶中的元素提供一个接口，暴露自己的实现结构。
计算每个桶中的元素链的长度能够帮助我们发现散列函数的问题
使用这个接口计算过散列函数的质量。

```C++
template<typename T> void hash_stats(T const& table) {
    unsigned zeros = 0;
    unsigned ones  = 0;
    unsigned many  = 0;
    unsigned many_sigma = 0;
    for (unsigned i = 0; i < table.bucket_count(); ++i) {
        unsigned how_many_this_bucket = 0;
        for (auto it = table.begin(i); it != table.end(i); ++it) {
            how_many_this_bucket += 1;
        }
        switch(how_many_this_bucket) {
        case 0:
            zeros += 1;
            break;
        case 1:
            ones += 1;
            break;
        default:
            many += 1;
            many_sigma += how_many_this_bucket;
            break;
        }
    }
    std::cout << "unordered_map with " << table.size()
              << " entries" << std::endl
              << "    " << table.bucket_count() << " buckets"
              << " load factor " << table.load_factor()
              << ", max load factor "
              << table.max_load_factor() << std::endl;
    if (ones > 0 && many > 0)
        std::cout << "    " << zeros << " empty buckets, "
                  << ones << " buckets with one entry, "
                  << many << " buckets with multiple entries, "
                  << std::endl;
    if (many > 0)
        std::cout << "    average length of multi-entry chain "
        << ((float) many_sigma) / many << std::endl;
}
```

我发现，如果使用 Boost 项目中的散列函数，那么 15% 的元素会冲突，自动分配存储空间得到的表的负载系数为 0.38，这意味着 62% 的骨干数组都没有被使用。这个散列函数远比我所期待的差。


---

插入与删除

与 std::map 类似，std::unordered_map 也提供了两种插入方法：带插入提示的和不带插入提示的。
但与 map 不同的是，unordered_map 并不使用插入提示。这只是一种接口兼容性。

插入 15.5ms
先reserve 再insert 14.9ms

设置大的 load factor，性能下降。

---

遍历

```C++
for (auto it = test_container.begin();
          it != test_container.end();
        ++it) {
    sum += it->second;
}
```

0.34ms， 是 vector 的 2.8倍


---

查找

10.4ms， 比 map快 3倍。 比 二分的vector快 1.7倍。

但散列表是如此受开发人员器重，我原本期待会出现跨数量级的性能提升，但结果却没有看到。


## 10.9 其他数据结构

Boost提供了以下容器
- boost::circular_buffer, 和deque类似，但 更高效
- Boost.Container ， 标准库容器的 各种变种，包括 
  - 稳定的vector(重新分配也不会迭代器失效)， 
  - 以std::vector 作为底层 实现的 map/multimap/set/multiset，  
  - 一个长度可变 但 最大长度固定的 静态 vector， 
  - 只有几个元素时 具有最优行为的 vector
- dynamic_bitset， bit组成的 vector     。。bitset
- Fusion， 元组上的容器和迭代器
- Boost图形库(BGL)， 适用于 遍历图形 的算法和数据结构
- boost.heap, 比 std::priority_queue 更好的性能，更微秒的行为
- Boost.Intrusive. 侵入式容器 (依赖于 显示 包含链接的节点类型的容器)。 侵入容器的 重点是 提高 热点代码的 性能。这个库包含单向和双向链表、关联容器、无序关联容器和各种显式平衡树实现。在大多数容器中都加入了 make_shared 、移动语义和 emplace() 成员函数，减少了对侵入式容器的需求。
- boost.lockfree, 无锁，无等待 的队列 和栈
- Boost.MultiIndex, 多个具有不同行为的索引的容器



# ch11 优化IO

讲解如何在读写文本数据时高效地使用 C++ 流 I/O 函数

## 11.1 ==读取文件的秘诀==

下面是将文件读取到字符串中的简单函数。
我碰到过很多次这样的代码了，特别是在解析 XML 或是 JSON 前经常会出现这样的代码

```C++
std::string file_reader(char const* fname) {
    std::ifstream f;
    f.open(fname);
    if (!f) {
        std::cout << "Can't open " << fname
                  << " for reading" << std::endl;
        return "";
    }

    std::stringstream s;
    std::copy(std::istreambuf_iterator<char>(f.rdbuf()),
              std::istreambuf_iterator<char>(),
              std::ostreambuf_iterator<char>(s) );
    return s.str();
}
```

std::copy() 会将 f 的流缓冲区复制到 std::stringstream s 的流缓冲区中


### 11.1.1 创建一个吝啬的函数签名

从库设计的角度看，file_reader() 是可以改善的（请参见 8.3.2 节）。
它做了几件不同的事情：
- 打开文件；
- 进行错误处理（以报告打开文件出错的形式）；
- 读取已打开且有效的流到字符串中。

作为一个库函数，这几种职责混合在一起使得调用方难以使用 file_reader() 函数。

file_reader() 同样还会分配一块`新的内存`并返回它，这里存在一个潜在的问题，因为这会导致返回值在`调用链中`传递的时候发生`多次复制`

如果文件无法打开， file_reader() 会返回空字符串。
如果文件能够打开，但是其中一个字符都没有，那么它也会返回一个空字符串

下面是升级版，它分离了打开文件处理与读取流处理，并且有一个用户不会立刻想要改变的函数签名。

```C++
void stream_read_streambuf_stringstream(
    std::istream& f,
    std::string& result) {
    std::stringstream s;
    std::copy(std::istreambuf_iterator<char>(f.rdbuf()),
              std::istreambuf_iterator<char>(),
              std::ostreambuf_iterator<char>(s) );
    std::swap(result, s.str());
}
```
。。外面打开文件，然后 istream 传进来
。。这里只做: 复制 文件内容 到 result


吝啬的回报是 f 变成了 std::istream ，而不是 std::ifstream 

客户端代码:
```C++
std::string s;
std::ifstream f;
f.open(fname);
if (!f) {
    std::cerr << "Can't open " << fname
              << " for reading" << std::endl;
}
else {
    stream_read_streambuf_stringstream(f, s);
}
```

性能测试: 读取一个 1万行文字的 文件100次，由于是反复读取同一个文件，操作系统几乎总是会缓存文件内容。 
消耗了 `1548ms`

尽管 stream_read_streambuf_stringstream() 使用了标准库惯用法，但`并非`特别高效。
- 它使用字符迭代器一次复制一个字符。因此我有理由怀疑每获取一个字符都会在 std::istream 中，甚至是在主机操作系统的文件 I/O API 中发生大量的机械操作。
- 同样，我有理由认为 std::stringstream 中的 std::string 每次只会增长一个字符，导致产生了对内存分配器的大量调用。


“复制流迭代器”的设计思想有几个变种。
下面的代码 使用 std::string::assign() 将一个迭代器从输入流中复制到一个 std::string 中

```C++
void stream_read_streambuf_string(
    std::istream& f,
    std::string& result) {
    result.assign(std::istreambuf_iterator<char>(f.rdbuf()),
                  std::istreambuf_iterator<char>());
}
```

VS2010 1510ms ，没有变化
VS2015 1787ms ，性能下降


### 11.1.2 缩短调用链

下面是 一次一个字符的 另一个变种
std::istream 有一个 << 运算符，它接收流缓冲区作为参数。
<< 运算符可能会绕过 istream API 直接调用流缓冲区。

```C++
void stream_read_streambuf(std::istream& f, std::string& result) {
    std::stringstream s;
    s << f.rdbuf();
    std::swap(result, s.str());
}
```

VS2010， 1294ms 快17%
VS2015， 1181ms 快51%


### 11.1.3 减少重新分配

调用 reserve() 为存储文件内容的 std::string 预先分配内

```C++
void stream_read_string_reserve(std::istream& f,
                                std::string& result)
{
    f.seekg(0,std::istream::end);
    std::streamoff len = f.tellg();
    f.seekg(0);
    if (len > 0)
        result.reserve(static_cast<std::string::size_type>(len));

    result.assign(std::istreambuf_iterator<char>(f.rdbuf()),
                  std::istreambuf_iterator<char>());
}
```

通过将流指针移动到流尾部，读取偏移量后再将流指针复位到流头部来`计算流长度`。
istream::tellg() 实际上返回一个代表流指针位置的小型结构体，其中包含一个部分读取 UTF-8 多字节字符的偏移量。
幸运的是，这个结构体能被转换为有符号整数类型。之所以这个类型必须是有符号的，是因为 tellg() 可能会失败——例如当流没有被打开时或是发生错误时，抑或是到达文件末尾时——这时它会返回 -1

windows 上，这段代码 并没有比 上一次的 好。


计算流长度并预先分配存储空间的技巧很实用。
优秀的库设计总是会在它们自己的函数中复用这些工具。
```C++
std::streamoff stream_size(std::istream& f) {
    std::istream::pos_type current_pos = f.tellg();
    if (-1 == current_pos)
        return -1;
    f.seekg(0,std::istream::end);
    std::istream::pos_type end_pos = f.tellg();
    f.seekg(current_pos);
    return end_pos - current_pos;
}
```
读取流的函数可能会在流已经被部分消费后被调用。
stream_size() 会通过先保存流指针的当前位置，然后找到指向流末尾的流指针，最后计算当前位置与末尾位置之间的差值，来应对这种可能性



下面的代码要求 在函数外估算出文件大小。
这允许开发人员在无法决定流大小时使用一个估算值。
当没有提供估算值时，该函数的默认行为与 stream_read_string() 相同
```C++
void stream_read_string_2(std::istream& f,
                          std::string& result,
                          std::streamoff len = 0)
{
    if (len > 0)
        result.reserve(static_cast<std::string::size_type>(len));

    result.assign(std::istreambuf_iterator<char>(f.rdbuf()),
                  std::istreambuf_iterator<char>());
}
```
VS2010 1566
VS2015 1766

与 stream_read_string() 相比，stream_read_string_2() 并没有明显的性能优势。
这项技巧失败了吗？我们稍后再来解释

### 11.1.4 更大的吞吐量: 使用==更大的输入缓冲区==

C++ 流包含一个继承自 std::streambuf 的类，用于改善从操作系统底层以更大块的数据单位读取文件时的性能。
数据会被读取到 streambuf 的缓冲区中，我们可以使用之前讨论过的基于迭代器的输入方法来从中逐字节地提取数据。
互联网上的有些文章建议通过增大输入缓冲区的大小来改善性能。

```C++
std::ifstream in8k;
in8k.open(filename);
char buf[8192];
in8k.rdbuf()->pubsetbuf(buf, sizeof(buf));
```

许多开发人员在互联网上抱怨 pubsetbuf() 使用起来`非常麻烦`。
pubsetbuf() 必须在`打开流后`和从流中`读取`任意字符`之前`被调用。
如果流中有一个状态位（如 failbit 或 eofbit ）被设置了，那么函数调用就会失败。

测试发现性能==提升不大==，大约 20-50ms 的提升。  继续增加 缓冲区大小，不会有进一步的提升。

### 11.1.5 更大的吞吐量: 一次读取一行

```C++
void stream_read_getline(std::istream& f, std::string& result) {
    std::string line;
    result.clear();
    while (getline(f, line))
        (result += line) += "\n";
}
```

VS2010 1284ms
VS2015 1440ms

尽管 result 可能碰巧已经足够长了， 但是预先分配 依然是一个好主意
```C++
void stream_read_getline_2(std::ifstream& f,
                           std::string& result,
                           std::streamoff len = 0)
{
    std::string line;
    result.clear();

    if (len > 0)
        result.reserve(static_cast<std::string::size_type>(len));
    while (getline(f, line))
        (result += line) += "\n";
}
```
与 stream_read_getline() 相比，这项性能优化努力只将性能提高了 3%。
而将其与增大 streambuf 的缓存区大小的技巧一起使用时，性能测试结果分别是 1193（VS2010）毫秒和 1404（VS2015）毫秒


另一个提高吞吐量的方法是使用 std::streambuf 的成员函数 ==sgetn()== ，它能够获取任意数量的数据到缓冲区参数中。
对于一个普通大小的文件，==读取整个文件只需一次函数调用==。
```C++
bool stream_read_sgetn(std::istream& f, std::string& result) {
    std::streamoff len = stream_size(f);
    if (len == -1)
        return false;

    result.resize (static_cast<std::string::size_type>(len));

    f.rdbuf()->sgetn(&result[0], len);
    return true;
}
```

stream_read_sgetn() ==很高效==。
它的测试结果分别是 307 毫秒（VS2010）和 148 毫秒（VS2015），比 stream_read_streambuf() ==快了 4 倍==。
如果增大 rdbuf ，那么测试结果分别缩短至 244 毫秒（VS2010）和 134 毫秒（VS2015）。
如果整体时间更短，那么原本增大 rdbuf 所带来的改善效果也会被放大。



### 11.1.6 再次缩短函数调用链

std::istream 提供了一个 read() 成员函数，它能够将字符==直接复制到缓冲区==中。
这个函数模仿了 Linux 上的底层 read() 函数和 Windows 上的底层 Readfile() 函数。
如果 std::istream::read() 直接连接到这个底层功能，绕过缓冲区和 C++ 流 I/O 的其他“负担”，它应当能够更加高效。
而且，如果能够一次读取整个文件，那么函数调用也会非常高效。

。。。dpdk 吗? 。

```C++
bool stream_read_string(std::istream& f, std::string& result) {
    std::streamoff len = stream_size(f);
    if (len == -1)
        return false;

    result.resize (static_cast<std::string::size_type>(len));

    f.read(&result[0], result.length());
    return true;
}
```

267 毫秒（VS2010）和 144 毫秒（VS2015），
比 stream_read_sgetn() 快了大约 25%，
比 file_reader() 快了 5 倍。

stream_read_sgetn() 和 stream_read_string() 都有一个问题，那就是它们要求指针 `&s[0]` 指向连续存储块。
在 C++11 之前，尽管我所知道的所有标准库中的字符串都是连续地存储字符，但其实 C++ 标准并没有这种要求。
C++11 标准在 21.4.1 节中首次清晰地要求字符串必须连续地存储字符。

下面这个函数首先动态地分配字符数组，然后将数据读入其中，接着使用 assign() 函数将数据复制到字符串中，我对它进行了性能测试。
这个函数对那些实现方法`违反`了`连续存储字符`的标准的新奇的字符串也适用
```C++
bool stream_read_array(std::istream& f, std::string& result) {
    std::streamoff len = stream_size(f);
    if (len == -1)
        return false;

    std::unique_ptr<char> data(new char[static_cast<size_t>(len)]);

    f.read(data.get(), static_cast<std::streamsize>(len));
    result.assign(data.get(), static_cast<std::string::size_type>(len));
    return true;
}
```
307 毫秒（VS2010）和 186 毫秒（VS2015），只比 stream_read_string() 稍慢了一点。


### 11.1.7 无用的技巧

我阅读过一些非常复杂的技巧，它们建议自己编写 streambuf 来改善性能

```C++
// 引用自：http://stackoverflow.com/questions/8736862
class custombuf : public std::streambuf
{
public:
    custombuf(std::string& target): target_(target) {
        this->setp(this->buffer_, this->buffer_ + bufsize - 1);
    }
private:
    std::string& target_;
    enum { bufsize = 8192 };
    char buffer_[bufsize];
    int overflow(int c) {
        if (!traits_type::eq_int_type(c, traits_type::eof())) {
            *this->pptr() = traits_type::to_char_type(c);
            this->pbump(1);
        }
        this->target_.append(this->pbase(),
                             this->pptr() - this->pbase());
        this->setp(this->buffer_, this->buffer_ + bufsize - 1);
        return traits_type::not_eof(c);
    }
    int sync() { this->overflow(traits_type::eof()); return 0; }
};

std::string stream_read_custombuf(std::istream& f) {
    std::string data;
    custombuf sbuf(data);
    std::ostream(&sbuf) << f.rdbuf() << std::flush;
    return data;
}
```

这段示例代码的问题在于它试图去`优化`一种`低效算法`。

1312 毫秒（VS2010）和 1182 毫秒（VS2015），并没有比 stream_read_streambuf() 更优秀。


## 11.2 ==写文件==

要想测试读取文件的函数，必须创建文件

第一个写文件的函数
```C++
void stream_write_line(std::ostream& f, std::string const& line) {
    f << line << std::endl;
}
```
1972 毫秒（VS2010）和 2110 毫秒（VS2015）

stream_write_line() 每次会写入一行数据，并以 std::endl 结束。
我当时不知道 `endl 会刷新输出`。
如果没有 std::endl ，那么写文件应当会快很多，因为 std::ofstream 只是将几个大数据块传递给了操作系统。

```C++
void stream_write_line_noflush(std::ostream& f,
                               std::string const& line)
{
    f << line << "\n";
}
```

。。但是 \n 也会刷新吧? 。。 不刷新。

367 毫秒（VS2010）和 302 毫秒（VS2015），比 stream_write_line() 快了大约 5 倍。

我还对 stream_write_line_noflush() 进行了一项将整个文件内容先保存在一个字符串中然后输出的性能测试。
果不其然，这种方法的速度更快。具体的性能测试结果分别是 132 毫秒（VS2010）和 137 毫秒（VS2015）。
这比将文件内容逐行写入到文件中快了 1.7 倍。


## 11.3 从std::cin读，向std::cout写

要求从 std::cin 中输入会首先刷新 std::cout ，这样交互控制台程序就会显示出它们的提示

调用 istream::tie() 可以得到一个指向捆绑流的指针，前提是该捆绑流存在。调用 istream::tie(nullptr) 会打破已经存在的捆绑关系


关于 std::cin 和 std::cout 的另外一件需要知道的事情的是，C++ 流在概念上是与 C 的 FILE* 对象的 stdin 和 stdout 连接在一起的。
这让程序能够同时使用 C++ 和 C 的 I/O 语句，并使得输入或输出的交叉在某种程度上有了意义。
std::cout 与 stdout 的连接是实现定义（implementation-defined）的。
多数标准库实现默认都会直接将 std::cout 发送至 stdout 。
stdout 默认是按行缓存的，在 C++ 的输入输出流中没有这种方式。
每当 stdout 遇到新的一行，它都会刷新缓冲区。

切断连接有助于改善性能。
调用静态成员函数 std::ios_base::sync_with_stdio(false) 可以打破这种连接，改善性能，但==代价==是如果程序`同时使用`了 C 和 C++ I/O 函数，那么`交叉行为将变得不可预测`。

。。那就是说 纯C++的话 切断没有问题。 。不好说，底层的库 有没有 使用C。


# ch12 优化并发

许多开发人员都对他们的操作系统的并发特性或是 C 语言中的 POSIX 线程（pthread）库更加熟悉。


## 12.1 复习并发

通过提高计算资源的使用率来减少程序运行的时间的。

从性能优化的角度看，==并发的挑战是找到足够多的独立任务来充分地使用所有可用的计算资源==，即使有些任务必须等待外部事件的发生或是资源变为可用状态。


最著名的几种并发形式如下。

==时间分割 time slicing==

这是操作系统中的一个调度函数。在时间分割中，操作系统会维护一份当前正在执行的程序和系统任务的列表，并为每个程序都分配时间块。

操作系统是依赖于处理器和硬件的。它会使用计时器和周期性的中断来调整处理器的调度。C++ 程序并不知道它被时间分割了。

---

==虚拟化 virtualization==

一种常见的虚拟化技术是让一个称为“hypervisor”的轻量级操作系统将处理器的时间块分配给客户虚拟机 。
客户虚拟机（VM）包含一个文件系统镜像和一个内存镜像，通常这都是一个正在运行一个或多个程序的操作系统。
当 hypervisor 运行客户虚拟机后，某些处理器指令和对内存区域的某些访问会产生 Trap（陷入），并将它下传给 hypervisor，这将允许 hypervisor 竞争 I/O 设备和其他硬件资源。

另外一种虚拟化技术是使用传统操作系统作为客户虚拟机的主机。
如果主机和客户虚拟机上运行的操作系统相同，那么就能够使用操作系统的 I/O 工具更加高效地竞争 I/O 资源

与传统的时间分割一样，C++ 程序同样不知道它运行于 hypervisor 下的一台客户虚拟机中。 C++ 程序也许会间接地注意到它们所使用的资源受到了限制。

---

==容器化 containerization==

容器化与虚拟化的相似之处在于，容器中也有一个包含了程序在检查点的状态的文件系统镜像和内存镜像；
不同之处在于容器主机是一个操作系统，这样能够直接地提供 I/O 和系统资源，而不必通过 hypervisor 去较低效地竞争资源

对于运行于容器中的 C++ 程序，容器化是不可见的

---

==对称式多处理（symmetric multiprocessing）==

对称式多处理器（symmetric multiprocessor）是一种包含若干执行相同机器代码并访问相同物理内存的执行单元的计算机。
现代多核处理器都是对称式多处理器。
当前正在执行的程序和系统任务能够运行于任何可用的执行单元上，尽管选择执行单元可能会给性能带来影响。

对称式多处理器使用真正的硬件并发执行多线程控制。
如果对称式多处理器有 n 个执行单元，那么一个计算密集型程序的执行时间最多可以被缩短为 1/n 

软件线程可能会，也可能不会运行于各自硬件线程之上，因此可能会也可能不会减少程序运行的总时间，而硬件线程则与此形成了鲜明的对比。

---

==同步多线程（simultaneous multithreading）==

有些处理器的硬件核心有==两个（或多个）寄存器集==，可以相应地执行两条或多条==指令流==。
当一条指令流停顿时（如需要访问主内存），处理器核心能够执行另外一条指令流上的指令。
具有这种特性的处理器核心的行为就像是有两个（或多个）核心一样，这样一个“四核处理器”就能够真正地处理八个硬件线程。

---

==多进程==

进程是并发的执行流，这些执行流有它们自己的受保护的虚拟内存空间。进程之间通过管道、队列、网络 I/O 或是其他不共享的机制进行通信。
线程使用同步原语或是通过等待输入（即发生阻塞直至输入变为可用状态）来进行同步。

有些操作系统允许在进程间共享指定的内存块。
这些在进程间共享内存的机制非常神秘，而且依赖于操作系统。
本书将不会对这些内容进行讲解。

进程的主要==优点==是操作系统会隔离各个进程。

进程==最大的缺点==是它们有太多的状态：虚内存表、多执行单元上下文、所有暂停线程的上下文。
进程的启动、停止以及互相之间的切换都比线程慢。

C++ 无法直接操作进程。
通常，一个 C++ 程序的表现形式就是操作系统中的一个进程。
C++ 中`没有`任何工具能够`操作进程`，因为`并非`所有的操作系统都有进程的概念。
有些小型处理器会为程序分割时间，但`不会隔离程序`，所以这些程序看起来更像是线程。

---

==分布式处理（distributed processing）==

分布式处理是指程序活动分布于一组处理器上。
这些处理器可以不同。
相比于处理器的处理速度，它们之间的通信速度非常慢。
一组通过 TCP/IP 协议进行通信的云服务器的实例就是一种分布式处理。

在典型的分布式处理结构中，数据通过管道或网络流向进程，进程在对输入数据进行处理后再将数据放入到下一段管道中。
这种模型与 Unix 的命令行管道一样古老，使得相对重量级的进程也能够高效地运行。
管道中的进程具有很长的生命周期，这样能够避免启动进程的开销。
进程能够连续地对工作单元进行处理，因此根据输入数据的情况，它们可能会使用整个分割时间。
最重要的是，进程之间不会共享内存或是同步，因此它们能够`全速运行`。


---

==线程==

线程是进程中的并发执行流，它们之间共享内存。
线程使用同步原语进行同步，使用共享的内存地址进行通信。

与进程相比，线程的`优点`在于消耗的资源更少，创建和切换也更快。

线程也有几个`缺点`。
由于进程中的所有线程都共享相同的内存空间，一个线程`写入无效的内存地址`可能会覆盖掉其他线程的数据结构，导致`线程崩溃`或出现不可预测的行为。
此外，访问共享内存远比访问不共享的内存`慢`，并且内存中保存的内容必须在线程之间`同步`，否则线程将会难以解释这些内容。

大多数操作系统都有自己的支持多线程的库。
一直到现在，具有丰富的并发开发经验的 C++ 开发人员一直都使用原生线程库或是提供了基本线程服务功能的跨平台解决方案——POSIX 线程库。


---

==任务==

任务是在一个独立线程的上下文中能够被异步调用的执行单元。
在基于任务的并发中，任务和线程是独立地和显式地被管理的，这样可以将一个任务分配给一个线程去执行。
相比之下，在基于线程的并发中，线程以及在线程上运行的可执行代码是作为一个单元被管理的。

基于任务的并发构建于线程之上，因此任务也具有线程的优点和缺点。

基于任务的并发的另外一个优势是，处于活动状态的软件线程的数量能够与硬件线程的数量匹配起来，这样线程就能运行得非常高效。
程序能够设置待执行任务的优先级和队列。
相比之下，在基于线程的系统中，操作系统以一种不透明的和依赖于操作系统的方式设置线程优先级。

任务的灵活性的代价比应用程序的复杂性更大。
程序必须实现对任务设置优先级或是排序任务的方法。
另外，程序还必须管理==任务运行的基础——线程池==。

---

---

12.1.2 交叉执行

并发程序能够大致被抽象为==加载 （load）、存储 （store）和分支 （branch）==，而分支常常被忽略了，仿佛所有编程的复杂性都是不相关的。

两个线程的并发执行的控制可以被建模为两个线程的简单的加载和存储语句的交叉

在如今这个多核处理器时代，单独语句的交叉成为了可能，这样会更加频繁地观察到竞争条件。

---

12.1.3 顺序一致性

C++ 认为计算机模型是简单和直观的。
这个模型有一个要求，那就是程序具有顺序一致性 （sequential consistency）。
也就是说，程序表现得`看起来像是`语句的`执行顺序`与语句的`编写顺序`是`一致`的，遵守 C++ 流程控制语句的控制。

“看起来像是”，这就使得许多编译器优化和创新的微处理器设计成为可能。



---

12.1.4 竞争

在 C++ 的标准内存模型中，只要程序中不会发生竞争，那么它的行为看起来像是具有顺序一致性；
如果程序中会`发生竞争`，就可能会`违背`顺序一致性。

并发的 C++ 程序必须显式地强制进行特定的交叉以保证顺序一致性。


---

12.1.5 同步

同步 是多线程中语句交互的强制顺序

同步原语 是一种编程结构，其目的是通过强制并发程序的交叉来实现同步。
所有的同步原语的工作原理都是让一个线程等待另外一个线程或是挂起 线程。
通过强制指定特定的执行顺序，同步原语避免了竞争的发生。

理解同步原语只是一种概念上的存在非常重要。

---

12.1.6 原子性

如果没有线程能够在另外一个线程对共享变量计算到一半的时候看到该变量被更新了，那么在共享变量（特别是具有多个成员变量的类实例）上执行的这个操作就具有原子性 （atomicity）

---

互斥实现原子性

传统上，原子性是通过互斥实现的。
每个线程在访问共享变量前都必须获得一个==互斥量== （mutex），并在完成操作后释放这个互斥量。
`获取和释放互斥量之间`的程序部分被称为==临界区== （critical section）。

编译器和处理器都会移动加载语句和存储语句。
有一种称为==内存栅栏== （memory fence）的机制可以防止共享变量的加载和存储泄漏至临界区外。
在处理器中，有些特殊的指令可以告诉处理器不要移动加载语句和存储语句穿越内存栅栏。
在编译器中，内存栅栏是概念上的。
优化器不会跨越函数调用移动加载语句和存储语句，因为在任何函数调用中都可能存在临界区。

位于临界区顶部的内存栅栏必须防止共享变量的`加载`被泄漏至临界区外。我们称这个内存栅栏具有==获得语义== （acquire semantics），因为它在线程获得互斥量时才存在。
类似地，位于临界区底部的内存栅栏必须防止共享变量的`存储`被泄漏至临界区外。我们称这个内存栅栏具有==释放语义== （release semantics），因为它在线程释放互斥量时才存在。

---

原子性硬件操作

互斥量可能导致 资源饥饿，甚至 死锁。

对于整数和指针这样的简单类型变量，在某些计算机上执行的某些操作是具有原子性的，因为这些操作是都通过`一条单独的机器指令执行`的。
这些特殊的原子性指令`带有内存栅栏`，能够确保指令在执行过程中不会被其他的指令中断。

原子性指令形成了实现互斥量和其他同步原语的基础。
我们只使用硬件的原子性操作就可以实现巧妙得令人赞叹的线程安全的数据结构。
我们称其为==无锁编程== （lock-free programming），因为以这种方式工作的代码无须等待获取互斥量。


## 12.2 复习C++并发方式

。 https://en.cppreference.com/w/cpp/thread

### 12.2.1 线程

`<thread>` 头文件 提供了 std::thread 模板类，用于创建 线程对象 作为 OS的线程 的 包装器。

std::thread 接收一个 `可调用对象` ( 函数指针，函数对象，lambda，绑定表达式 ) 作为参数，并在 新的 软件线程中 执行这个对象。
C++ 使用可变模板参数转发“魔法”调用带有可变参数列表的函数，而底层操作系统的线程调用通常接收一个指向带有 void* 参数的 void 函数的指针作为参数

std::thread 是一个用于管理操作系统线程的 RAII
它有一个返回`操作系统原生线程处理句柄`的 `get() 成员函数`，程序可以使用该处理句柄访问`操作系统中更丰富的作用于线程上的函数集合`。

```C++
void f1(int n) {
    std::cout << "thread " << n << std::endl;
}

void thread_example() {
    std::thread t1;          // 线程变量，不是一个线程
    t1 = std::thread(f1, 1); // 将一个线程赋值给线程变量
    t1.join();               // 等待线程结束
    std::thread t2(f1, 2);
    std::thread t3(std::move(t2));
    std::thread t4([]() { return; });// 也可以与lambda表达式配合使用
    t4.detach();
    t3.join();
}
```

线程 t1 会被初始化为一个`空线程`。由于每个线程都有一个唯一的指向底层资源的句柄，因此线程无法被复制，但是我们能够使用移动赋值运算符将一个右值赋值给空线程。
t1 可以拥有任何一个执行`接收一个整数参数的函数`的线程。std::thread 的构造函数接收一个指向 f1 的函数指针和一个整数作为参数。`第二个参数`会被==转发给==在 std::thread 的构造函数中启动的`可调用对象（f1` ）。
线程 t2 是用同一个函数但是不同参数启动的。
线程 t3 是一个移动构造函数的示例。在被移动构造后，t3 运行的是作为 t2 启动的线程，t2 变为了`空线程`。
线程 t4 展示了如何使用 lambda 表达式作为线程的可调用对象启动线程。


std::thread 代表的操作系统线程必须在 std::thread 被销毁`之前`被销毁掉。
我们可以像 t3.join() 这样加入线程，这表示`当前线程`会`等待被加入的线程执行完毕`。
我们可以像 t4.detach() 这样将`操作系统线程`从 std::thread 对象中分离出来。在这种情况下，线程会继续执行，但对启动它的线程来说变成了不可见的。
当被`分离`线程的可调用对象`返回时它就会结束`。如果可调用对象`不会返回`，那么就会`发生资源泄露`，被分离的线程会继续消耗资源，直到整个程序结束。
如果在 std::thread 被销毁前既没有调用过 join() 也没有调用过 detach() ，它的==析构函数会调用terminate()== ，整个程序会突然停止。


尽管我们能够直接使用 std::thread ，但是使用基于它编写出更加优秀的工具的话，可能有助于提高生产率。
函数对象`返回的任何值都会被忽略`。函数对象抛出的`异常`会导致 `terminate()` 被调用，使程序无条件地突然停止。
这些限制让对 std::thread 的调用变得`非常脆弱`，就像是标准的制定人员不希望开发人员使用它一样。

。。jthread 是C++20的。 析构时 join()。   而且还可以处理 外部的 中断线程请求。

### 12.2.2 promise, future

`<future>`

std::promise模板 和 std::future模板 是 一个线程向另一个线程 发送和 接收 消息的模板类
可以让线程 异步计算，抛出异常。
promise，future共享一个 称为 `共享状态(shared state)` 的 动态分配 内存的变量， 这个变量可以保存一个 已定义类型的值(。。模板声明的那个类型)，或 标准包装器中 封装的任意类型的异常。

一个执行线程能够在 future 上被挂起，因此 future 也扮演着同步设备的角色

可以使用 promise 和 future 简单地实现异步函数调用和返回
不过，promise 和 future 的用途远比这广泛。
它们可以实现一幅动态改变线程之间的通信点的图。
但是反过来说，它们不提供任何结构化机制，因此完全自由的通信图可能会难以调试
。。。? 动态改变线程间通信点???

promise可以将 共享状态 设置为 一个指定类型的值 或 一个异常
发送线程并不会等待共享状态变为可读状态，它能够立即继续执行

promise 的共享状态直到被设置为一个值或是一个异常后`才就绪`。
共享状态必须且`只能被设置一次`，否则会发生以下情况。
- 多次设置，共享状态会变成 std::future_error 异常。错误代码是 promise_already_satisfied
- 没有设置，promise析构时，设置 std::future_error, 错误代码 broken_promise


future 是一个`同步原语`，接收线程会在对 future 的 ==get()== 成员函数的调用中==挂起==，`直到`相应的 promise 设置了共享状态的值或是异常，变为就绪状态为止。

在被 构造 出来或是 通过 promise 赋值 后，future ==才是有效==的。
在 future 无效时，接收线程是`无法`在 future 上`挂起`的

promise 和 future 无法被复制。可以move

理想情况下，promise 是在发送线程中被创建的，而 future 则是在接收线程中被创建的。
有一种编程惯用法是在`发送线程`中创建 promise ，然后使用 std::move(promise) 将其作为右值引用`传递`给接收线程，这样它的内容就会被移动到属于接收线程的 promise 中。
。。? 不是 接收线程 构造吗? 然后给 发送线程，然后 发送线程 发送信息(设置promise)。
。。或者说 main线程，或 父线程 构造 promise 和 future， 然后 把 promise给 子线程/计算线程

开发人员可以使用 ==std::async()== 来做到这一点。

我们也可以通过`指向发送线程的引用`来`传递` promise

```C++
void promise_future_example() {
    auto meaning = [](std::promise<int>& prom) {  // 形参 promise＆
        prom.set_value(42); // 计算"meaning of life"
    };

    std::promise<int> prom;
    std::thread(meaning, std::ref(prom)).detach();  // std::ref

    std::future<int> result = prom.get_future();  // 。。这个可以在 thread 之前吗? 看下面，似乎不能。但是 packaged_task 可以
    std::cout << "the meaning of life: " << result.get() << "\n";
}
```

promise 的 prom 在 std::thread 被调用之前被创建出来了。
这种写法并==不完美==，因此它没有考虑 broken_promise 的情况。
尽管如此，但`这是有必要的`，因为如果没有在线程开始之前构造出 prom ，就无法确保在调用 result.get() 之前 future 的 result 是有效的。

由于 prom 是一个`引用参数`，因此==必须==将其包装在 ==std::ref()== 中才能使参数转发正常工作

程序可能会在`线程开始运行之前`执行 prom.get_future() 。
这就是在构造出线程之前先创建 prom 的原因——这样 future 是有效的，程序会==挂起==等待线程。
。。get_future 会挂起。。所以 必须 thread 之后 才可以 get_future， 不然 挂起后， 不会执行 std::thread 了。
。。?但是看 packaged_task 可以。
。。或者说 这里的 挂起 是指  get的 挂起?

程序会在 result.get() 中挂起，等待线程设置 prom 的共享状态。

future 中并`没有什么神秘的地方`。
如果设计人员想设计一个先返回整数值然后返回字符串的线程，可以创建两个 promise ，然后在接收程序创建两个对应的 future 。
。。。岂不是 变相的 多return 。。。6啊 。。。不， 直接 形参ref 就是 变相的 多返回了。

future 变为就绪状态释放了一个信号，表明计算完成了。
由于程序会在 future 上挂起，因此无需在线程终止上挂起。
这对于在 12.2.3 节中讨论的 std::async() 和在 12.3.3 节中讨论的线程池非常重要，因为相比于销毁然后重新创建线程，这种方法在重用线程上更加高效。
。。。? 线程终止上挂起 是什么?。。


### 12.2.3 异步任务 packaged_task，async()

`<future>` 定义了 任务(task)

std::packaged_task 模板 可以包装任意的 可调用对象 (函数指针，函数对象，lambda，绑定表达式)， 使其能被异步调用。

packaged_task 自身也是一个 可调用对象，它可以作为 可调用对象参数 传递给 std::thread。

task的最大优点是 task能在不突然终止程序的情况下 抛出异常或返回值。task的 异常或返回值 可以通过 future 获得。

```C++
void promise_future_example_2() {
    auto meaning = std::packaged_task<int(int)>([](int n) { return n; });
    auto result = meaning.get_future();   // .可以thread之前。
    auto t = std::thread(std::move(meaning), 42);

    std::cout << "the meaning of life: " << result.get() << "\n";
    t.join();
}
```

。。promise 是 将 promise作为 形参ref 传递进去，子线程计算完，它会设置 promise.set_value(11);  即， promise 是 程序员 编程 设置的， 而且 可以 传递多个 promise (。只要形参也是多个promise)。
。。而 packaged_task，就是 C++自动 帮你设置 promise，设置的值时 可调用对方的 返回值，或它 抛出的异常。

packaged_task 类型的变量 meaning 包含一个可调用对象和一个 std::promise 。

---

`<async>` 提供了 ==std::async()==

。。`std::launch::async`  `std::launch::deferred`

执行一个可调用对象参数，这个可调用参数==可能==是在新线程的上下文中被执行的
返回的是一个 std::future

有些实现方式可能会为了改善性能而选择在线程池外部分配 std::async() 线程

```C++
void promise_future_example_3() {
    auto meaning = [](int n) { return n; };
    auto result = std::async(std::move(meaning), 42);
    std::cout << "the meaning of life: " << result.get() << "\n";
}
```

这里使用了类型推导来决定 std::async() 的模板参数。

线程终止是由 std::async() 负责的，它可能会将线程保留在线程池中
。。但是线程池 都没有配置啊。

这段示例代码不需要显式地负责线程终止。
如果回收线程比销毁线程然后重新创建线程更加高效，那么在需要时，std::async() 可能会使用 ==C++ 运行时系统维护的线程池==来回收线程。
在 C++17 标准中可能会加入==显式的线程池==。


### 12.2.4 mutex,shared_mutex

`<mutex>` 提供 4种互斥量

std::mutex
    一种简单且相对高效的互斥量
    lock,try_lock,unlock
    还有全局方法: std::lock() std::try_lock() 可以锁多个
std::recursive_mutex
    一种线程能够递归获取的互斥量，就像函数的嵌套调用一样。
    由于该类需要对它`被获取的次数计数`，因此可能稍微低效。
std::timed_mutex
    允许在一定时间内尝试获取互斥量。
    要想在一定时间内尝试获取互斥量，通常需要操作系统的介入，导致与 std::mutex 相比，这类互斥量的`延迟显著地增大`了。
std::recursive_timed_mutex
    一种能够在一定时间内递归地获取的互斥量。开销大

根据我的经验，在一定时间内递归地获取互斥量是一种警告，它表明应当简化设计

递归锁的界线难以划清，因此容易引起死锁。

---

`<shared_mutex>` C++14

共享互斥锁，也称为 reader/writer互斥量

一个`单独的`线程可以以`排他模式`锁住共享互斥量来`原子性地更新`数据结构。
`多个`线程能够以`共享`模式锁住一个共享互斥量来`原子性地读取`数据结构，但是在所有的读取者都释放互斥量之前无法以排他模式锁住它。

std::shared_timed_mutex
    一种同时支持`定时`和`非定时`获取互斥量的共享互斥量。
std::shared_mutex
    一个更加简单的共享互斥量，按照计划在 `C++17` 中会被加入。



### 12.2.5 lock

一种结构化方式获取和释放互斥量的 RAII 类

`获取`互斥量也被称为`锁住` 互斥量，`释放`互斥量也被称为`解锁` 互斥量

`<mutex>`
std::lock_guard
    简单的RAII。
    构造器 获得锁，析构器释放锁
    。只有 构造器，析构器，operator=
std::unique_lock
    通用的互斥量所有权类，提供RAII锁，延迟锁，定时锁，互斥量所有权转移，条件变量
    有: lock,try_lock,try_lock_for,try_lock_until,unlock; swap,release

C++14 `<shared_mutex>`
std::shared_lock
    共享（reader/writer）互斥量的一个互斥量所有权类。它提供了 std::unique_lock 的所有复杂特性，另外还有共享互斥量的控制权。
    有: lock,try_lock,try_lock_for,try_lock_until,unlock; swap,release
    。。但是 并没有 共享锁，独占锁的 方法啊。 就是 没有 lock_shared, lock_exclusive 之类的。

C++17 `<mutex>`
std::scoped_lock
    一次锁 多个mutex。 使用了 避免死锁算法



### 12.2.6 条件变量

`<condition_variable>`

条件变量 允许 C++实现 在java中作为同步类被广泛使用的 监视器的 概念。

一个监视器在多线程之间共享一个数据结构。
当一个线程成功地进入监视器后，它就拥有一个允许它更新共享数据结构的互斥量。
线程可能会在更新共享数据结构后退出监视器，放弃它的排他访问权限。
它也可能会阻塞在一个条件变量上，暂时地放弃排他访问权限直到这个条件变量变为特定的值

一个监视器可以有一个或多个条件变量。
每个条件变量都表示数据结构中一个概念上的状态改变事件。
当运行于监视器中的一个线程更新数据结构时，它==必须通知所有==会受到这次更新影响的条件变量，它们所表示的事件发生了。


2种实现方式，区别是 所接收的参数锁的一般性

std::condition_variable
    最高效的条件变量，需要使用 std::unique_lock 来锁住互斥量
std::condition_variable_any
    一种能够使用任何 BasicLockable 锁（即任何具有 lock() 和 unlock() 成员函数的锁）的条件变量


有些操作系统可能会==虚假地通知==条件变量（我的经验是`程序错误`也可能会引发这种现象）
当一个线程被条件变量释放后，该线程必须验证数据结构的状态是否与预期相同

生产者，消费者
```C++
void cv_example() {
    std::mutex m;
    std::condition_variable cv;
    bool terminate = false;
    int shared_data = 0;
    int counter = 0;

    auto consumer = [&]() {
        std::unique_lock<std::mutex> lk(m);
        do {
            while (!(terminate || shared_data != 0))
                cv.wait(lk);
            if (terminate)
                break;
            std::cout << "consuming " << shared_data << std::endl;
            shared_data = 0;
            cv.notify_one();
        } while (true);
    };

    auto producer = [&]() {
        std::unique_lock<std::mutex> lk(m);
        for (counter = 1; true; ++counter) {
            cv.wait(lk,[&]() {return terminate || shared_data == 0;});
            if (terminate)
                break;
            shared_data = counter;
            std::cout << "producing " << shared_data << std::endl;
            cv.notify_one();
        }
    };

    auto p = std::thread(producer);
    auto c = std::thread(consumer);
    std::this_thread::sleep_for(std::chrono::milliseconds(1000));
    {
        std::lock_guard<std::mutex> l(m);
        terminate = true;
    }
    std::cout << "total items consumed " << counter << std::endl;
    cv.notify_all();
    p.join();
    c.join();
    exit(0);
}
```

生产者通过将一个名为 shared_data 的整数变量设为非零值来进行“生产”

消费者通过将其重新设置为零来“消费”shared_data

消费者通过锁住互斥量 m 进入`监视器`。

。。一堆代码的解释


### 12.2.7 ==atomic,内存栅栏==

`<atomic>` 提供了 用于构建多线程同步原语的底层工具: ==内存栅栏== 和 ==原子性的加载存储==

std::atomic 提供了一种更新==任意==数据结构的标准机制，==前提==条件是这种数据结构有可用的==复制构造==函数或是==移动构造==函数。

std::atomic 的任何特化实现都必须为任意类型 T 提供以下函数
- load(), `T load(memory_order)`  原子复制 T对象到 atomic外部
- store()， `store(T, memory_order)` 原子复制 T对象到 atomic内部
- is_lock_free()， 如果在这个类型上 定义的 `所有操作都没有使用互斥`，那么返回true， 就如同是`一条单独`的 读改写 机器指令 进行操作

std::atomic 的性能取决于 编译代码的处理器
- Intel架构的 PC具有 丰富的 读-改-写 指令，原子访问的 性能开销取决于 内存栅栏，其中部分栅栏 没有任何性能开销
- 在有 读改写 指令的 单核处理器上， atomic不会生成任何额外代码
- 在没有 原子 读改写 的处理器上， atomic需要使用 昂贵的 互斥锁


---

==内存栅栏==

https://zh.cppreference.com/w/cpp/atomic/memory_order

![d44d54623c5a7d95716b4c6d8661c258.png](../_resources/d44d54623c5a7d95716b4c6d8661c258.png)


std::atomic 的很多 成员函数 都可以接收一个 可选参数 memory_order， 它会选择一个 围绕在操作上下的 栅栏。

默认 `memory_order_acq_rel`， 安全但开销昂贵的 完全栅栏

有许多栅栏可以选择，但是 最好是由知识渊博的开发专家来做出决定。

==memory_order_acquire==
可以理解为“通过其他线程完成所有工作”的意思。
它确保`随后的加载` 不会被移动到`当前的加载`或是前面的加载`之前`

在原子性地读取在繁忙等待 while 循环中的标识位时，可以使用 memory_order_acquire

==memory_order_release==
可以理解为“通过这个线程将所有工作释放到这个位置”的意思
它确保这个线程完成的`之前的加载和存储`不会被移动到`当前的存储` `之后`。

==memory_order_acq_rel==
结合上面的2种保证。

==memory_order_consume==
acquire的弱化(但更快)
它只要求`当前的加载`发生在其他`依赖`这次加载数据的操作`之前`

==memory_order_relaxed==
允许所有的重新排序


这里少一个 ==memory_order_seq_cst==
被标为 memory_order_seq_cst 的原子操作不仅以与释放-获得定序相同的方式进行内存定序（在一个线程中先发生于存储的任何副作用都变成进行加载的线程中的可见副作用），还对所有带此标签的内存操作建立了一个单独全序。


x86的 所有加载 都有 acquire语义，所有存储 都有 release语义，即 x86架构对内存访问 加上了 非常严格的顺序。   。。所以x86 设置 memory_order_relax 也没用?
PowerPC，ARM，排序能力更弱，但是性能更高。
这意味着x86 ok的代码，放到 ARM上 可能出问题。

原子性访问并非万灵丹。内存栅栏的性能开销非常昂贵

```C++
typedef unsigned long long counter_t;
std::atomic<counter_t> x;
for (counter_t i = 0, iterations = 10'000'000 * multiplier; i < iterations; ++i)
    x = i;
```

```C++
typedef unsigned long long counter_t;
counter_t x;
for (counter_t i = 0, iterations = 10'000'000 * multiplier;
     i < iterations; ++i)
    x = i;
```
耗时 15318ms， 非原子性的 只需要 992ms。 差 14倍。

---

12.2.8 未来的C++并发特性

C++17 可能引入
- 协作多线程，在协作多线程中，两个或多个软件线程通过语句显式地互相传递执行，这样实际上在同一时间只有一个线程在运行。 协程就是协作多线程的例子
- SIMD指令
  C++ 编译器通常不会生成 SIMD 指令，因为它们的行为很复杂，不太符合 C++ 描述程序的方式。依赖于编译器的编译指令或是内联汇编特性允许在函数中插入 SIMD 指令，然后这些函数会被收录到用于数字信号处理或是计算机图形等专业任务的库中。因此，SIMD 编程是同时依赖于处理器和编译器的。


## 12.3 ==优化多线程C++程序==

执行`许多`线程需要频繁地切换上下文，这种开销是昂贵的

### 12.3.1 std::async代替std::thread

std::thread 有一个非常严重的问题，那就是每次调用都会启动一个新的软件线程
启动线程时，直接开销，间接开销会使得这个操作非常昂贵
- 直接开销包括: 调用OS为线程在OS的表中分配空间，为线程的栈分配内存，初始化线程寄存器，调度线程运行
- 间接开销: 增加了使用的内存总量。 如果频繁启动和停止大量线程，那么线程会竞争有限的 高速缓存，导致 高速缓存抖动
- 软件线程数量大于 硬件线程时，需要OS进行大量调度，所有线程都会变慢


```C++
std::thread t;
t = std::thread([]() { return; });
t.join();
```
测试10000次， 1350ms，即windows上 启动和停止一个线程 需要 135微秒。  这个开销是 直接执行lambda的 数千倍。


并发编程的一项`实用优化技巧`是用==复用线程==取代在每次需要时创建新线程。

尽管切换线程的有些开销（保存和恢复寄存器并刷新和重新填充高速缓存）是相同的，但可以`移除或减少`为线程分配内存以及操作系统调度线程等其他开销。

模板函数 std::async() 会运行线程上下文中的可调用对象，但是它的实现方式允许复用线程。

`std::async(std::launch::async, []() { return; });`
1万次，86ms，快了14倍


### 12.3.2 创建和核心数量一样多的可执行线程

性能优化开发人员要区别出具有不同行为的两种线程
- 连续计算的可运行线
- 等待外部事件，接着进行短暂计算的可等待线程

。。阿姆达尔定律直接秒

`std::thread::hardware_concurrency()` 函数，它可以返回可用核心的数量


单线程计算
```C++
void timewaster(unsigned iterations) {
    for (counter_t i = 0; i < iterations; ++i)
        fibonacci(n);
}
```

多线程计算
```C++
void multithreaded_timewaster(
        unsigned iterations,
        unsigned threads)
{
    std::vector<std::thread> t;
    t.reserve(threads);
    for (unsigned i = 0; i < threads; ++i)
        t.push_back(std::thread(timewaster, iterations/threads));
    for (unsigned i = 0; i < threads; ++i)
        t[i].join();
}
```

单线程 3087ms

多线程，std::thread::hardware_concurrency() 返回4， 所以 预测4线程运行最快，测试下来，确实4线程最快， 1870ms

4线程 是 单线程的 一半时间，而不是 1/4

### 12.3.3 实现任务队列和线程池

解决不知道有多少个线程正在运行这个问题的方法是让线程更加明显：使用线程池 和任务队列(一种存储待执行的计算的列表的数据结构)

。。一般 线程池 自带队列吧。

在`面向任务的编程` 中，程序是一组可运行任务（runnable task）对象的集合，这些任务由`线程池`中的线程负责执行。
当一个线程变为可用状态后，它会从任务队列中取得一个任务并执行。执行完任务后，线程并不会终止，而是要么继续做下一个任务，要么挂起，等待新任务的到来。

面向任务的编程有以下几个优点。
- 面向任务的编程能够通过非阻塞 I/O 调用`高效地处理 I/O` 完成事件，提高处理器的利用率。
- 使用线程池和任务队列能够`移除`为短周期任务`启动线程`的间接开销。
- 面向任务的编程将异步处理集中在一组数据结构中，因此容易限制使用中的线程的数量。

面向任务的编程的一个缺点是控制返转 （inversion of control）。
控制流不再由程序指定，而是变为事件消息接收的顺序。
这会增加讨论或调试面向任务编程的难度，但以我的经验看，很少会发生这种混乱的情况。

。。可惜 似乎 至今没有 官方的线程池和 任务队列。
。下面是 百度AI 给的。
。百度AI: 使用标准库的`<thread>和<mutex>`等组件，或者使用第三方库如 Intel Threading Building Blocks (TBB) 或 Boost.Asio
```C++
#include <iostream>
#include <vector>
#include <queue>
#include <thread>
#include <mutex>
#include <condition_variable>
#include <functional>
 
class ThreadPool {
public:
    ThreadPool(size_t threads) : stop(false) {
        for (size_t i = 0; i < threads; ++i) {
            workers.emplace_back([this] {
                while (true) {
                    std::function<void()> task;
                    {
                        std::unique_lock<std::mutex> lock(this->queueMutex);
                        this->condition.wait(lock, [this] { return this->stop || !this->tasks.empty(); });
                        if (this->stop && this->tasks.empty()) return;
                        task = std::move(this->tasks.front());
                        this->tasks.pop();
                    }
                    task(); // Execute the task
                }
            });
        }
    }
 
    template<class F, class... Args>
    void enqueue(F&& f, Args&&... args) {
        auto task = std::bind(std::forward<F>(f), std::forward<Args>(args)...);
        {
            std::unique_lock<std::mutex> lock(queueMutex);
            if (stop) throw std::runtime_error("Enqueue on stopped ThreadPool");
            tasks.emplace(task);
        }
        condition.notify_one(); // Notify one waiting thread
    }
 
    ~ThreadPool() {
        {
            std::unique_lock<std::mutex> lock(queueMutex);
            stop = true;
        }
        condition.notify_all(); // Notify all waiting threads to exit
        for (std::thread &worker : workers) {
            worker.join(); // Wait for all threads to finish
        }
    }
 
private:
    std::vector<std::thread> workers;
    std::queue<std::function<void()>> tasks;
    std::mutex queueMutex;
    std::condition_variable condition;
    bool stop;
};
 
// Example usage:
int main() {
    ThreadPool pool(4); // Create a thread pool with 4 threads
    for (int i = 0; i < 10; ++i) { // Enqueue 10 tasks to the pool
        pool.enqueue([i] { std::cout << "Task " << i << " is running\n"; });
    }
    return 0; // Main thread will wait for the pool to finish all tasks before exiting.
}
```


### 12.3.4 在单独的线程中执行IO

磁盘转速和网络连接距离等物理现实问题造成在程序请求数据和数据变为可用状态之间存在着延迟。因此，I/O 是适用并发的绝佳位置。另外一个典型的 I/O 问题是，程序在写数据之前或是读数据之后必须对它进行转换。例如，我们先从互联网上读取一个 XML 文件，接着解析它，从中提取程序所需信息。由于在对数据进行转换之前是无法直接使用它的，我们可以考虑将整个处理（包括读数据和解析数据）移动到一个单独的线程中。
。。不理解


### 12.3.5 没有同步的程序

同步和互斥 降低了 多线程程序的速度。

编写没有同步的程序，有3个简单的方法 和一个 困难的方法

==面向事件编程==
程序是一组由框架调用的事件处理函数的集合。
底层框架从事件队列中将每个事件分发给注册了该事件的事件处理函数。

面向事件程序的主要缺点也是控制返转 ，控制流会变为事件消息接收的顺序。

==协程==
协程是可执行对象，虽然它会显式地将执行从一个对象转交给另外一个对象，但是它们会记住执行指针，这样如果它们被再次调用了也可以继续执行。

协程有两种。
第一种有自己的栈，而且可以在执行途中的任何位置将控制转交给另外一个协程。
第二种是向另外一个线程借栈，并且只能在它的顶层转交控制


==消息传递==
在消息传递程序中，控制线程从一个或多个输入源中接收输入，对输入进行转换后将它放到一个或多个输出槽中


==无锁编程==
在无锁程序中，硬件同步的原子性操作取代了昂贵的互斥量。


### 12.3.6 移除启动和停止代码
程序中有部分代码难以并发执行，那就是在 main() 得到控制权前执行的代码以及在 main() 退出后执行的代码。

在 main() 开始执行前，所有具有静态存储期的变量都会被初始化。
对于基本数据类型，初始化的性能开销是 0。链接器会让变量指向初始化数据。
但是对于具有静态存储期的`类类型`，初始化过程会以标准所指定的特定顺序，在单独的线程中连续地调用各个变量的构造函数。

。。除非 懒加载，但是没有意义。


## 12.4 让同步更高效

std::mutex 所基于的互斥量是一种混合设计，它会先在一个原子变量上`繁忙等待`一小段时间，然后如果不能很快获得互斥量，就在操作系统信号上挂起。
。。自旋锁 转 重量级锁


### 12.4.1 减小临界区的范围

临界区是指`获取互斥量`和`释放`互斥量之间所包围的区域。

如果在临界区中并`没有访问共享变量`而是只做其他事情，那么其他线程就会白白浪费等待时间。

。例子是，临界区中 把 cout移除掉。

临界区中执行IO无法提高性能
难以高效使用监视器概念。除非等待一个条件变量，否则代码总是在监视器中


### 限制并发线程的数量


### 避免==惊群==

当有`许多线程`挂起在一个事件 (例如只能服务一个线程的工作) 上时 就会发生 ==惊群== (thundering herd)
当发生这个事件时，`所有线程`都会变为 可运行状态，但是 只有`几个核心`，因此只有`几个线程` 能立即运行。 其中==只有一个== 线程能==拿到 互斥量== 继续真正的工作， OS将`其他线程` 移动到 ==可运行队列==，并最终==逐个运行==线程，这些线程发现 事件已经被其他线程消费，==只能继续挂起==， 消耗了很多时间，但是 没有任何进展。

避免“惊群”问题的方法就是`限制`创建出的服务事件的`线程的数量`。
两个线程可能比一个线程好，但是 100 个线程可能并不会更好
。。下面的 锁护送 还提到一种: `sleep(rand())`

相比于将线程与每项工作相关联的设计，对于实现工作队列的软件设计来说，限制线程数可能更容易。


### 12.4.4 避免==锁护送==

当`大量线程同步`，挂起在某个资源或是临界区上时会发生锁护送 （lock convoy）
这会导致额外的阻塞，因为它们`都会试图立即`继续进行处理，但是`每次却只有一个`线程能够继续处理，仿佛是在护送锁一样。

。。就是 大量线程 竞争一个锁?

一种简单的情况是接二连三地发生“惊群”现象。
大量线程竞争一个互斥量，这样大量线程会挂起在该互斥量的操作系统信号上。
当持有互斥量的线程释放它时，事件就会发生，所有挂起的线程都会变为可运行状态。
第一个被分配到处理器的线程会再次锁住互斥量。
所有的其他线程最终都会被分配到处理器，看到互斥量仍然被锁住了，然后再次挂起。
这对程序的整体影响是操作系统虽然花费了很多时间重启线程，但大多数线程都无法继续处理。
更糟糕的是，所有的线程都仍然是同步的。
当下个线程释放互斥量时它们会立即醒来，然后如此往复循环。

一种更复杂的情况则是“惊群”线程都试图去获取第二个互斥量或执行读取文件等某种因设备的物理特性而成为性能瓶颈的操作。
由于线程都是同步的，它们几乎会在同时试图去访问第二个资源。
这些线程在同一个时间请求相同的资源会导致`序列化`，使性能下降。如果它们没有同步，那么它们可能都会继续处理。

当系统通常都运行良好，但偶尔会看起来失去响应几秒钟，那么就可以看出发生了锁护送。

尽管仍然总是有在另外一个地方出现锁护送的风险，但==减少线程数量==或是==调度线程在不同的时间启动==能够缓解出现锁护送的情况。    。。。==sleep(rand())==
有时，最好能够简单地确认一下，某个组的任务是否因为共享了某个硬件设备或是其他性能瓶颈资源而无法并发执行。


### 12.4.5 减少竞争

==注意内存和IO都是资源==
文件IO，网络IO
出现性能问题时，我们要回过头问: 现在整个程序正在进行什么处理?

==复制资源==
有时候，我们可以复制表，让每个线程都有一份==非共享的副本==，来移除多线程对于共享的 map 或是散列表等资源的竞争。
我们甚至能够复制磁盘驱动器、网卡等硬件资源来提高吞吐量

==分割资源==
有时候我们可以==分割数据结构==，让每个线程只访问它们所需的那部分数据，来避免多线程竞争同一个数据结构
。。java 的ConcurrentHashMap 锁 Bucket

==细粒度锁==
我们可以使用多个互斥量，而不是一个互斥量来锁住整个数据结构。
例如，在散列表中，我们可以使用一个互斥量锁住散列表的骨干数组，防止其被修改（例如插入和删除元素），然后用另外一个互斥量锁住元素，防止它们被修改。
这里，reader/writer 锁是一个不错的选择。要访问散列表的一条元素时，线程可以使用读锁锁住骨干数组，然后用一个读锁或写锁锁住元素。
要插入或删除一条元素时，线程可以使用写锁锁住骨干数组。

。。? 分层 锁。 和 分割资源差不多啊。   不会 分割资源 是真的分成 多个吧?

==无锁数据结构==

使用无锁散列表等无锁数据结构来摆脱对互斥的依赖。
这是细粒度锁的终极形态。

==资源的调度==

有些资源——例如磁盘驱动器——是无法被复制或分割的。但是我们可以调度磁盘活动，让它们`不要同时发生`，或是让`访问磁盘相邻部分的活动同时发生`。
尽管操作系统会在细粒度级别调度读写操作，但是程序能够通过序列化读取配置文件等操作，避免它们同时发生


### 12.4.6 不要在单核系统上繁忙等待

。就是 单核系统 不能使用 自旋锁。  确实不能，单核，你自旋没有意义。 不可能等到的。
。。单片机啊。

### 不要永远等待

。。但是 基本都是 mutex，很少用 timed_mutex 吧。

### 自己设计互斥量可能会低效

。。造轮子。

### 限制生产者输出队列的长度

在生产者 / 消费者程序中，任何时候只要生产者比消费者快，数据就会在生产者和消费者之间`累积`。
这种情况会产生许多问题，其中包括如下几个。
- 生产者竞争处理器，内存分配器 和其他资源， 进而降低 消费者的处理速度，使问题恶化
- 生产者最终消费完所有的 内存，导致程序异常终止
- 如果程序能恢复，重启之前 需要处理 队列中 累积的所有数据，会增加 程序的 恢复时间。

解决方法是`限制队列长度`并在列队`满员后阻塞生产者`。
队列的长度只需足够应对消费者性能的变化就可以了。
多数情况下，队列其实只需能容纳`若干元素即可`。
队列中的任何多余元素都只会导致生产者的运行遥遥领先，增加资源消耗，却对并发没有任何益处。

。。生产者 和消费者 也是竞争， 就是 无限队列时， 生产者 无限生产， 占据了大量 CPU，导致 消费者 没有CPU可用，无法消费。

## 12.5 并发库

- Boost.Thread
- POSIX, pthreads
- TBB  。。感觉已经没了。 intel 有个 oneTBB
- 0mq/ZeroMQ，用于连接消息传递程序的通信库， 。。。类似于MQ，但是不需要 message broker，支持java，rust，go，zig，等很多。
- MPI, 分布式计算机网络中的消息传递的一个 API 规范
- OpenMP
- C++AMP，微软的，竞争对手是 CUDA，OpenCL 。。。


# ch13 优化内存管理

`内存管理器` 是 C++ 运行时系统中监视动态变量的内存分配情况的一组函数和数据结构。

在许多 C++ 程序中，内存管理器的函数都是热点函数

在我看来，在进行性能优化时首先`应该寻找其他`能够优化的地方，这可能会比改善内存管理器更加有效果。
作为热点代码的内存管理器，其`性能通常已经被榨干`了

对大型程序进行的研究表明，优化内存管理的性能改善效果范围是从`微不足道至大约 30%`。

C++ 内存管理器有大量的 API，是高度可定制的。
尽管许多程序员永远不会使用这些 API，但它确实提供了许多进行性能优化的方法。
通过替换 C 函数 malloc() 和 free() ，能够将几种高性能内存管理器加入到 C++ 中。
除此之外，开发人员还能够为热点类和标准库容器替换专门的内存管理器。


## 13.1 复习C++内存管理器API

### 动态变量的生命周期

动态变量有 5个唯一的生命周期

最常见的 new 表达式 的各种重载形式执行`分配` 和`放置` 生命阶段。在`使用` 阶段后，delete 表达式 会执行`销毁` 和`释放` 阶段。

==分配==
程序要求 内存管理器 返回一个 指向 至少包含指定数量未类型化的内存字节 的连续内存地址的 指针。
如果没有足够的可用内存，那么分配将失败。
C的 malloc， C++的new() 参加这一阶段。

==放置==
程序创建动态变量的初始值，将值放置到被分配的内存中。
如果变量是一个`类的实例`，那么它的==构造函数==之一将会被调用。
如果变量是一个简单类型，那么它可能会被初始化。
如果构造函数抛出`异常`，那么放置会失败，需要将被分配的`存储空间返回给内存管理器`。
`new 表达式` 参与这个阶段。

==使用==
程序从动态变量中读取值，调用动态变量的成员函数并将值写入到动态变量中。

==销毁==
如果变量时一个类实例，那么调用==析构器==，析构器需要返回持有的所有系统资源，完成变量的清理工作。
如果析构器抛出异常，程序无条件终止
delete表达式管理这个阶段

==释放==
将被销毁的动态变量的存储空间返回给`内存管理器`
C的free()，C++的delete()运算符 参加这一阶段


### 内存管理函数==分配和释放内存==

C++提供了 一组内存管理函数，而不是C的 malloc()，free()

==new()/new[]()运算符实现分配==

new表达式 调用new()运算符的若干版本之一 来获得 动态变量的内存， 或调用 new[]() 获得 动态数组的内存。
C++提供了这些运算符的 默认实现。还隐式声明了这些运算符，这样 程序无需 `#include <new>` 。

当有需要时，我们还能够在程序中重写这些默认实现来实现自己的运算符。

new()运算符对于 性能优化非常重要，因为默认内存管理器的开销是昂贵的。
在有些情况下，通过实现专门的运算符能够让程序非常高效地分配内存。

C++定义的 new() 的重载
- `void* ::operator new(size_t)`
  默认情况下，都是使用这个重载，实参是 分配内存的最小字节数， 如果没有足够内存，抛出 `std::bac_alloc` 异常
  new() 的==其他重载 都会调用这个重载==。
  通过在任意编译单元中提供一个 `::operator new(size_t)` 的定义，程序能够==全局地改变内存的分配方式==。
  C++没有规定，但是标准库中，底层 通常使用 malloc()
- `void* ::operator new[](size_t)`
  为==数组==分配内存
  。。这个是不是 最后 `new(元素个数 * 元素size)` ?   还有 这里的 参数 是 整个数组的内存空间 还是 元素个数?， 应该是 元素个数吧?
- `void* ::operator new(size_t, const std::nothrow_tag&)`
  `Foo* p = new(std::nothrow) Foo(123);`， new()的 ==不抛异常的重载==
  没有可用内存，==返回 nullptr==，而不是抛出 std::bac_alloc
  标准库中，调用 new(size_t)， 并且捕获所有异常
- `void* ::operator new[](size_t, const std::nothrow_tag&)`
  new()的 ==不抛异常的数组版本==
- `void* ::operator new(size_t, void*)`
  ==placement new==, 第二个参数指向了 内存。 最后返回 第二个参数
- `void* ::operator new[](size_t, void*)`
  数组版的 placement new

。。所以 (数组，单个变量) * (new，nothrow new，placement new)  一共6个

==delete()运算符释放被分配的内存==

delete表达式 调用 delete()运算符， 将分配给动态变量的内存返回给 运行时系统
delete[]() 返回 动态数组的内存

如果一个程序==定义了 new()== 运算符来从一个特殊的内存池中或是以一种特别的方式分配内存，它==也必须==在相同的作用域内相应地==定义一个  delete()== 运算符，将所分配的内存返回给内存池，否则 delete() 运算符的行为就是`未定义`的。

==C中的内存管理函数==

为了兼容，C++提供了C的 malloc, calloc, realloc, free
- `void* malloc(size_t size)`
  返回一个 可以存储 size 字节的 空间的指针， 没有可用空间 返回 `nullptr`
- `void* free(void* p)`
  将p指向的存储空间返回给内存管理器
- `void* calloc(size_t count, size_t size)`
  ==数组==，计算 count*size，然后用 那个值 调用 `malloc`
- `void* realloc(void*p, size_t size)`
  可以改变一块内存的大小，如果有需要会将内存块`移动`到一个`新的存储空间`中去。
  旧的内存块中的`内容将会被复制到新的`存储块中，被复制的内容的大小是新旧两块内存块大小中的较小值。
  必须`谨慎使用` realloc() 。有时它会移动参数所指向的内存块并删除旧的内存块。如果它这么做了，指向旧内存块的指针将变为无效。有时它会重用现有的内存块，而这个内存块可能会比所请求的大小大。


根据C++标准， 
malloc，free 作用于 称为 heap 的 内存区域，
new()，delete() 作用于 称为 自由存储区(free store) 的内存区域

但 实际，据我所知 所有的实现，new 都会调用 malloc。  通过替换 malloc 和 free，程序可以 全局地 改变管理内存的方式
。。应该不是，不然 128k怎么处理。  不过确实 都会 (。。而不是说:直接转发) ， 但是 肯定还有 很多复杂的逻辑的。 

### new表达式构造动态变量

。。把之前的 new，nothrow new, placement new, 再讲解了一下，跳了很多

如果 type 的声明是一个数组，我们可以使用一个==非常量==表达式来定义最高（也就是最左）数组维度
这样就可以在运行时指定数组的大小。这是在 C++ 中唯一能够声明动态大小数组的方式。
在 C++ 中，一个 n 维的数组是一个 n -1 维数组的数组。因此，==最左维度就是最高维度。==

placement new
```C++
char mem[1000];
class Foo {...};
Foo* foo_p = new (mem) Foo(123);
```

==类专用new()运算符==

new 表达式在要创建的类型范围中查找 new() 运算符。
因此，一个类能够通过提供这些运算的实现来精准地掌握对它自己的内存分配。

要想使用全局 new() 运算符替代类专用 new() 运算符，程序员需要如下这样在 new 表达式中指定全局作用域运算符 ::
```C++
Foo* foo_p = ::new Foo(123);
```

类专用 new() 运算符是高效的，因为它为大小固定的对象分配内存。
因此，第一个未使用的内存块总是可用的。
如果类==没有==被用在`多线程`中，那么类专用 new() 运算符就可以`免去确保`类的内部数据结构是`线程安全`的这项`开销`。

类专用 new() 运算符需要定义为类的==静态成员函数==。

如果一个类实现了自定义定位放置 new() 运算符，那么它必须实现相应的 delete() 运算符，否则全局 delete() 运算符就会被调用，这会带来未定义的而且通常都不希望看到的结果。


### delete表达式处置动态变量

程序使用 delete 表达式将动态变量所使用的内存返回给内存管理器。

`delete p`  `delete[] arr`

### 显式调用析构器 销毁动态变量

`pFoo -> ~Foo();`


## 13.2 高性能内存管理器

默认的 C++ 内存管理器必须满足许多需求。
- 它必须足够高效，因此它非常有可能成为热点代码。
- 它必须能够在多线程程序中正常工作。访问默认内存管理器中的数据结构必须被序列化。
- 它必须能够高效地分配许多相同大小的对象（例如链表节点）。
- 它必须能够高效地分配许多不同大小的对象（例如字符串）。
- 它必须既能够分配非常大的数据结构（I/O 缓冲区，含有数百万个整数值的数组），也能够分配非常小的数据结构（例如一个指针）。
- 为了使性能最大化，它必须至少知道较大内存块的指针的对齐边界、缓存行和虚拟内存页。
- 它的运行时性能不能随着时间而降低。
- 它必须能够高效地复用返回给它的内存。

大多数 C++ 编译器所提供的 ::operator new() 都是 C 语言的 malloc() 函数的简单包装器。
在早期的 C++ 中，这些 malloc() 函数的实现只是为了满足 C 程序分配一些动态缓冲区的简单需求，而不是上述的 C++ 程序的那一长串需求。
用编译器厂商提供的简单的  malloc() 替代复杂的内存管理器`曾经`是一种非常成功的性能优化技巧，开发人员只要掌握这一个技巧就能成为性能优化专家。
。。用 malloc 代替 负载的内存管理器。。。

。。不过 new() 肯定不是直接调用 malloc了， 毕竟还有 128k的限制。


对于老式的操作系统和嵌入式开发，下面是一些 malloc的代替品
。。到底是 该用 malloc 还是 该用 复杂的内存管理器?
。。不过这里说了是 老式的。。。 但是 老式 不应该更需要 简单的malloc 吗。。

- Hoard
  德克萨斯大学的多处理器内存分配器的商业版本。它声称比 malloc() 快了 3~7 倍
- mtmalloc
  Solaris 上的 malloc() 的替代品，用于多线程高工作负载。它使用了一种`最速适配（fast-fit`）分配器。
- ptmalloc
  Linux 3.7 及以后的版本中提供的 malloc() 的替代品。它为每个线程设置了分配区（arena）以减少在多线程程序中的竞争。
- TCMalloc
  线程缓存版的 malloc()
  TCMalloc（位于 gperftools 包中）是谷歌提供的 malloc() 的替代品。
  它具有专业化的小型对象分配器和精心设计的用于管理大内存块的自旋锁。
  根据设计人员的说法，它比 glibc 的 malloc() 更好。
  tcmalloc 只在 Linux 上进行过测试。

对于小型嵌入式项目，实现自己的内存管理器并不是不可能的。
在互联网上查找关键字“fast-fit memory allocation”能查出很多资料，开发人员可以参考这些资料进行开发


## 13.3 提供类专用内存管理器

当动态创建类实例的代码被确定为热点代码时，通过提供类专用内存管理器能够改善程序性能

。。。这个走的有点远了。。。随便看看。。

### 分配固定大小内存的内存管理器

下面的代码定义了一个简单的分配固定大小内存块的内存管理器，它会从一个名为“分配区”（arena）的单独的、静态声明的存储空间块中分配内存块。
作为从自由存储区分配内存的一种方式，我们经常在嵌入式工程中看到这种分配固定大小内存块的内存管理器。 
fixed_block_memory_manager 非常简单：一个单独的未使用内存块的链表。

```C++
template <class Arena> struct fixed_block_memory_manager {
    template <int N>
        fixed_block_memory_manager(char(&a)[N]);
    fixed_block_memory_manager(fixed_block_memory_manager&)
        = delete;
    ~fixed_block_memory_manager() = default;
    void operator=(fixed_block_memory_manager&) = delete;

    void* allocate(size_t);
    size_t block_size() const;
    size_t capacity() const;
    void clear();
    void deallocate(void*);
    bool empty() const;

private:
    struct free_block {
        free_block* next;
    };
    free_block* free_ptr_;
    size_t      block_size_;
    Arena       arena_;
};
```

下面定义的 `构造函数` 接收一个 C 风格的字符数组作为它的参数。这个数组形成了分配内存块的分配区。它的构造函数是一个以数组大小作为模板参数的模板函数
```C++
template <class Arena>
    template <int N>
        inline fixed_block_memory_manager<Arena>
        ::fixed_block_memory_manager(char(&a)[N]) :
            arena_(a), free_ptr_(nullptr), block_size_(0) {
            /* empty */
        }
```

fixed_block_memory_manager  的 allocate() 的定义
```C++
template <class Arena>
    inline void* fixed_block_memory_manager<Arena>
                 ::allocate(size_t size) {
    if (empty()) {
        free_ptr_ = reinterpret_cast<free_block*>
                    (arena_.allocate(size));
        block_size_ = size;
        if (empty())
            throw std::bad_alloc();
    }
    if (size != block_size_)
        throw std::bad_alloc();
    auto p = free_ptr_;
    free_ptr_ = free_ptr_->next;
    return p;
}
```

deallocate()
```C++
template <class Arena>
    inline void fixed_block_memory_manager<Arena>
                ::deallocate(void* p) {
    if (p == nullptr)
        return;
    auto fp = reinterpret_cast<free_block*>(p);
    fp->next = free_ptr_;
    free_ptr_ = fp;
}
```

其他成员函数的定义
```C++
template <class Arena>
    inline size_t fixed_block_memory_manager<Arena>
                  ::capacity() const {
    return arena_.capacity();
}
template <class Arena>
    inline void fixed_block_memory_manager<Arena>::clear() {
    free_ptr_ = nullptr;
    arena_.clear();
}
```

### 内存块分配区

fixed_block_memory_manager 中唯一的复杂点在于未使用内存块的链表是如何被初始化的。这种复杂性被考虑在单独的模板类内部。

```C++
struct fixed_arena_controller {
    template <int N>
        fixed_arena_controller(char(&a)[N]);
    fixed_arena_controller(fixed_arena_controller&) = delete;
   ~fixed_arena_controller() = default;
    void operator=(fixed_arena_controller&) = delete;

    void*  allocate(size_t);
    size_t block_size() const;
    size_t capacity() const;
    void   clear();
    bool   empty() const;

private:
    void*  arena_;
    size_t arena_size_;
    size_t block_size_;
};
```

构造器
```C++
template <int N>
    inline fixed_arena_controller
           ::fixed_arena_controller(char (&a)[N]) :
    arena_(a), arena_size_(N), block_size_(0) {
        /*空*/
    }
```


```C++
inline void* fixed_arena_controller
             ::allocate(size_t size) {
    if (!empty())
        return nullptr; // arena已经被分配了

    block_size_ = std::max(size, sizeof(void*));
    size_t count = capacity();
    if (count == 0)
        return nullptr; // arena太小了，甚至容不下一个元素

    char* p;
    for (p = (char*)arena_; count > 1; --count, p += size) {
        *reinterpret_cast<char**>(p) = p + size;
    }
    *reinterpret_cast<char**>(p) = nullptr;
    return arena_;
}
```

```C++
inline size_t fixed_arena_controller::block_size() const {
    return block_size_;
}

inline size_t fixed_arena_controller::capacity() const {
    return block_size_ ? (arena_size_ / block_size_) : 0;
}

inline void fixed_arena_controller::clear() {
    block_size_ = 0;
}

inline bool fixed_arena_controller::empty() const {
    return block_size_ == 0;
}
```


### 添加一个类专用new()操作符

new() 运算符和 delete() 运算符都是内联函数，它们会将请求转发给 mgr_ 的成员函数 allocate() 和 deallocate()

```C++
class MemMgrTester {
    int contents_;
public:
    MemMgrTester(int c) : contents_(c) {}

    static void* operator new(size_t s) {
        return mgr_.allocate(s);
    }
    static void operator delete(void* p) {
        mgr_.deallocate(p);
    }
    static fixed_block_memory_manager<fixed_arena_controller> mgr_;
};
```

能够像这样被重置的内存管理器被称作==内存池管理器== （pool memory manager），它所控制的分配区则被称为==内存池== （memory pool）。内存池管理器非常适用于数据结构被构造、使用然后被销毁的情况。

初始化内存管理器
```C++
char arena[4004];
fixed_block_memory_manager<fixed_arena_controller>
    MemMgrTester::mgr_(arena);
```


### 分配固定大小内存块的内存管理器的性能

新建实例，比malloc()快15倍。
新建数组，快3.3倍


### 分配固定大小内存块的内存管理器的变化形式

当未使用内存块的链表是空的时，不是分配一个新的固定大小内存块的分配区，而是使用 malloc() 分配内存。
被释放的内存块会被缓存在未使用内存块的链表中供快速复用。

可以通过调用 malloc() 或是 ::new 创建分配区，而不使用固定分配区。
如果有需要，还可以维护分配区链，这样就不会限制会分配多少个小内存块了。
即使偶尔会调用 malloc() ，分配固定大小内存块的内存管理器仍然能够保持它速度快和内存碎片少的优势。

如果类的实例在使用一段时间后会被全部销毁，那么可以将分配固定大小内存块的内存管理器作为内存池使用。
内存池会如平常一样分配内存，但是不会释放内存。
当程序使用完类的实例后，它们会通过重新初始化静态分配区或是将动态分配的分配区返回给系统内存管理器立刻回收。
但是即使它们都被立即回收了，被分配的内存块仍然必须被通过调用析构函数删除。
互联网上的许多内存池分配器都忘记了这个微小却重要的细节。

我们可以设计一种通用的内存管理器来满足来自另外一个分配区的申请不同大小内存块的请求，并返回不同大小的内存块到另外一个未使用内存块的链表中。
如果所有请求的大小四舍五入后都变为了 2 的下一个幂，那么它就是一个==“最快适配==”内存管理器。
典型的最快适配内存管理器只分配大小小于某个最大值的对象，如果请求的大小大于这个最大值，它会将请求转发给默认内存管理器。
最快适配内存管理器的代码太大了，本书将不会展示，读者可以在互联网上查到这些代码。

。。linux的 伙伴系统?

Boost 有一个叫作“Pool”（http://www.boost.org/doc/libs/release/libs/pool/ ）的分配固定大小内存块的内存管理器。


### 非线程安全的内存管理器是高效的



## 13.4 自定义标准库分配器

。。也是快速过。

C++ 标准库的容器类会使用大量的动态变量。我们可以在它们那里寻找优化机会

Allocator 是一个管理内存的模板类。作为被扩展的基础，一个分配器会做三件事情：从内存管理器中获取存储空间，返回存储空间给内存管理器，以及从相关联的分配器中复制构造出它自己

分配器的实现可以非常简单，也可以复杂到让人头脑发麻。

默认分配器 `std::allocator<T>` 是 `::operator new()` 的一个简单的包装器


分配器有两种基本类型。
最简单的分配器是`无状态`的，也就是说一种`没有非静态状态`的分配器类型。
默认分配器 `std::allocator<T>` 对于标准库容器是无状态的。

无状态分配器具有以下特点。
- 无状态分配器能够被默认构造，无需显式地创建一个无状态分配器的实例，然后将它传递给容器类的构造函数。
- 一个无状态分配器不会在容器实例中占用任何空间。


### 最小C++11分配器

。。最小 == 只有最基本功能。 要来干嘛。

### C++98分配器的其他定义

。。挺长的， 但C++98 。。。


### 一个分配固定大小内存块的分配器

```C++
extern fixed_block_memory_manager<fixed_arena_controller>
    list_memory_manager;

template <typename T> class StatelessListAllocator {
public:
   ...

    pointer allocate(
        size_type count,
        typename std::allocator<void>::const_pointer = nullptr) {
        return reinterpret_cast<pointer>
                (list_memory_manager.allocate(count * sizeof(T)));
    }
    void deallocate(pointer p, size_type) {
        string_memory_manager.deallocate(p);
    }
};
```

修改后的 allocate()
```C++
template <class Arena>
    inline void* fixed_block_memory_manager<Arena>
                 ::allocate(size_t size) {
    if (empty()) {
        free_ptr_ = reinterpret_cast<free_block*>
                        (arena_.allocate(size));
        block_size_ = size;
        if (empty())
            throw std::bad_alloc();
    }
    if (size > block_size_)
        throw std::bad_alloc();
    auto p = free_ptr_;
    free_ptr_ = free_ptr_->next;
    return p;
}
```


### 字符串的分配固定大小内存块的分配器

```C++
template <typename T> class NewAllocator {
public:
   ...
    pointer allocate(
        size_type /*count*/,
        typename std::allocator<void>::const_pointer = nullptr) {
        return reinterpret_cast<pointer>
                   (string_memory_manager.allocate(512));
    }

    void deallocate(pointer p, size_type) {
        ::operator delete(p);
    }
};
```

使用分配固定大小内存块的字符串分配器的版本的 remove_ctrl()
```C++
typedef std::basic_string<
    char,
    std::char_traits<char>,
    StatelessStringAllocator<char>> fixed_block_string;

fixed_block_string remove_ctrl_fixed_block(std::string s) {
    fixed_block_string result;
    for (size_t i = 0; i<s.length(); ++i) {
        if (s[i] >= 0x20)
            result = result + s[i];
    }
    return result;
}
```











