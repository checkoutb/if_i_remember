
http://icyfenix.cn/summary/

2023-09-19 15:47

[[toc]]

---

https://jcp.org/en/jsr/detail?id=370



# 探索起步

## 单体架构：Spring Boot

### 技术组件
标准组件
- JSR 370 Java API for RESTful Web Services 2.1 
  RESTFul 服务方面，采用的实现为 Jersey 2，亦可替换为 Apache CXF、RESTeasy、WebSphere、WebLogic 等。
- JSR 330 Dependency Injection for Java 1.0 
  依赖注入方面，采用的的实现为 SpringBoot 2 中内置的 Spring Framework 5。少量地方由于 Spring 在对@Named、@Inject 等注解的支持表现上与本身提供的注解差异，使用了 Spring 的私有注解。
- JSR 338 Java Persistence 2.2 
  持久化方面，采用的实现为 Spring Data JPA。可替换为 Batoo JPA、EclipseLink、OpenJPA 等实现，只需将使用 CrudRepository 所省略的代码手动补全回来即可
- JSR 380 Bean Validation 2.0 
  数据验证方面，采用的实现为 Hibernate Validator 6，可替换为 Apache BVal 等其他验证框架。
- JSR 315 Java Servlet 3.0 
  Web 访问方面，采用的实现为 SpringBoot 2 中默认的 Tomcat 9 Embed，可替换为 Jetty、Undertow 等其他 Web 服务器。

非标准组件
- JSR 375 Java EE Security API specification 1.0 
  认证/授权方面，在 2017 年才发布的 JSR 375 中仍然没有直接包含 OAuth2 和 JWT 的直接支持，因后续实现微服务架构时对比的需要，单体架构中选择了 Spring Security 5 作为认证服务，Spring Security OAuth 2.3 作为授权服务，Spring Security JWT 作为 JWT 令牌支持，并未采用标准的 JSR 375 实现，如 Soteria。
- JSR 353/367 Java API for JSON Processing/Binding 
  在 JSON 序列化/反序列化方面，由于 Spring Security OAuth 的限制（使用 JSON-B 作为反序列化器时的结果与 Jackson 等有差异），采用了 Spring Security OAuth 默认的 Jackson，并未采用标准的 JSR 353/367 实现，如 Apache Johnzon、Eclipse Yasson 等。

### 工程结构

单体架构后端参考（并未完全遵循）了 DDD 的分层模式和设计原则，整体分为以下四层：
- Resource
  对应 DDD 中的 User Interface 层，负责==向用户显示信息或者解释用户发出的命令==。请注意，这里指的“用户”不一定是使用用户界面的人，可以是位于另一个进程或计算机的服务。由于本工程采用了 MVVM 前后端分离模式，这里所指的用户实际上是前端的服务消费者，所以这里以 RESTful 中的核心概念“资源”（Resource）来命名。
- Application
  对应 DDD 中的 Application 层，负责==定义软件本身对外暴露的能力==，即软件本身==可以完成哪些任务==，并==负责对内协调领域对象来解决问题==。根据 DDD 的原则，==应用层要尽量简单，不包含任何业务规则或者知识，而只为下一层中的领域对象协调任务，分配工作，使它们互相协作==，这一点在代码上表现为 Application 层中一般==不会存在任何的条件判断语句==。在许多项目中，Application 层都会被选为==包裹事务==（代码进入此层事务开始，退出此层事务提交或者回滚）的载体。
- Domain
  对应 DDD 中的 Domain 层，负责==实现业务逻辑==，即表达业务概念，处理业务状态信息以及业务规则这些行为，此层是==整个项目的重点==。
- Infrastructure
  对应 DDD 中的 Infrastructure 层，向其他层提供==通用的技术能力==，譬如持久化能力、远程服务通讯、工具集，等等。

![fd1b0b4b79598b6991f6ffcac38054d2.png](../_resources/fd1b0b4b79598b6991f6ffcac38054d2.png)



## 微服务：Spring Cloud

由不同编程语言、不同技术框架所开发的微服务系统中，基于 Spring Cloud 的解决方案仍然是最为主流的选择。
。。不同语言，怎么选择spring cloud。 只能JVM系可以用啊。

微服务环境中必然会面临的==服务发现、远程调用、负载均衡、集中配置等==非功能性的需求。

笔者个人是一直不太倾向于 Spring Cloud Netflix 这种以应用代码去解决基础设施功能问题的“解题思路”，以自顶向下的视角来看，这既是==虚拟化的微服务基础设施==完全成熟之前必然会出现的应用形态，也是微服务进化过程中必然会被替代的过渡形态。
。。docker？？？
。。虚拟化的微服务基础设施的 特点是什么？

### 需求场景

随着业务增长，对于系统的并发和可用方面的要求也越来越高。需要更多的硬件资源，这是合情合理的，但是，如果我们把需求场景列的更具体些，便会发现“合理”下面的许多无可奈何之处：
- 制约软件质量与业务能力提升的最大因素是人而非硬件。
  无论是引入外包团队，抑或是让少量技术专家带着大量普通水平的开发者去共同完成一个大型系统就成为了必然的选择。
  在单体架构下，没有什么有效==阻断错误传播==的手段，系统中“整体”与“部分”的关系没有物理的划分，系统质量只能靠研发与项目管理措施来尽可能地保障，少量的技术专家很难阻止大量螺丝钉式的程序员或者不熟悉原有技术架构的外包人员在某个不起眼的地方==犯错并产生全局性的影响==，并不容易做出整体可靠的大型系统。
- 技术异构的需求从可选渐渐成为必须。
  可能遇到很多想做 Java 却不擅长的事情。
  譬如想去做人工智能，进行深度学习训练，发现大量的库和开源代码都离不开 Python；
  想要引入分布式协调工具时，发现近几年 ZooKeeper 已经有被后起之秀 Golang 的 Etcd 蚕食替代的趋势；
  想要做集中式缓存，发现无可争议的首选是 ANSI C 编写的 Redis，等等。

系统发展到一定程度，我们总能找到充分的理由去拆分与重构它。

在笔者设定的演示案例中，准备把单体的 Fenix's Bookstore拆分成为==“用户”、“商品”、“交易”==三个能够独立运行的子系统


![4f26588b0e4d16ff286e73f83d3ab9fd.png](../_resources/4f26588b0e4d16ff286e73f83d3ab9fd.png)


### 技术组件
微服务部分主要采用了 Netflix OSS 组件进行支持

- 配置中心
  默认采用Spring Cloud Config ，亦可使用Spring Cloud Consul 、Spring Cloud Alibaba Nacos 代替。
- 服务发现
  默认采用Netflix Eureka ，亦可使用Spring Cloud Consul 、Spring Cloud ZooKeeper 、Etcd 等代替。
- 服务网关
  默认采用Netflix Zuul ，亦可使用Spring Cloud Gateway 代替。
- 服务治理
  默认采用Netflix Hystrix ，亦可使用Sentinel 、Resilience4j 代替。
- 进程内负载均衡
  默认采用Netflix Ribbon ，亦可使用Spring Cloud Loadbalancer 代替。
- 声明式HTTP客户端
  默认采用Spring Cloud OpenFeign 。声明式的 HTTP 客户端其实没有找替代品的必要性，如果需要，可考虑Retrofit ，或者使用 RestTemplete 乃至于更底层的OkHTTP 、HTTPClient 以命令式编程来访问，多写一些代码而已了。


## 微服务: Kuternetes

以 Docker Swarm、Apache Mesos 与 Kubernetes 为主要竞争者的“容器战争”终于有了明确的结果，Kubernetes 登基加冕是容器发展中一个==时代的终章==，也将是软件架构发展下一个==纪元的开端==

。。k8s 这么猛吗。。

### 需求场景

初步解决了扩容缩容、独立部署、运维和管理等问题，满足了产品经理不断提出的日益复杂的业务需求。
可是，对于团队的开发人员、设计人员、架构人员来说，并没有感觉到工作变得轻松，微服务中的各种新技术名词，如配置中心、服务发现、网关、熔断、负载均衡等等，就够一名新手学习好长一段时间；
从产品角度来看，各种 Spring Cloud 的技术套件，如 Config、Eureka、Zuul、Hystrix、Ribbon、Feign 等，也占据了产品的==大部分编译后的代码容量==。
之所以微服务架构里，我们选择在==应用层面==而==不是基础设施层面==去解决这些分布式问题，完全是因为==由硬件构成的基础设施，跟不上由软件构成的应用服务的灵活性的无奈之举==。
当 Kubernetes 统一了容器编排管理系统之后，这些纯技术性的底层问题，便开始有了被广泛认可和采纳的==基础设施层面的解决方案==。
为此，Fenix's Bookstore 也迎来了它在“后微服务时代”中的下一次架构演进，这次升级的目标主要有如下两点：

- 目标1：尽可能缩减非业务功能代码的比例。
  在 Fenix's Bookstore 中，用户服务（Account）、商品服务（Warehouse）、交易服务（Payment）三个工程是真正承载业务逻辑的，
  认证授权服务（Security）可以认为是同时涉及到了技术与业务，
  而配置中心（Configuration）、网关（Gateway）和服务注册中心（Registry）则是纯技术性。
  我们希望尽量==消除这些纯技术的工程==，以及那些依附在其他业务工程上的==纯技术组件==。
- 目标2：尽可能在不影响原有的代码的前提下完成迁移。
  得益于 Spring Framework 4 中的 Conditional Bean 等声明式特性的出现，对于近年来新发布的 Java 技术组件，
  声明式编程 （Declarative Programming）已经逐步取代命令式编程 （Imperative Programming）成为主流的选择。
  在声明式编程的支持下，我们可以从目的而不是过程的角度去描述编码意图，使得代码几乎不会与具体技术实现产生耦合，若要更换一种技术实现，只需要调整配置中的声明便可做到。

如果仅以 Java 代码的角度来衡量，本工程与此前基于 Spring Cloud 的实现没有丝毫差异，两者的每一行 ==Java 代码都是一模一样==的；
真正的==区别==在 Kubernetes 的实现版本中直接==删除了配置中心、服务注册中心的工程，在其他工程的 pom.xml 中也删除了如 Eureka、Ribbon、Config 等组件的依赖==。取而代之的是==新增了若干以 YAML 配置文件为载体的Skaffold 和 Kubernetes 的资源描述==，这些资源描述文件，将==会动态构建出 DNS 服务器、服务负载均衡器等一系列虚拟化的基础设施，去代替原有的应用层面的技术组件==。

对比spring cloud，修改了服务的实现框架
![0b62522d46fdbbcf66b716f3230fbc70.png](../_resources/0b62522d46fdbbcf66b716f3230fbc70.png)

### 技术组件

采用基于 Kubernetes 的微服务架构，并采用 Spring Cloud Kubernetes 做了适配，其中主要的技术组件包括：
- 环境感知
  Spring Cloud Kubernetes 本身引入了 Fabric8 的Kubernetes Client 作为容器环境感知，不过引用的版本相当陈旧，
  如 Spring Cloud Kubernetes 1.1.2 中采用的是 Fabric8 Kubernetes Client 4.4.1，
  Fabric8 提供的兼容性列表中该版本只支持到 Kubernetes 1.14，实测在 1.16 上也能用，但是在 1.18 上无法识别到最新的 Api-Server，
  因此 Maven 引入依赖时需要手工处理，排除旧版本，引入新版本（本工程采用的是 4.10.1）。
- 配置中心
  采用 Kubernetes 的 ConfigMap 来管理，通过Spring Cloud Kubernetes Config 自动将 ConfigMap 的内容注入到 Spring 配置文件中，并实现动态更新。
- 服务发现
  采用 Kubernetes 的 Service 来管理，通过Spring Cloud Kubernetes Discovery 自动将 HTTP 访问中的服务转换为FQDN 。
- 负载均衡
  采用 Kubernetes Service 本身的负载均衡能力实现（就是 DNS 负载均衡），可以不再需要 Ribbon 这样的客户端负载均衡了。
  Spring Cloud Kubernetes 从 1.1.2 开始也已经移除了对 Ribbon 的适配支持，也（暂时）没有对其代替品 Spring Cloud LoadBalancer 提供适配。
- 服务网关
  网关部分仍然保留了 Zuul，未采用 Ingress 代替。
  这里有两点考虑，
  一是 Ingress Controller 不算是 Kubernetes 的自带组件，它可以有不同的选择（KONG、Nginx、Haproxy，等等），同时也需要独立安装，作为演示工程，出于环境复杂度最小化考虑未使用 Ingress；
  二是 Fenix's Bookstore 的前端工程是存放在网关中的，移除了 Zuul 之后也仍然要维持一个前端工程的存在，不能进一步缩减工程数量，也就削弱了移除 Zuul 的动力。
- 服务熔断
  仍然采用 Hystrix，Kubernetes 本身无法做到精细化的服务治理，包括熔断、流控、监视，等等，我们将在基于 Istio 的服务网格架构中解决这个问题。
- 认证授权
  仍然采用 Spring Security OAuth 2，Kubernetes 的 RBAC 授权可以解决服务层面的访问控制问题，但 Security 是跨越了业务和技术的边界的，认证授权模块本身仍承担着对前端用户的认证、授权职责，这部分是与业务相关的



## 服务网格：Istio

http://icyfenix.cn/exploration/projects/servicemesh_arch_istio.html


当软件架构演进至基于 Kubernetes 实现的微服务时，已经能够相当充分地享受到虚拟化技术发展的红利，
==如应用能够灵活地扩容缩容、不再畏惧单个服务的崩溃消亡、立足应用系统更高层来管理和编排各服务之间的版本、交互。==

光靠着 Kubernetes 本身的虚拟化基础设施，难以做到精细化的服务治理，譬如==熔断、流控、观测==，等等；
而即使是那些它可以提供支持的分布式能力，譬如通过 DNS 与服务来实现的服务发现与负载均衡，也只能说是初步解决了的分布式中如何调用服务的问题而已，只靠 DNS 难以满足==根据不同的配置规则、协议层次、均衡算法等去调节负载均衡的执行过程这类高级的配置需求==。

基于 Kubernetes 之上构筑的==服务网格（Service Mesh）==是目前最先进的架构风格，即通过==中间人流量劫持==的方式，以介乎于应用和基础设施之间的==边车代理==（Sidecar）来做到既让用户代码可以专注业务需求，不必关注分布式的技术，又能实现几乎不亚于此前 Spring Cloud 时代的那种通过代码来解决分布式问题的可配置、安全和可观测性。这一个目标，现在已成为了最热门的服务网格框架Istio的 Slogan：Connect, Secure, Control, And Observe Services。

### 需求场景

随着 Kubernetes 集群中的 Pod 数量规模越来越庞大，
到一定程度之后，运维的同学无奈地表示已经不可能够依靠人力来跟进微服务中出现的各种问题了：
一个请求在哪个服务上调用失败啦？是 A 有调用 B 吗？还是 C 调用 D 时出错了？
为什么这个请求、页面忽然卡住了？
怎么调度到这个 Node 上的服务比其他 Node 慢那么多？
这个 Pod 有 Bug，消耗了大量的 TCP 链接数……

一个很现实的问题是高端技术人员的数量总是有限的，人多了就不可能保证每个人都是精英，如何让普通的、初级的程序员依然能够做出靠谱的代码，成为这一阶段技术管理者的要重点思考的难题。
这时候，团队内部出现了一种声音：微服务太复杂了，已经学不过来了，让我们回归单体吧……

迎来了它的下一次技术架构的演进，这次的进化的目标主要有以下两点：
- 目标一：实现在大规模虚拟服务下可管理、可观测的系统。
  必须找到某种方法，==针对应用系统整体层面==，而不是针对单一微服务==来连接、调度、配置和观测服务==的执行情况。
  此时，可视化整个系统的服务调用关系，动态配置调节服务节点的断路、重试和均衡参数，针对请求统一收集服务间的处理日志等功能就不再是系统锦上添花的外围功能了，而是关乎系统是否能够正常运行、运维的必要支撑点。
- 目标二：在代码层面，裁剪技术栈深度，==回归单体架构==中基于 Spring Boot 的开发模式，而不是 Spring Cloud 或者 Spring Cloud Kubernetes 的技术架构。
  我们并不是要去开历史的倒车，相反，我们是很贪心地希望开发重新变得简单的同时，又不能放弃现在微服务带来的一切好处。
  在这个版本的 Fenix's Bookstore 里，所有与 Spring Cloud 相关的技术组件，如上个版本遗留的 Zuul 网关、Hystrix 断路器，还有上个版本新引入用于感知适配 Kubernetes 环境的 Spring Cloud Kubernetes 都将会==被拆除==掉。
  如果只观察单个微服务的技术堆栈，它与最初的单体架构几乎没有任何不同——甚至还更加简单了，连从单体架构开始一直保护着服务调用安全的 Spring Security 都移除掉（由于 Fenix's Bookstore 借用了 Spring Security OAuth2 的密码模式做为登陆服务的端点，所以在 Jar 包层面 Spring Security 还是存在的，但其用于安全保护的 Servlet 和 Filter 已经被关闭掉）

从升级目标可以明确地得到一种导向，我们必须==控制住服务数量膨胀==后传递到运维团队的压力，让“每位运维人员能支持服务的数量”这个比例指标有指数级地提高才能确保微服务下运维团队的健康运作。
对于开发团队，我们可以只要求==一小部分核心==的成员对微服务、Kubernetes、Istio 等技术有深刻的理解即可，其余==大部分开发==人员，仍然可以基于最传统、普通的 Spirng Boot 技术栈来开发功能。升级改造之后的应用架构如下图所示：


![4fba39576f46db279c624a9869cf6e19.png](../_resources/4fba39576f46db279c624a9869cf6e19.png)


### 技术组件

基于 Istio 的服务网格架构，其中主要的技术组件包括：
- 配置中心：
  通过 Kubernetes 的 ConfigMap 来管理。
- 服务发现：
  通过 Kubernetes 的 Service 来管理，由于已经不再引入 Spring Cloud Feign 了，所以在 OpenFeign 中，直接使用短服务名进行访问。
- 负载均衡：
  未注入边车代理时，依赖 KubeDNS 实现基础的负载均衡，一旦有了 Envoy 的支持，就可以配置丰富的代理规则和策略。
- 服务网关：
  依靠 Istio Ingress Gateway 来实现，已经移除了 Kubernetes 版本中保留的 Zuul 网关。
- 服务容错：
  依靠 Envoy 来实现，已经移除了 Kubernetes 版本中保留的 Hystrix。
- 认证授权：
  依靠 Istio 的安全机制来实现，实质上已经不再依赖 Spring Security 进行 ACL 控制，但 Spring Security OAuth 2 仍然以第三方 JWT 授权中心的角色存在，为系统提供终端用户认证，为服务网格提供令牌生成、公钥JWKS等支持。



## 无服务：AWS Lambda
无服务架构（Serverless）与微服务架构本身==没有继承替代关系==，它们并不是同一种层次的架构，无服务的云函数可以作为微服务的一种实现方式，甚至==可能是未来很主流==的实现方式。
在这部文档中我们的话题主要还是聚焦在如何解决分布式架构下的种种问题，相对而言无服务架构并非重点，不过为保证架构演进的完整性，笔者仍然建立了无服务架构的简单演示工程。

不过，由于无服务架构原理上就决定了它对程序的==启动性能==十分敏感，这天生就不利于 Java 程序，尤其不利于 Spring 这类启动时组装的 CDI 框架。
因此基于 Java 的程序，除非使用==GraalVM 做提前编译==、将 Spring 的大部分 Bean 提前初始化，或者迁移至Quarkus 这以原生程序为目标的框架上，否则是很难实际用于生产的



# 演进中的架构

## 原始分布式时代 (20世纪70-80)

```text
UNIX 的分布式设计哲学
Simplicity of both the interface and the implementation are more important than any other attributes of the system — including correctness, consistency, and completeness
保持接口与实现的简单性，比系统的任何其他属性，包括准确性、一致性和完整性，都来得更加重要。
—— Richard P. Gabriel，The Rise of 'Worse is Better' ，1991
```


当时研究这些技术都带着浓厚的 UNIX 设计风格，有一个预设的==重要原则==是 使分布式环境中的服务调用、资源访问、数据存储等操作尽可能==透明化、简单化==，使开发人员不必过于关注他们访问的方法或其他资源是位于本地还是远程

“调用远程方法”与“调用本地方法”尽管只是两字之差，但若要同时兼顾简单、透明、性能、正确、鲁棒、一致等特点的话，两者的复杂度就完全不可同日而语了。
- 远程方法不能再依靠本地方法那些以内联为代表的传统编译优化来提升速度
- 远程的服务在哪里（服务发现），有多少个（负载均衡），网络出现分区、超时或者服务出错了怎么办（熔断、隔离、降级），方法的参数与返回结果如何表示（序列化协议），信息如何传输（传输协议），服务权限如何管理（认证、授权），如何保证通信安全（网络安全层），如何令调用不同机器的服务返回相同的结果（分布式数据一致性）等

==某个功能能够进行分布式，并不意味着它就应该进行分布式，强行追求透明的分布式操作，只会自寻苦果==

。。20世纪70，80年代就开始了，但是没有成功。



## 单体系统时代

单体架构（Monolithic）
“单体”只是表明系统中主要的过程调用都是进程内调用，不会发生进程间通信，仅此而已。

对于小型系统——即由单台机器就足以支撑其良好运行的系统，
单体不仅易于开发、易于测试、易于部署，且由于系统中各个功能、模块、方法的调用过程都是进程内调用，不会发生进程间通信 （Inter-Process Communication，IPC。广义上讲，可以认为 RPC 属于 IPC 的一种特例，但请注意这里两个“PC”不是同个单词的缩写），
因此也是运行效率最高的一种架构风格，完全不应该被贴上“反派角色”的标签，
反倒是那些爱赶技术潮流却不顾需求现状的微服务吹捧者更像是个反派。

单体系统的不足，必须基于软件的性能需求超过了单机，软件的开发人员规模明显超过了“2 Pizza Team ”范畴的前提下才有讨论的价值，因此，本文后续讨论中所说的单体，均应该是特指“大型的单体系统”

。。双比萨团队 Two-pizza teams ，就是说让团队保持在两个比萨能让队员吃饱的小规模的概念。团队要小到让每个成员都能做出显著的贡献，并且相互依赖，有共同目标，以及统一的成功标准。

笔者相信肯定有一部分人说起单体架构、巨石系统的缺点时，在脑海中闪过的第一个特点就是它的“不可拆分”，难以扩展，因此才不能支撑越来越大的软件规模。这种想法看似合理，其实是有失偏颇的，至少不完整。


从纵向角度来看，笔者从未见过实际生产环境里有哪个大型的现代信息系统是完全不分层的。
分层架构（Layered Architecture）已是现在几乎所有信息系统建设中都普遍认可、采用的软件设计方法

无论是单体还是微服务，抑或是其他架构风格，都会对代码进行纵向层次划分，收到的外部请求在各层之间以不同形式的数据结构进行流转传递，触及最末端的数据库后按相反的顺序回馈响应

。。service层， dao层

在“拆分”这方面，单体系统的真正缺陷不在如何拆分，而在==拆分之后的隔离与自治能力上的欠缺==

由于所有代码都运行在同一个进程空间之内，所有模块、方法的调用都无须考虑网络分区、对象复制这些麻烦的事和性能损失。
获得了进程内调用的简单、高效等好处的同时，也意味着如果任何一部分代码出现了缺陷，过度消耗了进程空间内的资源，所==造成的影响也是全局性的、难以隔离的==。
譬如内存泄漏、线程爆炸、阻塞、死循环等问题，都将==会影响整个程序==，而不仅仅是影响某一个功能、模块本身的正常运作。
如果消耗的是某些更高层次的公共资源，譬如端口号或者数据库连接池泄漏，影响还将会波及==整台机器==，甚至是==集群中其他单体==副本的正常工作。

由于所有代码都共享着同一个进程空间，不能隔离，也就无法（其实还是有办法的，譬如使用 OSGi 这种运行时模块化框架，但是很别扭、很复杂）做到单独停止、更新、升级某一部分代码，因为不可能有“停掉半个进程，重启 1/4 个程序”这样不合逻辑的操作，所以从可维护性来说，单体系统也是不占优势的。
程序升级、修改缺陷往往需要制定专门的停机更新计划，做灰度发布、A/B 测试也相对更复杂。

如果说共享同一进程获得==简单、高效==的代价是同时损失了各个功能模块的==自治、隔离能力==，那这两者孰轻孰重呢？这个问题的潜台词似乎是在比较微服务、单体架构哪种更好用、更优秀？

由于隔离能力的缺失，单体除了难以阻断错误传播、不便于动态更新程序以外，还面临难以技术异构的困难，每个模块的代码都通常==需要使用一样的程序语言，乃至一样的编程框架==去开发。
单体系统的技术栈异构并非一定做不到，譬如 JNI 就可以让 Java 混用 C 或 C++，但这通常是迫不得已的，并不是优雅的选择。

==微服务取代单体==系统成为潮流趋势的根本原因，笔者认为==最重要的理由==是：单体系统很难兼容“Phoenix”的特性。这种架构风格潜在的观念是希望系统的每一个部件，每一处代码都尽量可靠，靠不出或少出缺陷来构建可靠系统。

单体靠高质量来保证高可靠性的思路，在小规模软件上还能运作良好，但系统规模越大，交付一个可靠的单体系统就变得越来越具有挑战性。

正是随着软件架构演进，构筑可靠系统从“追求尽量不出错”，到正视“出错是必然”的观念转变，才是微服务架构得以挑战并逐步开始取代运作了数十年的单体架构的底气所在。

在新旧世纪之交，人们曾经探索过几种服务拆分方法，将一个大的单体系统拆分为若干个更小的、不运行在同一个进程的独立服务，这些服务拆分方法后来导致了面向服务架构 （Service-Oriented Architecture）的一段兴盛期，我们称其为“SOA 时代”。


## SOA 时代

http://icyfenix.cn/architecture/architect-history/soa.html

SOA 架构（Service-Oriented Architecture）
面向服务的架构是一次具体地、系统性地成功解决分布式服务主要问题的架构模式。

为了对大型的单体系统进行拆分，让每一个子系统都能独立地部署、运行、更新，开发者们曾经尝试过多种方案，这里列举以下三种较有代表性的架构模式:
- 烟囱式架构 （Information Silo Architecture）：
  信息烟囱又名信息孤岛（Information Island），使用这种架构的系统也被称为孤岛式信息系统或者烟囱式信息系统。
  它指的是一种完全不与其他相关信息系统进行互操作或者协调工作的设计模式。
  而唯一的问题，也是致命的问题是，企业中真的存在完全不发生交互的部门吗？对于两个信息系统来说，哪怕真的毫无业务往来关系，但系统的人员、组织、权限等主数据，会是完全独立、没有任何重叠的吗？这样“独立拆分”“老死不相往来”的系统，显然不可能是企业所希望见到的。

- 微内核架构 （Microkernel Architecture）：
  微内核架构也被称为插件式架构（Plug-in Architecture）。
  既然在烟囱式架构中，没有业务往来关系的系统也可能需要共享人员、组织、权限等一些的公共的主数据，那不妨就将这些主数据，连同其他可能被各子系统使用到的公共服务、数据、资源集中到一块，成为一个被所有业务系统共同依赖的==核心==（Kernel，也称为 Core System），具体的业务系统以插件模块（Plug-in Modules）的形式存在，这样也可提供可扩展的、灵活的、天然隔离的功能特性，即微内核架构，如图 1-2 所示。
  这种模式很适合桌面应用程序，也经常在 Web 应用程序中使用。
  任何计算机系统都是由各种软件互相配合工作来实现具体功能的，本节列举的不同架构实现的软件，都可视作整个系统的某种插件。
  对于平台型应用来说，如果我们希望将新特性或者新功能及时加入系统，微内核架构会是一种不错的方案。
  微内核架构也可以嵌入到其他的架构模式之中，通过插件的方式来提供新功能的定制开发能力，如果你准备实现一个能够支持二次开发的软件系统，微内核也会是一种良好的选择。
  不过，微内核架构也有它的局限和使用前提，它假设系统中各个插件模块之间是互不认识，不可预知系统将安装哪些模块，因此这些==插件==可以访问内核中一些公共的资源，但==不会直接交互==。可是，无论是企业信息系统还是互联网应用，这一前提假设在许多场景中都并不成立，我们必须找到办法，既能拆分出独立的系统，也能让拆分后的子系统之间顺畅地互相调用通信。

![1c15efe09515d6611bc8f23b38c6c460.png](../_resources/1c15efe09515d6611bc8f23b38c6c460.png)

- 事件驱动架构 （Event-Driven Architecture）：
  为了能让子系统互相通信，一种可行的方案是在子系统之间建立一套事件队列管道（Event Queues），来自系统外部的消息将以事件的形式发送至管道中，各个==子系统从管道里获取自己感兴趣、能够处理的事件消息，也可以为事件新增或者修改其中的附加信息，甚至可以自己发布一些新的事件到管道队列中去==，如此，每一个消息的处理者都是独立的，高度解耦的，但又能与其他处理者（如果存在该消息处理者的话）通过事件管道进行互动，如图 1-3 所示。

![db214579f3873d54d04b4e61beb5bfc7.png](../_resources/db214579f3873d54d04b4e61beb5bfc7.png)


当系统演化至事件驱动架构时，原始分布式时代结尾中提到的第二条通往更大规模软件的路径，即仍在并行发展的远程服务调用也迎来了 ==SOAP 协议==的诞生（详见远程服务调用一文），此时“面向服务的架构”（Service Oriented Architecture，SOA）已经有了它登上软件架构舞台所需要的全部前置条件。


软件架构来到 SOA 时代，许多概念、思想都已经能在今天微服务中找到对应的身影了，譬如服务之间的松散耦合、注册、发现、治理，隔离、编排，等等。
这些在今天微服务中耳熟能详的名词概念，大多数也是在分布式服务刚被提出时就已经可以预见的困难点。SOA 针对这些问题，甚至是针对“软件开发”这件事情本身，都进行了更加系统性、更加具体的探索。

SOAP 协议被逐渐边缘化的本质原因：过于严格的规范定义带来过度的复杂性。而构建在 SOAP 基础之上的 ESB、BPM、SCA、SDO 等诸多上层建筑，进一步加剧了这种复杂性。


## 微服务时代

微服务架构（Microservices）
微服务是一种==通过多个小型服务==组合来==构建单个应用==的架构风格，这些服务==围绕业务能力==而非特定的技术标准来构建。各个服务可以采用==不同的编程语言==，不同的数据存储技术，运行在不同的进程之中。==服务采取轻量级的通信机制和自动化的部署机制实现通信与运维==。

微服务真正的崛起是在 2014 年，相信阅读此文的大多数读者，也是从 Martin Fowler 与 James Lewis 合写的文章《Microservices: A Definition of This New Architectural Term 》中首次了解到微服务
文中列举了微服务的九个核心的业务与技术特征，下面将其一一列出并解读。

- 围绕业务能力构建（Organized around Business Capability）。
  这里再次强调了康威定律的重要性，==有怎样结构、规模、能力的团队，就会产生出对应结构、规模、能力的产品==。
  这个结论不是某个团队、某个公司遇到的巧合，而是必然的演化结果。如果本应该归属同一个产品内的功能被划分在不同团队中，必然会产生大量的跨团队沟通协作，跨越团队边界无论在管理、沟通、工作安排上都有更高昂的成本，高效的团队自然会针对其进行改进，当团队、产品磨合调节稳定之后，团队与产品就会拥有一致的结构。

- 分散治理（Decentralized Governance）。
  这是要表达“谁家孩子谁来管”的意思，服务对应的==开发团队有直接对服务运行质量负责的责任==，也应该有着不受外界干预地掌控服务各个方面的权力，譬如选择与其他服务异构的技术来实现自己的服务。
  这一点在真正实践时多少存有宽松的处理余地，大多数公司都不会在某一个服务使用 Java，另一个用 Python，下一个用 Golang，而是通常会有统一的主流语言，乃至统一的技术栈或专有的技术平台。
  微服务不提倡也并不反对这种“统一”，只要负责提供和维护基础技术栈的团队，有被各方依赖的觉悟，要有“经常被凌晨 3 点的闹钟吵醒”的心理准备就好。微服务更加强调的是确实有必要技术异构时，应能够有选择“不统一”的权利，譬如不应该强迫 Node.js 去开发报表页面，要做人工智能训练模型时，应该可以选择 Python，等等。

- 通过服务来实现独立自治的组件（Componentization via Services）。
  之所以强调通过“服务”（Service）而不是“类库”（Library）来构建组件，是因为类库在编译期静态链接到程序中，通过本地调用来提供功能，而==服务是进程外组件，通过远程调用来提供功能==。
  前面的文章里我们已经分析过，尽管远程服务有更高昂的调用成本，但这是为组件带来隔离与自治能力的必要代价。

- 产品化思维（Products not Projects）。
  避免把==软件研发==视作要去完成某种功能，而是==视作一种持续改进、提升的过程==。
  譬如，不应该把运维只看作运维团队的事，把开发只看作开发团队的事，团队应该为软件产品的整个生命周期负责，开发者不仅应该知道软件如何开发，还应该知道它如何运作，用户如何反馈，乃至售后支持工作是怎样进行的。
  注意，这里服务的用户不一定是最终用户，也可能是消费这个服务的另外一个服务。以前在单体架构下，程序的规模决定了无法让全部人员都关注完整的产品，组织中会有开发、运维、支持等细致的分工的成员，各人只关注于自己的一块工作，但在微服务下，要求开发团队中每个人都具有产品化思维，关心整个产品的全部方面是具有可行性的。

- 数据去中心化（Decentralized Data Management）。
  微服务明确地提倡数据应该按领域分散管理、更新、维护、存储，在单体服务中，一个系统的各个功能模块通常会使用同一个数据库，诚然中心化的存储天生就更容易避免一致性问题，但是，同一个数据实体在不同服务的视角里，它的抽象形态往往也是不同的。
  譬如，Bookstore 应用中的书本，在销售领域中关注的是价格，在仓储领域中关注的库存数量，在商品展示领域中关注的是书籍的介绍信息，如果作为==中心化的存储，所有领域都必须修改和映射到同一个实体之中，这便使得不同的服务很可能会互相产生影响而丧失掉独立性==。尽管在==分布式中要处理好一致性的问题也相当困难==，很多时候都没法使用传统的事务处理来保证，但是两害相权取其轻，有一些必要的代价仍是值得付出的。

- 强终端弱管道（Smart Endpoint and Dumb Pipe）。
  弱管道（Dumb Pipe）几乎算是直接指名道姓地反对 SOAP 和 ESB 的那一堆复杂的通信机制。ESB 可以处理消息的编码加工、业务规则转换等；BPM 可以集中编排企业业务服务；SOAP 有几十个 WS-*协议族在处理事务、一致性、认证授权等一系列工作，这些构筑在通信管道上的功能也许对某个系统中的某一部分服务是有必要的，但对于另外更多的服务则是强加进来的负担。
  如果服务需要上面的额外通信能力，就应该在服务自己的 Endpoint 上解决，而不是在通信管道上一揽子处理。微服务提倡类似于经典 UNIX 过滤器那样简单直接的通信方式，RESTful 风格的通信在微服务中会是更加合适的选择。

- 容错性设计（Design for Failure）。
  不再虚幻地追求服务永远稳定，而是接受==服务总会出错==的现实，要求在微服务的设计中，有自动的机制对其依赖的服务能够进行快速故障检测，在持续出错的时候进行隔离，在服务恢复的时候重新联通。
  所以“断路器”这类设施，对实际生产环境的微服务来说并不是可选的外围组件，而是一个必须的支撑点，如果没有容错性的设计，系统很容易就会被因为一两个服务的==崩溃所带来的雪崩==效应淹没。==可靠系统完全可能由会出错的服务组成==，这是微服务最大的价值所在，也是这部开源文档标题“凤凰架构”的含义。

- 演进式设计（Evolutionary Design）。
  容错性设计承认服务会出错，演进式设计则是承认服务会被报废淘汰。
  一个设计良好的服务，应该是能够报废的，而不是期望得到长存永生。
  假如系统中出现不可更改、无可替代的服务，这并不能说明这个服务是多么的优秀、多么的重要，反而是一种系统设计上脆弱的表现，微服务所追求的独立、自治，也是反对这种脆弱性的表现。

- 基础设施自动化（Infrastructure Automation）。
  基础设施自动化，如 CI/CD 的长足发展，显著减少了构建、发布、运维工作的复杂性。
  由于微服务下运维的对象比起单体架构要有数量级的增长，使用微服务的团队更加依赖于基础设施的自动化，人工是很难支撑成百上千乃至成千上万级别的服务的。


微服务时代充满着自由的气息，微服务时代充斥着迷茫的选择。


## 后微服务时代

后微服务时代（Cloud Native）
从软件层面独力应对微服务架构问题，发展到软、硬一体，合力应对架构问题的时代，此即为“后微服务时代”。

分布式架构中出现的问题，如注册发现、跟踪治理、负载均衡、传输通信等，其实在 SOA 时代甚至可以说从原始分布式时代起就已经存在了，只要是分布式架构的系统，就无法完全避免，但我们不妨换个思路来想一下，这些问题一定要由软件系统自己来解决吗？
如果不局限于采用软件的方式，这些问题几乎都有对应的硬件解决方案。
譬如，某个系统需要伸缩扩容，通常会购买新的服务器，部署若干副本实例来分担压力；
如果某个系统需要解决负载均衡问题，通常会布置负载均衡器，选择恰当的均衡算法来分流；
如果需要解决传输安全问题，通常会布置 TLS 传输链路，配置好 CA 证书以保证通信不被窃听篡改；
如果需要解决服务发现问题，通常会设置 DNS 服务器，让服务访问依赖稳定的记录名而不是易变的 IP 地址，等等。
经过计算机科学多年的发展，这些问题大多有了专职化的基础设施去解决，而之所以微服务时代，人们选择在软件的代码层面而不是硬件的基础设施层面去解决这些分布式问题，很大程度上是因为由==硬件构成的基础设施，跟不上由软件构成的应用服务的灵活性==的无奈之举。
软件可以只使用键盘命令就能拆分出不同的服务，只通过拷贝、启动就能够伸缩扩容服务，硬件难道就不可以通过敲键盘就变出相应的应用服务器、负载均衡器、DNS 服务器、网络链路这些设施吗？

行文至此，估计大家已经听出下面要说的是==虚拟化 技术和容器化== 技术了。

。。我想的是，云服务器。。。
。。不过云服务器是不是就是 容器化的？  不太可能真的有一台 2g 4核的 服务器啊。

笔者在表 1-1 列出了在同一个分布式服务的问题在传统 ==Spring Cloud 中提供的应用层==面的解决方案与在 ==Kubernetes 中提供的基础设施层==面的解决方案，尽管因为各自出发点不同，解决问题的方法和效果都有所差异，但这无疑是提供了一条全新的、前途更加广阔的解题思路。

|-|kubernetes|spring cloud|
|--|--|--|
|弹性伸缩|Autoscaling|无|
|服务发现|KubeDNS / CoreDNS|Spring Cloud Eureka|
|配置中心|ConfigMap / Secret|Spring Cloud Config|
|服务网关|Ingress Controller|Spring Cloud Zuul|
|负载均衡|Load Balancer|Spring Cloud Ribbon|
|服务安全|RBAC API|Spring Cloud Security|
|跟踪监控|Metrics API / Dashboard|Spring Cloud Turbine|
|降级熔断|无|Spring Cloud Hystrix|


“前途广阔”不仅仅是一句恭维赞赏的客气话，当虚拟化的基础设施从单个服务的容器扩展至由多个容器构成的服务集群、通信网络和存储设施时，软件与硬件的界限便已经模糊。
一旦虚拟化的硬件能够跟上软件的灵活性，那些与业务无关的技术性问题便有可能从软件层面剥离，悄无声息地解决于硬件基础设施之内，让软件得以只专注业务，真正“围绕业务能力构建”团队与产品。如此，DCE 中未能实现的“透明的分布式应用”成为可能，Martin Fowler 设想的“凤凰服务器 “成为可能，Chad Fowler 提出的“不可变基础设施 ”也成为可能，从软件层面独力应对分布式架构所带来的各种问题，发展到应用代码与基础设施软、硬一体，合力应对架构问题的时代，现在常被媒体冠以“云原生”这个颇为抽象的名字加以宣传。云原生时代与此前微服务时代中追求的目标并没有本质改变，在服务架构演进的历史进程中，笔者更愿意称其为“后微服务时代”。


仅从功能上看，单纯的 Kubernetes 反而不如之前的 Spring Cloud 方案。
这是因为有一些问题处于应用系统与基础设施的边缘，使得完全在基础设施层面中确实很难精细化地处理。举个例子，微服务 A 调用了微服务 B 的两个服务，称为 B1和 B2，假设 B1表现正常但 B2出现了持续的 500 错，那在达到一定阈值之后就应该对 B2进行熔断，以避免产生雪崩效应 。如果仅在基础设施层面来处理，这会遇到一个两难问题，切断 A 到 B 的网络通路则会影响到 B1的正常调用，不切断的话则持续受 B2的错误影响。

。。？负载均衡 别往 B2 发不就可以了？ 不不不， 是否错误，是 微服务定义的。。但是 5xx 系列可以说明 服务不可用了。 这样就需要在 负载均衡上 设置 断路器 的逻辑。。似乎不太合适。但是，又可以，毕竟 对于 业务来说， 不会感知到的。

基础设施是针对整个容器来管理的，粒度相对粗旷，只能到容器层面，对单个远程服务就很难有效管控
。。对， 负载均衡 一般是转发给 IP， 这台机器 只是 一个接口有问题， 不收所有请求的话， 就浪费了。 但是，有错误，处理得够快，就 无所谓。
。。但是，spring cloud 的断路器，已经非常的完整，不需要额外代码了。完全可以结合啊。 为什么要求 kubernetes 实现断路器？

类似的情况不仅仅在断路器上出现，服务的监控、认证、授权、安全、负载均衡等都有可能面临细化管理的需求，
譬如服务调用时的负载均衡，往往需要根据流量特征，调整负载均衡的层次、算法，等等，
而 DNS 尽管能实现一定程度的负载均衡，但通常并不能满足这些额外的需求。

。。DNS负载均衡技术的实现原理是在DNS服务器中为同一个主机名配置多个IP地址，在应答DNS查询时，DNS服务器对每个查询将以DNS文件中主机记录的IP地址按顺序返回不同的解析结果，将客户端的访问引导到不同的机器上去
。。存储系统DNS负载均衡特性支持的均衡策略有加权轮询、按CPU利用率、按连接数、按端口带宽利用率和按综合负载。


为了解决这一类问题，虚拟化的基础设施很快完成了第二次进化，引入了今天被称为“服务网格 ”（Service Mesh）的“边车代理模式”（Sidecar Proxy），如图 1-5 所示。
所谓的“边车”是一种带垮斗的三轮摩托，我小时候还算常见，现在基本就只在影视剧中才会看到了。

这个场景里指的具体含义是由系统自动在服务容器（通常是指 Kubernetes 的 Pod）中注入一个通信代理服务器，相当于那个挎斗，以类似网络安全里中间人攻击的方式进行流量劫持，在应用毫无感知的情况下，悄然接管应用所有对外通信。
这个代理除了实现正常的服务间通信外（称为数据平面通信），还接收来自控制器的指令（称为控制平面通信），根据控制平面中的配置，对==数据平面==通信的内容进行分析处理，以实现熔断、认证、度量、监控、负载均衡等各种附加功能。
这样便实现了既不需要在应用层面加入额外的处理代码，也提供了几乎不亚于程序代码的精细管理能力。

图来自 Istio 的配置文档 ，图中的 Mixer 在 Istio 1.5 之后已经取消，这里仅作示意
![ffc5fbbec4ee5252ae0a447641b37ced.png](../_resources/ffc5fbbec4ee5252ae0a447641b37ced.png)


今天服务网格仍然是个新潮的概念，仍然未完全成熟，甚至连 Kubernetes 也还算是个新生事物。但笔者相信，未来 Kubernetes 将会成为服务器端标准的运行环境，如同现在 Linux 系统；
服务网格将会成为微服务之间通信交互的主流模式，把“选择什么通信协议”、“怎样调度流量”、“如何认证授权”之类的技术问题隔离于程序代码之外，取代今天 Spring Cloud 全家桶中大部分组件的功能，微服务只需要考虑业务本身的逻辑，这才是最理想的Smart Endpoints 解决方案。



## 无服务时代

无服务架构（Serverless）
如果说微服务架构是分布式系统这条路的极致，那无服务架构，也许就是“不分布式”的云端系统这条路的起点。

2012 年，Iron.io 公司 率先提出了“无服务”（Serverless，应该翻译为“无服务器”才合适，但现在称“无服务”已形成习惯了）的概念，
2014 年开始，亚马逊发布了名为 Lambda 的商业化无服务应用，并在后续的几年里逐步得到开发者认可，发展成目前世界上最大的无服务的运行平台；
2018 年，中国的阿里云、腾讯云等厂商也开始跟进，发布了旗下的无服务的产品，“无服务”已成了近期技术圈里的“新网红”之一。

2009 年，云计算概念刚提出的早期，UC Berkeley 大学曾发表的论文《Above the Clouds: A Berkeley View of Cloud Computing 》，文中预言的云计算的价值、演进和普及在过去的十年里一一得到验证。十年之后的 2019 年，UC Berkeley 的第二篇有着相同命名风格的论文《Cloud Programming Simplified: A Berkeley View on Serverless Computing 》发表，再次预言未来“无服务将会发展成为未来云计算的主要形式”，由此来看，“无服务”也同样是被主流学术界所认可的发展方向之一。

无服务现在还没有一个特别权威的“官方”定义，但它的概念并没有前面各种架构那么复杂，本来无服务也是以“简单”为主要卖点的，它只涉及两块内容：后端设施（Backend）和函数（Function）。

- 后端设施
  指数据库、消息队列、日志、存储，等等这一类用于支撑业务逻辑运行，但本身无业务含义的技术组件，这些后端设施都运行在云中，无服务中称其为“后端即服务”（Backend as a Service，BaaS）。
- 函数
  指业务逻辑代码，这里函数的概念与粒度，都已经很接近于程序编码角度的函数了，其区别是无服务中的函数运行在云端，不必考虑算力问题，不必考虑容量规划（从技术角度可以不考虑，从计费的角度你的钱包够不够用还是要掂量一下的），无服务中称其为“函数即服务”（Function as a Service，FaaS）。

无服务的愿景是让开发者只需要纯粹地关注业务，
不需要考虑技术组件，后端的技术组件是现成的，可以直接取用，没有采购、版权和选型的烦恼；
不需要考虑如何部署，部署过程完全是托管到云端的，工作由云端自动完成；
不需要考虑算力，有整个数据中心支撑，算力可以认为是无限的；
也不需要操心运维，维护系统持续平稳运行是云计算服务商的责任而不再是开发者的责任。
在 UC Berkeley 的论文中，把无服务架构下开发者不再关心这些技术层面的细节，类比成当年软件开发从汇编语言踏进高级语言的发展过程，开发者可以不去关注寄存器、信号、中断等与机器底层相关的细节，从而令生产力得到极大地解放。

笔者自己对无服务中短期内的发展并没有那么乐观。与单体架构、微服务架构不同，无服务架构有一些天生的特点决定了它现在不是，以后如果没有重大变革的话，估计也很难成为一种普适性的架构模式。
。。就是 函数不能一直处于激活状态，不然的话，占用了CPU，无法达到"无限算力"。所以函数有 冷启动时间，响应的性能不太好。

无论如何，云计算毕竟是大势所趋，今天信息系统建设的概念和观念，在（较长尺度的）明天都是会转变成适应云端的，笔者并不怀疑 Serverless+API 的设计方式会成为以后其中一种主流的软件形式，届时无服务还会有更广阔的应用空间。



# 架构师视角

## 访问远程服务

### 远程服务调用 RPC

有不少开发者对 RPC 本身解决什么问题、如何解决这些问题、为什么要这样解决都或多或少存在认知模糊。本节，笔者会从历史到现状，从表现到本质，尽可能深入地解释清楚 RPC 的来龙去脉。

#### 进程间通信

http://icyfenix.cn/architect-perspective/general-architecture/api-style/rpc.html

RPC 出现的最初目的，就是为了让计算机能够跟调用本地方法一样去调用远程方法。

先来看一下本地方法调用时，计算机是如何处理的。笔者通过以下这段 Java 风格的伪代码，来定义几个稍后要用到的概念

```Java
// Caller    :  调用者，代码里的main()
// Callee    ： 被调用者，代码里的println()
// Call Site ： 调用点，即发生方法调用的指令流位置
// Parameter ： 参数，由Caller传递给Callee的数据，即“hello world”
// Retval    ： 返回值，由Callee传递给Caller的数据。以下代码中如果方法能够正常结束，它是void，如果方法异常完成，它是对应的异常
public static void main(String[] args) {
	System.out.println(“hello world”);
}
```

在完全不考虑编译器优化的前提下，程序运行至调用 `println()` 方法输出 hello world这行时，计算机（物理机或者虚拟机）要完成以下几项工作。

1. 传递方法参数：将字符串helloworld的引用地址压栈
2. 确定方法版本：根据println()方法的签名，确定其执行版本。
   这其实并不是一个简单的过程，不论是编译时静态解析也好，是运行时动态分派也好，总之必须根据某些语言规范中明确定义原则，找到明确的Callee，“明确”是指唯一的一个Callee，或者有严格优先级的多个Callee，譬如不同的重载版本。笔者曾在《深入理解 Java 虚拟机 》中用一整章篇幅介绍该过程，有兴趣的读者可以参考，这里就不赘述了。
3. 执行被调方法：从栈中弹出Parameter的值或引用，以此为输入，执行Callee内部的逻辑；这里我们只关心方法如何调用的，不关心方法内部具体是如何执行的。
4. 返回执行结果：将Callee的执行结果压栈，并将程序的指令流恢复到Call Site的下一条指令，继续向下执行。

我们再来考虑如果println()方法不在当前进程的内存地址空间中，会发生什么问题。
不难想到，此时至少面临两个直接的障碍：
- 首先，第一步和第四步所做的传递参数、传回结果都依赖于栈内存的帮助，如果Caller与Callee分属==不同的进程==，就不会拥有相同的==栈==内存，将参数在Caller进程的内存中压栈，对于 Callee 进程的执行毫无意义。
- 其次，第二步的方法版本选择依赖于语言规则的定义，如果Caller与Callee不是同一种语言实现的程序，方法版本选择就将是一项模糊的不可知行为。

暂时忽略第二个障碍，假设Caller与Callee是使用同一种语言实现的，先来解决两个进程之间如何交换数据的问题，
这件事情在计算机科学中被称为“进程间通信 ”（Inter-Process Communication，IPC）。可以考虑的办法有以下几种。
- 管道（Pipe）或者具名管道（Named Pipe）：
  管道类似于两个进程间的桥梁，可通过管道在进程间传递少量的字符流或字节流。
  普通管道只用于有亲缘关系进程（由一个进程启动的另外一个进程）间的通信，
  具名管道摆脱了普通管道没有名字的限制，除具有管道所有的功能外，它还允许无亲缘关系进程间的通信。
  管道典型的应用就是命令行中的|操作符，譬如：`ps -ef | grep java`。
  ps与grep都有独立的进程，以上命令就通过管道操作符|将ps命令的标准输出连接到grep命令的标准输入上。
- 信号（Signal）：
  信号用于通知目标进程有某种事件发生，除了用于进程间通信外，进程还可以发送信号给进程自身。
  信号的典型应用是kill命令，譬如 `kill -9 <pid>`。由 Shell 进程向指定 PID 的进程发送 SIGKILL 信号。
- 信号量（Semaphore）：
  信号量用于两个进程之间同步协作手段，它相当于操作系统提供的一个特殊变量，程序可以在上面进行wait()和notify()操作。
- 消息队列（Message Queue）：
  以上三种方式只适合传递传递少量信息，POSIX 标准中定义了消息队列用于进程间数据量较多的通信。
  进程可以向队列添加消息，被赋予读权限的进程则可以从队列消费消息。
  消息队列克服了==信号承载信息量少==，==管道只能用于无格式字节流以及缓冲区大小受限==等缺点，但实时性相对受限。
- 共享内存（Shared Memory）：
  允许多个进程访问同一块公共的内存空间，这是效率最高的进程间通信形式。
  原本每个进程的内存地址空间都是相互隔离的，但操作系统提供了让进程主动创建、映射、分离、控制某一块内存的程序接口。
  当一块内存被多进程共享时，各个进程往往会与其它通信机制，譬如信号量结合使用，来达到进程间同步及互斥的协调操作。
- 套接字接口（Socket）：
  消息队列和共享内存只适合==单机多进程==间的通信，套接字接口是==更为普适的进程间通信==机制，可用于不同机器之间的进程通信。
  套接字（Socket）起初是由 UNIX 系统的 BSD 分支开发出来的，现在已经移植到所有主流的操作系统上。
  出于效率考虑，**当仅限于本机进程间通信时，套接字接口是被优化过的，不会经过网络协议栈，不需要打包拆包、计算校验和、维护序号和应答**等操作，只是简单地将应用层数据从一个进程拷贝到另一个进程，这种进程间通信方式有个专名的名称：UNIX Domain Socket，又叫做 IPC Socket。


#### 通信的成本
最初计算机科学家们的想法，就是将 RPC 作为 IPC 的一种特例来看待的，这个观点在今天，仅分类上这么说也仍然合理，只是到具体操作手段上不会这么做了。

基于套接字接口的通信方式（IPC Socket），它不仅适用于本地相同机器的不同进程间通信，由于 Socket 是网络栈的统一接口，它也理所当然地能支持基于网络的跨机器的进程间通信。
这种通信已经被实践验证过是有效的，譬如 Linux 系统的图形化界面中，X Window 服务器和 GUI 程序之间的交互就是由这套机制来实现。
此外，这样做有一个看起来无比诱人的好处，由于 Socket 是各个操作系统都有提供的标准接口，完全有可能把远程方法调用的通信细节隐藏在操作系统底层，从应用层面上看来可以做到远程调用与本地的进程间通信在编码上完全一致。
但这种 透明的 调用形式却反而造成了程序员误以为**通信是无成本的假象，因而被滥用以致于显著降低了分布式系统的性能**。

1987 年，在“透明的 RPC 调用”一度成为主流范式的时候，Andrew Tanenbaum 对这种透明的 RPC 范式提出了一系列质问：
- 两个进程通信，谁作为服务端，谁作为客户端？
- 怎样进行异常处理？异常该如何让调用者获知？
- 服务端出现多线程竞争之后怎么办？
- 如何提高网络利用的效率，譬如连接是否可被多个请求复用以减少开销？是否支持多播？
- 参数、返回值如何表示？应该有怎样的字节序？
- 如何保证网络的可靠性？譬如调用期间某个链接忽然断开了怎么办？
- 发送的请求服务端收不到回复该怎么办？

论文的中心观点是：本地调用与远程调用当做一样处理，这是犯了方向性的错误，把系统间的调用做成透明，反而会增加程序员工作的复杂度。

到 1994 年至 1997 年间，由 ACM 和 Sun 院士Peter Deutsch 、套接字接口发明者Bill Joy 、Java 之父James Gosling 等一众在 Sun Microsystems 工作的大佬们共同总结了通过网络进行分布式运算的八宗罪 （8 Fallacies of Distributed Computing）：
- The network is reliable —— 网络是可靠的。
- Latency is zero —— 延迟是不存在的。
- Bandwidth is infinite —— 带宽是无限的。
- The network is secure —— 网络是安全的。
- Topology doesn't change —— 拓扑结构是一成不变的。
- There is one administrator —— 总会有一个管理员。
- Transport cost is zero —— 不必考虑传输成本。
- The network is homogeneous —— 网络是同质化的。

Remote procedure call is the synchronous language-level transfer of control between programs in disjoint address spaces whose primary communication medium is a narrow channel.
远程服务调用是指位于互不重合的内存地址空间中的两个程序，在语言层面上，以同步的方式使用带宽有限的信道来传输程序控制信息。


#### 3个基本问题

几十年来所有流行过的 RPC 协议，都不外乎变着花样使用各种手段来解决以下三个基本问题：
- 如何表示数据
  数据包括了传递给方法的参数，以及方法执行后的返回值
  在不同硬件指令集、不同操作系统下，同样的数据类型也完全可能有不一样表现细节，譬如数据宽度、字节序的差异等等
- 如何传递数据
  如何通过网络，在两个服务的 Endpoint 之间相互操作、交换数据。
  这里“交换数据”通常指的是应用层协议，实际传输一般是基于标准的 TCP、UDP 等标准的传输层
  协议来完成的
  两个服务交互不是只扔个序列化数据流来表示参数和结果就行的，许多在此之外信息，譬如异常、超时、安全、认证、授权、事务，等等，都可能产生双方需要交换信息的需求。
  专门有一个名称“Wire Protocol ”来用于表示这种两个 Endpoint 之间交换这类数据的行为
- 如何确定方法
  考虑不同语言，事情又立刻麻烦起来，每门语言的方法签名都可能有所差别，所以“如何表示同一个方法”，“如何找到对应的方法”还是得弄个跨语言的统一的标准才行。



#### 统一的RPC

CORBA，Web Service

那些面向透明的、简单的 RPC 协议，如 DCE/RPC、DCOM、Java RMI，要么依赖于操作系统，要么依赖于特定语言，总有一些先天约束；
那些面向通用的、普适的 RPC 协议；如 CORBA，就无法逃过使用复杂性的困扰，CORBA 烦琐的 OMG IDL、ORB 都是很好的佐证；
而那些意图通过技术手段来屏蔽复杂性的 RPC 协议，如 Web Service，又不免受到性能问题的束缚。简单、普适、高性能这三点，似乎真的难以同时满足


#### 分裂的RPC

现在，已经相继出现过 
RMI（Sun/Oracle）、
Thrift（Facebook/Apache）、
Dubbo（阿里巴巴/Apache）、
gRPC（Google）、
Motan1/2（新浪）、
Finagle（Twitter）、
brpc（百度/Apache）、
.NET Remoting（微软）、
Arvo（Hadoop）、
JSON-RPC 2.0（公开规范，JSON-RPC 工作组）
……等等难以穷举的协议和框架

这些 RPC 功能、特点不尽相同，有的是某种语言私有，有的能支持==跨越多门语言==，有的运行在应用层 ==HTTP 协议之上==，有的能直接运行于传输层 ==TCP/UDP 协议==之上，但肯定不存在哪一款是“最完美的 RPC”。
今时今日，任何一款具有生命力的 RPC 框架，都不再去追求大而全的“完美”，而是有自己的针对性特点作为主要的发展方向，举例分析如下。
- 朝着面向对象发展，
  不满足于 RPC 将面向过程的编码方式带到分布式，希望在分布式系统中也能够进行跨进程的面向对象编程，代表为 RMI、.NET Remoting，之前的 CORBA 和 DCOM 也可以归入这类，这条线有一个别名叫做==分布式对象== （Distributed Object）。
- 朝着性能发展，
  代表为 gRPC 和 Thrift。
  决定 RPC ==性能==的主要就两个因素：==序列化效率和信息密度==。
  序列化效率很好理解，序列化输出结果的容量越小，速度越快，效率自然越高；
  信息密度则取决于协议中有效荷载（Payload）所占总传输数据的比例大小，使用传输协议的层次越高，信息密度就越低，SOAP 使用 XML 拙劣的性能表现就是前车之鉴。
  gRPC 和 Thrift 都有自己优秀的专有序列化器，而传输协议方面，gRPC 是基于 HTTP/2 的，支持多路复用和 Header 压缩，Thrift 则直接基于传输层的 TCP 协议来实现，省去了额外应用层协议的开销。
- 朝着简化发展，
  代表为 JSON-RPC，说要选功能最强、速度最快的 RPC 可能会很有争议，但选功能弱的、速度慢的，JSON-RPC 肯定会候选人中之一。
  ==牺牲了功能和效率，换来的是协议的简单轻便，接口与格式都更为通用==，尤其适合用于 Web 浏览器这类一般不会有额外协议支持、额外客户端支持的应用场合。


到了最近几年，RPC 框架有明显的朝着==更高层次==（不仅仅负责调用远程服务，还管理远程服务）与==插件化==方向发展的趋势，不再追求独立地解决 RPC 的全部三个问题（表示数据、传递数据、表示方法），而是==将一部分功能设计成扩展点，让用户自己去选择==。
框架聚焦于提供核心的、更高层次的能力，譬如提供==负载均衡、服务注册、可观察性等==方面的支持。这一类框架的代表有 Facebook 的 Thrift 与阿里的 Dubbo。
尤其是断更多年后重启的 Dubbo 表现得更为明显，它默认有自己的传输协议（Dubbo 协议），同时也支持其他协议；默认采用 Hessian 2 作为序列化器，如果你有 JSON 的需求，可以替换为 Fastjson，如果你对性能有更高的追求，可以替换为Kryo 、FST 、Protocol Buffers 等效率更好的序列化器，如果你不想依赖其他组件库，直接使用 JDK 自带的序列化器也是可以的。这种设计在一定程度上缓和了 RPC 框架必须取舍，难以完美的缺憾。

大家不妨来反思一下：开发一个分布式系统，是不是就一定要用 RPC 呢？RPC 的三大问题源自于对本地方法调用的类比模拟，如果我们把思维从“方法调用”的约束中挣脱，那参数与结果如何表示、方法如何表示、数据如何传递这些问题都会海阔天空，拥有焕然一新的视角。但是我们写程序，真的可能不面向方法来编程吗？这就是笔者下一节准备谈的话题了。








### REST 设计风格

REST 无论是在思想上、概念上，还是使用范围上，与 RPC 都不尽相同，充其量只能算是有一些相似，应用会有一部分重合之处，但本质上并不是同一类型的东西。

REST 与 RPC 在思想上差异的核心是抽象的目标不一样，即==面向资源的编程==思想与==面向过程的编程==思想两者之间的区别

REST 只能说是风格而不是规范、协议，并且能完全达到 REST 所有指导原则的系统也是不多见的

RPC 一些发展方向，如分布式对象、提升调用效率、简化调用复杂性
- 分布式对象这一条线的应用与 REST 可以说是毫无关联
- 重视远程服务 调用 效率 的应用场景，就基本上已经排除了 REST 应用得最多的 供浏览器端 消费的远程服务
- 对追求简化调用的场景——前面提到的浏览器端就属于这一类的典型，
  众多 RPC 里也就 JSON-RPC 有机会与 REST 竞争，其他 RPC 协议与框架，哪怕是能够支持 HTTP 协议，哪怕提供了 JavaScript 版本的客户端（如 gRPC-Web），也只是具备前端使用的理论可行性 ，很少见有实际项目把它们真的用到浏览器上的。


#### 理解REST

“REST”（Representational State Transfer）

- 资源（Resource）：
  譬如你现在正在阅读一篇名为《REST 设计风格》的文章，这篇文章的内容本身（你可以将其理解为其蕴含的信息、数据）我们称之为“资源”。
  无论你是购买的书籍、是在浏览器看的网页、是打印出来看的文稿、是在电脑屏幕上阅读抑或是手机上浏览，尽管呈现的样子各不相同，但其中的==信息是不变==的，你所阅读的==仍是同一份“资源”==。

- 表征（Representation）：
  当你通过电脑浏览器阅读此文章时，浏览器向服务端发出请求“我需要这个资源的 HTML 格式”，==服务端向浏览器返回的这个 HTML 就被称之为“表征”==，你可能通过其他方式拿到本文的 PDF、Markdown、RSS 等其他形式的版本，它们也同样是一个资源的多种表征。可见“表征”这个概念是指信息与用户交互时的==表示形式==，这与我们软件分层架构中常说的“表示层”（Presentation Layer）的语义其实是一致的。

- 状态（State）：
  当你读完了这篇文章，想看后面是什么内容时，你向服务器发出请求“给我下一篇文章”。但是“下一篇”是个相对概念，必须依赖“当前你正在阅读的文章是哪一篇”才能正确回应，这类==在特定语境中才能产生的上下文信息即被称为“状态”==。我们所说的有状态（Stateful）抑或是无状态（Stateless），都是只相对于服务端来说的，服务器要完成“取下一篇”的请求，要么==自己记住用户的状态==：这个用户现在阅读的是哪一篇文章，这称为==有状态==；要么==客户端来记住状态==，在请求的时候明确告诉服务器：我正在阅读某某文章，现在要读它的下一篇，这称为==无状态==。

- 转移（Transfer）：
  无论状态是由服务端还是客户端来提供的，==“取下一篇文章”这个行为逻辑必然只能由服务端来提供==，因为只有服务端拥有该资源及其表征形式。==服务器通过某种方式，把“用户当前阅读的文章”转变成“下一篇文章”，这就被称为“表征状态转移==”。


介绍几个现在不涉及但稍后要用到的概念名词。
- 统一接口（Uniform Interface）：
  上面说的服务器“通过某种方式”让表征状态发生转移，具体是什么方式？如果你真的是用浏览器阅读本文电子版的话，请把本文滚动到结尾处，右下角有下一篇文章的 URI 超链接地址，这是服务端渲染这篇文章时就预置好的，点击它让页面跳转到下一篇，就是所谓“某种方式”的其中一种方式。
  任何人都不会对点击超链接网页会出现跳转感到奇怪，但你细想一下，URI 的含义是统一资源标识符，是一个名词，如何能表达出“转移”动作的含义呢？答案是 HTTP 协议中已经提前约定好了一套“统一接口”，它包括：GET、HEAD、POST、PUT、DELETE、TRACE、OPTIONS 七种基本操作，任何一个支持 HTTP 协议的服务器都会遵守这套规定，对特定的 URI 采取这些操作，服务器就会触发相应的表征状态转移。

- 超文本驱动（Hypertext Driven）：
  尽管表征状态转移是由浏览器主动向服务器发出请求所引发的，该请求导致了“在浏览器屏幕上显示出了下一篇文章的内容”这个结果的出现。但是，你我都清楚这不可能真的是浏览器的主动意图，浏览器是根据用户输入的 URI 地址来找到网站首页，服务器给予的首页超文本内容后，浏览器再通过超文本内部的链接来导航到了这篇文章，阅读结束时，也是通过超文本内部的链接来再导航到下一篇。
  浏览器作为所有网站的通用的客户端，任何网站的导航（状态转移）行为都不可能是预置于浏览器代码之中，而是由服务器发出的请求响应信息（超文本）来驱动的。这点与其他带有客户端的软件有十分本质的区别，在那些软件中，业务逻辑往往是预置于程序代码之中的，有专门的页面控制器（无论在服务端还是在客户端中）来驱动页面的状态转移。

- 自描述消息（Self-Descriptive Messages）：
  由于资源的表征可能存在多种不同形态，在消息中应当有明确的信息来告知客户端该消息的类型以及应如何处理这条消息。
  一种被广泛采用的自描述方法是在名为“Content-Type”的 HTTP Header 中标识出互联网媒体类型（MIME type），譬如“Content-Type : application/json; charset=utf-8”，则说明该资源会以 JSON 的格式来返回，请使用 UTF-8 字符集进行处理。


Fielding 提出 REST 时所谈论的范围是“架构风格与网络的软件架构设计”（Architectural Styles and Design of Network-based Software Architectures），而不是现在被人们所狭义理解的一种“远程服务设计风格”



#### RESTful 的系统

Fielding 认为，一套理想的、完全满足 REST 风格的系统应该满足以下六大原则。

1. 服务端与客户端分离（Client-Server）
  将用户界面所关注的逻辑和数据存储所关注的逻辑分离开来，有助于提高用户界面的跨平台的可移植性，这一点正越来越受到广大开发者所认可，
  以前完全基于服务端控制和渲染（如 JSF 这类）框架实际用户已甚少，而在服务端进行==界面控制（Controller）==，通过服务端或者客户端的模版渲染引擎来进行界面渲染的框架（如 Struts、SpringMVC 这类）也受到了颇大的冲击。
  这一点主要推动力量与 REST 可能关系并不大，前端技术（从 ES 规范，到语言实现，到前端框架等）的近年来的高速发展，使得==前端表达能力大幅度加强==才是真正的幕后推手。
  由于前端的日渐强势，现在还流行起由前端代码反过来驱动服务端进行渲染的 SSR（Server-Side Rendering）技术，在 Serverless、SEO 等场景中已经占领了一块领地。

2. 无状态（Stateless）
  无状态是 REST 的一条==核心原则==，部分开发者在做服务接口规划时，觉得 REST 风格的服务怎么设计都感觉别扭，很有可能的一种原因是在服务端持有着比较重的状态。
  REST 希望==服务器不要去负责维护状态==，每一次==从客户端发送的请求中，应包括所有的必要的上下文信息==，会话信息也由客户端负责保存维护，服务端依据客户端传递的状态来执行业务处理逻辑，驱动整个应用的状态变迁。
  客户端承担状态维护职责以后，会产生一些==新的问题==，譬如==身份认证、授权==等可信问题，它们都应有针对性的解决方案（这部分内容可参见“安全架构”的内容）。
  但必须承认的现状是，目前大多数的系统都==达不到这个要求==，往往越复杂、越大型的系统越是如此。
  服务端无状态可以在==分布式计算==中获得非常高价值的好处，但大型系统的上下文状态数量完全可能膨胀到让客户端在每次请求时提供变得不切实际的程度，在==服务端==的内存、会话、数据库或者缓存等地方==持有一定的状态==成为一种是==事实上存在，并将长期存在、被广泛使用==的主流的方案。

3. 可缓存（Cacheability）
  无状态服务虽然提升了系统的可见性、可靠性和可伸缩性，但==降低了系统的网络性==。“降低网络性”的通俗解释是某个功能如果==使用有状态的设计只需要一次（或少量）请求就能完成==，使用无状态的设计则可能会==需要多次请求==，或者在==请求中带有额外冗余的信息==。
  为了缓解这个矛盾，REST 希望软件系统能够如同万维网一样，允许客户端和中间的通讯传递者（譬如代理）==将部分服务端的应答缓存起来==。当然，为了缓存能够正确地运作，服务端的应答中必须明确地或者间接地表明本身是否可以进行缓存、可以缓存多长时间，以避免客户端在将来进行请求的时候得到过时的数据。运作良好的缓存机制可以减少客户端、服务器之间的交互，甚至有些场景中可以完全避免交互，这就进一步提高了性能。

4. 分层系统（Layered System）
  这里所指的并不是表示层、服务层、持久层这种意义上的分层。
  而是==指客户端一般不需要知道是否直接连接到了最终的服务器，抑或连接到路径上的中间服务器==。中间服务器可以通过==负载均衡和共享缓存==的机制提高系统的可扩展性，这样也便于缓存、伸缩和安全策略的部署。
  该原则的典型的应用是内容分发网络（Content Distribution Network，CDN）。如果你是通过网站浏览到这篇文章的话，你所发出的请求一般（假设你在中国国境内的话）并不是直接访问位于 GitHub Pages 的源服务器，而是访问了位于国内的 CDN 服务器，但作为用户，你完全不需要感知到这一点。我们将在“透明多级分流系统”中讨论如何构建自动的、可缓存的分层系统。

5. 统一接口（Uniform Interface）
  这是 REST 的另一条==核心原则==，REST 希望开发者==面向资源编程==，希望软件系统设计的重点放在抽象系统该==有哪些资源==上，而==不是==抽象系统该==有哪些行为（服务）==上。
  这条原则你可以类比计算机中对文件管理的操作来理解，管理文件可能会进行创建、修改、删除、移动等操作，这些操作数量是可数的，而且对所有文件都是固定的、统一的。
  如果面向资源来设计系统，同样会具有类似的操作特征，由于 REST 并没有设计新的协议，所以这些操作都借用了 HTTP 协议中固有的操作命令来完成。
  ==统一接口也是 REST 最容易陷入争论的地方==，基于网络的软件系统，到底是面向资源更好，还是面向服务更合适，这事情哪怕是很长时间里都不会有个定论，也许永远都没有。但是，已经有一个==基本清晰的结论是：面向资源编程的抽象程度通常更高==。==抽象程度高==意味着==坏处==是往往==距离人类的思维方式更远==，而==好处==是往往==通用程度会更好==。
  用这样的语言去诠释 REST，大概本身就挺抽象的，笔者还是举个例子来说明：譬如，几乎每个系统都有的登录和注销功能，如果你理解成登录对应于 login()服务，注销对应于 logout()服务这样两个独立服务，这是“符合人类思维”的；如果你理解成登录是 PUT Session，注销是 DELETE Session，这样你只需要设计一种“Session 资源”即可满足需求，甚至以后对 Session 的其他需求，如查询登陆用户的信息，就是 GET Session 而已，其他操作如修改用户信息等都可以被这同一套设计囊括在内，这便是“抽象程度更高”带来的好处。
  想要在架构设计中合理恰当地利用统一接口，Fielding 建议系统应能做到每次请求中都包含资源的 ID，所有操作均通过资源 ID 来进行；建议每个资源都应该是自描述的消息；建议通过超文本来驱动应用状态的转移。

6. 按需代码（Code-On-Demand ）
  按需代码被 Fielding 列为一条==可选原则==。它是指任何按照客户端（譬如浏览器）的请求，==将可执行的软件程序从服务器发送到客户端的技术==，按需代码赋予了客户端无需事先知道所有来自服务端的信息应该如何处理、如何运行的宽容度。举个具体例子，以前的Java Applet 技术，今天的WebAssembly 等都属于典型的按需代码，蕴含着具体执行逻辑的代码是存放在服务端，只有当客户端请求了某个 Java Applet 之后，代码才会被传输并在客户端机器中运行，结束后通常也会随即在客户端中被销毁掉。将按需代码列为可选原则的原因并非是它特别难以达到，而更多是出于必要性和性价比的实际考虑。


REST 的基本思想是面向资源来抽象问题
RPC 是将本地的方法调用思路迁移到远程方法调用上



#### RMM 成熟度

如何评价服务是否 RESTful

Richardson 将服务接口“REST 的程度”从低到高，分为 0 至 3 级：

0. The Swamp of Plain Old XML
   完全不 REST。另外，关于 Plain Old XML 这说法，SOAP 表示感觉有被冒犯到。
1. Resources
   开始引入资源的概念。
2. HTTP Verbs
   引入统一接口，映射到 HTTP 协议的方法上。
3. Hypermedia Controls
   超媒体控制在本文里面的说法是“超文本驱动”，在 Fielding 论文里的说法是“Hypertext As The Engine Of Application State，HATEOAS”，其实都是指同一件事情。


第0级 例子

医院开放了一个`/appointmentService` 的Web API，
传入日期、医生姓名作为参数，可以得到该时间段该名医生的空闲时间，该 API 的一次 HTTP 调用如下所示

```text
POST /appointmentService?action=query HTTP/1.1

{date: "2020-03-04", doctor: "mjones"}
```

然后服务器会传回一个包含了所需信息的回应：
```text
HTTP/1.1 200 OK

[
	{start:"14:00", end: "14:50", doctor: "mjones"},
	{start:"16:00", end: "16:50", doctor: "mjones"}
]
```

我觉得 14:00 的时间比较合适，于是进行预约确认，并提交了我的基本信息：
```text
POST /appointmentService?action=confirm HTTP/1.1

{
	appointment: {date: "2020-03-04", start:"14:00", doctor: "mjones"},
	patient: {name: icyfenix, age: 30, ……}
}
```

如果预约成功，那我能够收到一个预约成功的响应：
```text
HTTP/1.1 200 OK

{
	code: 0,
	message: "Successful confirmation of appointment"
}
```

如果发生了问题，譬如有人在我前面抢先预约了，那么我会在响应中收到某种错误信息：
```text
HTTP/1.1 200 OK

{
	code: 1
	message: "doctor not available"
}
```

整个预约服务宣告完成，直接明了，我们采用的是非常直观的基于 RPC 风格的服务设计似乎很容易就解决了所有问题……了吗？

。。1. post到底。2. 通过 参数表明行为。3. 始终返回 200 。 4. code



第 1 级 例子

第 0 级是 RPC 的风格，如果需求永远不会变化，也不会增加，那它完全可以良好地工作下去。
但是，如果你不想为预约医生之外的其他操作、为获取空闲时间之外的其他信息去编写额外的方法，或者改动现有方法的接口，那还是应该考虑一下如何使用 REST 来抽象资源。

通往 REST 的第一步是引入资源的概念，在 API 中基本的体现是==围绕着资源而不是过程来设计服务==，说的直白一点，可以理解为==服务的 Endpoint 应该是一个名词而不是动词==。
此外，==每次请求中都应包含资源的 ID==，所有操作均通过资源 ID 来进行，

譬如，获取医生指定时间的空闲档期：
```text
POST /doctors/mjones HTTP/1.1

{date: "2020-03-04"}
```

然后服务器传回一组包含了 ID 信息的档期清单，注意，ID 是资源的唯一编号，有 ID 即代表“医生的档期”被视为一种资源

```text
HTTP/1.1 200 OK

[
	{id: 1234, start:"14:00", end: "14:50", doctor: "mjones"},
	{id: 5678, start:"16:00", end: "16:50", doctor: "mjones"}
]
```

我还是觉得 14:00 的时间比较合适，于是又进行预约确认，并提交了我的基本信息：
```text
POST /schedules/1234 HTTP/1.1

{name: icyfenix, age: 30, ……}
```

后面预约成功或者失败的响应消息在这个级别里面与之前一致，就不重复了。
比起第 0 级，第 1 级的特征是引入了资源，通过资源 ID 作为主要线索与服务交互，
但第 1 级至少还有三个问题并没有解决：
- 一是只处理了查询和预约，如果我临时想换个时间，要调整预约，或者我的病忽然好了，想删除预约，这都需要提供新的服务接口。
- 二是处理结果响应时，只能靠着结果中的code、message这些字段做分支判断，每一套服务都要设计可能发生错误的 code，这很难考虑全面，而且也不利于对某些通用的错误做统一处理；
- 三是并没有考虑认证授权等安全方面的内容，譬如要求只有登陆用户才允许查询医生档期时间，某些医生可能只对 VIP 开放，需要特定级别的病人才能预约，等等。


第 2 级
第 1 级遗留三个问题都可以靠引入统一接口来解决。
HTTP 协议的七个标准方法是经过精心设计的，只要架构师的抽象能力够用，它们几乎能涵盖资源可能遇到的所有操作场景。
REST 的做法是把不同业务需求抽象为对资源的增加、修改、删除等操作来==解决第一个问题==；
使用 HTTP 协议的 Status Code，可以涵盖大多数资源操作可能出现的异常，而且 Status Code 可以自定义扩展，以此==解决第二个==问题；
依靠 HTTP Header 中携带的额外认证、授权信息来==解决第三个==问题，这个在实战中并没有体现，请参考安全架构中的“凭证”相关内容。

获取医生档期，应采用具有查询语义的 GET 操作进行：
```text
GET /doctors/mjones/schedule?date=2020-03-04&status=open HTTP/1.1
```

服务器会传回一个包含了所需信息的回应：
```text
HTTP/1.1 200 OK

[
	{id: 1234, start:"14:00", end: "14:50", doctor: "mjones"},
	{id: 5678, start:"16:00", end: "16:50", doctor: "mjones"}
]
```

我仍然觉得 14:00 的时间比较合适，于是又进行预约确认，并提交了我的基本信息，用以创建预约，这是符合 POST 的语义的：
```text
POST /schedules/1234 HTTP/1.1

{name: icyfenix, age: 30, ……}
```

如果预约成功，那我能够收到一个预约成功的响应：
```text
HTTP/1.1 201 Created

Successful confirmation of appointment
```

如果发生了问题，譬如有人在我前面抢先预约了，那么我会在响应中收到某种错误信息：
```text
HTTP/1.1 409 Conflict

doctor not available
```


#### 第 3 级 例子

第 2 级是目前绝大多数系统所到达的 REST 级别，但仍不是完美的，
至少还存在一个问题：你是如何知道预约 mjones 医生的档期是需要访问/schedules/1234这个服务 Endpoint 的？
也许你甚至第一时间无法理解为何我会有这样的疑问，这当然是程序代码写的呀！
但 REST 并不认同这种已烙在程序员脑海中许久的想法。
RMM 中的 Hypermedia Controls、Fielding 论文中的 HATEOAS 和现在提的比较多的“超文本驱动”，所希望的是==除了第一个请求是由你在浏览器地址栏输入所驱动之外，其他的请求都应该能够自己描述清楚后续可能发生的状态转移，由超文本自身来驱动==。
所以，当你输入了查询的指令之后：
```text
GET /doctors/mjones/schedule?date=2020-03-04&status=open HTTP/1.1
```

服务器传回的响应信息应该==包括诸如如何预约档期、如何了解医生信息等可能的后续操作==：
```text
HTTP/1.1 200 OK

{
	schedules：[
		{
			id: 1234, start:"14:00", end: "14:50", doctor: "mjones",
			links: [
				{rel: "comfirm schedule", href: "/schedules/1234"}
			]
		},
		{
			id: 5678, start:"16:00", end: "16:50", doctor: "mjones",
			links: [
				{rel: "comfirm schedule", href: "/schedules/5678"}
			]
		}
	],
	links: [
		{rel: "doctor info", href: "/doctors/mjones/info"}
	]
}
```

如果做到了第 3 级 REST，那服务端的 API 和客户端也是完全解耦的，你要调整服务数量，或者同一个服务做 API 升级将会变得非常简单。


#### 不足与争议

> 面向资源的编程思想只适合做 CRUD，面向过程、面向对象编程才能处理真正复杂的业务逻辑

针对那些比较抽象的场景，如果真不好把 HTTP 方法映射为资源的所需操作，REST 也并非刻板的教条，用户是可以使用自定义方法的，按 Google 推荐的 REST API 风格，==自定义方法 应该放在资源路径末尾，嵌入冒号加自定义动词的后缀==。
譬如，我可以把删除操作映射到标准 DELETE 方法上，如果此外还要提供一个==恢复删除的 API==，那它可能会被设计为：
`POST /user/user_id/cart/book_id:undelete`

最后，笔者再重复一遍，面向资源的编程思想与另外两种主流编程思想只是抽象问题时所处的立场不同，只有选择问题，没有高下之分：
- 面向过程编程时，为什么要以算法和处理过程为中心，输入数据，输出结果？当然是为了符合计算机世界中主流的交互方式。
- 面向对象编程时，为什么要将数据和行为统一起来、封装成对象？当然是为了符合现实世界的主流的交互方式。
- 面向资源编程时，为什么要将数据（资源）作为抽象的主体，把行为看作是统一的接口？当然是为了符合网络世界的主流的交互方式。


> REST 与 HTTP 完全绑定，不适合应用于要求高性能传输的场景中

笔者个人很大程度上赞同此观点，但并不认为这是 REST 的缺陷，锤子不能当扳手用并不是锤子的质量有问题。
面向资源编程与协议无关，但是 REST（特指 Fielding 论文中所定义的 REST，而不是泛指面向资源的思想）的确依赖着 HTTP 协议的标准方法、状态码、协议头等各个方面。
HTTP 并不是传输层协议，它是应用层协议，如果仅将 HTTP 当作传输是不恰当的（SOAP：再次感觉有被冒犯到）。
对于需要直接控制传输，如二进制细节、编码形式、报文格式、连接方式等细节的场景中，REST 确实不合适，这些场景往往存在于服务集群的内部节点之间，这也是之前曾提及的，REST 和 RPC 尽管应用场景的确有所重合，但重合的范围有多大就是见仁见智的事情。


> REST 不利于事务支持

这个问题首先要看你怎么看待“事务（Transaction）”这个概念。
如果“事务”指的是数据库那种的狭义的刚性 ACID 事务，那除非完全不持有状态，否则分布式系统本身与此就是有矛盾的（CAP 不可兼得），这是分布式的问题而不是 REST 的问题。
如果“事务”是指通过服务协议或架构，在==分布式服务中，获得对多个数据同时提交的统一协调能力（2PC/3PC）==，譬如WS-AtomicTransaction 、WS-Coordination 这样的功能性协议，这 ==REST 确实不支持==，假如你已经理解了这样做的代价，仍决定要这样做的话，==Web Service 是比较好的选择==。
如果“事务”只是指希望保障数据的最终一致性，说明你已经放弃刚性事务了，这才是分布式系统中的正常交互方式，使用 REST 肯定不会有什么阻碍，谈不上“不利于”。
当然，对此 REST 也并没有什么帮助，这完全取决于你系统的事务设计，我们会在事务处理中再详细讨论。


> REST 没有传输可靠性支持

是的，并没有。在 HTTP 中你发送出去一个请求，通常会收到一个与之相对的响应，譬如 HTTP/1.1 200 OK 或者 HTTP/1.1 404 Not Found 诸如此类的。
但如果你没有收到任何响应，那就无法确定消息到底是没有发送出去，抑或是没有从服务端返回回来，这其中的关键差别是服务端到底是否被触发了某些处理？
应对传输可靠性==最简单粗暴的做法是把消息再重发一遍==。
这种简单处理能够成立的前提是服务应具有==幂等性== （Idempotency），即服务被重复执行多次的效果与执行一次是相等的。
==HTTP 协议要求 GET、PUT 和 DELETE 应具有幂等性==，我们把 REST 服务映射到这些方法时，也应当保证幂等性。
对于 POST 方法，曾经有过一些专门的提案（如POE ，POST Once Exactly），但并未得到 IETF 的通过。
对于 POST 的重复提交，浏览器会出现相应警告，如 Chrome 中“确认重新提交表单”的提示，
对于服务端，就应该做预校验，==如果发现可能重复，返回 HTTP/1.1 425 Too Early==。
另，Web Service 中有WS-ReliableMessaging 功能协议用于支持消息可靠投递。
类似的，由于 REST 没有采用额外的 Wire Protocol，所以除了事务、可靠传输这些功能以外，一定还可以在 WS-*协议中找到很多 REST 不支持的特性。


> REST 缺乏对资源进行“部分”和“批量”的处理能力

这个观点笔者是认同的，这很可能是未来面向资源的思想和 API 设计风格的发展方向。
HTTP 本身成了束缚 REST 的无形牢笼

通过具体例子来解释 REST 这方面的局限性：
- 譬如你仅仅想获得某个用户的姓名，
  - RPC 风格中可以设计一个“getUsernameById”的服务，返回一个字符串，尽管这种服务的通用性实在称不上“设计”二字，但确实可以工作；
  - REST 风格中你将向服务端请求整个用户对象，然后丢弃掉返回的结果中该用户除用户名外的其他属性，这便是一种“过度获取”（Overfetching）。

与此相对的缺陷是对资源的批量操作的支持，有时候我们不得不为此而专门设计一些抽象的资源才能应对。
譬如你准备把某个用户的名字增加一个“VIP”前缀，提交一个 PUT 请求修改这个用户的名称即可，而你要给 1000 个用户加 VIP 时，如果真的去调用 1000 次 PUT，浏览器会回应你 HTTP/1.1 429 Too Many Requests，老板则会揍你一顿。
此时，你就不得不先创建一个（如名为“VIP-Modify-Task”）任务资源，把 1000 个用户的 ID 交给这个任务，最后驱动任务进入执行状态。
又譬如你去网店买东西，下单、冻结库存、支付、加积分、扣减库存这一系列步骤会涉及到多个资源的变化，你可能面临不得不创建一种“事务”的抽象资源，或者用某种具体的资源（譬如“结算单”）贯穿这个过程的始终，每次操作其他资源时都带着事务或者结算单的 ID。HTTP 协议由于本身的无状态性，会相对不适应（并非不能够）处理这类业务场景。

一种理论上较优秀的可以解决以上这几类问题的方案是==GraphQL== ，这是由 Facebook 提出并开源的一种面向资源 API 的数据查询语言，如同 SQL 一样，挂了个“查询语言”的名字，但其实 CRUD 都有涉猎。
比起依赖 HTTP 无协议的 REST，GraphQL 可以说是另一种“有协议”的、更彻底地面向资源的服务方式。然而凡事都有两面，离开了 HTTP，它又面临着几乎所有 RPC 框架所遇到的那个如何推广交互接口的问题。


## 事务处理

事务处理几乎在每一个信息系统中都会涉及，它存在的意义是为了保证系统中所有的数据都是符合期望的，且相互关联的数据之间不会产生矛盾，即数据状态的一致性（Consistency）。

按照数据库的经典理论，要达成这个目标，需要三方面共同努力来保障。
- 原子性（Atomic）
  在同一项业务处理过程中，事务保证了对多个数据的修改，要么同时成功，要么同时被撤销。
- 隔离性（Isolation）
  在不同的业务处理过程中，事务保证了各自业务正在读、写的数据互相独立，不会彼此影响。
- 持久性（Durability）
  事务应当保证所有成功被提交的数据修改都能够正确地被持久化，不丢失数据。

以上四种属性即事务的“ACID”特性，但笔者对这种说法其实不是太认同，因为这四种特性并不正交，==A、I、D 是手段，C 是目的，前者是因，后者是果==，弄到一块去完全是为了拼凑个单词缩写。

事务的概念虽然最初起源于数据库系统，但今天已经有所延伸，
而不再局限于数据库本身了，所有需要保证数据一致性的应用场景，
包括但不限于数据库、事务内存 、缓存、消息队列、分布式存储，等等，都有可能会用到事务

- 当一个服务只使用一个数据源时，
  通过 A、I、D 来获得一致性是最经典的做法，也是相对容易的。
  此时，多个并发事务所读写的数据能够被数据源感知是否存在冲突，并发事务的读写在时间线上的最终顺序是由数据源来确定的，这种事务间一致性被称为“==内部一致性==”。

- 当一个服务使用到多个不同的数据源，甚至多个不同服务同时涉及多个不同的数据源时，问题就变得相对困难了许多。
  此时，并发执行甚至是先后执行的多个事务，在时间线上的顺序并不由任何一个数据源来决定，这种涉及多个数据源的事务间一致性被称为“==外部一致性==”。


### 场景事例
Fenix's Bookstore 是一个在线书店。每当一本书被成功售出时，需要确保以下三件事情被正确地处理：
-    用户的账号扣减相应的商品款项。
-    商品仓库中扣减库存，将商品标识为待配送状态。
-    商家的账号增加相应的商品款项。

。扣钱，扣库存，加钱。


### 本地事务

本地事务是指仅操作单一事务资源的、不需要全局事务管理器进行协调的事务

本地事务是最基础的一种事务解决方案，只适用于单个服务使用单个数据源的场景。
从应用角度看，它是直接依赖于数据源本身提供的事务能力来工作的，在程序代码层面，最多只能对事务接口做一层标准化的包装（如 JDBC 接口），并==不能深入参与到事务的运作过程当中==，事务的开启、终止、提交、回滚、嵌套、设置隔离级别，乃至与应用代码贴近的事务传播方式，全部都要依赖底层数据源的支持才能工作，这一点与后续介绍的 XA、TCC、SAGA 等主要靠应用程序代码来实现的事务有着十分明显的区别。


如今研究事务的实现原理，必定会追溯到ARIES 理论（Algorithms for Recovery and Isolation Exploiting Semantics，ARIES），直接翻译过来是“基于语义的恢复与隔离算法”，

ARIES 是现代数据库的基础理论，就算不能称所有的数据库都实现了 ARIES，至少也可以称现代的主流关系型数据库（Oracle、MS SQLServer、MySQL/InnoDB、IBM DB2、PostgreSQL，等等）在事务实现上都深受该理论的影响。
https://cs.stanford.edu/people/chrismre/cs345/rl/aries.pdf
http://vldb.org/conf/1990/P392.PDF



#### 实现原子性和持久性

原子性和持久性在事务里是密切相关的两个属性，原子性保证了事务的多个操作要么都生效要么都不生效，不会存在中间状态；
持久性保证了一旦事务生效，就不会再因为任何原因而导致其修改的内容被撤销或丢失。

数据必须要成功写入磁盘、磁带等持久化存储器后才能拥有持久性，
只存储在内存中的数据，一旦遇到应用程序忽然崩溃，或者数据库、操作系统一侧的崩溃，甚至是机器突然断电宕机等情况就会丢失，后文我们将这些意外情况都统称为“崩溃”（Crash）。
实现原子性和持久性的最大困难是“写入磁盘”这个操作并不是原子的，不仅有“写入”与“未写入”状态，还客观地存在着“正在写”的中间状态。
正因为写入中间状态与崩溃都不可能消除，所以如果不做额外保障措施的话，将内存中的数据写入磁盘，并不能保证原子性与持久性。下面通过具体事例来说明。

按照前面预设的场景事例，从 Fenix's Bookstore 购买一本书需要修改三个数据：在用户账户中减去货款、在商家账户中增加货款、在商品仓库中标记一本书为配送状态。由于写入存在中间状态，所以可能发生以下情形。

- 未提交事务，写入后崩溃：
  程序还没修改完三个数据，但数据库已经将其中一个或两个数据的变动写入磁盘，此时出现崩溃，一旦重启之后，数据库必须要有办法得知崩溃前发生过一次不完整的购物操作，将已经修改过的数据从磁盘中恢复成没有改过的样子，以保证原子性。
- 已提交事务，写入前崩溃：
  程序已经修改完三个数据，但数据库还未将全部三个数据的变动都写入到磁盘，此时出现崩溃，一旦重启之后，数据库必须要有办法得知崩溃前发生过一次完整的购物操作，将还没来得及写入磁盘的那部分数据重新写入，以保证持久性。

但是，已提交事务 和 写入前 感觉冲突啊。提交的时候，应该必然已经到磁盘了吧。

由于写入中间状态与崩溃都是无法避免的，为了保证原子性和持久性，就只能在崩溃后采取恢复的补救措施，这种数据恢复操作被称为“==崩溃恢复==”（Crash Recovery，也有资料称作 Failure Recovery 或 Transaction Recovery）。


额外知识：Shadow Paging
通过==日志实现事务的原子性和持久性==是当今的==主流==方案，但并不是唯一的选择。
除日志外，还有另外一种称为“Shadow Paging ”（有中文资料翻译为“影子分页”）的事务实现机制，常用的轻量级数据库 SQLite Version 3 采用的事务机制就是 Shadow Paging。

Shadow Paging 的大体思路是对数据的变动会写到硬盘的数据中，但并==不是直接就地修改==原先的数据，而是先将数据==复制一份副本==，保留原数据，修改副本数据。
在事务过程中，被修改的数据会同时存在两份，一份是修改前的数据，一份是修改后的数据，这也是“影子”（Shadow）这个名字的由来。
当事务成功提交，所有数据的修改都成功持久化之后，==最后一步==是去==修改数据的引用指针==，将引用从原数据改为新复制出来修改后的副本，最后的“修改指针”这个操作将被认为是原子操作，现代磁盘的写操作可以认为在硬件上保证了不会出现“改了半个值”的现象。
所以 Shadow Paging 也可以保证原子性和持久性。Shadow Paging 实现事务要比 Commit Logging 更加简单，但涉及隔离性与并发锁时，Shadow Paging 实现的==事务并发能力就相对有限==，因此在高性能的数据库中应用不多。

Commit Logging 保障数据持久性、原子性的原理并不难理解：
- 首先，日志一旦成功写入 Commit Record，那整个事务就是成功的，即使真正修改数据时崩溃了，重启后根据已经写入磁盘的日志信息==恢复==现场、继续修改数据即可，这保证了==持久性==；
- 其次，如果日志没有成功写入 Commit Record 就发生崩溃，那整个事务就是失败的，系统重启后会看到一部分没有 Commit Record 的日志，那将这部分日志标记为==回滚==状态即可，整个事务就像完全没好有发生过一样，这保证了==原子性==。

Commit Logging 存在一个==巨大的先天缺陷==：所有对数据的真实修改都必须发生在事务提交以后，即日志写入了 Commit Record 之后。
在此之前，即使磁盘 I/O 有足够空闲、即使某个事务修改的数据量非常庞大，占用了大量的内存缓冲区，无论有何种理由，都决不允许在事务提交之前就修改磁盘上的数据，这一点是 Commit Logging 成立的前提，却对提升数据库的性能十分不利

ARIES 提出了“Write-Ahead Logging”的日志改进方案，所谓“提前写入”（Write-Ahead），就是==允许在事务提交之前，提前写入变动数据==的意思。

Write-Ahead Logging 先将何时写入变动数据，按照事务提交时点为界，划分为 FORCE 和 STEAL 两类情况。
- FORCE：
  当事务提交后，要求变动数据必须同时完成写入则称为 FORCE，如果不强制变动数据必须同时完成写入则称为 NO-FORCE。现实中绝大多数数据库采用的都是 NO-FORCE 策略，因为只要有了日志，变动数据随时可以持久化，从优化磁盘 I/O 性能考虑，没有必要强制数据写入立即进行。
- STEAL：
  在事务提交前，允许变动数据提前写入则称为 STEAL，不允许则称为 NO-STEAL。从优化磁盘 I/O 性能考虑，允许数据提前写入，有利于利用空闲 I/O 资源，也有利于节省数据库缓存区的内存。

。。no-force 好， steal 好

Commit Logging 允许 NO-FORCE，但不允许 STEAL。

Write-Ahead Logging 允许 NO-FORCE，也允许 STEAL，
它给出的解决办法是增加了另一种被称为 ==Undo Log== 的日志类型，当变动数据写入磁盘前，必须先记录 ==Undo Log，注明修改了哪个位置的数据、从什么值改成什么值==，等等。以便在事务==回滚==或者崩溃==恢复==时根据 Undo Log 对提前写入的数据变动进行==擦除==。
Undo Log 现在一般被翻译为“==回滚日志==”，此前记录的用于崩溃==恢复时重演==数据变动的日志就相应被命名为 ==Redo Log，一般翻译为“重做日志”==。由于 Undo Log 的加入，Write-Ahead Logging 在崩溃恢复时会执行以下三个阶段的操作。

。。崩溃恢复， 是 从崩溃状态中恢复成 正常状态， 一般是 撤销 未commit的数据。 而不是重做。
。。redo log 就是 之前的 commit-log。

- 分析阶段（Analysis）：
  该阶段从最后一次==检查点（Checkpoint==，可理解为在==这个点之前==所有应该持久化的==变动都已安全落盘==）开始扫描日志，找出所有==没有 End Record 的事务==，组成==待恢复==的事务集合，这个集合至少会包括 Transaction Table 和 Dirty Page Table 两个组成部分。
- 重做阶段（Redo）：
  该阶段依据分析阶段中产生的待恢复的事务集合来==重演==历史（Repeat History），具体操作为：找出所有包含 ==Commit Record== 的日志，将这些日志修改的数据写入磁盘，写入完成后在日志中增加一条 ==End Record==，然后移除出待恢复事务集合。
- 回滚阶段（Undo）：
  该阶段处理经过分析、重做阶段后剩余的恢复事务集合，此时==剩下的==都是需要==回滚==的事务，它们被称为 Loser，根据 ==Undo Log== 中的信息，将已经提前写入磁盘的信息重新改写回去，以达到回滚这些 Loser 事务的目的。


Write-Ahead Logging 是 ARIES 理论的一部分，整套 ARIES 拥有严谨、高性能等很多的优点，但这些也是以高度复杂为代价的。
数据库按照是否允许 FORCE 和 STEAL 可以产生共计四种组合，
从优化磁盘 I/O 的角度看，NO-FORCE 加 STEAL 组合的性能无疑是最高的；
从算法实现与日志的角度看 NO-FORCE 加 STEAL 组合的复杂度无疑也是最高的。


force + no-steal 最慢
no-force + steal 最快

no-force 需要redo log
steal 需要 undo log

所以 force + no-steal 不需要日志。
no-force + steal 需要 undo，redo log


#### 实现隔离性

隔离性保证了每个事务各自读、写的数据互相独立，不会彼此影响

因为如果没有并发，所有事务全都是串行的，那就不需要任何隔离

要在并发下实现串行的数据访问该怎样做？几乎所有程序员都会回答：加锁同步呀！正确，现代数据库均提供了以下三种锁。
- 写锁（Write Lock，也叫作排他锁，eXclusive Lock，简写为 X-Lock）：
  如果数据有加写锁，就只有持有写锁的事务才能对数据进行写入操作，数据加持着写锁时，其他事务不能写入数据，也不能施加读锁。
- 读锁（Read Lock，也叫作共享锁，Shared Lock，简写为 S-Lock）：
  多个事务可以对同一个数据添加多个读锁，数据被加上读锁后就不能再被加上写锁，所以其他事务不能对该数据进行写入，但仍然可以读取。对于持有读锁的事务，如果该数据只有它自己一个事务加了读锁，允许直接将其升级为写锁，然后写入数据。
- 范围锁（Range Lock）：
  对于某个范围直接加==排他锁==，在这个范围内的数据不能被写入。
  `SELECT * FROM books WHERE price < 100 FOR UPDATE;`
  请注意“范围不能被写入”与“一批数据不能被写入”的差别，即不要把范围锁理解成一组排他锁的集合。
  加了范围锁后，不仅无法修改该范围内已有的数据，也==不能在该范围内新增或删除任何数据==，后者是一组排他锁的集合无法做到的。


#### 可串行化
串行化访问提供了强度最高的隔离性
ANSI/ISO SQL-92 中定义的最高等级的隔离级别便是可串行化（Serializable）。
如果不考虑性能优化的话，对事务所有读、写的数据==全都加上读锁、写锁和范围锁==即可做到可串行化

#### 可重复读(幻读)
可串行化的下一个隔离级别是可重复读（Repeatable Read）
可重复读对事务所涉及的数据==加读锁和写锁==，且一直持有至==事务结束==，但==不再加范围锁==。
可重复读比可串行化弱化的地方在于==幻读==问题（Phantom Reads），它是指在事务执行过程中，==两个完全相同的范围查询得到了不同的结果集==。

譬如现在准备统计一下 Fenix's Bookstore 中售价小于 100 元的书有多少本，会执行以下第一条 SQL 语句：
```sql
SELECT count(1) FROM books WHERE price < 100					/* 时间顺序：1，事务： T1 */
INSERT INTO books(name,price) VALUES ('深入理解Java虚拟机',90)	/* 时间顺序：2，事务： T2 */
SELECT count(1) FROM books WHERE price < 100					/* 时间顺序：3，事务： T1 */
```
可重复读==没有范围锁来禁止在该范围内插入==新的数据，这是一个事务受到其他事务影响，隔离性被破坏的表现。
。。有写锁，所以不会被删除。

这里的介绍是以 ==ARIES 理论==为讨论目标的，具体的数据库并不一定要完全遵照着理论去实现。
一个例子是 ==MySQL/InnoDB== 的默认隔离级别为==可重复读==，但它==在只读事务中可以完全避免幻读问题==，譬如上面例子中事务 T1 只有查询语句，是一个只读事务，所以例子中的问题在 MySQL 中并不会出现。

#### 读已提交(不可重复读)
可重复读的下一个隔离级别是读已提交（Read Committed），读已提交对事务涉及的数据加的==写锁==会一直持续到==事务结束==，但加的==读锁==在查询操作完成后就==马上会释放==。

读已提交 比 可重复读弱化的地方在于 不可重复读问题 （Non-Repeatable Reads），它是指在事务执行过程中，对==同一行数据==的两次查询得到了==不同的结果==。

```sql
SELECT * FROM books WHERE id = 1;   						/* 时间顺序：1，事务： T1 */
UPDATE books SET price = 110 WHERE id = 1; COMMIT;			/* 时间顺序：2，事务： T2 */
SELECT * FROM books WHERE id = 1; COMMIT;   				/* 时间顺序：3，事务： T1 */
```

如果隔离级别是读已提交，这两次重复执行的查询结果就会不一样，原因是读已提交的隔离级别缺乏贯穿整个事务周期的读锁，==无法禁止读取过的数据发生变化==，此时事务 T2 中的更新语句可以马上提交成功


#### 读未提交(脏读)
读已提交的下一个级别是读未提交（Read Uncommitted），读未提交对事务涉及的数据==只加写锁==，会一直持续到==事务结束==，但==完全不加读锁==。

读未提交比读已提交弱化的地方在于脏读问题 （Dirty Reads）
它是指在事务执行过程中，一个事务读取到了另一个事务未提交的数据。

```sql
SELECT * FROM books WHERE id = 1;   						/* 时间顺序：1，事务： T1 */
/* 注意没有COMMIT */
UPDATE books SET price = 90 WHERE id = 1;					/* 时间顺序：2，事务： T2 */
/* 这条SELECT模拟购书的操作的逻辑 */
SELECT * FROM books WHERE id = 1;			  				/* 时间顺序：3，事务： T1 */
ROLLBACK;			  										/* 时间顺序：4，事务： T2 */
```

事务 T1 已经按 90 元的价格卖出了几本。
原因是读未提交在数据上完全不加读锁，这==反而==令它能读到其他事务加了写锁的数据，即上述事务 T1 中两条查询语句得到的结果并不相同。
如果你不能理解这句话中的“反而”二字，请再重读一次==写锁的定义==：写锁禁止其他事务施加==读锁==，而不是禁止事务==读取==数据，如果事务 T1 ==读取数据并不需要去加读锁==的话，就会导致事务 T2 未提交的数据也马上就能被事务 T1 所读到。

。。写锁排斥 写锁，读锁。  但是 我不加锁，直接读。 哈哈。

其实不同隔离级别以及幻读、不可重复读、脏读等问题都只是表面现象，==是各种锁在不同加锁时间上组合应用所产生的结果==，以锁为手段来实现隔离性才是数据库表现出不同隔离级别的根本原因。

#### my总结
|隔离级别|缺陷|锁|原理|
|--|--|--|--|
|可序列化|无|读锁，写锁，范围锁|无|
|可重复读|幻读|读锁，写锁|没有范围锁，其他事务可以新增数据|
|读已提交|不可重复读|读锁(查询后释放，不会持续整个事务)，写锁|2次读锁间，其他事务可以修改值|
|读未提交|脏读|写锁|其他事务写锁，但本事务不会加锁，直接读，所以可以读到未commit的|



#### MVCC

除了都以锁来实现外，以上四种隔离级别还有另一个共同特点，就是幻读、不可重复读、脏读等问题都是由于一个事务在读数据过程中，受另外一个写数据的事务影响而破坏了隔离性，
针对这种“一个事务读+另一个事务写”的隔离问题，近年来有一种名为“==多版本并发控制==”（Multi-Version Concurrency Control，==MVCC==）的==无锁==优化方案被主流的商业数据库广泛采用。

MVCC 是一种==读取优化==策略，它的“无锁”是特指==读取时不需要加锁==

MVCC 的基本思路是对数据库的==任何修改都不会直接覆盖之前的数据==，而是==产生一个新版副本==与老版本共存，以此达到==读取时可以完全不加锁==的目的。
在这句话中，==“版本”是个关键词==，你不妨将版本理解为数据库中每一行记录都存在两个看不见的字段：==CREATE_VERSION 和 DELETE_VERSION==，这两个字段记录的值都是==事务 ID，事务 ID 是一个全局严格递增的数值==，然后根据以下规则写入数据。

- 插入数据时：
  CREATE_VERSION 记录插入数据的事务 ID，DELETE_VERSION 为空。
- 删除数据时：
  DELETE_VERSION 记录删除数据的事务 ID，CREATE_VERSION 为空。
- 修改数据时：
  将修改数据视为“删除旧数据，插入新数据”的组合，即先将原有数据==复制==一份，==原有数据==的 ==DELETE_VERSION 记录修改数据的事务 ID==，CREATE_VERSION 为空。复制出来的==新数据==的 ==CREATE_VERSION 记录修改数据的事务 ID==，DELETE_VERSION 为空。

。。2个字段，只有一个有值。

如有另外一个事务要==读取==这些发生了变化的数据，将根据==隔离级别==来决定到底应该读取哪个版本的数据。
- 隔离级别是可重复读：
  总是读取 CREATE_VERSION 小于或等于当前事务 ID 的记录，在这个前提下，如果数据仍有多个版本，则取最新（事务 ID 最大）的。
- 隔离级别是读已提交：
  总是取最新的版本即可，即最近被 Commit 的那个版本的数据记录。

另外两个隔离级别都没有必要用到 MVCC，因为读未提交直接修改原始数据即可，其他事务查看数据的时候立刻可以看到，根本无须版本字段。
可串行化本来的语义就是要阻塞其他事务的读取操作，而 MVCC 是做读取时无锁优化的，自然就不会放到一起用。

#### 乐观锁，悲观锁
MVCC 是只针对“读+写”场景的优化，如果是两个事务同时修改数据，即“写+写”的情况，那就没有多少优化的空间了，此时加锁几乎是唯一可行的解决方案，稍微有点讨论余地的是加锁的策略是“乐观加锁”（Optimistic Locking）还是“悲观加锁”（Pessimistic Locking）

前面笔者介绍的加锁都属于悲观加锁策略，即认为如果不先做加锁再访问数据，就肯定会出现问题。
相对地，乐观加锁策略认为事务之间数据存在竞争是偶然情况，没有竞争才是普遍情况，这样就不应该在一开始就加锁，而是应当在出现竞争时再找补救措施。
这种思路被称为“乐观并发控制 ”（Optimistic Concurrency Control，OCC），囿于篇幅与主题的原因，就不再展开了，不过笔者提醒一句，没有必要迷信什么乐观锁要比悲观锁更快的说法，这纯粹看==竞争的剧烈程度==，如果==竞争剧烈的话，乐观锁反而更慢==。


### 全局事务
与本地事务相对的是全局事务（Global Transaction），有一些资料中也将其称为外部事务（External Transaction），
在==本节==里，全局事务被限定为一种适用于==单个服务使用多个数据源==场景的事务解决方案。

理论上真正的全局事务并没有“单个服务”的约束，它本来就是 DTP（Distributed Transaction Processing ）模型中的概念
。。分布式事务处理。。


X/Open 组织（后来并入了The Open Group ）提出了一套名为X/Open XA （XA 是 eXtended Architecture 的缩写）的处理事务架构，
其核心内容是定义了==全局的事务管理器==（Transaction Manager，用于协调全局事务）和==局部的资源管理器==（Resource Manager，用于驱动本地事务）之间的==通信接口==。XA 接口是双向的，能在一个事务管理器和多个资源管理器（Resource Manager）之间形成通信桥梁，通过协调多个数据源的一致动作，实现==全局事务的统一提交或者统一回滚==

。。全局 事务 管理器，  局部 资源 管理器

XA 并不是 Java 的技术规范（XA 提出那时还没有 Java），而是一套语言无关的通用规范，所以 Java 中专门定义了JSR 907 Java Transaction API ，基于 XA 模式在 Java 语言中的实现了全局事务处理的标准，这也就是我们现在所熟知的 ==JTA==。
JTA 最主要的两个接口是：
- 事务管理器的接口：javax.transaction.TransactionManager。
  这套接口是给 Java EE 服务器提供容器事务（由容器自动负责事务管理）使用的，
  还提供了另外一套javax.transaction.==User==Transaction接口，用于通过程序代码手动开启、提交和回滚事务。
- 满足 XA 规范的资源定义接口：javax.transaction.xa.XAResource，
  任何资源（JDBC、JMS 等等）如果想要支持 JTA，只要实现 XAResource 接口中的方法即可。

JTA 原本是 ==Java EE== 中的技术，一般情况下应该由 JBoss、WebSphere、WebLogic 这些 Java EE 容器来提供支持，
但现在Bittronix 、Atomikos 和JBossTM （以前叫 Arjuna）都以 JAR 包的形式实现了 JTA 的接口，称为 JOTM（Java Open Transaction Manager），使得我们能够在 Tomcat、Jetty 这样的 ==Java SE== 环境下也能使用 JTA。

对本章的场景事例做另外一种假设：
如果书店的用户、商家、仓库分别==处于不同的数据库==中，其他条件仍与之前相同，那情况会发生什么变化呢？假如你平时以==声明式==事务来编码，那它与本地事务看起来可能没什么区别，都是标个==@Transactional==注解而已，但如果以==编程式事务==来实现的话，就能在写法上看出差异，伪代码如下所示

```Java
public void buyBook(PaymentBill bill) {
    userTransaction.begin();
    warehouseTransaction.begin();
    businessTransaction.begin();
	try {
        userAccountService.pay(bill.getMoney());
        warehouseService.deliver(bill.getItems());
        businessAccountService.receipt(bill.getMoney());

        userTransaction.commit();
        warehouseTransaction.commit();
        businessTransaction.commit();
	} catch(Exception e) {
        userTransaction.rollback();
        warehouseTransaction.rollback();
        businessTransaction.rollback();
	}
}
```

程序的目的是要做三次事务提交，但实际上代码并==不能这样写==

。。反面例子：  businessTransaction commit时 抛出异常，此时 userTransaction rollback 是无效的。


#### 2段式提交 2PC
XA 将事务提交拆分成为两阶段过程：
- 准备阶段：又叫作投票阶段，
  在这一阶段，协调者询问事务的所有参与者==是否准备好提交==，参与者如果已经准备好提交则回复 Prepared，否则回复 Non-Prepared。
  这里所说的准备操作跟人类语言中通常理解的准备并不相同，对于数据库来说，==准备操作是在重做日志中记录全部事务提交操作所要做的内容==，它与本地事务中真正提交的区别只是==暂不写入最后一条 Commit Record== 而已，这意味着在做完数据持久化后并不立即释放隔离性，即仍继续持有锁，维持数据对其他非事务内观察者的隔离状态。
- 提交阶段：又叫作执行阶段，
  协调者
  如果在上一阶段收到==所有事务参与者==回复的 Prepared 消息，则先自己在==本地持久化事务状态为 Commit==，在此操作完成后向所有参与者发送 Commit 指令，所有参与者立即执行提交操作；
  否则，任意一个参与者回复了 Non-Prepared 消息，或任意一个参与者超时未回复，协调者将自己的事务状态持久化为 Abort 之后，向所有参与者发送 Abort 指令，参与者立即执行回滚操作。对于数据库来说，这个阶段的提交操作应是==很轻量==的，仅仅是==持久化一条 Commit Record 而已==，通常能够快速完成，只有收到 Abort 指令时，才需要根据回滚日志清理已提交的数据，这可能是相对重负载的操作。

以上这两个过程被称为“两段式提交 ”（2 Phase Commit，2PC）协议，
而它能够成功保证一致性还需要一些其他前提条件。
- 必须假设网络在提交阶段的短时间内是可靠的，即==提交阶段不会丢失消息==。
  同时也假设网络通信在全过程都不会出现误差，即可以丢失消息，但不会传递错误的消息，XA 的设计目标并不是解决诸如拜占庭将军一类的问题。两段式提交中投票阶段失败了可以补救（回滚），而提交阶段失败了无法补救（不再改变提交或回滚的结果，只能等崩溃的节点重新恢复），因而此阶段耗时应尽可能短，这也是为了尽量控制网络风险的考虑。
- 必须假设因为网络分区、机器崩溃或者其他原因而导致失联的==节点最终能够恢复==，不会永久性地处于失联状态。
  由于在准备阶段已经写入了完整的重做日志，所以当失联机器一旦恢复，就能够从日志中找出已准备妥当但并未提交的事务数据，并向协调者查询该事务的状态，确定下一步应该进行提交还是回滚操作。

两段式提交原理简单，并不难实现，但有几个非常显著的缺点：
- 单点问题：
  ==协调者==在两段提交中具有举足轻重的作用，协调者等待参与者回复时可以有超时机制，允许参与者宕机，但参与者等待协调者指令时无法做超时处理。一旦宕机的不是其中某个参与者，而是协调者的话，所有参与者都会受到影响。如果协调者一直没有恢复，没有正常发送 Commit 或者 Rollback 的指令，那所有参与者都必须一直等待。
- 性能问题：
  两段提交过程中，所有参与者相当于被绑定成为一个统一调度的整体，期间要经过==两次远程服务调用，三次数据持久化==（准备阶段写重做日志，协调者做状态持久化，提交阶段在日志写入 Commit Record），整个过程将持续到参与者集群中最慢的那一个处理操作结束为止，这决定了两段式提交的==性能通常都较差==。
- 一致性风险：
  前面已经提到，==两段式提交的成立是有前提条件的==，当网络稳定性和宕机恢复能力的假设不成立时，仍可能出现一致性问题。
  宕机恢复能力这一点不必多谈，1985 年 Fischer、Lynch、Paterson 提出了“==FLP 不可能原理==”，证明了如果宕机最后不能恢复，那就不存在任何一种分布式协议可以正确地达成一致性结果。该原理在分布式中是==与“CAP 不可兼得原理“齐名的理论==。
  而==网络稳定性带来的一致性风险是指==：尽管提交阶段时间很短，但这仍是一段明确存在的危险期，如果协调者在发出准备指令后，根据收到各个参与者发回的信息确定事务状态是可以提交的，协调者会先持久化事务状态，并提交自己的事务，如果这时候网络忽然被断开，无法再通过网络向所有参与者发出 Commit 指令的话，就会导致部分数据（协调者的）已提交，但部分数据（参与者的）既未提交，也没有办法回滚，产生了数据不一致的问题。


#### 3段式提交 3PC

为了缓解两段式提交协议的一部分缺陷，具体地说是==协调者的单点==问题和==准备阶段的性能==问题，后续又发展出了“三段式提交 ”（3 Phase Commit，3PC）协议。

三段式提交把原本的两段式提交的==准备阶段再细分为两个阶段==，分别称为 ==CanCommit、PreCommit==，把==提交阶段改称为 DoCommit 阶段==。

新增的 CanCommit 是一个询问阶段，协调者让每个参与的数据库根据自身状态，评估该事务是否有可能顺利完成。
将准备阶段一分为二的理由是这个阶段是==重负载==的操作，一旦协调者发出开始准备的消息，每个参与者都将马上开始写重做日志，它们所涉及的数据资源即被锁住，如果此时某一个参与者宣告无法完成提交，相当于大家都白做了一轮无用功。
所以，增加一轮询问阶段，如果都得到了正面的响应，那事务==能够成功提交的把握就比较大==了，这也意味着因某个参与者提交时发生崩溃而导致大家全部回滚的风险相对变小。
因此，在==事务需要回滚==的场景中，==三段式的性能通常是要比两段式好很多的==，但在事务==能够正常提交的场景==中，==两者的性能都依然很差==，甚至三段式因为==多了一次询问==，还要稍微==更差==一些。

同样也是由于事务失败回滚概率变小的原因，在三段式提交中，如果在 PreCommit 阶段之后发生了协调者宕机，即参与者没有能等到 DoCommit 的消息的话，默认的操作策略将是==提交事务==而不是回滚事务或者持续等待，这就相当于避免了协调者单点问题的风险。

三段式提交对==单点问题和回滚时的性能==问题有所改善，但是它对==一致性风险==问题并未有任何改进，在这方面它面临的风险甚至反而是略有增加了的。
譬如，进入 PreCommit 阶段之后，协调者发出的指令不是 Ack 而是 Abort，而此时因网络问题，有部分参与者直至超时都未能收到协调者的 Abort 指令的话，这些参与者将会错误地提交事务，这就产生了不同参与者之间数据不一致的问题。





### 共享事务

与全局事务里讨论的单个服务使用多个数据源正好相反，
共享事务（Share Transaction）是指==多个服务共用同一个数据源==。

再强调一次“数据源”与“数据库”的区别：数据源是指提供数据的逻辑设备，不必与物理设备一一对应。
在部署应用集群时最常采用的模式是将同一套程序部署到多个中间件服务器上，构成多个副本实例来分担流量压力。它们虽然==连接了同一个数据库==，但每个==节点配有自己的专属的数据源==，通常是中间件以 JNDI 的形式开放给程序代码使用。

。。DataSource。 连接了同一个数据库， 但是 DateSource 对象是不同的。 所以 这个App的 DataSource 中开启的 事务， 在另一个App的 DataSource中 是不可用的。

。。这里是 多个服务 用一个 DataSource 。 DataSource 怎么共享的。。

举个具体例子，在 Fenix's Bookstore 的场景事例中，假设用户账户、商家账户和商品仓库都==存储于同一个数据库==之中，但用户、商户和仓库每个领域都部署了==独立的微服务==，此时一次购书的业务操作将==贯穿三个微服务==，它们都要在数据库中修改数据。
如果我们直接==将不同数据源就视为是不同数据库==，那上一节所讲的==全局事务==和下一节要讲的==分布式事务==都是==可行==的，
不过，==针对这种每个数据源连接的都是同一个物理数据库的特例，共享事务则有机会成为另一条可能提高性能、降低复杂度的途径，当然，也很有可能是一个伪需求。==

一种理论可行的方案是直接让各个服务==共享数据库连接==，在同一个应用进程中的不同持久化工具（JDBC、ORM、JMS 等）间共享数据库连接并不困难，某些中间件服务器，譬如 WebSphere 会内置有“可共享连接 ”功能来专门给予这方面的支持。
但这种==共享的前提==是数据源的使用者都在==同一个进程==内，由于数据库连接的基础是网络连接，它是与 IP 地址和端口号绑定的，字面意义上的“不同服务节点共享数据库连接”很难做到，
所以为了实现共享事务，就==必须新增一个“交易服务器”的中间角色==，无论是用户服务、商家服务还是仓库服务，它们都通过同一台交易服务器来与数据库打交道。
如果将交易服务器的对外接口按照 JDBC 规范来实现的话，那它完全可以视为是一个独立于各个服务的==远程数据库连接池==，或者直接作为==数据库代理==来看待。
此时三个服务所发出的交易请求就有可能做到交由交易服务器上的同一个数据库连接，通过本地事务的方式完成。
譬如，交易服务器根据不同服务节点传来的同一个事务 ID，使用同一个数据库连接来处理跨越多个服务的交易事务

之所以强调理论可行，是因为该方案是与实际生产系统中的压力方向相悖的，一个服务集群里==数据库才是压力最大而又最不容易伸缩拓展的重灾区==，
所以现实中只有类似ProxySQL 、MaxScale 这样用于对多个数据库实例做负载均衡的数据库代理（其实用 ProxySQL 代理单个数据库，再启用 Connection Multiplexing，已经接近于前面所提及的交易服务器方案了），
而几乎没有反过来代理一个数据库为多个应用提供事务协调的交易服务代理。
这也是说它更有可能是个伪需求的原因，如果你有充足理由让多个微服务去共享数据库，就必须找到更加站得住脚的理由来向团队==解释拆分微服务的目的==是什么才行。

在日常开发中，上述方案还存在一类更为常见的变种形式：使用==消息队列==服务器来代替交易服务器。
用户、商家、仓库的服务操作业务时，通过消息将所有对数据库的改动传送到消息队列服务器，通过消息的消费者来统一处理，实现由本地事务保障的持久化操作。这被称作“单个数据库的消息驱动更新 ”（Message-Driven Update of a Single Database）。

“共享事务”的提法和这里所列的两种处理方式在实际应用中并==不值得提倡==，鲜有采用这种方式的成功案例
笔者个人==不赞同==将共享事务作为一种常规的解决方案来考量。



### 分布式事务 Distributed Transaction

本章中所说的分布式事务（Distributed Transaction）特指
==多个服务同时访问多个数据源的事务处理机制==，
请注意它与DTP 模型 中“分布式事务”的差异。DTP 模型所指的“分布式”是==相对于数据源==而言的，并不涉及服务，这部分内容已经在“全局事务”一节里进行过讨论。
本节所指的“分布式”是==相对于服务==而言的，如果严谨地说，它更应该被称为“在分布式服务环境下的事务处理机制”。


人们曾经寄希望于 XA 的事务机制可以在本节所说的分布式环境中也能良好地应用，但这个美好的愿望今天已经被 CAP 理论彻底地击碎了


#### CAP 与 ACID
Consistency、Availability、Partition Tolerance Theorem

以严谨的数学推理证明了 CAP 猜想

这个定理里描述了一个分布式的系统中，涉及共享数据问题时，以下三个特性最多只能同时满足其中两个：
- 一致性（Consistency）：
  代表数据在==任何时刻、任何分布式节点==中所看到的都是==符合预期==的。一致性在分布式研究中是有严肃定义、有多种细分类型的概念，以后讨论==分布式共识算法==时，我们还会再提到一致性，那种面向副本复制的一致性与这里面向数据库状态的一致性严格来说并不完全等同，具体差别我们将在后续分布式共识算法中再作探讨。
- 可用性（Availability）：
  代表系统==不间断地提供服务的能力==，理解可用性要先理解与其密切相关两个指标：==可靠性（Reliability）和可维护性（Serviceability）==。
  - 可靠性使用平均无故障时间（Mean Time Between Failure，MTBF）来度量；
  - 可维护性使用平均可修复时间（Mean Time To Repair，MTTR）来度量。
  可用性衡量系统可以正常使用的时间与总时间之比，其表征为：A=MTBF/（MTBF+MTTR），即可用性是由可靠性和可维护性计算得出的比例值，譬如 99.9999%可用，即代表平均年故障修复时间为 32 秒。
- 分区容忍性（Partition Tolerance）：
  代表分布式环境中部分节点因==网络原因而彼此失联==后，即与其他节点形成“网络分区”时，系统仍能==正确地提供服务的能力==。

场景：
3个集群：账户，商家，库存
每个集群有N个节点。
每个节点都有自己的数据库 (这只是为了便于说明问题，实际中，不太可能：将用户余额这样的数据设计成存储在多个可写的数据库中)

假设某次交易请求分别由“账号节点 1”、“商家节点 2”、“仓库节点 N”联合进行响应。
当用户购买一件价值 100 元的商品后，账号节点 1 首先应给该用户账号扣减 100 元货款，它在自己数据库扣减 100 元很容易，但它还要把这次交易变动告知本集群的节点 2 到节点 N，并要确保能正确变更商家和仓库集群其他账号节点中的关联数据，此时将面临以下可能的情况。
- 如果该变动信息==没有及时同步==给其他账号节点，将导致有可能发生用户购买另一商品时，被分配给到另一个节点处理，由于看到账号上有==不正确的余额==而错误地发生了原本无法进行的交易，此为==一致性==问题。
- 如果由于要把该变动信息同步给其他账号节点，==必须暂时停止==对该用户的交易服务，直至数据同步一致后再重新恢复，将可能导致用户在下一次购买商品时，因系统暂时无法提供服务而被==拒绝交易==，此为==可用性==问题。
- 如果由于账号服务集群中某一部分节点，因出现==网络问题==，无法正常与另一部分节点交换账号变动信息，此时服务集群中无论哪一部分节点对外提供的服务都可能是不正确的，整个集群能否承受由于部分节点之间的连接中断而仍然能够正确地提供服务，此为==分区容忍性==。

还有库存，如果没有及时更新， 超卖
商家，同步商家的数据，导致商家不可用。


由于 CAP 定理已有严格的证明，本节不去探讨为何 CAP 不可兼得，而是直接分析如果舍弃 C、A、P 时所带来的不同影响。

- 如果放弃分区容忍性（CA without P），
  ==意味着我们将假设节点之间通信永远是可靠的==。永远可靠的通信在分布式系统中==必定不成立==的，这不是你想不想的问题，而是只要用到网络来共享数据，分区现象就会始终存在。
  在现实中，最容易找到放弃分区容忍性的例子便是传统的关系数据库集群，这样的集群虽然依然采用由网络连接的多个节点来协同工作，但数据却不是通过网络来实现共享的。
  以 Oracle 的 RAC 集群为例，它的每一个节点均有自己独立的 SGA、重做日志、回滚日志等部件，但各个节点是通过共享存储中的==同一份数据文件和控制文件==来获取数据的，通过共享磁盘的方式来避免出现网络分区。因而 Oracle RAC 虽然也是由多个实例组成的数据库，但它并不能称作是分布式数据库。
- 如果放弃可用性（CP without A），
  意味着我们将假设==一旦网络发生分区==，节点之间的信息==同步时间可以无限制地延长==，此时，问题相当于==退化到前面“全局事务”中讨论的一个系统使用多个数据源的场景之中==，我们可以通过 ==2PC/3PC 等手段==，同时获得分区容忍性和一致性。
  在现实中，选择放弃可用性的 CP 系统情况==一般用于对数据质量要求很高的场合==中，除了 DTP 模型的分布式数据库事务外，著名的 HBase 也是属于 CP 系统，以 HBase 集群为例，假如某个 RegionServer 宕机了，这个 RegionServer 持有的所有键值范围都将离线，直到数据恢复过程完成为止，这个过程要消耗的时间是无法预先估计的。
- 如果放弃一致性（AP without C），
  意味着我们将假设==一旦发生分区，节点之间所提供的数据可能不一致==。选择放弃一致性的 AP 系统目前是设计分布式系统的==主流选择==，因为 ==P 是分布式网络的天然属性==，你再不想要也无法丢弃；而 ==A 通常是建设分布式的目的==，
  如果可用性随着节点数量增加反而降低的话，很多分布式系统可能就失去了存在的价值，除非银行、证券这些涉及==金钱交易==的服务，宁可中断也不能出错，否则多数系统是不能容忍节点越多可用性反而越低的。
  目前大多数 NoSQL 库和支持分布式的缓存框架都是 AP 系统，以 Redis 集群为例，如果某个 Redis 节点出现网络分区，那仍不妨碍各个节点以自己本地存储的数据对外提供缓存服务，但这时有可能出现请求分配到不同节点时返回给客户端的是不一致的数据。


“事务”原本的目的就是获得“一致性”，而在分布式环境中，“一致性”却不得不成为通常被牺牲、被放弃的那一项属性。

人们又重新给一致性下了定义，
将前面我们在 CAP、ACID 中讨论的一致性称为==强一致性==（Strong Consistency），有时也称为==线性一致性==（Linearizability，通常是在讨论共识算法的场景中），
而把牺牲了 C 的 AP 系统又要尽可能获得正确的结果的行为称为追求==弱一致性==。不过，如果单纯只说“弱一致性”那其实就是“不保证一致性”的意思……人类语言这东西真的是博大精深。
在弱一致性里，人们又总结出了一种稍微强一点的特例，被称为==最终一致性==（Eventual Consistency），它是指：如果数据在一段时间之内没有被另外的操作所更改，那它最终将会达到与强一致性过程相同的结果，有时候面向最终一致性的算法也被称为“==乐观复制算法==”。


人们把使用 ACID 的事务称为“==刚性事务==”，而把笔者下面将要介绍几种==分布式事务的常见做法==统称为“==柔性事务==”。


#### 可靠事件队列

。。和 消息队列 没有关系。。。有一点点。

一种独立于 ACID 获得的强一致性之外的、使用 BASE 来达成一致性目的的途径。

BASE 分别是基本可用性（Basically Available）、柔性事务（Soft State）和最终一致性（Eventually Consistent）的缩写


我们继续以本章的场景事例来解释 Dan Pritchett 提出的“可靠事件队列”的具体做法，目标仍然是交易过程中正确修改账号、仓库和商家服务中的数据，图 3-7 列出了修改过程的时序图。

![6bc0b20e37e1dce995cc8977484b924a.png](../_resources/6bc0b20e37e1dce995cc8977484b924a.png)

1. 最终用户向 Fenix's Bookstore 发送交易请求：购买一本价值 100 元的《深入理解 Java 虚拟机》。
2. Fenix's Bookstore 首先应对用户账号扣款、商家账号收款、库存商品出库这三个操作有一个出错概率的先验评估，根据==出错概率的大小来安排它们的操作顺序==，这种评估一般直接体现在程序代码中，有一些大型系统也可能会实现动态排序。
   譬如，根据统计，最有可能的出现的交易异常是用户购买了商品，但是不同意扣款，或者账号余额不足；其次是仓库发现商品库存不够，无法发货；
   风险最低的是收款，如果到了商家收款环节，一般就不会出什么意外了。那顺序就应该安排成最==容易出错的最先进行==，即：账号扣款 → 仓库出库 → 商家收款。
3. 账号服务进行扣款业务，如扣款成功，则在自己的数据库建立一张消息表，里面存入一条消息：“事务 ID：某 UUID，扣款：100 元（状态：已完成），仓库出库《深入理解 Java 虚拟机》：1 本（状态：进行中），某商家收款：100 元（状态：进行中）”，注意，这个步骤中“扣款业务”和“写入消息”是使用同一个本地事务写入账号服务自己的数据库的。
4. 在系统中建立一个==消息服务==，定时==轮询消息表==，将状态是“进行中”的消息同时发送到库存和商家服务节点中去（也可以串行地发，即一个成功后再发送另一个，但在我们讨论的场景中没必要）。这时候可能产生以下几种情况。
   1. 商家和仓库服务都==成功完成==了收款和出库工作，向用户账号服务器返回执行结果，用户账号服务把消息状态从“进行中”更新为“已完成”。整个事务宣告顺利结束，达到最终一致性的状态。
   2. 商家或仓库服务中至少一个因网络原因，未能收到来自用户账号服务的消息。此时，由于用户账号服务器中存储的消息状态一直处于“进行中”，所以消息服务器将在每次轮询的时候持续地向未响应的服务重复发送消息。这个步骤的可重复性决定了所有被消息服务器发送的消息都必须具备==幂等性==，通常的设计是让消息带上一个唯一的事务 ID，以保证一个事务中的出库、收款动作会且只会被处理一次。
   3. 商家或仓库服务有某个或全部无法完成工作，譬如仓库发现《深入理解 Java 虚拟机》==没有库存==了，此时，仍然是持续自动重发消息，直至操作成功（譬如补充了新库存），或者被人工介入为止。由此可见，可靠事件队列只要第一步业务完成了，后续就没有失败回滚的概念，只许成功，不许失败。
   4. 商家和仓库服务成功完成了收款和出库工作，但回复的应答消息因网络原因丢失，此时，用户账号服务仍会重新发出下一条消息，但因操作具备幂等性，所以不会导致重复出库和收款，只会导致商家、仓库服务器重新发送一条应答消息，此过程重复直至双方网络通信恢复正常。
   5. 也有一些支持分布式事务的==消息框架，如 RocketMQ==，原生就支持分布式事务操作，这时候上述情况 2、4 也可以交由消息框架来保障。


以上这种靠着持续重试来保证可靠性的解决方案谈不上是 Dan Pritchett 的首创或者独创，它在计算机的其他领域中已被频繁使用，也有了专门的名字叫作“==最大努力交付==”（Best-Effort Delivery），
譬如 TCP 协议中未收到 ACK 应答自动重新发包的可靠性保障就属于最大努力交付。
而可靠事件队列还有一种更普通的形式，被称为“最大努力一次提交”（Best-Effort 1PC），指的就是将最有可能出错的业务以本地事务的方式完成后，采用不断重试的方式（不限于消息系统）来促使同一个分布式事务中的其他关联业务全部完成。


#### TCC 事务 (强隔离性)

TCC 是另一种常见的分布式事务机制，它是“Try-Confirm-Cancel”三个单词的缩写

前面介绍的可靠消息队列虽然能保证最终的结果是相对可靠的，过程也足够简单（相对于 TCC 来说），但整个过程完全==没有任何隔离性==可言

缺乏隔离性会带来的一个显而易见的问题便是“==超售==”：完全有可能两个客户在短时间内都成功购买了同一件商品，而且他们各自购买的数量都不超过目前的库存，但他们购买的数量之和却超过了库存。
如果这件事情处于刚性事务，且隔离级别足够的情况下是可以完全避免的，譬如，以上场景就需要“可重复读”（Repeatable Read）的隔离级别，以保证后面提交的事务会因为无法获得锁而导致失败，但用可靠消息队列就无法保证这一点

如果业务需要隔离，那架构师通常就应该重点考虑 TCC 方案，该方案天生适合用于==需要强隔离性的分布式事务==中。

在具体实现上，TCC 较为==烦琐==，它是一种==业务侵入式较强==的事务方案，==要求业务处理过程必须拆分为“预留业务资源”和“确认/释放消费资源”两个子过程==。如同 TCC 的名字所示，它分为以下三个阶段。

- Try：
  尝试执行阶段，完成所有业务==可执行性的检查==（保障==一致性==），并且预留好全部需用到的业务资源（保障隔离性）。
- Confirm：
  确认执行阶段，不进行任何业务检查，直接使用 Try 阶段准备的资源来完成业务处理。Confirm 阶段==可能会重复==执行，因此本阶段所执行的操作需要具备==幂等性==。
- Cancel：
  取消执行阶段，释放 Try 阶段预留的业务资源。Cancel 阶段==可能会重复==执行，也需要满足==幂等==性。

![c4d818c33e44516035956acfe33e9c60.png](../_resources/c4d818c33e44516035956acfe33e9c60.png)


1. 最终用户向 Fenix's Bookstore 发送交易请求：购买一本价值 100 元的《深入理解 Java 虚拟机》。
2. 创建事务，生成==事务 ID==，记录在活动日志中，进入 ==Try 阶段==：
    - 用户服务：检查业务可行性，可行的话，将该用户的 100 元设置为“==冻结==”状态，通知下一步进入 ==Confirm== 阶段；不可行的话，通知下一步进入 ==Cancel== 阶段。
    - 仓库服务：检查业务可行性，可行的话，将该仓库的 1 本《深入理解 Java 虚拟机》设置为“==冻结==”状态，通知下一步进入 ==Confirm== 阶段；不可行的话，通知下一步进入 ==Cancel== 阶段。
    - 商家服务：检查业务可行性，不需要冻结资源。
3. 如果第 2 步所有业务均反馈业务可行，将活动日志中的状态记录为 Confirm，==进入 Confirm== 阶段：
    - 用户服务：完成业务操作（扣减那被冻结的 100 元）。
    - 仓库服务：完成业务操作（标记那 1 本冻结的书为出库状态，扣减相应库存）。
    - 商家服务：完成业务操作（收款 100 元）。
4. 第 3 步如果全部完成，事务宣告==正常结束==，如果第 3 步中任何一方出现异常，不论是业务异常或者网络异常，都将根据活动日志中的记录，==重复执行==该服务的 Confirm 操作，即进行最大努力交付。
5. 如果==第 2 步==有任意一方反馈业务不可行，或任意一方超时，将活动日志的状态记录为 Cancel，进入 ==Cancel 阶段==：
    - 用户服务：取消业务操作（释放被冻结的 100 元）。
    - 仓库服务：取消业务操作（释放被冻结的 1 本书）。
    - 商家服务：取消业务操作（大哭一场后安慰商家谋生不易）。
6. 第 5 步如果全部完成，事务宣告以失败回滚结束，如果第 5 步中任何一方出现异常，不论是业务异常或者网络异常，都将根据活动日志中的记录，重复执行该服务的 Cancel 操作，即进行最大努力交付。


由上述操作过程可见，TCC 其实有点类似 2PC 的准备阶段和提交阶段，但 TCC 是位于用户代码层面，而不是在基础设施层面，这为它的实现带来了==较高的灵活性==，可以根据需要设计资源锁定的粒度。
TCC 在业务执行时只操作预留资源，几乎不会涉及锁和资源的争用，具有==很高的性能潜力==。
但是 TCC 并非纯粹只有好处，它也带来了==更高的开发成本和业务侵入性==，意味着有更高的开发成本和更换事务实现方案的替换成本，
所以，通常我们并==不会完全靠裸编码来实现 TCC==，而是基于某些==分布式事务中间件==（譬如阿里开源的Seata ）去完成，尽量减轻一些编码工作量




#### SAGA 事务

TCC 事务具有==较强的隔离性==，避免了“超售”的问题，而且其==性能==一般来说是本篇提及的几种柔性事务模式中==最高==的，但它仍不能满足所有的场景。

TCC 的最==主要限制==是它的==业务侵入性很强==，这里并不是重复上一节提到的它需要==开发编码==配合所带来的工作量，而更多的是指它所要求的==技术可控性上的约束==。

譬如，把我们的场景事例修改如下：由于中国网络支付日益盛行，现在用户和商家在书店系统中可以选择不再开设充值账号，至少不会强求一定要先从银行充值到系统中才能进行消费，允许直接在购物时通过 U 盾或扫码支付，在银行账号中划转货款。
这个需求完全符合国内网络支付盛行的现状，却给系统的事务设计增加了额外的限制：如果用户、商家的账号余额由银行管理的话，其==操作权限和数据结构就不可能再随心所欲的地自行定义==，通常也就==无法完成冻结款项、解冻、扣减这样的操作==，因为银行一般不会配合你的操作。

所以 TCC 中的第一步 ==Try 阶段往往无法施行==。我们只能考虑采用另外一种柔性事务方案：SAGA 事务。SAGA 在英文中是“长篇故事、长篇记叙、一长串事件”的意思。


大致思路是把一个大事务分解为可以交错运行的一系列子事务集合。
原本 SAGA 的目的是避免大事务长时间锁定数据库的资源，后来才发展成将一个分布式环境中的大事务分解为一系列本地事务的设计模式。

SAGA 由两部分操作组成。
- 大事务拆分若干个小事务，将==整个分布式事务 T 分解为 n 个子事务==，命名为 T1，T2，…，Ti，…，Tn。每个==子事务==都应该是或者能被视为是==原子==行为。如果分布式事务能够正常提交，其对数据的影响（最终一致性）应与连续按顺序成功提交 Ti等价。
- 为每一个==子事务==设计对应的==补偿==动作，命名为 C1，C2，…，Ci，…，Cn。Ti与 Ci必须满足以下条件：
  - Ti与 Ci都具备==幂等==性。
  - Ti与 Ci满足==交换==律（Commutative），即先执行 Ti还是先执行 Ci，其效果都是一样的。
  - ==Ci必须能成功提交==，即不考虑 Ci本身提交失败被回滚的情形，如出现就必须==持续重试==直至成功，或者要==人工介入==。

如果 T1到 Tn均成功提交，那事务顺利完成，否则，要采取以下两种==恢复==策略之一：
- 正向恢复（Forward Recovery）：
  如果 Ti事务提交失败，则==一直对 Ti进行重试==，直至成功为止（最大努力交付）。
  这种恢复方式==不需要补偿==，==适用于事务最终都要成功的场景==，譬如在别人的银行账号中扣了款，就一定要给别人发货。正向恢复的执行模式为：T1，T2，…，Ti（失败），Ti（重试）…，Ti+1，…，Tn。
- 反向恢复（Backward Recovery）：
  如果 Ti事务提交失败，则==一直执行 Ci对 Ti进行补偿==，直至成功为止（最大努力交付）。这里==要求 Ci必须（在持续重试后）执行成功==。反向恢复的执行模式为：T1，T2，…，Ti（失败），Ci（补偿），…，C2，C1。


与 TCC 相比，SAGA 不需要为资源设计冻结状态和撤销冻结的操作，==补偿操作往往要比冻结操作容易实现得多==。
譬如，前面提到的账号余额直接在银行维护的场景，从银行划转货款到 Fenix's Bookstore 系统中，这步是经由用户支付操作（扫码或 U 盾）来促使银行提供服务；如果后续业务操作失败，尽管我们无法要求银行撤销掉之前的用户转账操作，但是由 Fenix's Bookstore 系统将货款转回到用户账上作为补偿措施却是完全可行的。

SAGA 必须保证所有子事务都得以提交或者补偿，但 SAGA 系统本身也有可能会崩溃，所以它必须设计成与数据库类似的==日志机制==（被称为 SAGA Log）以==保证系统恢复后可以追踪到子事务的执行情况==，譬如执行至哪一步或者补偿至哪一步了。
另外，尽管补偿操作通常比冻结/撤销容易实现，但==保证正向、反向恢复过程的能严谨地进行也需要花费不少的工夫==，譬如通过==服务编排、可靠事件队列==等方式完成，
所以，SAGA 事务通常也不会直接靠裸编码来实现，一般也是在事务中间件的基础上完成，前面提到的 Seata 就同样支持 SAGA 事务模式。


基于数据补偿来代替回滚的思路，还可以应用在其他事务方案上，这些方案笔者就不开独立小节，放到这里一起来解释。举个具体例子，譬如阿里的 GTS（Global Transaction Service，Seata 由 GTS 开源而来）所提出的“AT 事务模式 ”就是这样的一种应用。

从整体上看是 AT 事务是参照了 XA 两段提交协议实现的，但针对 XA 2PC 的缺陷，即在准备阶段必须等待所有数据源都返回成功后，协调者才能统一发出 Commit 命令而导致的木桶效应（所有涉及的锁和资源都需要等待到最慢的事务完成后才能统一释放），设计了针对性的解决方案。
大致的==做法==是在业务数据提交时==自动拦截所有 SQL==，将 SQL 对数据修改前、修改后的结果分别保存快照，生成行锁，通过本地事务一起提交到操作的数据源中，相当于==自动记录了重做和回滚日志==。
如果分布式事务成功提交，那后续清理每个数据源中对应的日志数据即可；
如果分布式事务需要回滚，就根据日志数据自动产生用于补偿的“==逆向 SQL==”。基于这种补偿方式，分布式事务中所涉及的每一个数据源都可以单独提交，然后立刻释放锁和资源。
这种异步提交的模式，相比起 2PC 极大地提升了系统的==吞吐量==水平。而代价就是==大幅度地牺牲了隔离性==，甚至==直接影响到了原子性==。因为在缺乏隔离性的前提下，以补偿代替回滚并不一定是总能成功的。
譬如，当本地事务提交之后、分布式事务完成之前，该数据被补偿之前又被其他操作修改过，即出现了脏写（Dirty Write），这时候一旦出现分布式事务需要回滚，就不可能再通过自动的逆向 SQL 来实现补偿，只能由人工介入处理了。

通常来说，==脏写是一定要避免的==，所有传统关系数据库在最低的隔离级别上都仍然要加锁以避免脏写，因为脏写情况一旦发生，人工其实也很难进行有效处理。所以 GTS 增加了一个“==全局锁==”（Global Lock）的机制来实现写隔离，要求本地事务提交之前，一定要先拿到针对修改记录的全局锁后才允许提交，没有获得全局锁之前就必须一直等待，这种设计以牺牲一定性能为代价，避免了有两个分布式事务中包含的本地事务修改了同一个数据，从而避免脏写。在读隔离方面，AT 事务默认的隔离级别是读未提交（Read Uncommitted），这意味着可能产生脏读（Dirty Read）。也可以采用全局锁的方案解决读隔离问题，但直接阻塞读取的话，代价就非常大了，一般不会这样做。
由此可见，分布式事务中没有一揽子包治百病的解决办法，因地制宜地选用合适的事务处理方案才是唯一有效的做法。




## 透明多级分流系统

奥卡姆剃刀原则
Entities should not be multiplied without necessity
如无必要，勿增实体

现代的企业级或互联网系统，“分流”是必须要考虑的设计，分流所使用手段数量之多、涉及场景之广，可能连它的开发者本身都未必能全部意识到。
这听起来似乎并不合理，但笔者认为这恰好是优秀架构设计的一种体现，“分布广阔”源于“多级”，“意识不到”谓之“透明”，也即本章我们要讨论的主题“透明多级分流系统”（Transparent Multilevel Diversion System， “透明多级分流系统”这个词是笔者自己创造的，业内通常只提“Transparent Multilevel Cache”，但我们这里谈的并不仅仅涉及到缓存）的来由。

在用户使用信息系统的过程中，
请求从浏览器出发，
在域名服务器的指引下找到系统的入口，
经过网关、负载均衡器、缓存、服务集群等一系列设施，
最后触及到末端存储于数据库服务器中的信息，
然后逐级返回到用户的浏览器之中。

这其中要经过很多技术部件。作为系统的设计者，我们应该意识到不同的设施、部件在系统中有各自不同的价值

- 有一些部件位于客户端或网络的==边缘==，能够==迅速响应用户的请求==，避免给后方的 I/O 与 CPU 带来压力，典型如==本地缓存、内容分发网络、反向代理==等。
- 有一些部件的处理能力能够==线性拓展，易于伸缩==，可以使用较小的代价堆叠机器来获得与用户数量相匹配的并发性能，==应尽量作为业务逻辑的主要载体==，典型如集群中能够==自动扩缩的服务节点==。
- 有一些部件稳定服务对系统运行有==全局性的影响==，要时刻保持着容错备份，维护着高可用性，典型如==服务注册中心、配置中心==。
- 有一些设施是==天生的单点部件==，只能依靠升级机器本身的网络、存储和运算性能来提升处理能力，如位于==系统入口的路由、网关或者负载均衡器==（它们都可以做集群，但一次网络请求中无可避免至少有一个是单点的部件）、位于请求调用链末端的==传统关系数据库==等，都是典型的容易形成单点部件。

对系统进行流量规划时，我们应该充分理解这些部件的价值差异，有两条简单、普适的原则能指导我们进行设计：
- 第一条原则是==尽可能减少单点部件==，
  如果某些单点是无可避免的，则应尽最大限度==减少==到达单点部件的==流量==。
  在系统中往往会有多个部件能够处理、响应用户请求，譬如要获取一张存储在数据库的用户头像图片，浏览器缓存、内容分发网络、反向代理、Web 服务器、文件服务器、数据库都可能提供这张图片。==恰如其分地引导请求分流至最合适的组件中==，==避免绝大多数流量汇集到单点部件（如数据库）==，同时依然能够在绝大多数时候保证处理结果的准确性，使单点系统在出现故障时自动而迅速地实施补救措施，这便是系统架构中多级分流的意义。
- 另一条更关键的原则是==奥卡姆剃刀==原则。
  作为一名架构设计者，你应对多级分流的手段有全面的理解与充分的准备，同时清晰地意识到这些==设施并不是越多越好==。在实际构建系统时，你应当在有==明确需求、真正必要==的时候再去考虑部署它们。
  不是每一个系统都要追求高并发、高可用的，根据系统的用户量、峰值流量和团队本身的技术与运维能力来考虑如何部署这些设施才是合理的做法，==在能满足需求的前提下，最简单的系统就是最好的系统==。



### 客户端缓存

http://icyfenix.cn/architect-perspective/general-architecture/diversion-system/client-cache.html


在 HTTP 协议设计之初，便确定了服务端与客户端之间“无状态”（Stateless）的交互原则，即要求每次请求是独立的，每次请求无法感知也不能依赖另一个请求的存在，这既简化了 HTTP 服务器的设计，也为其水平扩展能力留下了广袤的空间
但无状态并不只有好的一面，由于每次请求都是独立的，服务端不保存此前请求的状态和资源，所以也不可避免地导致其携带有重复的数据，造成网络性能降低。

HTTP 协议对此问题的解决方案便是客户端缓存，在 HTTP 从 1.0 到 1.1，再到 2.0 版本的每次演进中，逐步形成了现在被称为“==状态缓存”、“强制缓存”（许多资料中简称为“强缓存”）和“协商缓存”的== HTTP 缓存机制。


状态缓存是指不经过服务器，客户端直接根据缓存信息对目标网站的状态判断，
以前==只有 301==/Moved Permanently（永久重定向）这一种；后来在RFC6797 中增加了HSTS（HTTP Strict Transport Security）机制，用于避免依赖 301/302 跳转 HTTPS 时可能产生的降级中间人劫持（详细可见安全架构中的“传输”），这也属于另一种状态缓存。
由于状态缓存所涉内容只有这么一点，后续我们就只聚焦讨论强制缓存与协商缓存两种机制。


#### 强制缓存

HTTP 的强制缓存对一致性处理的策略就如它的名字一样，十分直接：
假设在某个时点到来以前，譬如收到响应后的 10 分钟内，资源的内容和状态一定不会被改变，因此客户端可以无须经过任何请求，在该时点前一直持有和使用该资源的本地缓存副本。

根据约定，强制缓存在浏览器的地址输入、页面链接跳转、新开窗口、前进和后退中均可生效，
但在用户主动刷新页面时应当自动失效。HTTP 协议中设有以下两类 Header 实现强制缓存。

- Expires：
  Expires 是 HTTP/1.0 协议中开始提供的 Header，后面跟随一个==截至时间==参数。
  当服务器返回某个资源时带有该 Header 的话，意味着服务器承诺截止时间之前资源不会发生变动，浏览器可直接缓存该数据，不再重新发请求，示例
  ```http
  HTTP/1.1 200 OK
  Expires: Wed, 8 Apr 2020 07:28:00 GMT
  ```
  Expires 是 HTTP 协议最初版本中提供的缓存机制，设计非常直观易懂，但考虑得并不够周全，它至少存在以下显而易见的问题：
  - 受限于客户端的本地时间。
    譬如，在收到响应后，客户端修改了本地时间，将时间前后调整几分钟，就可能会造成缓存提前失效或超期持有。
  - 无法处理涉及到用户身份的私有资源，
    譬如，某些资源被登录用户缓存在自己的浏览器上是合理的，但如果被代理服务器或者内容分发网络缓存起来，则可能被其他未认证的用户所获取。
  - 无法描述“不缓存”的语义。
    譬如，浏览器为了提高性能，往往会自动在当次会话中缓存某些 MIME 类型的资源，在 HTTP/1.0 的服务器中就缺乏手段强制浏览器不允许缓存某个资源。以前为了实现这类功能，通常不得不使用脚本，或者手工在资源后面增加时间戳（譬如如“xx.js?t=1586359920”、“xx.jpg?t=1586359350”）来保证每次资源都会重新获取。
    关于“不缓存”的语义，在 HTTP/1.0 中其实预留了“Pragma: no-cache”来表达，但 Pragma 参数在 HTTP/1.0 中并没有确切描述其具体行为，随后就被 HTTP/1.1 中出现过的 Cache-Control 所替代，现在，尽管主流浏览器通常都会支持 Pragma，但行为仍然是不确定的，实际并没有什么使用价值。

- Cache-Control：
  Cache-Control 是 HTTP/1.1 协议中定义的强制缓存 Header，它的语义比起 Expires 来说就丰富了很多，如果 Cache-Control 和 Expires 同时存在，并且语义存在冲突（譬如 Expires 与 max-age / s-maxage 冲突）的话，规定必须以 Cache-Control 为准。Cache-Control 的使用示例如下：
  ```http
  HTTP/1.1 200 OK
  Cache-Control: max-age=600
  ```
  Cache-Control 在客户端的请求 Header 或服务器的响应 Header 中都可以存在，它定义了一系列的参数，且允许自行扩展（即不在标准 RFC 协议中，由浏览器自行支持的参数），其标准的参数主要包括有：
  - max-age和s-maxage：
    max-age 后面跟随一个以==秒==为单位的数字，表明相对于请求时间（在 Date Header 中会注明请求时间）多少秒以内缓存是有效的，资源不需要重新从服务器中获取。相对时间避免了 Expires 中采用的绝对时间可能受客户端时钟影响的问题。s-maxage 中的“s”是“==Share==”的缩写，意味“共享缓存”的有效时间，即允许被 ==CDN、代理==等持有的缓存有效时间，用于提示 CDN 这类服务器应在何时让缓存失效。
  - public和private：
    指明是否涉及到用户身份的私有资源，如果是 public，则可以被==代理、CDN== 等缓存，如果是 private，则==只能由用户的客户端==进行私有缓存。
  - no-cache和no-store：
    no-cache 指明该资源==不应该被缓存==，哪怕是同一个会话中对同一个 URL 地址的请求，也必须从服务端获取，令==强制缓存完全失效==，但此时下一节中的==协商缓存机制依然是生效的==；
    no-store 不强制会话中相同 URL 资源的重复获取，但==禁止浏览器、CDN 等以任何形式保存该资源==。
  - no-transform：
    ==禁止资源被任何形式地修改==。譬如，某些 CDN、透明代理支持==自动 GZip 压缩==图片或文本，以提升网络性能，而 no-transform 就禁止了这样的行为，它要求 ==Content-Encoding、Content-Range、Content-Type== 均不允许进行任何形式的修改。
  - min-fresh和only-if-cached：
    这两个参数是仅用于==客户端的请求== Header。
    min-fresh 后续跟随一个以秒为单位的数字，用于==建议==服务器能返回一个==不少于该时间的缓存资源==（即包含 max-age 且不少于 min-fresh 的数字）。
    only-if-cached 表示客户端要求==不必给它发送资源的具体内容==，此时客户端就==仅能使用事先缓存的资源来进行响应==，若==缓存不能命中==，就直接返回 ==503==/Service Unavailable 错误。
  - must-revalidate和proxy-revalidate：
    must-revalidate 表示在资源过期后，一定需要从服务器中进行获取，即超过了 max-age 的时间后，就等同于 no-cache 的行为，
    proxy-revalidate 用于提示==代理、CDN== 等设备资源过期后的缓存行为，除对象不同外，语义与 must-revalidate 完全一致。


#### 协商缓存

==强制缓存是基于时效性的==，但无论是人还是服务器，其实多数情况下都并没有什么把握去承诺某项资源多久不会发生变化。

另外一种==基于变化检测的缓存机制==，在一致性上会有比强制缓存==更好的表现==，但需要一次变化检测的交互开销，==性能上就会略差一些==，这种基于检测的缓存机制，通常被称为“==协商缓存==”。

另外，应注意在 HTTP 中协商缓存与强制缓存并没有互斥性，这==两套机制是并行==工作的，
譬如，当强制缓存存在时，直接从强制缓存中返回资源，无须进行变动检查；而当强制缓存超过时效，或者被禁止（no-cache / must-revalidate），协商缓存仍可以正常地工作。
协商缓存有==两种变动检查机制==，分别是根据==资源的修改时间==进行检查，以及根据==资源唯一标识==是否发生变化来进行检查，它们都是靠==一组成对出现的请求、响应 Header== 来实现的：
- Last-Modified 和 If-Modified-Since：
  Last-Modified 是==服务器的==响应 Header，用于告诉客户端这个资源的最后修改时间。对于带有这个 Header 的资源，当==客户端==需要再次请求时，会通过 If-Modified-Since 把之前收到的资源最后修改时间发送回服务端。
。。Last-Modified 是服务器的 响应 的header
。。If-Modified-Since 是客户端的 请求 的header

  如果此时服务端发现资源在该时间后没有被修改过，就只要返回一个 304/Not Modified 的响应即可，无须附带消息体，达到节省流量的目的
  ```http
  HTTP/1.1 304 Not Modified
  Cache-Control: public, max-age=600
  Last-Modified: Wed, 8 Apr 2020 15:31:30 GMT
  ```
  如果此时服务端发现资源在该时间之后有变动，就会返回 200/OK 的完整响应，在消息体中包含最新的资源
  ```http
  HTTP/1.1 200 OK
  Cache-Control: public, max-age=600
  Last-Modified: Wed, 8 Apr 2020 15:31:30 GMT

  Content
  ```

- Etag 和 If-None-Match：
  Etag 是服务器的响应 Header，用于告诉客户端这个==资源的唯一标识==。HTTP 服务器可以根据自己的意愿来选择如何生成这个标识，譬如 Apache 服务器的 Etag 值默认是对文件的索引节点（INode），大小和最后修改时间进行哈希计算后得到的。
  对于带有这个 Header 的资源，当客户端需要再次请求时，会通过 If-None-Match 把之前收到的资源唯一标识发送回服务端。

  如果此时服务端计算后发现资源的唯一标识与上传回来的一致，说明资源没有被修改过，就只要返回一个 304/Not Modified 的响应即可，无须附带消息体，达到节省流量的目的

  如果此时服务端发现资源的唯一标识有变动，就会返回 200/OK 的完整响应，在消息体中包含最新的资源

Etag 是 HTTP 中==一致性最强的缓存机制==，
譬如，
Last-Modified 标注的最后修改只能精确到秒级，如果某些文件在 1 秒钟以内，被修改多次的话，它将不能准确标注文件的修改时间；
又或者如果某些文件会被定期生成，可能内容并没有任何变化，但 Last-Modified 却改变了，导致文件无法有效使用缓存，
这些情况 Last-Modified 都有==可能产生资源一致性问题==，只能使用 Etag 解决。

Etag 却又是 HTTP 中==性能最差==的缓存机制，
体现在每次请求时，服务端都必须对资源进行==哈希计算==，这比起简单获取一下修改时间，开销要大了很多。
Etag 和 Last-Modified 是允许一起使用的，服务器会优==先验证 Etag==，在 Etag 一致的情况下，==再去对比 Last-Modified==，这是为了防止有一些 HTTP 服务器未将文件修改日期纳入哈希范围内。



到这里为止，HTTP 的协商缓存机制已经能很好地处理通过 URL 获取单个资源的场景，为什么要强调“==单个资源==”呢？
在 HTTP 协议的设计中，一个 URL 地址是有可能能够提供多份不同版本的资源，譬如，一段文字的==不同语言版本==，一个文件的==不同编码格式==版本，一份数据的==不同压缩方式==版本，等等。
因此针对请求的缓存机制，也必须能够提供对应的支持。为此，HTTP 协议设计了以 
Accept*（Accept、Accept-Language、Accept-Charset、Accept-Encoding）开头的一套请求 Header 和对应的以 
Content-*（Content-Language、Content-Type、Content-Encoding）开头的响应 Header，这些 Headers 被称为 HTTP 的==内容协商机制==。
与之对应的，对于一个 URL 能够获取多个资源的场景中，缓存也同样也需要有明确的标识来获知根据什么内容来对同一个 URL 返回给用户正确的资源。这个就是 Vary Header 的作用，Vary 后面应该跟随一组其他 Header 的名字，譬如：
```http
HTTP/1.1 200 OK
Vary: Accept, User-Agent
```
以上响应的含义是应该根据 MIME 类型和浏览器类型来缓存资源，获取资源时也需要根据请求 Header 中对应的字段来筛选出适合的资源版本。

根据约定，协商缓存不仅在浏览器的==地址输入、页面链接跳转、新开窗口、前进、后退==中生效，而且在用户==主动刷新页面==（F5）时也同样是==生效==的，
只有用户==强制刷新==（Ctrl+F5）或者==明确禁用缓存==（譬如在 DevTools 中设定）时才会失效，此时客户端向服务端发出的请求会自动带有“Cache-Control: no-cache”。



### 域名解析

域名缓存（DNS Lookup）
DNS 也许是全世界最大、使用最频繁的信息查询系统，如果没有适当的分流机制，DNS 将会成为整个网络的瓶颈。

世界根域名服务器的 ZONE 文件只有 2MB 大小

无论是使用浏览器抑或是在程序代码中访问某个网址域名，
譬如以www.icyfenix.com.cn为例，如果没有缓存的话，都会先经过 DNS 服务器的解析翻译，找到域名对应的 IP 地址才能开始通信，这项操作是操作系统自动完成的，一般不需要用户程序的介入。
不过，DNS 服务器并不是一次性地将“www.icyfenix.com.cn”直接解析成 IP 地址，需要经历一个递归的过程。首先 DNS 会将域名还原为“www.icyfenix.com.cn.”，注意==最后多了一个点==“.”，它是“.root”的含义。早期的域名必须带有这个点才能被 DNS 正确解析，如今几乎所有的操作系统、DNS 服务器都可以自动补上结尾的点号，然后开始如下解析步骤：

1. 客户端先检查本地的 DNS 缓存，
   查看是否存在并且是存活着的该域名的地址记录。DNS 是==以存活时间（Time to Live，TTL）来衡量缓存的有效情况==的，所以，如果某个域名改变了 IP 地址，DNS 服务器并没有任何机制去通知缓存了该地址的机器去更新或者失效掉缓存，只能依靠 TTL 超期后的重新获取来保证一致性。后续==每一级 DNS 查询的过程都会有类似的缓存查询==操作，再遇到时笔者就不重复叙述了。
2. 客户端将地址发送给本机操作系统中配置的本地 DNS（Local DNS），
   这个本地 DNS 服务器可以由用户手工设置，也可以在 DHCP 分配时或者在拨号时从 PPP 服务器中自动获取到。
3. 本地 DNS 收到查询请求后，会按照“是否有www.icyfenix.com.cn的权威服务器”→“是否有icyfenix.com.cn的权威服务器”→“是否有com.cn的权威服务器”→“是否有cn的权威服务器”的顺序，依次查询自己的地址记录，如果都没有查询到，就会一直找到最后点号代表的根域名服务器为止。这个步骤里涉及了两个重要名词：
  -  权威域名服务器（Authoritative DNS）：
    是指负责翻译特定域名的 DNS 服务器，“权威”意味着这个域名应该翻译出怎样的结果是由它来决定的。DNS 翻译域名时无需像查电话本一样刻板地一对一翻译，根据来访机器、网络链路、服务内容等各种信息，可以玩出很多花样，权威 DNS 的灵活应用，在后面的内容分发网络、服务发现等章节都还会有所涉及。
  -  根域名服务器（Root DNS）
    是指固定的、无需查询的顶级域名（Top-Level Domain）服务器，可以默认为它们已内置在操作系统代码之中。全世界一共有 13 组根域名服务器（注意并不是 13 台，每一组根域名都通过任播的方式建立了一大群镜像，根据维基百科的数据，迄今已经超过 1000 台根域名服务器的镜像了）。13 这个数字是由于 DNS 主要采用 UDP 传输协议（在需要稳定性保证的时候也可以采用 TCP）来进行数据交换，未分片的 ==UDP 数据包==在 IPv4 下最大有效值为 512 字节，最多可以存放 ==13 组地址记录==，由此而来的限制。
4. 现在假设本地 DNS 是全新的，
   上面不存在任何域名的权威服务器记录，所以当 DNS 查询请求按步骤 3 的顺序一直查到根域名服务器之后，它将会得到“cn的权威服务器”的地址记录，然后通过“cn的权威服务器”，得到“com.cn的权威服务器”的地址记录，以此类推，最后找到能够解释www.icyfenix.com.cn的权威服务器地址。
5. 通过“www.icyfenix.com.cn的权威服务器”，
   查询www.icyfenix.com.cn的地址记录，地址记录并不一定就是指 IP 地址，在 RFC 规范中有定义的地址记录类型已经多达数十种，譬如 IPv4 下的 IP 地址为 A 记录，IPv6 下的 AAAA 记录、主机别名 CNAME 记录，等等。

每种记录类型中还可以包括多条记录，以一个域名下配置多条不同的 A 记录为例，此时权威服务器可以根据自己的==策略==来进行选择，典型的应用是==智能线路==：根据访问者所处的不同地区（譬如华北、华南、东北）、不同服务商（譬如电信、联通、移动）等因素来确定返回==最合适==的 A 记录，将访问者路由到最合适的数据中心，达到==智能加速==的目的。


DNS 系统多级分流的设计使得 DNS 系统能够经受住全球网络流量不间断的冲击，但也并非全无缺点。
典型的问题是==响应速度==，当极端情况（各级服务器均无缓存）下的域名解析可能导致每个域名都必须递归多次才能查询到结果，显著影响传输的响应速度

专门有一种被称为“==DNS 预取== ”（DNS Prefetching）的==前端优化==手段用来避免这类问题：如果网站后续要使用来自于其他域的资源，那就在网页加载时生成一个 link 请求，促使浏览器提前对该域名进行预解释，譬如下面代码所示：
`<link rel="dns-prefetch" href="//domain.not-icyfenx.cn">`

另一种可能更严重的缺陷是 DNS 的分级查询意味着每一级都有可能受到==中间人攻击==的威胁，产生被劫持的风险。要攻陷位于递归链条顶层的（譬如根域名服务器，cn 权威服务器）服务器和链路是非常困难的，它们都有很专业的安全防护措施。
但很多位于递归链底层或者来自本地运营商的 Local DNS 服务器的安全防护则相对松懈，甚至不少地区的运营商自己就会主动进行劫持，专门返回一个错的 IP，通过在这个 IP 上代理用户请求，以便给特定类型的资源（主要是 HTML）注入广告，以此牟利。

最近几年出现了另一种新的 DNS 工作模式：HTTPDNS （也称为 DNS over HTTPS，DoH）。
它将原本的 DNS 解析服务开放为一个基于 HTTPS 协议的查询服务，替代基于 UDP 传输协议的 DNS 域名解析，通过程序代替操作系统直接从权威 DNS 或者可靠的 Local DNS 获取解析数据，从而绕过传统 Local DNS。
这种做法的好处是完全免去了“中间商赚差价”的环节，不再惧怕底层的域名劫持，能够有效避免 Local DNS 不可靠导致的域名生效缓慢、来源 IP 不准确、产生的智能线路切换错误等问题。


### 传输链路
传输链路优化（Transmission Optimization）
今天的传输链路优化原则，在若干年后的未来再回头看它们时，其中多数已经成了奇技淫巧，有些甚至成了反模式

不少人的第一直觉会认为传输链路是开发者完全不可控的因素，网络路由跳点的数量、运营商铺设线路的质量决定了线路带宽的大小、速率的高低。
然而事实并非如此，程序发出的==请求能否与应用层、传输层协议提倡的方式相匹配==，对传输的效率也会有极大影响。
最容易体现这点的是那些前端网页的优化技巧，只要简单搜索一下，就能找到很多以==优化链路传输为目的的前端设计==原则，
譬如经典的雅虎 YSlow-23 条规则 中与传输相关的内容如下。
- Minimize HTTP Requests。
  ==减少请求数量==：请求每次都需要建立通信链路进行数据传输，这些开销很昂贵，减少请求的数量可有效的提高访问性能，对于前端开发者，可能用来减少请求数量的手段包括： 
  - 雪碧图（CSS Sprites）
  - CSS、JS 文件合并/内联（Concatenation / Inline）
  - 分段文档（Multipart Document）
  - 媒体（图片、音频）内联（Data Base64 URI）
  - 合并 Ajax 请求（Batch Ajax Request）

- Split Components Across Domains。
  ==扩大并发请求数==：现代浏览器（Chrome、Firefox）一般对==每个域名支持 6 个==（IE 为 8-13 个）并发请求，如果希望更快地加载大量图片或其他资源，需要进行==域名分片==（Domain Sharding），将图片同步到不同主机或者同一个主机的不同域名上。

- GZip Components。
  启用==压缩传输==：启用压缩能够大幅度减少需要在网络上传输内容的大小，节省网络流量。

- Avoid Redirects。
  ==避免页面重定向==：当页面发生了重定向，就会延迟整个文档的传输。在 HTML 文档到达之前，页面中不会呈现任何东西，降低了用户体验。

- Put Stylesheets at the Top，Put Scripts at the Bottom。
  按重要性调节==资源优先级==：将==重要的、马上就要使用的==、对客户端展示影响大的资源，放在 HTML 的==头部==，以便优先下载。

这些原则在今天暂时仍算得上有一定价值，但在若干年后再回头看它们，大概率其中多数已经成了奇技淫巧，有些甚至成了反模式。
导致这种变化的原因是 HTTP 协议还在持续发展，从 20 世纪 90 年代的 HTTP/1.0 和 HTTP/1.1，到 2015 年发布的 HTTP/2，再到 2019 年的 HTTP/3，由于 HTTP 协议本身的变化，使得“适合 HTTP 传输的请求”的特征也在==不断变化==。


#### 连接数优化

我们知道 HTTP（特指 HTTP/3 以前）是以 TCP 为传输层的应用层协议，
但 HTTP over TCP 这种搭配只能说是 TCP 在当今网络中统治性地位所造就的结果，而不能说它们两者配合工作就是合适的。
回想一下你上网平均每个页面停留的时间，以及每个页面中包含的资源（HTML、JS、CSS、图片等）数量，可以总结出 ==HTTP 传输对象的主要特征是数量多、时间短、资源小、切换快==。
另一方面，TCP 协议要求必须在==三次握手== 完成之后才能开始数据传输，这是一个可能高达“百毫秒”为计时尺度的事件；另外，TCP 还有==慢启动== 的特性，使得刚刚建立连接时传输速度是最低的，后面再逐步加速直至稳定。
由于 TCP 协议本身是面向于==长时间、大数据传输==来设计的，在长时间尺度下，它连接建立的高昂成本才不至于成为瓶颈，它的稳定性和可靠性的优势才能展现出来。
因此，可以说 HTTP over TCP 这种搭配在目标特征上确实是有矛盾的，以至于 HTTP/1.x 时代，大量短而小的 TCP 连接导致了网络性能的瓶颈。
为了缓解 HTTP 与 TCP 之间的矛盾，聪明的程序员们一面致力于减少发出的请求数量，另外一方面也致力于增加客户端到服务端的连接数量，这就是上面 Yslow 规则中“Minimize HTTP Requests”与“Split Components Across Domains”两条优化措施的根本依据所在。

。。http3 是 udp

通过前端开发者的各种 Tricks，的确能够减少消耗 TCP 连接数量，这是有数据统计作为支撑的。
HTTP Archive 对最近五年来数百万个 URL 地址采样得出的结论：页面平均请求没有改变的情况下（桌面端下降 3.8%，移动端上升 1.4%），TCP 连接正在持续且幅度较大地下降（桌面端下降 36.4%，移动端下降 28.6%）。


但是，通过开发人员的 Tricks 来节省 TCP 连接，这样的优化措施并非只有好处，它们同时也带来了诸多不良的副作用：
- 如果你用 CSS Sprites 将多张图片合并，意味着任何场景下哪怕只用到其中一张小图，也必须完整加载整个大图片；任何场景下哪怕一张小图要进行修改，都会导致整个缓存失效，类似地，样式、脚本等其他文件的合并也会造成同样的问题。
- 如果你使用了媒体内嵌，除了要承受 Base64 编码导致传输容量膨胀 1/3 的代价外（Base64 以 8 bit 表示 6 bit 数据），也将无法有效利用缓存。
- 如果你合并了异步请求，这就会导致所有请求返回时间都受最慢的那个请求的拖累，整体响应速度下降.
- 如果你把图片放到不同子域下面，将会导致更大的 DNS 解析负担，而且浏览器对两个不同子域下的同一图片必须持有两份缓存，也使得缓存效率的下降。


HTTP 的设计者们并不是没有尝试过在协议层面去解决连接成本过高的问题，
即使是 HTTP 协议的最初版本（指 HTTP/1.0，忽略非正式的 HTTP/0.9 版本）就已经支持了==连接复用==技术（连接复用技术在 HTTP/1.0 中并不是默认开启的，是在 HTTP/1.1 中变为默认开启），即今天大家所熟知的==持久连接== （Persistent Connection），也称为连接Keep-Alive 机制 。
持久连接的原理是==让客户端对同一个域名长期持有一个或多个不会用完即断的 TCP 连接==。
典型做法是在客户端维护一个 ==FIFO 队列==，每次取完数据（如何在不断开连接下判断取完数据将会放到稍后传输压缩部分去讨论）之后一段时间内不自动断开连接，以便获取下一个资源时直接复用，避免创建 TCP 连接的成本。

但是，连接复用技术依然是不完美的，最明显的副作用是“==队首阻塞== ”（Head-of-Line Blocking）问题。
请设想以下场景：浏览器有 10 个资源需要从服务器中获取，此时它将 10 个资源放入队列，入列顺序只能按照浏览器遇见这些资源的先后顺序来决定的。但如果这 10 个资源中的第 1 个就让服务器陷入长时间运算状态会怎样呢？当它的请求被发送到服务端之后，服务端开始计算，而运算结果出来之前 TCP 连接中并没有任何数据返回，此时后面 9 个资源都必须阻塞等待。
因为服务端虽然可以并行处理另外 9 个请求（譬如第 1 个是复杂运算请求，消耗 CPU 资源，第 2 个是数据库访问，消耗数据库资源，第 3 个是访问某张图片，消耗磁盘 I/O 资源，这就很适合并行），但问题是处理结果无法及时返回客户端，服务端不能哪个请求先完成就返回哪个，更不可能将所有要返回的资源混杂到一起交叉传输，原因是只使用一个 TCP 连接来传输多个资源的话，如果顺序乱了，客户端就很难区分哪个数据包归属哪个资源了。

2014 年，IETF 发布的RFC 7230 中提出了名为“==HTTP 管道==”（HTTP Pipelining）复用技术，试图在 HTTP ==服务器==中也建立类似客户端的 FIFO 队列，让客户端一次将所有要请求的资源名单全部发给服务端，由服务端来安排返回顺序，管理传输队列。
无论队列维护在服务端还是客户端，其实都无法完全避免队首阻塞的问题，但由于服务端能够较为准确地评估资源消耗情况，进而能够更紧凑地安排资源传输，保证队列中两项工作之间尽量减少空隙，甚至做到并行化传输，从而提升链路传输的效率。
可是，由于 HTTP 管道需要多方共同支持，协调起来相当复杂，推广得并不算成功。

==队首阻塞==问题一直持续到第二代的 HTTP 协议，即 ==HTTP/2== 发布后才算是被比较完美地==解决==。
在 HTTP/1.x 中，==HTTP 请求==就是传输过程中==最小粒度的信息单位==了，所以如果将多个请求切碎，再混杂在一块传输，客户端势必难以分辨重组出有效信息。
而在 HTTP/2 中，==帧（Frame）==才是==最小粒度==的信息单位，它可以用来描述各种数据，譬如请求的 Headers、Body，或者用来做控制标识，譬如打开流、关闭流。这里说的流（Stream）是一个逻辑上的数据通道概念，==每个帧都附带一个流 ID 以标识这个帧属于哪个流==。
这样，在同一个 TCP 连接中传输的多个数据帧就可以根据==流 ID== 轻易区分出开来，在客户端毫不费力地将不同流中的数据重组出不同 HTTP 请求和响应报文来。
这项设计是 HTTP/2 的最重要的技术特征一，被称为 ==HTTP/2 多路复用== （HTTP/2 Multiplexing）技术

有了多路复用的支持，HTTP/2 就可以对==每个域名只维持一个 TCP 连接==（One Connection Per Origin）来以==任意顺序传输任意数量的资源==，既减轻了服务器的连接压力，开发者也不用去考虑域名分片这种事情来突破浏览器对每个域名最多 6 个连接数限制了。
而更重要的是，==没有了 TCP 连接数的压力，就无须刻意压缩 HTTP 请求==了，所有通过合并、内联文件（无论是图片、样式、脚本）以减少请求数的需求都不再成立，甚至反而是==徒增副作用的反模式==。

对于许多小资源，甚至可能出现 Headers 的容量比 Body 的还要大，
以至于在 HTTP/2 中必须专门考虑如何进行 ==Header 压缩==的问题。
但是，以下几个因素决定了==通过合并资源文件减少请求数==，==对节省 Headers== 成本也并==没有太大帮助==：
- Header 的传输成本在 Ajax（尤其是只返回少量数据的请求）请求中可能是比重很大的开销，但在图片、样式、脚本这些静态资源的请求中，通常并不占主要。
- 在 HTTP/2 中 Header 压缩的原理是基于==字典编码的信息复用==，简而言之是同一个连接上产生的==请求和响应越多==，==动态字典积累得越全==，头部压缩==效果也就越好==。所以 HTTP/2 是单域名单连接的机制，合并资源和域名分片反而对性能提升不利。
- 与 HTTP/1.x 相反，HTTP/2 本身反而变得==更适合传输小资源==了，譬如传输 1000 张 10K 的小图，HTTP/2 要比 HTTP/1.x 快，但传输 10 张 1000K 的大图，则应该 HTTP/1.x 会更快。这一方面是 TCP 连接数量（相当于多点下载）的影响，更多的是由于 TCP 协议可靠传输机制导致的，一个错误的 TCP 包会导致所有的流都必须等待这个包重传成功，这个问题就是 HTTP/3 要解决的目标了。因此，把小文件合并成大文件，在 HTTP/2 下是毫无好处的。


#### 传输压缩
链路优化中缓存、连接之外另一个主要话题：压缩，同时也是为了解决上一节遗留的问题：如何==不以断开 TCP 连接==为标志来==判断资源已传输完毕==。

HTTP 很早就支持了GZip 压缩，由于 HTTP 传输的主要内容，譬如 HTML、CSS、Script 等，主要是文本数据，对于文本数据启用压缩的收益是非常高的，传输数据量一般会==降至原有的 20%==左右。
而对于那些不适合压缩的资源，Web 服务器则能根据 MIME 类型来自动判断是否对响应进行压缩，这样，==已经采用过压缩算法存储的资源==，如 JPEG、PNG 图片，便==不会被二次压缩==，空耗性能。

不过，大概就没有多少人想过==压缩==与之前提到的用于==节约 TCP 的持久连接机制==是存在==冲突==的。
在网络时代的早期，服务器处理能力还很薄弱，为了启用压缩，会是把静态资源==先预先压缩为.gz== 文件的形式存放起来，当客户端可以接受压缩版本的资源时（请求的 Header 中包含 Accept-Encoding: gzip）就返回压缩后的版本（响应的 Header 中包含 Content-Encoding: gzip），否则就返回未压缩的原版，这种方式被称为“==静态预压缩== ”（Static Precompression）。
而现代的 Web 服务器处理能力有了大幅提升，已经没有人再采用麻烦的预压缩方式了，都是由服务器对符合条件的请求将在输出时进行“==即时压缩== ”（On-The-Fly Compression），整个压缩过程全部在内存的数据流中完成，不必等资源压缩完成再返回响应，这样可以显著提高“首字节时间 ”（Time To First Byte，TTFB），改善 Web 性能体验。
而这个过程中唯一不好的地方就是服务器再也==没有办法给出 Content-Length== 这个响应 Header 了，因为输出 Header 时服务器还不知道压缩后资源的确切大小。

到这里，大家想明白即时压缩与持久链接的冲突在哪了吗？
持久链接机制不再依靠 TCP 连接是否关闭来判断资源请求是否结束，它会重用同一个连接以便向同一个域名请求多个资源，这样，客户端就必须要有除了关闭连接之外的其他机制来==判断一个资源什么时候算传递完毕==，这个机制最初（在 HTTP/1.0 时）就只有 Content-Length，即靠着请求 Header 中明确给出资源的长度，传输到达该长度即宣告一个资源的传输已结束。
由于启用即时压缩后就无法给出 Content-Length 了，如果是 HTTP/1.0 的话，持久链接和即时压缩只能二选其一，事实上在 HTTP/1.0 中两者都支持，却默认都是不启用的。
依靠 Content-Length 来判断传输结束的缺陷，不仅仅在于即时压缩这一种场景，譬如对于==动态内容==（Ajax、PHP、JSP 等输出），服务器也同样无法事先得知 Content-Length。


HTTP/1.1 版本中修复了这个缺陷，增加了另一种“==分块传输编码== ”（Chunked Transfer Encoding）的==资源结束判断机制==，彻底解决了 Content-Length 与持久链接的冲突问题。
分块编码==原理==相当简单：在响应 Header 中加入“Transfer-Encoding: chunked”之后，就代表这个响应报文将采用分块编码。此时，报文中的 Body 需要改为用一系列“分块”来传输。每个分块包含十六进制的长度值和对应长度的数据内容，长度值独占一行，数据从下一行开始。最后以一个长度值为 0 的分块来表示资源结束。
举个具体例子（例子来自于维基百科 ，为便于观察，只分块，未压缩）：
```http
HTTP/1.1 200 OK
Date: Sat, 11 Apr 2020 04:44:00 GMT
Transfer-Encoding: chunked
Connection: keep-alive

25
This is the data in the first chunk

1C
and this is the second one

3
con

8
sequence

0
```

根据分块长度可知，前两个分块包含显式的回车换行符（CRLF，即\r\n 字符）
"This is the data in the first chunk\r\n"      (37 字符 => 十六进制: 0x25)
"and this is the second one\r\n"               (28 字符 => 十六进制: 0x1C)
"con"                                          (3  字符 => 十六进制: 0x03)
"sequence"                                     (8  字符 => 十六进制: 0x08)

所以解码后的内容为：
This is the data in the first chunk
and this is the second one
consequence


一般来说，Web 服务器给出的数据分块大小应该（但并不强制）是一致的，而不是如例子中那样随意。HTTP/1.1 通过分块传输解决了即时压缩与持久连接并存的问题，到了 HTTP/2，由于多路复用和单域名单连接的设计，已经无须再刻意去提持久链接机制了，但数据压缩仍然有节约传输带宽的重要价值



#### 快速 UDP 网络连接

2013 年，Google 在它的服务器（如 Google.com、YouTube.com 等）及 Chrome 浏览器上同时启用了名为“==快速 UDP 网络连接== ”（Quick UDP Internet Connections，QUIC）的全新传输协议。
在 2015 年，Google 将 ==QUIC== 提交给 IETF，并在 IETF 的推动下对 QUIC 进行重新规范化（为以示区别，业界习惯将此前的版本称为 gQUIC，规范化后的版本称为 iQUIC），使其不仅能满足 HTTP 传输协议，日后还能支持 SMTP、DNS、SSH、Telnet、NTP 等多种其他上层协议。
2018 年末，IETF 正式批准了 HTTP over QUIC 使用 HTTP/3 的版本号，将其确立为最新一代的互联网标准。

从名字上就能看出 QUIC 会以 UDP 协议为基础，而 UDP 协议没有丢包自动重传的特性，因此 QUIC 的==可靠传输能力==并不是由底层协议提供，而是==完全由自己来实现==。
由 QUIC 自己实现的==好处==是能==对每个流能做单独的控制==，如果在一个流中发生错误，协议栈仍然可以独立地继续为其他流提供服务。
这对提高易出错链路的性能非常有用，因为在大多数情况下，TCP 协议接到数据包丢失或损坏通知之前，可能已经收到了大量的正确数据，但是在纠正错误之前，其他的正常请求都会等待甚至被重发，这也是在连接数优化一节中，笔者提到 HTTP/2 未能解决传输大文件慢的根本原因。

QUIC 的另一个设计目标是==面向移动设备的专门支持==，由于以前 TCP、UDP 传输协议在设计时根本不可能设想到今天移动设备盛行的场景，因此肯定不会有任何专门的支持。
QUIC 在移动设备上的==优势体现在网络切换时的响应速度==上，譬如当移动设备在不同 WiFi 热点之间切换，或者从 WiFi 切换到移动网络时，如果使用 TCP 协议，现存的所有连接都必定会超时、中断，然后根据需要重新创建。
这个过程会带来很高的延迟，因为超时和重新握手都需要大量时间。为此，QUIC 提出了==连接标识符的概念==，该标识符可以==唯一地标识客户端与服务器之间的连接==，而==无须依靠 IP 地址==。这样，切换网络后，只需向服务端发送一个包含此标识符的数据包即可重用既有的连接，因为即使用户的 IP 地址发生变化，原始连接连接标识符依然是有效的。

无论是 TCP 协议还是 HTTP 协议，都已经存在了数十年时间。它们积累了大量用户的同时，也承载了很重的技术惯性，要使 HTTP 从 TCP 迁移走，即使由 Google 和 IETF 来推动依然不是一件容易的事情。
一个最显著的==问题==是互联网基础设施中的==许多中间设备，都只面向 TCP 协议去建造==，仅对 UDP 提供很基础的支持，有的甚至完全阻止 UDP 的流量。因此，Google 在 Chromium 的网络协议栈中同时启用了 QUIC 和传统 TCP 连接，并在 ==QUIC 连接失败时以零延迟回退到 TCP 连接==，尽可能让用户无感知地逐步地扩大 QUIC 的使用面。

根据W3Techs 的数据，截至 2020 年 10 月，全球已有 48.9%的网站支持了 HTTP/2 协议，按照维基百科中的记录，这个数字在 2019 年 6 月时还只是 36.5%。
在 HTTP/3 方面，今天也已经得到了 7.2%网站的支持。可以肯定地说，目前网络链路传输领域正处于新旧交替的时代，许多既有的设备、程序、知识都会在未来几年时间里出现重大更新。



### 内容分发网络 CDN
内容分发网络（Content Distribution Network）
CDN 是一种十分古老而又十分透明，没什么存在感的分流系统，许多人都说听过它，但真正了解过它的人却很少。

如果抛却其他影响服务质量的因素，仅从网络传输的角度看，一个互联网系统的速度取决于以下四点因素：
- 网站服务器接入网络运营商的链路所能提供的出口带宽。
- 用户客户端接入网络运营商的链路所能提供的入口带宽。
- 从网站到用户之间经过的不同运营商之间互联节点的带宽，一般来说两个运营商之间只有固定的若干个点是互通的，所有跨运营商之间的交互都要经过这些点。
- 从网站到用户之间的物理链路传输时延。爱打游戏的同学应该都清楚，延迟（Ping 值）比带宽更重要。

以上四个网络问题，除了第二个只能通过换一个更好的宽带才能解决之外，其余三个都能通过内容分发网络来显著改善。

内容分发网络的工作过程，主要涉及==路由解析、内容分发、负载均衡和所能支持的 CDN 应用内容==四个方面，由于下一节会专门讨论负载均衡的内容，所以这部分在本节就暂不涉及，我们来逐一了解 CDN 其余三个方面。


#### 路由解析

内容分发网络将用户请求路由到它的资源服务器上就是依靠 DNS 服务器来实现的

#### dig linux命令

CDN 路由解析的具体工作过程是：
1. 架设好“icyfenix.cn”的服务器后，将服务器的 IP 地址在你的 ==CDN 服务商==上注册为“源站”，注册后你会得到一个 ==CNAME==，即本例中的“icyfenix.cn.cdn.dnsv1.com.”。
2. 将得到的 CNAME 在你购买域名的 ==DNS 服务商==上注册为一条 CNAME 记录。
3. 当第一位用户来访你的站点时，将首先发生一次未命中缓存的 DNS 查询，域名服务商解析出 CNAME 后，返回给本地 DNS，至此之后==链路解析的主导==权就开始由==内容分发网络的调度服务==接管了。
4. 本地 DNS 查询 CNAME 时，由于能解析该 CNAME 的权威服务器只有 CDN 服务商所架设的权威 DNS，这个 DNS 服务将根据一定的均衡策略和参数，如拓扑结构、容量、时延等，在全国各地能提供服务的 CDN 缓存节点中挑选一个最适合的，将它的 IP 代替源站的 IP 地址，返回给本地 DNS。
5. 浏览器从本地 DNS 拿到 IP 地址，将该 IP 当作源站服务器来进行访问，此时该 IP 的 CDN 节点上可能有，也可能没有缓存过源站的资源，这点将在稍后“内容分发”小节讨论。
6. 经过内容分发后的 CDN 节点，就有能力代替源站向用户提供所请求的资源。

。。怎么把 部分内容 放到 CDN上？ 是第一步注册完后，就可以了？ 那样的话，需要更新服务器，还需要更新CDN的内容？


#### 内容分发
在 DNS 服务器的协助下，无论是对用户还是服务器，内容分发网络都可以是完全透明的，在两者都==不知情==的情况下，由 CDN 的缓存节点==接管了用户向服务器发出的资源请求==。
后面随之而来的问题是缓存节点中==必须有用户想要请求的资源副本==，才可能代替源站来响应用户请求。这里面又包括了两个子问题：“==如何获取源站资源==”和“==如何管理（更新）资源==”。

CDN 获取源站资源的过程被称为“内容分发”，“内容分发网络”的名字正是由此而来，可见这是 CDN 的核心价值。目前主要有以下两种主流的内容分发方式：

- 主动分发（Push）：
  分发由==源站主动发起==，将内容从源站或者其他资源库推送到用户边缘的各个 CDN 缓存节点上。
  这个推送的操作没有什么业界标准可循，可以采用任何传输方式（HTTP、FTP、P2P，等等）、任何推送策略（满足特定条件、定时、人工，等等）、任何推送时间，只要与后面说的更新策略相匹配即可。
  由于主动分发通常==需要源站、CDN 服务双方提供程序 API 接口层面的配合==，所以它对源站并不是透明的，只对用户一侧单向透明。
  ==主动分发一般用于网站要预载大量资源的场景==。
  譬如==双十一==之前一段时间内，淘宝、京东等各个网络商城就会开始把未来活动中所需用到的资源推送到 CDN 缓存节点中，特别常用的资源甚至会直接缓存到你的手机 APP 的存储空间或者浏览器的localStorage上。
- 被动回源（Pull）：
  被动回源由==用户访问所触发全自动、双向透明的资源缓存过程==。
  当某个资源==首次==被用户请求的时候，CDN 缓存节点发现自己没有该资源，就会实时从源站中获取，这时资源的响应时间可粗略认为是资源从源站到 CDN 缓存节点的时间，再加上资源从 CDN 发送到用户的时间之和。
  因此，被动回源的首次访问通常是比较慢的（但由于 CDN 的网络条件一般远高于普通用户，并不一定就会比用户直接访问源站更慢），==不适合应用于数据量较大的资源==。
  被动回源的优点是可以做到完全的双向透明，不需要源站在程序上做任何的配合，使用起来非常方便。
  这种分发方式是==小型站点==使用 CDN 服务的==主流选择==，如果不是自建 CDN，而是购买阿里云、腾讯云的 CDN 服务的站点，多数采用的就是这种方式。


对于“CDN ==如何管理（更新）资源==”这个问题，同样没有统一的标准可言，尽管在 HTTP 协议中，关于缓存的 Header 定义中确实是有对 CDN 这类共享缓存的一些指引性参数，譬如Cache-Control的 s-maxage，但是否要遵循，==完全取决于 CDN 本身的实现策略==。
更令人感到无奈的是，由于大多数网站的开发和运维人员并不十分了解 HTTP 缓存机制，所以导致如果 CDN 完全照着 HTTP Headers 来控制缓存失效和更新，效果反而会相当的差，还可能引发其他问题。
因此，CDN 缓存的管理就不存在通用的准则。


现在，==最常见==的做法是==超时被动失效==与==手工主动失效==相结合。
超时失效是指给予缓存资源一定的生存期，超过了生存期就在下次请求时重新被动回源一次。
而手工失效是指 CDN 服务商一般会提供给程序调用==来失效缓存==的接口，在网站更新时，由==持续集成的流水线自动调用该接口==来实现缓存更新，譬如“icyfenix.cn”就是依靠Travis-CI 的持续集成服务来触发 CDN 失效和重新预热的


#### CDN应用

内容分发网络最初是为了快速分发静态资源而设计的，但今天的 CDN 所能做的事情已经远远超越了开始建设时的目标，这部分应用太多，无法展开逐一细说，笔者只能对现在 ==CDN 可以做的事情==简要列举，以便读者有个总体认知。

- 加速静态资源：
  这是 CDN 本职工作。
- 安全防御：
  CDN 在广义上可以视作网站的堡垒机，==源站只对 CDN 提供服务==，由 CDN 来对外界其他用户服务，这样恶意攻击者就不容易直接威胁源站。CDN 对某些攻击手段的防御，如对DDoS 攻击的防御尤其有效。
  但需==注意==，将安全都寄托在 CDN 上本身是不安全的，一旦源站真实 IP 被泄漏，就会面临很高的风险。
- 协议升级：
  不少 CDN 提供商都同时对接（代售 CA 的）==SSL 证书服务==，可以实现源站是 HTTP 协议的，而对外开放的网站是基于 HTTPS 的。
  同理，可以实现源站到 CDN 是 HTTP/1.x 协议，CDN 提供的外部服务是 HTTP/2 或 HTTP/3 协议、实现源站是基于 IPv4 网络的，CDN 提供的外部服务支持 IPv6 网络，等等。
- 状态缓存：
  第一节介绍客户端缓存时简要提到了状态缓存，CDN 不仅可以缓存源站的资源，还可以缓存源站的状态，譬如源站的 301/302 转向就可以缓存起来让客户端直接跳转、还可以通过 CDN 开启HSTS、可以通过 CDN 进行OCSP 装订加速 SSL 证书访问，等等。
  有一些情况下甚至可以配置 CDN 对任意状态码（譬如 404）进行一定时间的缓存，以减轻源站压力，但这个操作应当慎重，在网站状态发生改变时去及时刷新缓存。
- 修改资源：
  CDN 可以在返回资源给用户的时候修改它的任何内容，以实现不同的目的。
  譬如，可以对源站未压缩的资源自动压缩并修改 Content-Encoding，以节省用户的网络带宽消耗、可以对源站未启用客户端缓存的内容加上缓存 Header，自动启用客户端缓存，可以修改CORS 的相关 Header，将源站不支持跨域的资源提供跨域能力，等等。
- 访问控制：
  CDN 可以实现 IP 黑/白名单功能，根据不同的来访 IP 提供不同的响应结果，根据 IP 的访问流量来实现 QoS 控制、根据 HTTP 的 Referer 来实现防盗链，等等。
- 注入功能：
  CDN 可以在不修改源站代码的前提下，为源站注入各种功能，图 4-7 是国际 CDN 巨头 CloudFlare 提供的 Google Analytics、PACE、Hardenize 等第三方应用，在 CDN 下均能做到无须修改源站任何代码即可使用。
- 绕过某些“不存在的”网络措施，
  这也是在国内申请 CDN 也必须实名备案的原因，就不细说了。


### 负载均衡
负载均衡（Load Balancing）
调度后方的多台机器，以统一的接口对外提供服务，承担此职责的技术组件被称为“负载均衡”。

真正大型系统的负载均衡过程往往是==多级==的。
譬如，在各地建有多个机房，或机房有不同网络链路入口的大型互联网站，会从 DNS 解析开始，通过“域名” → “CNAME” → “负载调度服务” → “就近的数据中心入口”的路径，先将来访地用户根据 IP 地址（或者其他条件）
分配到一个合适的数据中心中，然后才到稍后将要讨论的各式负载均衡。
在 DNS 层面的负载均衡与前面介绍的 DNS 智能线路、内容分发网络等，在工作原理上是类似的，其差别只是数据中心能提供的不仅有缓存，而是全方位的服务能力。
由于这种方式此前已经详细讲解过，后续我们所讨论的“负载均衡”就只聚焦于网络请求进入数据中心入口之后的其他级次的负载均衡。

无论在网关内部建立了多少级的负载均衡，从形式上来说都可以分为两种：
==四层负载均衡和七层负载均衡==。
在详细介绍它们是什么以及如何工作之前，我们先来建立两个总体的、概念性的印象。

- 四层负载均衡的优势是性能高，七层负载均衡的优势是功能强。
- 做多级混合负载均衡，通常应是低层的负载均衡在前，高层的负载均衡在后（想一想为什么？）。

我们所说的“四层”、“七层”，指的是经典的OSI 七层模型 中==第四层传输层==和==第七层应用层==

 	
||层|数据单元|功能|
|--|--|--|--|
|7| 	应用层Application Layer 	|数据Data 	|提供为应用软件提供服务的接口，用于与其他应用软件之间的通信。典型协议：HTTP、HTTPS、FTP、Telnet、SSH、SMTP、POP3 等|
|6| 	表达层Presentation Layer 	|数据Data 	|把数据转换为能与接收者的系统格式兼容并适合传输的格式。|
|5| 	会话层Session Layer 	|数据Data 	|负责在数据传输中设置和维护计算机网络中两台计算机之间的通信连接。|
|4| 	传输层Transport Layer 	|数据段Segments 	|把传输表头加至数据以形成数据包。传输表头包含了所使用的协议等发送信息。典型协议：TCP、UDP、RDP、SCTP、FCP 等|
|3| 	网络层Network Layer 	|数据包Packets 	|决定数据的传输路径选择和转发，将网络表头附加至数据段后以形成报文（即数据包）。典型协议：IPv4/IPv6、IGMP、ICMP、EGP、RIP 等|
|2| 	数据链路层Data Link Layer 	|数据帧Frame 	|负责点对点的网络寻址、错误侦测和纠错。当表头和表尾被附加至数据包后，就形成数据帧（Frame）。典型协议：WiFi（802.11）、Ethernet（802.3）、PPP 等。|
|1| 	物理层Physical Layer 	|比特流Bit 	|在物理网络上传送数据帧，它负责管理电脑通信设备和网络媒体之间的互通。包括了针脚、电压、线缆规范、集线器、中继器、网卡、主机接口卡等。|

现在所说的“四层负载均衡”其实是多种均衡器工作模式的统称，
“四层”的意思是说这些工作模式的==共同特点是维持着同一个 TCP 连接==，而不是说它只工作在第四层。
事实上，这些模式==主要都是工作在二层（数据链路层，改写 MAC 地址==）和==三层（网络层，改写 IP 地址==）上，单纯只处理第四层（传输层，可以改写 TCP、UDP 等协议的内容和端口）的数据无法做到负载均衡的转发，
因为 OSI 的下三层是媒体层（Media Layers），上四层是主机层（Host Layers），既然流量都已经到达目标主机上了，也就谈不上什么流量转发，最多只能做代理了。
但出于习惯和方便，现在几乎所有的资料都把它们统称为四层负载均衡，笔者也同样称呼它为四层负载均衡，如果读者在某些资料上看见“二层负载均衡”、“三层负载均衡”的表述，应该了解这是在描述它们工作的层次，与这里说的“四层负载均衡”并不是同一类意思。

下面笔者来介绍几种常见的四层负载均衡的工作模式。


#### 数据链路层负载均衡

参考上面 OSI 模型的表格，数据链路层传输的内容是数据帧（Frame），譬如常见的以太网帧、ADSL 宽带的 PPP 帧等。
我们讨论的具体上下文里，目标必定就是==以太网帧==了，按照IEEE 802.3 标准，最典型的 1500 Bytes ==MTU== 的以太网帧结构如表 4-2 所示。

。。maximum transmission unit 最大传输单元

以太网帧结构说明
|数据项 	|取值|
|--|--|
|前导码 	|10101010 7 Bytes|
|帧开始符 	|10101011 1 Byte|
|MAC 目标地址 	|6 Bytes|
|MAC 源地址 	|6 Bytes|
|802.1Q标签（可选） 	|4 Bytes|
|以太类型 |2 Bytes|
|有效负载 	|==1500== Bytes|
|冗余校验 |4 Bytes|
|帧间距 |12 Bytes|

帧结构中其他数据项的含义在本节中可以暂时不去理会，
只需注意到“MAC 目标地址”和“MAC 源地址”两项即可。
我们知道每一块网卡都有独立的 MAC 地址，以太帧上这两个地址告诉了交换机，
此帧应该是从连接在交换机上的哪个端口的网卡发出，送至哪块网卡的。


由于二层负载均衡器在转发请求过程中只修改了帧的 MAC 目标地址，不涉及更上层协议（没有修改 Payload 的数据），所以在更上层（第三层）看来，所有数据都是未曾被改变过的。
由于第三层的数据包，即 IP 数据包中包含了源（客户端）和目标（均衡器）的 ==IP 地址==，只有真实服务器保证自己的 IP 地址与数据包中的目标 IP 地址一致，这个数据包才能被正确处理。
因此，使用这种负载均衡模式时，需要把真实物理服务器集群==所有机器的虚拟 IP 地址== （Virtual IP Address，VIP）配置成与==负载均衡器的虚拟 IP 一样==，这样经均衡器转发后的数据包就能在真实服务器中顺利地使用。
也正是因为实际处理请求的真实物理服务器 IP 和数据请求中的目的 IP 是一致的，所以响应结果就==不再需要通过负载均衡服务器进行地址交换==，可将响应结果的数据包直接从真实服务器返回给用户的客户端，避免负载均衡器网卡带宽成为瓶颈，因此数据链路层的负载均衡==效率是相当高==的。

![4b2c5dc398607e10c6a60a157f73df9d.png](../_resources/4b2c5dc398607e10c6a60a157f73df9d.png)

上述==只有请求经过负载均衡器==，而服务的==响应无须从负载均衡器原路返回==的工作模式，整个请求、转发、响应的链路形成一个“三角关系”，所以这种负载均衡模式也常被很形象地称为“==三角传输模式==”（Direct Server Return，DSR），也有叫“==单臂模式==”（Single Legged Mode）或者“==直接路由==”（Direct Routing）。

虽然数据链路层负载均衡==效率很高==，但它==并不能适用于所有的场合==，除了那些==需要感知应用层协议信息的负载均衡场景它无法胜任==外（所有的四层负载均衡器都无法胜任，将在后续介绍七层均衡器时一并解释），它在==网络一侧受到的约束也很大==。
二层负载均衡器直接改写目标 MAC 地址的工作原理决定了它与真实的服务器的通信必须是二层可达的，通俗地说就是==必须位于同一个子网当中==，无法跨 VLAN。优势（效率高）和劣势（不能跨子网）共同决定了数据链路层负载均衡==最适合用来做数据中心的第一级均衡设备==，用来连接其他的下级负载均衡器。


#### 网络层负载均衡

根据 OSI 七层模型，在第三层网络层传输的单位是分组数据包（Packets），这是一种在分组交换网络 （Packet Switching Network，PSN）中传输的结构化数据单位。
以 IP 协议为例，一个 IP 数据包由 Headers 和 Payload 两部分组成， Headers 长度最大为 60 Bytes，其中包括了 20 Bytes 的固定数据和最长不超过 40 Bytes 的可选的额外设置组成。
按照 IPv4 标准，一个典型的分组数据包的 Headers 部分具有如表 4-3 所示的结构。

|长度 	|存储信息|
|--|--|
|0-4 Bytes 	|版本号（4 Bits）、首部长度（4 Bits）、分区类型（8 Bits)、总长度（16 Bits）|
|5-8 Bytes 	|报文计数标识（16 Bits）、标志位（4 Bits）、片偏移（12 Bits）|
|9-12 Bytes |	TTL 生存时间（8 Bits）、上层协议代号（8 Bits）、首部校验和（16 Bits）|
|13-16 Bytes| 	源地址（32 Bits）|
|17-20 Bytes| 	目标地址（32 Bits）|
|20-60 Bytes| 	可选字段和空白填充|


在本节中，无须过多关注表格中的其他信息，只要知道在 IP 分组数据包的 Headers 带有源和目标的 IP 地址即可。
源和目标 IP 地址代表了数据是从分组交换网络中哪台机器发送到哪台机器的，我们可以沿用与二层改写 MAC 地址相似的思路，通过改变这里面的 IP 地址来实现数据包的转发。
具体有两种常见的修改方式。

第一种是保持原来的数据包不变，==新创建一个数据包==，把原来数据包的 Headers 和 Payload 整体作为另一个新的数据包的 Payload，在这个新数据包的 Headers 中写入真实服务器的 IP 作为目标地址，然后把它发送出去。
经过三层交换机的转发，真实服务器收到数据包后，必须在接收入口处设计一个针对性的拆包机制，把由负载均衡器自动添加的那层 Headers 扔掉，还原出原来的数据包来进行使用。
这样，真实服务器就同样拿到了一个原本不是发给它（目标 IP 不是它）的数据包，达到了流量转发的目的。那时候还没有流行起“禁止套娃”的梗，所以设计者给这种“套娃式”的传输起名叫做“==IP 隧道== ”（IP Tunnel）传输，也还是相当的形象。

尽管因为要封装新的数据包，IP 隧道的转发模式比起直接路由模式效率会有所下降，但由于并没有修改原有数据包中的任何信息，所以 IP 隧道的转发模式仍然具备==三角传输==的特性，即负载均衡器转发来的请求，可以由真实服务器去直接应答，无须在经过均衡器原路返回。
而且由于 IP 隧道工作在网络层，所以==可以跨越 VLAN==，因此摆脱了直接路由模式中网络侧的约束。此模式从请求到响应的过程如图 4-9 所示。

![a6a9d176429229313c0de3685f91c26b.png](../_resources/a6a9d176429229313c0de3685f91c26b.png)

而这种转发方式也有缺点。
第一个缺点是它要求真实服务器必须支持“IP 隧道协议 ”（IP Encapsulation），就是它得学会自己拆包扔掉一层 Headers，这个其实并不是什么大问题，现在几乎所有的 Linux 系统都支持 IP 隧道协议。
另外一个缺点是这种模式仍必须通过专门的配置，必须保证==所有的真实服务器与均衡器有着相同的虚拟 IP 地址==，因为回复该数据包时，需要使用这个虚拟 IP 作为响应数据包的源地址，这样客户端收到这个数据包时才能正确解析。这个限制就相对麻烦一些，它与“透明”的原则冲突，需由系统管理员介入。


而且，对服务器进行虚拟 IP 的配置并不是在任何情况下都可行的，尤其是当有好几个服务共用一台物理服务器的时候，
此时就必须考虑第二种修改方式——==改变目标数据包==：直接把数据包 Headers 中的==目标地址==改掉，修改后原本由用户发给均衡器的数据包，也会被三层交换机转发送到真实服务器的网卡上，而且因为没有经过 IP 隧道的额外包装，也就无须再拆包了。
但问题是这种模式是通过修改目标 IP 地址才到达真实服务器的，如果真实服务器直接将应答包返回客户端的话，这个应答数据包的源 IP 是真实服务器的 IP，也即均衡器修改以后的 IP 地址，客户端不可能认识该 IP，自然就无法再正常处理这个应答了。
因此，==只能让应答流量继续回到负载均衡==，由负载均衡把应答包的源 IP 改回自己的 IP，再发给客户端，这样才能保证客户端与真实服务器之间的正常通信。
如果你对网络知识有些了解的话，肯定会觉得这种处理似曾相识，这不就是在家里、公司、学校上网时，由一台路由器带着一群内网机器上网的“网络地址转换 ”（Network Address Translation，==NAT==）操作吗？
这种负载均衡的模式的确被称为 ==NAT 模式==，此时，负载均衡器就是充当了家里、公司、学校的上网路由器的作用。
NAT 模式的负载均衡器==运维起来十分简单==，只要机器将自己的网关地址设置为均衡器地址，就无须再进行任何额外设置了。此模式从请求到响应的过程如图 4-10 所示。

![ebb1cac0cedc7d3a08b450462de6e192.png](../_resources/ebb1cac0cedc7d3a08b450462de6e192.png)

在==流量压力比较大==的时候，NAT 模式的负载均衡会带来==较大的性能损失==，比起直接路由和 IP 隧道模式，甚至会出现==数量级上的下降==。
这点是显而易见的，由负载均衡器代表整个服务集群来进行应答，各个服务器的响应数据都会互相挣抢均衡器的出口带宽，这就好比在家里用 NAT 上网的话，如果有人在下载，你打游戏可能就会觉得卡顿是一个道理，此时整个系统的瓶颈很容易就出现在负载均衡器上。

还有一种更加彻底的 NAT 模式：即均衡器在转发时，不仅修改目标 IP 地址，连源 IP 地址也一起改了，==源地址就改成均衡器自己的 IP==，称作 Source NAT（SNAT）。这样做的好处是真实服务器==无须配置网关就能够让应答流量经过正常的三层路由回到负载均衡器上==，做到了彻底的透明。但是缺点是由于做了 SNAT，真实服务器处理请求时就==无法拿到客户端的 IP== 地址了，从真实服务器的视角看来，所有的流量都来自于负载均衡器，这样有一些需要根据目标 IP 进行控制的业务逻辑就无法进行


#### 应用层负载均衡

前面介绍的四层负载均衡工作模式都属于“==转发==”，即直接将承载着 TCP 报文的底层数据格式（IP 数据包或以太网帧）转发到真实服务器上，此时客户端到响应请求的真实服务器维持着==同一条 TCP 通道==。
但工作在四层之后的负载均衡模式就无法再进行转发了，==只能进行代理==，此时真实服务器、负载均衡器、客户端三者之间由==两条独立的 TCP 通道==来维持通信，转发与代理的区别如图 4-11 所示。

![9ec335510fc0320af2e3643df938d3a7.png](../_resources/9ec335510fc0320af2e3643df938d3a7.png)

“代理”这个词，根据“哪一方能感知到”的原则，可以分为“==正向代理”、“反向代理”和“透明代理==”三类。
正向代理就是我们通常简称的代理，指==在客户端设置==的、代表客户端与服务器通信的代理服务，它是==客户端可知，而对服务器透明==的。
反向代理是指在设置在==服务器这一侧==，==代表真实服务器==来与客户端通信的代理服务，此时它对客户端来说是透明的。
至于透明代理是指对双方都透明的，配置在网络中间设备上的代理服务，譬如，架设在路由器上的透明翻墙代理。

根据以上定义，很显然，七层负载均衡器它就==属于反向代理==中的一种，如果只论网络性能，七层均衡器肯定是无论如何比不过四层均衡器的，它比四层均衡器至少多一轮 TCP 握手，有着跟 NAT 转发模式一样的带宽问题，而且通常要耗费更多的 CPU，因为可用的解析规则远比四层丰富。
所以如果用七层均衡器去做下载站、视频站这种流量应用是不合适的，起码不能作为第一级均衡器。但是，==如果网站的性能瓶颈并不在于网络性能，要论整个服务集群对外所体现出来的服务性能，七层均衡器就有它的用武之地了==。
这里面七层均衡器的底气就是来源于它==工作在应用层，可以感知应用层通信的具体内容，往往能够做出更明智的决策==，玩出更多的花样来。

举个生活中的例子，
四层均衡器就像银行的自助排号机，转发效率高且不知疲倦，每一个达到银行的客户根据排号机的顺序，选择对应的窗口接受服务；
而七层均衡器就像银行大堂经理，他会先确认客户需要办理的业务，再安排排号。
这样办理理财、存取款等业务的客户，会根据银行内部资源得到统一协调处理，加快客户业务办理流程，有一些无须柜台办理的业务，由大堂经理直接就可以解决了，譬如，反向代理的就能够实现静态资源缓存，对于静态资源的请求就可以在反向代理上直接返回，无须转发到真实服务器。


代理的工作模式相信大家应该是比较熟悉的，这里不再展开，只是简单列举了一些==七层代理==可以实现的==功能==，以便读者对它“功能强大”有个直观的感受。

- 前面介绍 CDN 应用时，所有 CDN 可以做的缓存方面的工作（就是除去 CDN 根据物理位置就近返回这种优化链路的工作外），七层均衡器全都可以实现，譬如静态资源缓存、协议升级、安全防护、访问控制，等等。
- 七层均衡器可以实现==更智能化的路由==。譬如，根据 Session 路由，以实现亲和性的集群；根据 URL 路由，实现专职化服务（此时就相当于网关的职责）；甚至根据用户身份路由，实现对部分用户的特殊服务（如某些站点的贵宾服务器），等等。
- 某些安全攻击可以由七层均衡器来==抵御==，譬如一种常见的 DDoS 手段是 SYN Flood 攻击，即攻击者控制众多客户端，使用虚假 IP 地址对同一目标大量发送 SYN 报文。从技术原理上看，由于四层均衡器无法感知上层协议的内容，这些 SYN 攻击都会被转发到后端的真实服务器上；而七层均衡器下这些 SYN 攻击自然在负载均衡设备上就被过滤掉，不会影响到后面服务器的正常运行。类似地，可以在七层均衡器上设定多种策略，譬如过滤特定报文，以防御如 SQL 注入等应用层面的特定攻击手段。
- 很多微服务架构的系统中，链路治理措施都需要在七层中进行，譬如==服务降级、熔断、异常注入==，等等。譬如，一台服务器只有出现物理层面或者系统层面的故障，导致无法应答 TCP 请求才能被四层均衡器所感知，进而剔除出服务集群，如果一台服务器能够应答，只是==一直在报 500 错，那四层均衡器对此是完全无能为力==的，只能由七层均衡器来解决。


#### 均衡策略与实现
负载均衡的两大职责是“选择谁来处理用户请求”和“将用户请求转发过去”。
到此我们仅介绍了后者，即请求的转发或代理过程。
前者是指均衡器所采取的均衡策略，由于这一块涉及的均衡算法太多，笔者无法逐一展开，所以本节仅从功能和应用的角度去介绍一些常见的均衡策略。

- 轮循均衡（Round Robin）：
  每一次来自网络的请求轮流分配给内部中的服务器，从 1 至 N 然后重新开始。此种均衡算法适合于集群中的所有服务器都有相同的软硬件配置并且平均服务请求相对均衡的情况。
- 权重轮循均衡（Weighted Round Robin）：
  根据服务器的不同处理能力，给每个服务器分配不同的权值，使其能够接受相应权值数的服务请求。譬如：服务器 A 的权值被设计成 1，B 的权值是 3，C 的权值是 6，则服务器 A、B、C 将分别接收到 10%、30％、60％的服务请求。此种均衡算法能确保高性能的服务器得到更多的使用率，避免低性能的服务器负载过重。
- 随机均衡（Random）：
  把来自客户端的请求随机分配给内部中的多个服务器，在数据足够大的场景下能达到相对均衡的分布。
- 权重随机均衡（Weighted Random）：
  此种均衡算法类似于权重轮循算法，不过在分配处理请求时是个随机选择的过程。
- 一致性哈希均衡（Consistency Hash）：
  根据请求中某一些数据（可以是 MAC、IP 地址，也可以是更上层协议中的某些参数信息）作为特征值来计算需要落在的节点上，算法一般会保证同一个特征值每次都一定落在相同的服务器上。一致性的意思是保证当服务集群某个真实服务器出现故障，只影响该服务器的哈希，而不会导致整个服务集群的哈希键值重新分布。
- 响应速度均衡（Response Time）：
  负载均衡设备对内部各服务器发出一个探测请求（例如 Ping），然后根据内部中各服务器对探测请求的最快响应时间来决定哪一台服务器来响应客户端的服务请求。此种均衡算法能较好的反映服务器的当前运行状态，但这最快响应时间仅仅指的是负载均衡设备与服务器间的最快响应时间，而不是客户端与服务器间的最快响应时间。
- 最少连接数均衡（Least Connection）：
  客户端的每一次请求服务在服务器停留的时间可能会有较大的差异，随着工作时间加长，如果采用简单的轮循或随机均衡算法，每一台服务器上的连接进程可能会产生极大的不平衡，并没有达到真正的负载均衡。最少连接数均衡算法对内部中需负载的每一台服务器都有一个数据记录，记录当前该服务器正在处理的连接数量，当有新的服务连接请求时，将把当前请求分配给连接数最少的服务器，使均衡更加符合实际情况，负载更加均衡。此种均衡策略适合长时处理的请求服务，如 FTP 传输。


从实现角度来看，负载均衡器的实现分为“==软件均衡器”和“硬件均衡器==”两类。
在软件均衡器方面，又分为直接建设在==操作系统内核==的均衡器和==应用程序==形式的均衡器两种。
前者的代表是 LVS（Linux Virtual Server），
后者的代表有 Nginx、HAProxy、KeepAlived 等，
前者性能会更好，因为无须在内核空间和应用空间中来回复制数据包；而后者的优势是选择广泛，使用方便，功能不受限于内核版本。

在硬件均衡器方面，往往会直接采用应用专用集成电路 （Application Specific Integrated Circuit，ASIC）来实现，有专用处理芯片的支持，避免操作系统层面的损耗，得以达到最高的性能。这类的代表就是著名的 ==F5 和 A10== 公司的负载均衡产品。



### 服务端缓存

缓存（Cache）
软件开发中的缓存并非多多益善，它有收益，也有风险。


为系统引入缓存之前，第一件事情是确认你的系统==是否真的需要缓存==。
很多人会有意无意地把硬件里那种常用于区分不同产品档次、“多多益善”的缓存（如 CPU L1/2/3 缓存、磁盘缓存，等等）代入软件开发中去，实际上这两者差别很大，
在软件开发中==引入缓存的负面作用要明显大于硬件的缓存==：
从开发角度来说，引入缓存会提高系统复杂度，因为你要考虑缓存的==失效、更新、一致性==等问题（硬件缓存也有这些问题，只是不需要由你去考虑，主流的 ISA 也都没有提供任何直接操作缓存的指令）；
从运维角度来说，缓存会掩盖掉一些缺陷，让问题在更久的时间以后，出现在距离发生现场更远的位置上；
从安全角度来说，缓存可能泄漏某些保密数据，也是容易受到攻击的薄弱点。
冒着上述种种风险，仍能说服你引入缓存的理由，总结起来无外乎以下两种：
- 为缓解 CPU 压力而做缓存：
  譬如把方法运行结果存储起来、把原本要实时计算的内容提前算好、把一些公用的数据进行复用，这可以节省 CPU 算力，顺带提升响应性能。
- 为缓解 I/O 压力而做缓存：
  譬如把原本对网络、磁盘等较慢介质的读写访问变为对内存等较快介质的访问，将原本对单点部件（如数据库）的读写访问变为到可扩缩部件（如缓存中间件）的访问，顺带提升响应性能。

如果可以通过增强 CPU、I/O 本身的性能（譬如扩展服务器的数量）来满足需要的话，那==升级硬件往往是更好的解决方案==，即使需要一些额外的投入成本，也通常要优于引入缓存后可能带来的风险。

#### 缓存属性
有不少软件系统最初的缓存功能是以 HashMap 或者 ConcurrentHashMap 为起点演进的。
当开发人员发现系统中某些资源的构建成本比较高，而这些资源又有被重复使用的可能性时，会很自然地产生“循环再利用”的想法，将它们放到 Map 容器中，下次需要时取出重用，避免重新构建，这种原始朴素的复用就是最基本的缓存了。
不过，一旦我们专门把“缓存”看作一项技术基础设施，一旦它有了通用、高效、可统计、可管理等方面的需求，其中要考虑的因素就变得复杂起来。通常，我们设计或者选择缓存至少会考虑以下四个维度的属性：

- 吞吐量：
  缓存的吞吐量使用 OPS 值（每秒操作数，Operations per Second，ops/s）来衡量，反映了对缓存进行并发读、写操作的效率，即缓存本身的工作效率高低。
- 命中率：
  缓存的命中率即成功从缓存中返回结果次数与总请求次数的比值，反映了引入缓存的价值高低，命中率越低，引入缓存的收益越小，价值越低。
- 扩展功能：
  缓存除了基本读写功能外，还提供哪些额外的管理功能，譬如最大容量、失效时间、失效事件、命中率统计，等等。
- 分布式支持：
  缓存可分为“进程内缓存”和“分布式缓存”两大类，前者只为节点本身提供服务，无网络访问操作，速度快但缓存的数据不能在各个服务节点中共享，后者则相反。


#### 吞吐量

HashMap 并不是线程安全的容器，如果要让它在多线程并发下能正确地工作，
就要用 Collections.synchronizedMap 进行包装，这相当于给 Map 接口的所有访问方法都自动加全局锁；
或者改用 ConcurrentHashMap 来实现，这相当于给 Map 的访问分段加锁（从 JDK 8 起已取消分段加锁，改为 CAS+Synchronized 锁单个元素）。
无论采用怎样的实现方法，线程安全措施都会带来一定的吞吐量损失。

进一步说，如果只比较吞吐量，完全不去考虑命中率、淘汰策略、缓存统计、过期失效等功能该如何实现，那也不必选择，JDK 8 改进之后的 ConcurrentHashMap 基本上就是你能找到的==吞吐量最高==的缓存容器了。
可是很多场景里，以上提及的功能至少有部分一两项是必须的，不可能完全不考虑，这才涉及到不同缓存方案的权衡问题。

根据 Caffeine 给出的一组目前业界主流进程内缓存实现方案，
包括有 Caffeine、ConcurrentLinkedHashMap、LinkedHashMap、Guava Cache、Ehcache 和 Infinispan Embedded 的对比，
从Benchmarks 中体现出的它们在 8 线程、75%读操作、25%写操作下的吞吐量来看，各种缓存组件库的性能差异还是十分明显的，最高与最低的相差了足有一个数量级，具体如图 4-12 所示。

![2e513841f973bd6deebe24327d8fb03d.png](../_resources/2e513841f973bd6deebe24327d8fb03d.png)

这种并发读写的场景中，吞吐量受多方面因素的共同影响，譬如，
怎样设计数据结构以尽可能==避免数据竞争==，存在竞争风险时怎样处理==同步==（主要有使用锁实现的悲观同步和使用CAS 实现的乐观同步）、如何==避免伪共享==现象 （False Sharing，这也算是典型缓存提升开发复杂度的例子）发生，等等。
其中第一点尽可能避免竞争是最关键的，无论如何实现同步都不会比直接无须同步更快，
笔者下面以 Caffeine 为例，介绍一些缓存如何避免竞争、提高吞吐量的设计。

缓存中最主要的==数据竞争==源于==读取数据的同时，也会伴随着对数据状态的写入操作，写入数据的同时，也会伴随着数据状态的读取操作==。
譬如，读取时要同时更新数据的最近访问时间和访问计数器的状态（后文会提到，为了追求高效，可能不会记录时间和次数，譬如通过调整链表顺序来表达时间先后、通过 Sketch 结构来表达热度高低），以实现缓存的淘汰策略；
又或者读取时要同时判断数据的超期时间等信息，以实现失效重加载等其他扩展功能。
对以上==伴随读写操作而来的状态维护==，有两种可选择的处理思路，
一种是以 Guava Cache 为代表的同步处理机制，即在==访问数据时一并完成缓存淘汰、统计、失效等状态变更操作==，通过==分段加锁等优化手段来尽量减少竞争==。
另一种是以 Caffeine 为代表的==异步日志提交机制==，这种机制参考了经典的数据库设计理论，将==对数据的读、写过程看作是日志==（即对数据的操作指令）的提交过程。尽管日志也涉及到写入操作，有并发的数据变更就必然面临锁竞争，但异步提交的日志已经将原本在 Map 内的锁转移到日志的追加写操作上，日志里腾挪优化的余地就比在 Map 中要大得多。

在 Caffeine 的实现中，设有专门的==环形缓存区== （Ring Buffer，也常称作 Circular Buffer）来记录由于数据读取而产生的状态变动日志。为进一步减少竞争，Caffeine 给==每条线程==（对线程取 Hash，哈希值相同的使用同一个缓冲区）都设置==一个专用的环形缓冲==。


额外知识：环形缓冲
所谓环形缓冲，并非 Caffeine 的专有概念，
它是一种拥有读、写两个指针的数据复用结构，在计算机科学中有非常广泛的应用。
举个具体例子，譬如一台计算机通过键盘输入，并通过 CPU 读取“HELLO WIKIPEDIA”这个长 14 字节的单词，通常需要一个至少 14 字节以上的缓冲区才行。但如果是环形缓冲结构，读取和写入就应当一起进行，在读取指针之前的位置均可以重复使用，==理想情况下，只要读取指针不落后于写入指针一整圈==，这个缓冲区就可以持续工作下去，能==容纳无限多个新字符==。
否则，就必须阻塞写入操作去等待读取清空缓冲区。

![7ecc0d40eaf3e9febc34896ab6cef5e3.png](../_resources/7ecc0d40eaf3e9febc34896ab6cef5e3.png)

。。这个是gif，但是joplin粘贴不了。。
。。就是 write的pointer 一直往前跑，直到套圈。

从 Caffeine 读取数据时，数据本身会在其内部的 ConcurrentHashMap 中直接返回，而==数据的状态==信息变更就==存入环形缓冲==中，由==后台线程异步处理==。
如果异步处理的速度跟不上状态变更的速度，导致缓冲区满了，那此后接收的状态的变更信息就会直接被==丢弃==掉，直至缓冲区重新富余。
通过==环形缓冲==和==容忍有损失的状态变更==，Caffeine 大幅降低了由于数据读取而导致的垃圾收集和锁竞争，因此 Caffeine 的读取性能几乎能与 ConcurrentHashMap 的读取性能相同。

向 Caffeine 写入数据时，将使用传统的==有界队列==（ArrayQueue）来存放状态变更信息，写入带来的状态变更是无损的，不允许丢失任何状态，这是考虑到许多状态的默认值必须通过写入操作来完成初始化，因此写入会有一定的性能损失。根据 Caffeine 官方给出的数据，相比 ConcurrentHashMap，Caffeine 在写入时大约会慢 10%左右。


命中率与淘汰策略

缓存需要在消耗空间与节约时间之间取得平衡，这要求缓存必须能够自动或者由人工淘汰掉缓存中的低价值数据，
由人工管理的缓存淘汰主要取决于开发者如何编码，不能一概而论，这里只讨论由缓存自动进行淘汰的情况。
笔者所说的“缓存如何自动地实现淘汰低价值目标”，现在被称为缓存的淘汰策略，也常称作替换策略或者清理策略。

缓存实现自动淘汰低价值数据的容器之前，首先要定义怎样的数据才算是“低价值”？
由于缓存的通用性，这个问题的答案必须是与具体业务逻辑是无关的，只能从缓存工作过程收集到的统计结果来确定数据是否有价值，通用的统计结果包括但不限于数据==何时进入缓存、被使用过多少次、最近什么时候被使用==，等等。
由此决定了一旦确定选择何种统计数据，及如何通用地、自动地==判定缓存中每个数据价值高低==，也相当于决定了缓存的淘汰策略是如何实现的。目前，最基础的淘汰策略实现方案有以下三种：

- FIFO（First In First Out）：
  优先淘汰最早进入被缓存的数据。FIFO ==实现十分简单==，但一般来说它==并不是优秀的淘汰策略==，越是频繁被用到的数据，往往会越早被存入缓存之中。如果采用这种淘汰策略，很可能会大幅降低缓存的命中率。
- LRU（Least Recent Used）：
  优先淘汰最久未被使用访问过的数据。LRU 通常会采用 HashMap 加 LinkedList 双重结构（如 LinkedHashMap）来实现，以 HashMap 来提供访问接口，保证常量时间复杂度的读取性能，以 LinkedList 的链表元素顺序来表示数据的时间顺序，每次缓存命中时把返回对象调整到 LinkedList 开头，每次缓存淘汰时从链表末端开始清理数据。
  对==大多数==的缓存场景来说，==LRU 都明显要比 FIFO 策略合理==，尤其适合用来处理短时间内频繁访问的热点对象。
  但相反，它的==问题==是如果一些热点数据在系统中经常被频繁访问，但==最近一段时间因为某种原因未被访问过==，此时这些热点数据依然要面临==淘汰==的命运，LRU 依然可能错误淘汰价值更高的数据。
- LFU（Least Frequently Used）：
  优先淘汰最不经常使用的数据。LFU 会给每个数据添加一个访问计数器，每访问一次就加 1，需要淘汰时就清理计数器数值最小的那批数据。
  LFU 可以解决上面 LRU 中热点数据间隔一段时间不访问就被淘汰的问题，但同时它又引入了两个新的问题，
  首先是需要对每个缓存的数据==专门去维护一个计数器==，每次访问都要更新，在上一节“吞吐量”里解释了这样做会带来==高昂的维护开销==；
  另一个问题是不便于处理==随时间变化的热度变化==，譬如某个曾经频繁访问的数据现在不需要了，它也很难自动被清理出缓存。



缓存淘汰策略直接影响缓存的命中率，没有一种策略是完美的、能够满足全部系统所需的。
不过，随着淘汰算法的发展，近年来的确出现了许多相对性能要更好的，也更为复杂的新算法。
以 ==LFU== 分支为例，针对它存在的两个问题，近年来提出的 ==TinyLFU 和 W-TinyLFU== 算法就往往会有更好的效果。

- TinyLFU（Tiny Least Frequently Used）：
  TinyLFU 是 LFU 的改进版本。为了缓解 LFU 每次访问都要修改计数器所带来的性能负担，TinyLFU 会首先采用 Sketch 对访问数据进行分析，所谓 Sketch 是统计学上的概念，指==用少量的样本数据来估计全体数据的特征==，这种做法显然牺牲了一定程度的准确性，但是只要样本数据与全体数据具有相同的概率分布，Sketch 得出的结论仍不失为一种高效与准确之间权衡的有效结论。
  借助==Count–Min Sketch== 算法（可视为==布隆过滤器的一种等价变种==结构），TinyLFU 可以用相对小得多的记录频率和空间来==近似地找出缓存中的低价值数据==。
  为了解决 LFU 不便于处理随时间变化的热度变化问题，TinyLFU 采用了基于“==滑动时间窗==”（在“流量控制”中我们会更详细地分析这种算法）的==热度衰减算法==，简单理解就是==每隔一段时间，便会把计数器的数值减半==，以此解决“旧热点”数据难以清除的问题。
。。每隔一段时间，数值减半，真的6。
- W-TinyLFU（Windows-TinyLFU）：
  W-TinyLFU 又是 TinyLFU 的改进版本。TinyLFU 在实现减少计数器维护频率的同时，也带来了无法很好地应对==稀疏突发访问==的问题，所谓稀疏突发访问是指有一些绝对频率较小，但突发访问频率很高的数据，譬如某些运维性质的任务，也许一天、一周只会在特定时间运行一次，其余时间都不会用到，此时 TinyLFU 就很难让这类元素通过 Sketch 的过滤，因为它们无法在运行期间积累到足够高的频率。
  应对短时间的突发访问是 LRU 的强项，W-TinyLFU 就结合了 ==LRU 和 LFU 两者的优点==，从整体上看是它是 LFU 策略，从局部实现上看又是 LRU 策略。
  具体做法是将新记录暂时放入一个名为 Window Cache 的前端 LRU 缓存里面，让这些对象可以在 Window Cache 中累积热度，如果能通过 TinyLFU 的过滤器，再进入名为 Main Cache 的主缓存中存储，主缓存根据数据的访问频繁程度分为不同的段（LFU 策略，实际上 W-TinyLFU 只分了两段），但单独某一段局部来看又是基于 LRU 策略去实现的（称为 Segmented LRU）。每当前一段缓存满了之后，会将低价值数据淘汰到后一段中去存储，直至最后一段也满了之后，该数据就彻底清理出缓存。

仅靠以上简单的、有限的介绍，你不一定能完全理解 TinyLFU 和 W-TinyLFU 的工作原理，但肯定能看出这些改进算法比起原来基础版本的 LFU 要复杂了许多。有时候为了取得理想的效果，采用较为复杂的淘汰策略是不得已的选择，
Caffeine 官方给出的 W-TinyLFU 以及另外两种高级淘汰策略ARC （Adaptive Replacement Cache）、LIRS （Low Inter-Reference Recency Set）与基础的 LFU 策略之间的对比，如图 4-13 所示

![548ffa7f5c17993fd53430173098940c.png](../_resources/548ffa7f5c17993fd53430173098940c.png)

在搜索场景中，三种高级策略的命中率较为接近于理想曲线（Optimal），而 LRU 则差距最远，Caffeine 官方给出的 数据库、网站、分析类等应用场景中，这几种策略之间的绝对差距不尽相同，但相对排名基本上没有改变，最基础的淘汰策略的命中率是最低的。对其他缓存淘汰策略感兴趣的读者可以参考维基百科中对Cache Replacement Policies的介绍。


#### 扩展功能
一般来说，一套标准的 Map 接口（或者来自JSR 107 的 javax.cache.Cache 接口）就可以满足缓存访问的基本需要，不过在“访问”之外，专业的缓存往往还会提供很多额外的功能。笔者简要列举如下：
- 加载器：
  许多缓存都有“CacheLoader”之类的设计，加载器可以让缓存从只能被动存储外部放入的数据，变为能够==主动通过加载器去加载指定 Key 值的数据==，加载器也是==实现自动刷新功能的基础前提==。
- 淘汰策略：
  有的缓存淘汰策略是固定的，也有一些缓存能够支持用户自己根据需要选择不同的淘汰策略。
- 失效策略：
  要求缓存的数据在一定时间后自动失效（移除出缓存）或者自动刷新（使用加载器重新加载）。
- 事件通知：
  缓存可能会提供一些事件监听器，让你在数据状态变动（如失效、刷新、移除）时进行一些额外操作。有的缓存还提供了对缓存数据本身的监视能力（Watch 功能）。
- 并发级别：
  对于通过分段加锁来实现的缓存（以 Guava Cache 为代表），往往会提供并发级别的设置。
  可以简单将其理解为缓存内部是使用多个 Map 来分段存储数据的，并发级别就用于计算出使用 Map 的数量。
  如果将这个参数设置过大，会引入更多的 Map，需要额外维护这些 Map 而导致更大的时间和空间上的开销；
  如果设置过小，又会导致在访问时产生线程阻塞，因为多个线程更新同一个 ConcurrentMap 的同一个值时会产生锁竞争。
- 容量控制：
  缓存通常都支持指定==初始容量和最大容量==，
  初始容量目的是减少扩容频率，这与 Map 接口本身的初始容量含义是一致的。
  最大容量类似于控制 Java 堆的-Xmx 参数，当缓存接近最大容量时，会自动清理掉低价值的数据。
- 引用方式：
  支持将数据设置为==软引用或者弱引用==，提供引用方式的设置是为了将缓存与 Java 虚拟机的垃圾收集机制联系起来。
- 统计信息：
  提供诸如缓存命中率、平均加载时间、自动回收计数等统计。
- 持久化：
  支持==将缓存的内容存储到数据库或者磁盘==中，进程内缓存提供持久化功能的作用不是太大，但==分布式缓存大多都会考虑提供持久化功能==。


几款主流进程内缓存方案对比
|-|ConcurrentHashMap|Ehcache|Guava Cache|Caffeine|
|--|--|--|--|--|
|访问性能|最高|一般|良好|优秀，接近ConcurrentHashMap|
|淘汰策略|无|支持多种淘汰策略FIFO、LRU、LFU 等|LRU|W-TinyLFU|
|扩展功能|只提供基础的访问接口|并发级别控制,失效策略,容量控制,事件通知,统计信息|大致同左|大致同左|



#### 分布式缓存

相比起缓存数据在进程内存中读写的速度，一旦涉及网络访问，由网络传输、数据复制、序列化和反序列化等操作所导致的延迟要比内存访问高得多，
所以对分布式缓存来说，处理与==网络有相关的操作==是对吞吐量影响更大的因素，往往也是比淘汰策略、扩展功能更重要的关注点，这决定了尽管也有 Ehcache、Infinispan 这类能同时支持分布式部署和进程内嵌部署的缓存方案，
但通常进程内缓存和分布式缓存选型时会有完全不同的候选对象及考察点。我们决定使用哪种分布式缓存前，首先必须确认自己需求是什么？

- 从访问的角度来说，
  如果是频繁更新但甚少读取的数据，通常是不会有人把它拿去做缓存的，因为这样做没有收益。对于甚少更新但频繁读取的数据，理论上更适合做==复制式缓存==；对于更新和读取都较为频繁的数据，理论上就更适合做==集中式缓存==。笔者简要介绍这两种分布式缓存形式的差别与代表性产品：
  - 复制式缓存：
    复制式缓存可以看作是“==能够支持分布式的进程内缓存==”，它的工作原理与 Session 复制类似。
    缓存中所有数据在分布式集群的==每个节点==里面都存在有==一份副本==，读取数据时无须网络访问，直接从当前节点的进程内存中返回，理论上可以做到与进程内缓存一样高的读取性能；当==数据发生变化时，就必须遵循复制协议，将变更同步到集群的每个节点中==，复制性能随着节点的增加呈现平方级下降，变更数据的代价十分高昂。
    复制式缓存的代表是JBossCache，这是 JBoss 针对企业级集群设计的缓存方案，支持 JTA 事务，依靠 JGroup 进行集群节点间数据同步。
    以 JBossCache 为典型的复制式缓存曾有一段短暂的兴盛期，但今天基本上已经==很难再见到使用这种缓存形式==的大型信息系统了，JBossCache 被淘汰的主要原因是==写入性能实在差到不堪入目的程度==，它在小规模集群中同步数据尚算差强人意，但在大规模集群下，很容易就因网络同步的速度跟不上写入速度，进而导致在内存中累计大量待重发对象，最终引发 OutOfMemory 崩溃。
    如果对 JBossCache 没有足够了解的话，稍有不慎就要被埋进坑里。
    为了缓解复制式同步的写入效率问题，JBossCache 的继任者Infinispan提供了另一种分布式同步模式（这种同步模式的名字就叫做“分布式”），允许用户配置数据==需要复制的副本数量==，譬如集群中有八个节点，可以要求每个数据只保存四份副本，此时，缓存的总容量相当于是传统复制模式的一倍，如果要访问的数据在本地缓存中没有存储，Infinispan 完全有能力感知网络的拓扑结构，==知道应该到哪些节点中寻找数据==。
  - 集中式缓存：
    集中式缓存是目前分布式缓存的==主流==形式，集中式缓存的==读、写都需要网络访问==，其==好处是不会随着集群节点数量的增加而产生额外的负担==，其==坏处自然是读、写都不再可能达到进程内缓存那样的高性能==。
    集中式缓存还有一个必须提到的关键特点，它与使用缓存的应用分处在独立的进程空间中，其好处是它能够为==异构语言==提供服务，
    譬如用 C 语言编写的Memcached完全可以毫无障碍地为 Java 语言编写的应用提供缓存服务；
    但其坏处是如果要缓存对象等复杂类型的话，基本上就只能靠序列化来支撑具体语言的类型系统（支持 Hash 类型的缓存，可以部分模拟对象类型），不仅有序列化的成本，还很容易导致传输成本也显著增加。
    举个例子，假设某个有 100 个字段的大对象变更了其中 1 个字段的值，通常缓存也==不得不把整个对象所有内容重新序列化传输出去==才能实现更新，因此，一般集中式缓存更提倡==直接缓存原始数据类型而不是对象==。相比之下，JBossCache 通过它的字节码自审（Introspection）功能和树状存储结构（TreeCache），做到了自动跟踪、处理对象的部分变动，用户修改了对象中哪些字段的数据，缓存就只会同步对象中真正变更那部分数据。
    如今==Redis==广为流行，基本上已经打败了 Memcached 及其他集中式缓存框架，成为==集中式缓存的首选==，甚至可以说成为了==分布式缓存的实质上的首选==，几乎到了不必管读取、写入哪种操作更频繁，都可以无脑上 Redis 的程度。
    也因如此，之前说到哪些数据适合用复制式缓存、哪些数据适合集中式缓存时，笔者都在开头加了个拗口的“理论上”。
    尽管 Redis 最初设计的本意是 NoSQL 数据库而不是专门用来做缓存的，可今天它确实已经成为许多分布式系统中无可或缺的基础设施，广泛用作缓存的实现方案。

- 从数据一致性角度说，
  ==缓存==本身也有==集群部署==的需求，理论上你应该认真考虑一下是否能接受不同节点取到的缓存数据有可能存在差异。
  譬如刚刚放入缓存中的数据，另外一个节点马上访问发现未能读到；刚刚更新缓存中的数据，另外一个节点访问在短时间内读取到的仍是旧的数据，等等。
  根据分布式缓存集群是否能保证数据一致性，可以将它分为 ==AP 和 CP== 两种类型（在“分布式事务”中已介绍过 CAP 各自的含义）。
  此处又一次出现了“理论上”，是因为我们实际开发中通常不太会把追求强一致性的数据使用缓存来处理，可以这样做，但是没必要（可类比 MESI 等缓存一致性协议）。
  譬如，==Redis 集群就是典型的 AP== 式，有着高性能高可用等特点，却并不保证强一致性。
  而能够保证==强一致性的 ZooKeeper、Doozerd、Etcd== 等分布式协调框架，通常不会有人==将它们当为“缓存框架”来使用==，这些分布式协调框架的吞吐量相对 Redis 来说是非常有限的。
  不过 ZooKeeper、Doozerd、Etcd 倒是常与 Redis 和其他分布式缓存搭配工作，用来实现其中的==通知、协调、队列、分布式锁==等功能。


分布式缓存与进程内缓存各有所长，也有各有局限，它们是互补而非竞争的关系，如有需要，完全可以同时把进程内缓存和分布式缓存互相搭配，构成透明多级缓存（Transparent Multilevel Cache，TMC），如图 4-14 所示。
先不考虑“透明”的话，多级缓存是很好理解的，使用进程内缓存做一级缓存，分布式缓存做二级缓存，如果能在一级缓存中查询到结果就直接返回，否则便到二级缓存中去查询，再将二级缓存中的结果回填到一级缓存，以后再访问该数据就没有网络请求了。如果二级缓存也查询不到，就发起对最终数据源的查询，将结果回填到一、二级缓存中去。


![9535b55a65262004a84c9b13b1142561.png](../_resources/9535b55a65262004a84c9b13b1142561.png)


尽管多级缓存结合了进程内缓存和分布式缓存的优点，但它的代码侵入性较大，需要由开发者承担多次查询、多次回填的工作，也不便于管理，如超时、刷新等策略都要设置多遍，数据更新更是麻烦，很容易会出现各个节点的一级缓存、以及二级缓存里数据互相不一致的问题。
必须“透明”地解决以上问题，多级缓存才具有实用的价值。

一种常见的==设计原则==是变更以分布式缓存中的数据为准，访问以进程内缓存的数据优先。大致做法是当数据发生变动时，在集群内发送推送通知（简单点的话可采用 Redis 的 PUB/SUB，求严谨的话引入 ZooKeeper 或 Etcd 来处理），让各个节点的一级缓存自动失效掉相应数据。
当访问缓存时，提供统一封装好的一、二级缓存联合查询接口，接口外部是只查询一次，接口内部自动实现优先查询一级缓存，未获取到数据再自动查询二级缓存的逻辑。


#### 缓存风险

#### 缓存穿透
如果查询的数据在==数据库中根本不存在==的话，缓存里自然也不会有，这类请求的流量每次都不会命中，每次都会触及到末端的数据库，缓存就起不到缓解压力的作用了，这种查询不存在数据的现象被称为缓存穿透。

通常会采取下面两种办法：
- 对于==业务逻辑==本身就不能避免的缓存穿透，
  可以约定在==一定时间内对返回为空的 Key 值依然进行缓存==（注意是正常返回但是结果为空，不应把抛异常的也当作空值来缓存了），使得在一段时间内缓存最多被穿透一次。
  如果后续业务在数据库中对该 Key 值插入了新记录，那应当在==插入之后主动清理掉缓存==的 Key 值。
  如果业务时效性允许的话，也可以将对缓存设置一个较短的超时时间来自动处理。
- 对于恶意攻击导致的缓存穿透，通常会在缓存之前设置一个==布隆过滤器==来解决。
  所谓恶意攻击是指请求者刻意构造数据库中==肯定不存在的 Key== 值，然后==发送大量请求==进行查询。
  布隆过滤器是用最小的代价来判断某个元素是否存在于某个集合的办法。如果布隆过滤器给出的判定结果是请求的数据不存在，那就直接返回即可，连缓存都不必去查。
  虽然维护布隆过滤器本身需要一定的成本，但比起攻击造成的资源损耗仍然是值得的。

。。主键是 int， 发送各种各样 负数的id。

#### 缓存击穿
如果缓存中==某些热点数据==忽然因某种原因==失效==了，
譬如典型地由于超期而失效，此时又有==多个针对该数据的请求同时发送过来==，这些请求将全部未能命中缓存，都到达真实数据源中去，导致其压力剧增，这种现象被称为缓存击穿。
要避免缓存击穿问题，通常会采取下面的两种办法：
- 加锁同步，以请求该数据的 Key 值为锁，使得只有第一个请求可以流入到真实的数据源中，其他线程采取阻塞或重试策略。
  如果是==进程内缓存==出现问题，施加==普通互斥锁==即可，如果是==分布式缓存==中出现的问题，就施==加分布式锁==，这样数据源就不会同时收到大量针对同一个数据的请求了。
- 热点数据由代码来手动管理，缓存击穿是仅针对热点数据被自动失效才引发的问题，对于这类数据，可以直接由开发者==通过代码来有计划地完成更新、失效==，避免由缓存的策略自动管理。

。。部分key 永不过期。 部分key 主动刷新。 存活时间 随机。


#### 缓存雪崩
缓存击穿是针对==单个==热点数据失效，由大量请求击穿缓存而给真实数据源带来压力。
有另一种可能是更普遍的情况，不需要是针对单个热点数据的大量请求，而是由于==大批不同的数据在短时间内一起失效==，导致了这些数据的请求都击穿了缓存到达数据源，同样令数据源在短时间内压力剧增。

出现这种情况，往往是系统有专门的==缓存预热==功能，也可能大量公共数据是由某一次冷操作加载的，这样都可能出现由此载入缓存的大批数据具有相同的过期时间，在同一时刻一起失效。
还有一种情况是缓存服务由于某些原因崩溃后==重启==，此时也会造成大量数据同时失效，这种现象被称为缓存雪崩。要避免缓存雪崩问题，通常会采取下面的三种办法：

- 提升缓存系统可用性，建设分布式缓存的集群。
- 启用透明多级缓存，各个服务节点一级缓存中的数据通常会具有不一样的加载时间，也就分散了它们的过期时间。
- 将缓存的生存期从固定时间改为一个时间段内的随机时间，譬如原本是一个小时过期，那可以缓存不同数据时，设置生存期为 55 分钟到 65 分钟之间的某个随机时间。



#### 缓存污染

缓存污染是指==缓存中的数据与真实数据源中的数据不一致==的现象。
尽管笔者在前面是说过缓存通常不追求强一致性，但这显然不能等同于缓存和数据源间连最终的一致性都可以不要求了。

缓存污染多数是由开发者更新缓存不规范造成的
譬如你从缓存中获得了某个对象，更新了对象的属性，但最后因为某些原因，譬如后续业务发生异常回滚了，最终没有成功写入到数据库，此时缓存的数据是新的，数据库中的数据是旧的。

为了尽可能的提高使用缓存时的一致性，已经总结不少更新缓存可以遵循设计模式，
譬如 ==Cache Aside、Read/Write Through、Write Behind Caching== 等。
其中最简单、成本最低的 Cache Aside 模式是指：
- 读数据时，先读缓存，缓存没有的话，再读数据源，然后将数据放入缓存，再响应请求。
- 写数据时，先写数据源，然后==失效==（而不是更新）掉缓存。

写数据时强调两点：
一是先后顺序是==先数据源后缓存==。
另一点是==应当失效==缓存，而不是去尝试更新缓存

如果去更新缓存，更新过程中数据源又被其他请求再次修改的话，缓存又要面临处理多次赋值的复杂时序问题

Cache Aside 模式依然是不能保证在一致性上绝对不出问题的，否则就无须设计出Paxos这样复杂的共识算法了。
典型的出错场景是如果某个数据是从未被缓存过的，请求会直接流到真实数据源中，如果数据源中的写操作发生在查询请求之后，结果回填到缓存之前，也会出现缓存中回填的内容与数据库的实际数据不一致的情况。
但这种情况的概率是很低的，Cache Aside 模式仍然是以低成本更新缓存，并且获得相对可靠结果的解决方案。


## 架构安全性

http://icyfenix.cn/architect-perspective/general-architecture/system-security/

我们谈论的计算机系统安全，不仅仅是指“防御系统被黑客攻击”这样狭隘的安全，还至少应包括（不限于）以下这些问题的具体解决方案：

- 认证（Authentication）：
  系统如何正确分辨出操作用户的真实身份？
- 授权（ Authorization）：
  系统如何控制一个用户该看到哪些数据、能操作哪些功能？
- 凭证（Credential）：
  系统如何保证它与用户之间的承诺是双方当时真实意图的体现，是准确、完整且不可抵赖的？
- 保密（Confidentiality）：
  系统如何保证敏感数据无法被包括系统管理员在内的内外部人员所窃取、滥用？
- 传输（Transport Security）：
  系统如何保证通过网络传输的信息无法被第三方窃听、篡改和冒充？
- 验证（Verification）：
  系统如何确保提交到每项服务中的数据是合乎规则的，不会对系统稳定性、数据一致性、正确性产生风险？

还有其他一些安全相关的内容主要是由管理、运维、审计领域为主导，尽管也需要软件架构和开发的配合参与，但不列入本章的讨论范围之内，
譬如：安全审计、系统备份与恢复、信息系统安全法规与制度、计算机防病毒制度、保护私有信息规则，等等。



### 认证

认证（Authentication）
系统如何正确分辨出操作用户的真实身份？

==认证、授权和凭证==可以说是一个系统中最基础的安全设计，哪怕再简陋的信息系统，大概也不可能忽略掉“用户登录”功能。
信息系统为用户提供服务之前，总是希望先弄清楚“==你是谁？”（认证）、“你能干什么？”（授权）以及“你如何证明？==”（凭证）这三个基本问题。
账户和权限信息的存储、管理与使用都面临一系列复杂的问题。对于某些大规模的信息系统，账户和权限的管理往往要由专门的基础设施来负责，譬如微软的活动目录 （Active Directory，AD）或者轻量目录访问协议 （Lightweight Directory Access Protocol，LDAP），跨系统的共享使用甚至会用到区块链技术。

另外还有一个认知偏差：尽管“认证”是解决“你是谁？”的问题，但这里的“你”并不一定是指人（真不是在骂你），也可能是指外部的代码，即第三方的类库或者服务。


#### 认证的标准

在 1999 年，随 J2EE 1.2（它是 J2EE 的首个版本，为了与 J2SE 同步，初始版本号直接就是 1.2）发布的 Servlet 2.2 中，添加了一系列用于认证的 API，主要包括下列两部分内容：

- 标准方面，
  添加了四种内置的、不可扩展的认证方案，即 Client-Cert、Basic、Digest 和 Form。
- 实现方面，
  添加了与认证和授权相关的一套程序接口，譬如HttpServletRequest::isUserInRole()、HttpServletRequest::getUserPrincipal()等方法。

笔者之所以引用这件事，是希望从它包含的两部分内容中引出一个架构安全性的经验原则：==以标准规范为指导、以标准接口去实现==。

Basic、Digest、Form 和 Client-Cert 这四种认证方案都很有代表性，刚好分别覆盖了==通信信道、协议和内容==层面的认证。而这三种层面认证恰好涵盖了主流的三种认证方式，具体含义和应用场景列举如下。

- 通信信道上的认证：
  你和我建立通信连接之前，要先证明你是谁。在网络传输（Network）场景中的典型是基于 SSL/TLS 传输安全层的认证。
- 通信协议上的认证：
  你请求获取我的资源之前，要先证明你是谁。在互联网（Internet）场景中的典型是基于 HTTP 协议的认证。
- 通信内容上的认证：
  你使用我提供的服务之前，要先证明你是谁。在万维网（World Wide Web）场景中的典型是基于 Web 内容的认证。


关于通信信道上的认证，由于内容较多，又与后续介绍微服务安全方面的话题关系密切，将会独立放到本章的“传输”里，而且 J2EE 中的 Client-Cert 其实并不是用于 TLS 的，以它引出 TLS 并不合适。下面重点了解基于通信协议和通信内容的两种认证方式。


#### HTTP 认证

IETF 在RFC 7235 中定义了 HTTP 协议的通用认证框架，要求所有支持 HTTP 协议的服务器，在未授权的用户意图访问服务端保护区域的资源时，应返回 401 Unauthorized 的状态码，同时应在响应报文头里附带以下两个分别代表网页认证和代理认证的 Header 之一，告知客户端应该采取何种方式产生能代表访问者身份的凭证信息：
```text
WWW-Authenticate: <认证方案> realm=<保护区域的描述信息>
Proxy-Authenticate: <认证方案> realm=<保护区域的描述信息>
```

接收到该响应后，客户端必须遵循服务端指定的认证方案，在请求资源的报文头中加入身份凭证信息，由服务端核实通过后才会允许该请求正常返回，否则将返回 403 Forbidden 错误。请求头报文应包含以下 Header 项之一：
```text
Authorization: <认证方案> <凭证内容>
Proxy-Authorization: <认证方案> <凭证内容>
```



#### Web认证

WebAuthn 规范涵盖了“注册”与“认证”两大流程，先来介绍注册流程，它大致可以分为以下步骤：

- 用户进入系统的注册页面，这个页面的格式、内容和用户注册时需要填写的信息均不包含在 WebAuthn 标准的定义范围内。
- 当用户填写完信息，点击“提交注册信息”的按钮后，服务端先暂存用户提交的数据，生成一个随机字符串（规范中称为 Challenge）和用户的 UserID（在规范中称作凭证 ID），返回给客户端。
- 客户端的 WebAuthn API 接收到 Challenge 和 UserID，把这些信息发送给验证器（Authenticator），验证器可理解为用户设备上 TouchID、FaceID、实体密钥等认证设备的统一接口。
- 验证器提示用户进行验证，如果支持多种认证设备，还会提示用户选择一个想要使用的设备。验证的结果是生成一个密钥对（公钥和私钥），由验证器存储私钥、用户信息以及当前的域名。然后使用私钥对 Challenge 进行签名，并将签名结果、UserID 和公钥一起返回客户端。
- 浏览器将验证器返回的结果转发给服务器。
- 服务器核验信息，检查 UserID 与之前发送的是否一致，并用公钥解密后得到的结果与之前发送的 Challenge 相比较，一致即表明注册通过，由服务端存储该 UserID 对应的公钥。


登录流程与注册流程类似，如果你理解了注册流程，就很容易理解登录流程了。登录流程大致可以分为以下步骤：

- 用户访问登录页面，填入用户名后即可点击登录按钮。
- 服务器返回随机字符串 Challenge、用户 UserID。
- 浏览器将 Challenge 和 UserID 转发给验证器。
- 验证器提示用户进行认证操作。由于在注册阶段验证器已经存储了该域名的私钥和用户信息，所以如果域名和用户都相同的话，就不需要生成密钥对了，直接以存储的私钥加密 Challenge，然后返回给浏览器。
- 服务端接收到浏览器转发来的被私钥加密的 Challenge，以此前注册时存储的公钥进行解密，如果解密成功则宣告登录成功。


#### 认证的实现

Java 其实也有自己的认证规范，第一个系统性的 Java 认证规范发布于 Java 1.3 时代，是由 Sun 公司提出的同时面向代码级安全和用户级安全的认证授权服务——JAAS（Java Authentication and Authorization Service，Java 认证和授权服务，Java 1.3 处于扩展包中，Java 1.4 时纳入标准包）。
尽管 JAAS 已经考虑了最终用户的认证，但代码级安全在规范中仍然占更主要的地位。
可能今天用过甚至听过 JAAS 的 Java 程序员都已经不多了，但是这个规范提出了很多在今天仍然活跃于主流 Java 安全框架中的概念，譬如一般把用户存放在“Principal”之中、密码存在“Credentials”之中、登录后从安全上下文“Context”中获取状态等常见的安全概念，都可以追溯到这一时期所定下的 API：
- LoginModule （javax.security.auth.spi.LoginModule）
- LoginContext （javax.security.auth.login.LoginContext）
- Subject （javax.security.auth.Subject）
- Principal （java.security.Principal）
- Credentials（javax.security.auth.Destroyable、javax.security.auth.Refreshable）

Java 社区一直有做持续的增强和补救，譬如 Java EE 6 中的 JASPIC、Java EE 8 中的 EE Security：
- JSR 115：Java Authorization Contract for Containers（JACC）
- JSR 196：Java Authentication Service Provider Interface for Containers（JASPIC）
- JSR 375： Java EE Security API（EE Security）

EJB的失败使得依赖于容器安全的 JAAS 无法得到大多数人的认可。

在今时今日，实际活跃于 Java 安全领域的是两个私有的（私有的意思是不由 JSR 所规范的，即没有 java/javax.*作为包名的）的安全框架：==Apache Shiro 和Spring Security==。

相较而言，Shiro 更便捷易用，而 Spring Security 的功能则要复杂强大一些。
无论是单体架构还是微服务架构的 Fenix's Bookstore，笔者都选择了 Spring Security 作为安全框架，这个选择与功能、性能之类的考量没什么关系，就只是因为 Spring Boot、Spring Cloud 全家桶的缘故。
这里不打算罗列代码来介绍 Shiro 与 Spring Security 的具体使用，如感兴趣可以参考 Fenix's Bookstore 的源码仓库。只从目标上看，两个安全框架提供的功能都很类似，大致包括以下四类：
- 认证功能：以 HTTP 协议中定义的各种认证、表单等认证方式确认用户身份，这是本节的主要话题。
- 安全上下文：用户获得认证之后，要开放一些接口，让应用可以得知该用户的基本资料、用户拥有的权限、角色，等等。
- 授权功能：判断并控制认证后的用户对什么资源拥有哪些操作许可，这部分内容会放到“授权”介绍。
- 密码的存储与验证：密码是烫手的山芋，存储、传输还是验证都应谨慎处理，我们会放到“保密”去具体讨论。


### 授权

授权（ Authorization）
系统如何控制一个用户该看到哪些数据、能操作哪些功能？

授权这个概念通常伴随着认证、审计、账号一同出现，并称为 `AAAA（Authentication、Authorization、Audit、Account，也有一些领域把 Account 解释为计费的意思）`。授权行为在程序中的应用非常广泛，给某个类或某个方法设置范围控制符（`public、protected、private、<Package>`）在本质上也是一种授权（访问控制）行为。而在安全领域中所说的授权就更具体一些，通常涉及以下两个相对独立的问题：

- 确保授权的过程可靠：
  对于单一系统来说，授权的过程是比较容易做到可控的，以前很多语境上提到授权，实质上讲的都是访问控制，理论上两者是应该分开的。而在涉及多方的系统中，授权过程则是一个比较困难却必须严肃对待的问题：如何既让第三方系统能够访问到所需的资源，又能保证其不泄露用户的敏感数据呢？常用的多方授权协议主要有 OAuth2 和 SAML 2.0（两个协议涵盖的功能并不是直接对等的）。
- 确保授权的结果可控：
  授权的结果用于对程序功能或者资源的访问控制
（Access Control），成理论体系的权限控制模型有很多，譬如自主访问控制 （Discretionary Access Control，DAC）、强制访问控制 （Mandatory Access Control，MAC）、基于属性的访问控制 （Attribute-Based Access Control，ABAC），还有最为常用的基于角色的访问控制 （Role-Based Access Control，RBAC）。


日常开发中最常用到的 RBAC 和 OAuth2 这两种访问控制和授权方案。


#### RBAC

谁（User）拥有什么权限（Authority）去操作（Operation）哪些资源（Resource）

RBAC 模型在业界中有多种说法，其中以美国 George Mason 大学信息安全技术实验室提出的 RBAC96 模型最具有系统性，得到普遍的认可。
为了避免对每一个用户设定权限，RBAC ==将权限从用户身上剥离==，改为==绑定到“角色==”（Role）上，将权限控制变为对“角色拥有操作哪些资源的许可”这个逻辑表达式的值是否为真的求解过程。

![5cec54de1d9e1989fa6c2813e359e8c4.png](../_resources/5cec54de1d9e1989fa6c2813e359e8c4.png)


许可是抽象权限的具象化体现，权限在 RBAC 系统中的含义是“允许何种操作作用于哪些资源之上”，这句话的具体实例即为“许可”。
提出许可这个概念的目的其实与提出角色的目的是完全一致的，只是更为抽象。角色为的是解耦用户与权限之间的多对多关系，而==许可为的是解耦操作与资源之间的多对多关系==，譬如不同的数据都能够有增、删、改等操作，如果将数据与操作搅和在一起也会面临配置膨胀问题。

采用 RBAC 不仅是为了简化配置操作，还天然地满足了计算机安全中的“最小特权原则 ”（Least Privilege）。
在 RBAC 模型中，角色拥有许可的数量是根据完成该角色工作职责所需的最小权限来赋予的，最典型例子是操作系统权限管理中的用户组，根据对不同角色的职责分工，如管理员（Administrator）、系统用户（System）、验证用户（Authenticated Users）、普通用户（Users）、来宾用户（Guests）等分配各自的权限，既保证用户能够正常工作，也避免用户出现越权操作的风险。
当用户的职责发生变化时，在系统中就体现为它所隶属的角色被改变，譬如将“普通用户角色”改变“管理员角色”，就可以迅速让该用户具备管理员的多个细分权限，==降低权限分配错误的风险==。

RBAC 还允许对不同角色之间定义关联与约束，进一步强化它的抽象描述能力。
如不同的角色之间可以有==继承性==，典型的是 RBAC-1 模型的角色权限继承关系。

。。用户是多变的，来个人就要增加一个用户， 但是角色，一般来说，基本不会改变。

不同==角色之间也可以具有互斥性==，典型的是 RBAC-2 模型的角色职责分离关系。
互斥性要求权限被赋予角色时，或角色被赋予用户时应遵循的强制性职责分离规定。举个例子，角色的互斥约束可限制同一用户只能分配到一组互斥角色集合中至多一个角色，譬如==不能让同一名员工既当会计，也当出纳==，否则资金安全无法保证。
角色的基数约束可限制某一个用户拥有的最大角色数目，譬如不能让同一名员工从产品、设计、开发、测试全部包揽，否则产品质量无法保证。

建立访问控制模型的基本目的是为了管理垂直权限和水平权限。
垂直权限即功能权限，譬如前面提到的审稿编辑有通过审核的权限、开发经理有代码提交的权限、出纳有从账户提取资金的权限，这一类某个角色完成某项操作的许可，都可以直接翻译为功能权限。
由于实际应用与权限模型具有高度对应关系，将权限从具体的应用中抽离出来，放到通用的模型中是相对容易的，Spring Security、Apache Shiro 等权限框架就是这样的抽象产物，大多数系统都能采用这些权限框架来管理功能权限。

水平权限即数据权限管理起来则要困难许多。譬如用户 A、B 都属于同一个角色，但它们各自在系统中产生的数据完全有可能是私有的，A 访问或删除了 B 的数据也照样属于越权。
一般来说，数据权限是很难抽象与通用的，仅在角色层面控制并不能满足全部业务的需要，很多时候只能具体到用户，甚至要具体管理到发生数据的某一行、某一列之上，因此数据权限基本只能由信息系统自主来来完成，并不存在能放之四海皆准的通用数据权限框架

Kubernetes 完全遵循了 RBAC 来进行服务访问控制，
Fenix's Bookstore 所使用的 Spring Security 也参考了（但并没有完全遵循）RBAC 来设计它的访问控制功能。
Spring Security 的设计里，用户和角色都可以拥有权限，譬如在它的 HttpSecurity 接口就同时有着 hasRole()和 hasAuthority()方法，可能刚接触的程序员会疑惑，混淆它们之间的关系。Spring Security 的访问控制模型如图 5-6 所示，可与前面 RBAC 的关系图对比一下。

![445509cb27650944df981b9e45209486.png](../_resources/445509cb27650944df981b9e45209486.png)

Spring Security 中的 Role 和 Authority 的差异很小，它们完全共享同一套存储结构，唯一的差别仅是 Role 会在存储时自动带上“ROLE_”前缀罢了。
但从使用角度来看，Role 和 Authority 的差异可以很大，用户可以自行决定系统中到底 Permission 只能对应到角色身上，还是可以让用户也拥有某些角色中没有的权限。
这一点不符合 RBAC 的思想，但笔者个人认同这是一种创新而非破坏，在 Spring Security 的文档上说的很清楚：这取决于你自己如何使用。


#### OAuth2
相对更复杂烦琐的 OAuth2 认证授权协议（更烦琐的 OAuth1 已经完全被废弃了）。

OAuth2 是在RFC 6749 中定义的国际标准，在 RFC 6749 正文的第一句就阐明了 OAuth2 是面向于==解决第三方应用==（Third-Party Application）的认证授权协议。
如果你的系统并不涉及第三方，那引入 OAuth2 其实并无必要。

譬如你现在正在阅读的这个网站（https://icyfenix.cn ），它的建设和更新大致流程是：
笔者以 Markdown 形式写好了某篇文章，
上传到由GitHub 提供的代码仓库 ，
接着由Travis-CI 提供的持续集成服务会检测到该仓库发生了变化，触发一次 Vuepress 编译活动，生成目录和静态的 HTML 页面，然后推送回GitHub Pages ，再触发国内的 CDN 缓存刷新。

这个过程要能顺利进行，就存在一系列必须解决的授权问题，Travis-CI 只有得到了我的明确授权，GitHub 才能同意它读取我代码仓库中的内容，问题是它该如何获得我的授权呢？一种最简单粗暴的方案是把我的用户账号和密码都告诉 Travis-CI，但这显然导致了以下这些问题：

- 密码泄漏：
  如果 Travis-CI 被黑客攻破，将导致我的 GitHub 的密码也同时被泄漏。
- 访问范围：
  Travis-CI 将有能力读取、修改、删除、更新我放在 GitHub 上的所有代码仓库，而我并不希望它能够修改删除文件。
- 授权回收：
  只有修改密码才能回收我授予给 Travis-CI 的权力，可是我在 GitHub 的密码只有一个，授权的应用除了 Travis-CI 之外却还有许多，修改了意味着所有别的第三方的应用程序会全部失效。

以上列举的这些问题，也正是 OAuth2 所要解决的问题，尤其是要求第三方系统没有支持 HTTPS 传输安全的环境下依然能够解决这些问题，这并非易事。

OAuth2 给出了多种解决办法，这些办法的共同特征是以令牌（Token）代替用户密码作为授权的凭证。
有了令牌之后，哪怕令牌被泄漏，也不会导致密码的泄漏；令牌上可以设定访问资源的范围以及时效性；每个应用都持有独立的令牌，哪个失效都不会波及其他。
这样上面提出的三个问题就都解决了

![9d536150c3211a83bc5df89460630b9c.png](../_resources/9d536150c3211a83bc5df89460630b9c.png)

OAuth2 中几个关键术语
- 第三方应用（Third-Party Application）：
  需要得到授权访问我资源的那个应用，即此场景中的“Travis-CI”。
- 授权服务器（Authorization Server）：
  能够根据我的意愿提供授权（授权之前肯定已经进行了必要的认证过程，但它与授权可以没有直接关系）的服务器，即此场景中的“GitHub”。
- 资源服务器（Resource Server）：
  能够提供第三方应用所需资源的服务器，它与认证服务可以是相同的服务器，也可以是不同的服务器，此场景中的“我的代码仓库”。
- 资源所有者（Resource Owner）： 
  拥有授权权限的人，即此场景中的“我”。
- 操作代理（User Agent）：
  指用户用来访问服务器的工具，对于人类用户来说，这个通常是指浏览器，但在微服务中一个服务经常会作为另一个服务的用户，此时指的可能就是 HttpClient、RPCClient 或者其他访问途径。


“用令牌代替密码”确实是解决问题的好方法，但这充其量只能算个思路，距离可实施的步骤还是不够具体的，时序图中的“要求/同意授权”、“要求/同意发放令牌”、“要求/同意开放资源”几个服务请求、响应该如何设计，这就是执行步骤的关键了。对此，OAuth2 一共提出了四种不同的授权方式（这也是 OAuth2 复杂烦琐的主要原因），分别为：
- 授权码模式（Authorization Code）
- 隐式授权模式（Implicit）
- 密码模式（Resource Owner Password Credentials）
- 客户端模式（Client Credentials）

##### 授权码模式

授权码模式是四种模式中最严（luō）谨（suō）的，它考虑到了几乎所有敏感信息泄漏的预防和后果。具体步骤的时序如图 5-8 所示。

![04c1a6059ea916224aa56d711543c295.png](../_resources/04c1a6059ea916224aa56d711543c295.png)


##### 隐式授权模式
隐式授权省略掉了通过授权码换取令牌的步骤，整个授权过程都不需要服务端支持，一步到位。
代价是在隐式授权中，授权服务器不会再去验证第三方应用的身份，因为已经没有应用服务器了，ClientSecret 没有人保管，就没有存在的意义了。
但其实还是会限制第三方应用的回调 URI 地址必须与注册时提供的域名一致，尽管有可能==被 DNS 污染==之类的攻击所攻破，但仍算是尽可能努力一下。
同样的原因，也==不能避免==令牌暴露给资源所有者，==不能避免==用户机器上可能意图不轨的其他程序、HTTP 的中间人攻击等风险了。

![b1144562a3ce8343cb8d1c08fa90b558.png](../_resources/b1144562a3ce8343cb8d1c08fa90b558.png)

隐式模式与授权码模式的显著区别是授权服务器在得到用户授权后，直接返回了访问令牌，这显著地降低了安全性

##### 密码模式
前面所说的授权码模式和隐私模式属于纯粹的授权模式，它们与认证没有直接的联系，如何认证用户的真实身份是与进行授权互相独立的过程。但在密码模式里，认证和授权就被整合成了同一个过程了。

密码模式原本的设计意图是仅限于用户对第三方应用是高度可信任的场景中使用，因为用户需要把密码明文提供给第三方应用，第三方以此向授权服务器获取令牌。
这种高度可信的第三方是极为较罕见的，尽管介绍 OAuth2 的材料中，经常举的例子是“操作系统作为第三方应用向授权服务器申请资源”，但真实应用中==极少遇到==这样的情况，合理性依然十分有限。

![4d44cd39c50f80352bb786f725c783cf.png](../_resources/4d44cd39c50f80352bb786f725c783cf.png)


##### 客户端模式
客户端模式是四种模式中最简单的，它只涉及到两个主体，第三方应用和授权服务器。
如果严谨一点，现在称“第三方应用”其实已经不合适了，因为已经没有了“第二方”的存在，资源所有者、操作代理在客户端模式中都是不必出现的。
甚至严格来说叫“授权”都已不太恰当，资源所有者都没有了，也就不会有谁授予谁权限的过程

![1050f80a02777fa03f65876312cdef53.png](../_resources/1050f80a02777fa03f65876312cdef53.png)

OAuth2 中还有一种与客户端模式类似的授权模式，在RFC 8628 中定义为“设备码模式”（Device Code），这里顺带提一下。
设备码模式用于在无输入的情况下区分设备是否被许可使用，典型的应用便是手机锁网解锁（锁网在国内较少，但在国外很常见）或者设备激活（譬如某游戏机注册到某个游戏平台）的过程。





### 凭证
凭证（Credentials）
系统如何保证它与用户之间的承诺是双方当时真实意图的体现，是准确、完整且不可抵赖的？

在前面介绍 OAuth2 的内容中，每一种授权模式的最终目标都是拿到访问令牌，但从未涉及过拿回来的令牌应该长什么样子。
反而还挖了一些坑没有填（为何说 OAuth2 的一个主要缺陷是令牌难以主动失效）。
这节讨论的主角是令牌，同时，还会讨论如果不使用 OAuth2，如何以最传统的方式完成认证、授权。

“如何承载认证授权信息”这个问题的不同看法，代表了软件架构对待共享状态信息的两种不同思路：状态应该维护在服务端，抑或是在客户端之中？
在分布式系统崛起以前，这个问题原本已是有了较为统一的结论的，以 HTTP 协议的 Cookie-Session 机制为代表的服务端状态存储在三十年来都是主流的解决方案。
不过，到了最近十年，由于分布式系统中共享数据必然会受到 CAP 不兼容原理的打击限制，迫使人们重新去审视之前已基本放弃掉的客户端状态存储，这就让原本通常只在多方系统中采用的 JWT 令牌方案，在分布式系统中也有了另一块用武之地。
本节的话题，也就围绕着 Cookie-Session 和 JWT 之间的相同与不同而展开。


#### Cookie-Session

 HTTP 协议是一种无状态的传输协议，无状态是指协议对事务处理没有上下文的记忆能力，每一个请求都是完全独立的，
 但是我们中肯定有许多人并没有意识到 HTTP 协议无状态的重要性。
 假如你做了一个简单的网页，其中包含了 1 个 HTML、2 个 Script 脚本、3 个 CSS、还有 10 张图片，这个网页成功展示在用户屏幕前，需要完成 16 次与服务端的交互来获取上述资源，由于网络传输各种等因素的影响，服务器发送的顺序与客户端请求的先后并没有必然的联系，按照可能出现的响应顺序，理论上最多会有 P(16,16) = 20,922,789,888,000 种可能性。
 试想一下，如果 HTTP 协议不是设计成无状态的，这 16 次请求每一个都有依赖关联，先调用哪一个、先返回哪一个，都会对结果产生影响的话，那协调工作会有多么复杂。

可是，HTTP 协议的无状态特性又有悖于我们最常见的网络应用场景，典型就是认证授权，系统总得要获知用户身份才能提供合适的服务，
因此，我们也希望 HTTP 能有一种手段，让服务器至少有办法能够区分出发送请求的用户是谁。为了实现这个目的，RFC 6265 规范定义了 HTTP 的状态管理机制，在 HTTP 协议中增加了 Set-Cookie 指令，该指令的含义是以键值对的方式==向客户端发送==一组信息，此信息将在此后一段时间内的每次 HTTP 请求中，以名为 Cookie 的 Header 附带着重新发回给服务端，以便服务端区分来自不同客户端的请求。一个典型的 Set-Cookie 指令如下所示：
`Set-Cookie: id=icyfenix; Expires=Wed, 21 Feb 2020 07:28:00 GMT; Secure; HttpOnly`

收到该指令以后，客户端再对同一个域的请求中就会==自动附带==有键值对信息id=icyfenix，譬如以下代码所示：
```http
GET /index.html HTTP/2.0
Host: icyfenix.cn
Cookie: id=icyfenix
```

根据每次请求传到服务端的 Cookie，服务器就能分辨出请求来自于哪一个用户。
由于 Cookie 是放在请求头上的，属于额外的传输负担，不应该携带过多的内容，而且放在 Cookie 中传输也并==不安全==，容易被中间人窃取或被篡改，所以通常是不会像例子中设置id=icyfenix这样的明文信息。
一般来说，系统会把状态信息保存在服务端，在 Cookie 里只==传输的是一个无字面意义==的、不重复的字符串，习惯上以==sessionid或者jsessionid==为名，==服务器==拿这个字符串为 Key，在内存中开辟一块空间，以 Key/Entity 的结构==存储每一个在线用户的上下文状态==，再辅以一些超时自动清理之类的管理措施。
这种服务端的状态管理机制就是今天大家非常熟悉的 Session，Cookie-Session 也是最传统但今天依然广泛应用于大量系统中的，由服务端与客户端联动来完成的状态管理机制。

Session-Cookie 在单节点的单体服务环境中是最合适的方案，但当需要水平扩展服务能力，要部署集群时就开始面临麻烦了，由于 Session 存储在服务器的内存中，当服务器水平拓展成多节点时，设计者必须在以下三种方案中选择其一：

- 牺牲集群的一致性（Consistency），
  让均衡器采用亲和式的负载均衡算法，譬如根据用户 IP 或者 Session 来分配节点，每一个特定用户发出的==所有请求都一直被分配到其中某一个节点==来提供服务，每个节点都不重复地保存着一部分用户的状态，如果这个节点崩溃了，里面的用户状态便完全丢失。
- 牺牲集群的可用性（Availability），
  让各个节点之间采用==复制式的 Session==，每一个节点中的 Session 变动都会发送到组播地址的其他服务器上，这样某个节点崩溃了，不会中断都某个用户的服务，但 Session 之间组播复制的==同步代价高昂==，节点越多时，同步成本越高。
- 牺牲集群的分区容忍性（Partition Tolerance），
  让普通的服务节点中不再保留状态，将==上下文集中放在一个所有服务节点都能访问到的数据节点中==进行存储。
  此时的矛盾是数据节点就成为了单点，一旦数据节点损坏或出现网络分区，整个集群都不再能提供服务。


分布式环境中的状态管理一定会受到 CAP 的局限，无论怎样都不可能完美。

JWT 令牌与 Cookie-Session 并不是完全对等的解决方案，它只用来处理认证授权问题，充其量能携带少量非敏感的信息，只是 Cookie-Session 在认证授权问题上的替代品，而不能说 JWT 要比 Cookie-Session 更加先进，更不可能全面取代 Cookie-Session 机制。


#### JWT JSON Web Token

当服务器存在多个，客户端只有一个时，把状态信息存储在客户端，每次随着请求发回服务器去
这样做的缺点是无法携带大量信息，而且有泄漏和篡改的安全风险

确保信息==不被中间人篡改==则还是可以实现的，JWT 便是这个问题的标准答案。

JWT（JSON Web Token）定义于RFC 7519 标准之中，是目前广泛使用的一种令牌格式，尤其经常与 OAuth2 配合应用于分布式的、涉及多方的应用系统中


![42fe043f15adb82ce24286bda980574f.png](../_resources/42fe043f15adb82ce24286bda980574f.png)


右边的状态信息是对令牌使用 Base64URL 转码后得到的明文，请特别注意是明文，JWT 只解决防篡改的问题，并不解决防泄漏的问题，因此令牌默认是不加密的。
尽管你自己要加密也并不难做到，接收时自行解密即可，但这样做其实没有太大意义，原因笔者将在下一节“保密”中去解释。

右边的 JSON 结构是 JWT 令牌中携带的信息，左边的字符串呈现了 JWT 令牌的本体。
它最常见的使用方式是附在名为 Authorization 的 Header 发送给服务端，前缀在RFC 6750 中被规定为 Bearer。
如果你没有忘记“认证方案”与“OAuth 2”的内容，那看到 Authorization 这个 Header 与 Bearer 这个前缀时，便应意识到它是 HTTP 认证框架中的 OAuth 2 认证方案。如下代码展示了一次采用 JWT 令牌的 HTTP 实际请求：

```http
GET /restful/products/1 HTTP/1.1
Host: icyfenix.cn
Connection: keep-alive
Authorization: Bearer eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJ1c2VyX25hbWUiOiJpY3lmZW5peCIsInNjb3BlIjpbIkFMTCJdLCJleHAiOjE1ODQ5NDg5NDcsImF1dGhvcml0aWVzIjpbIlJPTEVfVVNFUiIsIlJPTEVfQURNSU4iXSwianRpIjoiOWQ3NzU4NmEtM2Y0Zi00Y2JiLTk5MjQtZmUyZjc3ZGZhMzNkIiwiY2xpZW50X2lkIjoiYm9va3N0b3JlX2Zyb250ZW5kIiwidXNlcm5hbWUiOiJpY3lmZW5peCJ9.539WMzbjv63wBtx4ytYYw_Fo1ECG_9vsgAn8bheflL8
```

从明文中可以看到 JWT 令牌是以 JSON 结构（毕竟名字就叫 JSON Web Token）存储的，结构总体上可划分为三个部分，每个部分间用点号.分隔开。

第一部分是令牌头（Header），内容如下所示：
```json
{
  "alg": "HS256",
  "typ": "JWT"
}
```
它描述了令牌的类型（统一为 typ:JWT）以及令牌签名的算法，示例中 HS256 为 HMAC SHA256 算法的缩写，其他各种系统支持的签名算法可以参考https://jwt.io/网站所列。


在本节及后面其他关于安全的内容中，经常会在某种哈希算法前出现“HMAC”的前缀，这是指散列消息认证码（Hash-based Message Authentication Code，HMAC）。可以简单将它理解为一种带有密钥的哈希摘要算法，实现形式上通常是把密钥以加盐方式混入，与内容一起做哈希摘要。

HMAC 哈希与普通哈希算法的差别是普通的哈希算法通过 Hash 函数结果易变性保证了原有内容未被篡改，HMAC 不仅保证了内容未被篡改过，还保证了该哈希确实是由密钥的持有人所生成的。


令牌的第二部分是负载（Payload），这是令牌真正需要向服务端传递的信息。
针对认证问题，负载至少应该包含能够告知服务端“这个用户是谁”的信息，针对授权问题，令牌至少应该包含能够告知服务端“这个用户拥有什么角色/权限”的信息。
JWT 的负载部分是可以完全自定义的，根据具体要解决的问题不同，设计自己所需要的信息，只是总容量不能太大，毕竟要受到 HTTP Header 大小的限制。一个 JWT 负载的例子如下所示
```json
{
  "username": "icyfenix",
  "authorities": [
    "ROLE_USER",
    "ROLE_ADMIN"
  ],
  "scope": [
    "ALL"
  ],
  "exp": 1584948947,
  "jti": "9d77586a-3f4f-4cbb-9924-fe2f77dfa33d",
  "client_id": "bookstore_frontend"
}
```


而 JWT 在 RFC 7519 中推荐（非强制约束）了七项声明名称（Claim Name），如有需要用到这些内容，建议字段名与官方的保持一致：

- iss（Issuer）：签发人。
- exp（Expiration Time）：令牌过期时间。
- sub（Subject）：主题。
- aud （Audience）：令牌受众。
- nbf （Not Before）：令牌生效时间。
- iat （Issued At）：令牌签发时间。
- jti （JWT ID）：令牌编号。

此外在 RFC 8225、RFC 8417、RFC 8485 等规范文档，以及 OpenID 等协议中，都定义有约定好公有含义的名称，内容比较多，笔者就不贴出来了，可以参考IANA JSON Web Token Registry 。
https://www.iana.org/assignments/jwt/jwt.xhtml




令牌的第三部分是签名（Signature），签名的意思是：使用在对象头中公开的特定签名算法，通过特定的密钥（Secret，由服务器进行保密，不能公开）对前面两部分内容进行加密计算，以例子里使用的 JWT 默认的 HMAC SHA256 算法为例，将通过以下公式产生签名值：
`HMACSHA256(base64UrlEncode(header) + "." + base64UrlEncode(payload) , secret)
`

签名的意义在于确保负载中的信息是可信的、没有被篡改的，也没有在传输过程中丢失任何信息。
因为被签名的内容哪怕发生了一个字节的变动，也会导致整个签名发生显著变化。
此外，由于签名这件事情只能由认证授权服务器完成（只有它知道 Secret），任何人都无法在篡改后重新计算出合法的签名值，所以服务端才能够完全信任客户端传上来的 JWT 中的负载信息。

JWT 默认的签名算法 HMAC SHA256 是一种带密钥的哈希摘要算法，加密与验证过程均只能由中心化的授权服务来提供，所以这种方式一般只适合于授权服务与应用服务处于同一个进程中的单体应用。
在多方系统或者授权服务与资源服务分离的分布式应用中，通常会采用非对称加密算法来进行签名，这时候除了授权服务端持有的可以用于签名的私钥外，还会对其他服务器公开一个公钥，公开方式一般遵循JSON Web Key 规范。
公钥不能用来签名，但是能被其他服务用于验证签名是否由私钥所签发的。
这样其他服务器也能不依赖授权服务器、无须远程通信即可独立判断 JWT 令牌中的信息的真伪。


JWT 令牌是多方系统中一种优秀的凭证载体，它不需要任何一个服务节点保留任何一点状态信息，就能够保障认证服务与用户之间的承诺是双方当时真实意图的体现，是准确、完整、不可篡改、且不可抵赖的。同时，由于 JWT 本身可以携带少量信息，这十分有利于 RESTful API 的设计，能够较容易地做成无状态服务，在做水平扩展时就不需要像前面 Cookie-Session 方案那样考虑如何部署的问题。现实中也确实有一些项目直接采用 JWT 来承载上下文来实现完全无状态的服务端，这能获得任意加入或移除服务节点的巨大便利，天然具有完美的水平扩缩能力。


JWT 也并非没有缺点的完美方案，它存在着以下几个经常被提及的缺点：
- 令牌难以主动失效: 
  需求是：要求一个用户只能在一台设备上登录，在 B 设备登录后，之前已经登录过的 A 设备就应该自动退出。必须设计一个“黑名单”的额外的逻辑，用来把要主动失效的令牌集中存储起来
- 相对更容易遭受重放攻击
  要在 JWT 层面解决重放攻击需要付出比较大的代价，无论是加入全局序列号（HTTPS 协议的思路）、Nonce 字符串（HTTP Digest 验证的思路）、挑战应答码（当下网银动态令牌的思路）、还是缩短令牌有效期强制频繁刷新令牌，在真正应用起来时都很麻烦。
  真要处理重放攻击，建议的解决方案是在信道层次（譬如启用 HTTPS）上解决，而不提倡在服务层次（譬如在令牌或接口其他参数上增加额外逻辑）上解决。
- 只能携带相当有限的数据
  Tomcat 就要求 Header 最大不超过 8KB，而在 Nginx 中则默认为 4KB
- 必须考虑令牌在客户端如何存储
- 无状态也不总是好的: 
  需求：请基于无状态 JWT 的方案，做一个在线用户实时统计功能



### 保密
保密（Confidentiality）
系统如何保证敏感数据无法被包括系统管理员在内的内外部人员所窃取、滥用？

#### 保密的强度
几种不同强度的保密手段
1. 以摘要代替明文
   如果密码本身比较复杂，那一次简单的哈希摘要至少可以保证即使传输过程中有信息泄漏，也不会被逆推出原信息；
   即使密码在一个系统中泄漏了，也不至于威胁到其他系统的使用，但这种处理不能防止弱密码被彩虹表攻击 所破解。
2. 先加盐值 再做哈希是应对弱密码的常用方法
   盐值可以替弱密码建立一道防御屏障，一定程度上防御已有的彩虹表攻击，但并不能阻止加密结果被监听、窃取后，攻击者直接发送加密结果给服务端进行冒认。
3. 将盐值变为动态值能有效防止冒认
   如果每次密码向服务端传输时都掺入了动态的盐值，让每次加密的结果都不同，那即使传输给服务端的加密结果被窃取了，也不能冒用来进行另一次调用。
   但这样协商出盐值的过程将变得极为复杂
   也难以阻止对其他服务的重放攻击
4. 给服务加入动态令牌
   在网关或其他流量公共位置建立校验逻辑，服务端愿意付出在集群中分发令牌信息等代价的前提下，可以做到防止重放攻击，但是依然不能抵御传输过程中被嗅探而泄漏信息的问题。
5. 启用 HTTPS 可以防御链路上的恶意嗅探
   也能在通信层面解决了重放攻击的问题。
   但是依然有因客户端被攻破产生伪造根证书风险、有因服务端被攻破产生的证书泄漏而被中间人冒认的风险、
   有因CRL 更新不及时或者OCSP Soft-fail 产生吊销证书被冒用的风险、
   有因 TLS 的版本过低或密码学套件选用不当产生加密强度不足的风险。
6. 保密强度还要进一步提升
   银行会使用独立于客户端的存储证书的物理设备（俗称的 U 盾）来避免根证书被客户端中的恶意程序窃取伪造；
   大型网站涉及到账号、金钱等操作时，会使用双重验证开辟一条独立于网络的信息通道（如手机验证码、电子邮件）来显著提高冒认的难度；
   甚至一些关键企业（如国家电网）或机构（如军事机构）会专门建设遍布全国各地的与公网物理隔离的专用内部网络来保障通信安全。


#### 客户端加密
客户端在用户登录、注册一类场景里是否需要对密码进行加密，这个问题一直存有争议。
==笔者的观点很明确==：为了保证==信息不被黑客窃取==而做客户端加密==没有太多意义==，对绝大多数的信息系统来说，启用 ==HTTPS 可以说是唯一的实际可行的方案==。

为了保证密码==不在服务端被滥用==，在客户端就开始加密是==很有意义==的。
大网站被==拖库==的事情层出不穷，==密码明文被写入数据库、被输出到日志中==之类的事情也屡见不鲜，做系统设计时就应该把明文密码这种东西当成是最烫手的山芋来看待，越早消灭掉越好，将一个潜在的炸弹从客户端运到服务端，对绝大多数系统来说都没有必要。

网络通信并非由发送方和接收方点对点进行的，客户端无法决定用户送出的信息能不能到达服务端，或者会经过怎样的路径到达服务端，在==传输链路必定是不安全==的假设前提下，无论客户端做什么防御措施，最终都会沦为“马其诺防线”。

中间人攻击（Man-in-the-Middle Attack，MitM）
在消息发出方和接收方之间拦截双方通信。
用日常生活中的写信来类比的话：你给朋友写了一封信，邮递员可以把每一份你寄出去的信都拆开看，甚至把信的内容改掉，然后重新封起来，再寄出去给你的朋友。
朋友收到信之后给你回信，邮递员又可以拆开看，看完随便改，改完封好再送到你手上。
你全程都不知道自己寄出去的信和收到的信都经过邮递员这个“中间人”转手和处理——换句话说，对于你和你朋友来讲，邮递员这个“中间人”角色是不可见的。


#### 密码存储和验证

这节笔者以 Fenix's Bookstore 中的真实代码为例，介绍对一个普通安全强度的信息系统，密码如何从客户端传输到服务端，然后存储进数据库的全过程。
“普通安全强度”是指在具有一定保密安全性的同时，避免消耗过多的运算资源，验证起来也相对便捷。
对多数信息系统来说，只要配合一定的密码规则约束，譬如密码要求长度、特殊字符等，再配合 HTTPS 传输，已足防御大多数风险了。
即使在用户采用了弱密码、客户端通信被监听、服务端被拖库、泄漏了存储的密文和盐值等问题同时发生，也能够最大限度避免用户明文密码被逆推出来。
下面先介绍密码创建的过程：

1. 用户在客户端注册，输入明文密码：123456
   `password = 123456`
2. 客户端对用户密码进行简单哈希摘要，
   可选的算法有 MD2/4/5、SHA1/256/512、BCrypt、PBKDF1/2，等等。
   为了突出“简单”的哈希摘要，这里笔者故意没有排除掉 MD 系这些已经有了高效碰撞手段的算法。
   `client_hash = MD5(password) // e10adc3949ba59abbe56e057f20f883e`
3. 为了防御彩虹表攻击应加盐处理，客户端加盐只取固定的字符串即可，如实在不安心，最多用伪动态的盐值（“伪动态”是指服务端不需要额外通信可以得到的信息，譬如由日期或用户名等自然变化的内容，加上固定字符串构成）。
   `client_hash = MD5(MD5(password) + salt)  // SALT = $2a$10$o5L.dWYEjZjaejOmN3x4Qu`
4. 假设攻击者截获了客户端发出的信息，
   得到了摘要结果和采用的盐值，那攻击者就可以枚举遍历所有 8 位字符以内（“8 位”只是举个例子，反正就是指弱密码，你如果拿 1024 位随机字符当密码用，加不加盐，彩虹表都跟你没什么关系）的弱密码，然后对每个密码再加盐计算，就得到一个针对固定盐值的对照彩虹表。为了应对这种暴力破解，并不提倡在盐值上做动态化，更理想的方式是引入慢哈希函数来解决。
   慢哈希函数是指这个函数执行时间是可以调节的哈希函数，通常是以控制调用次数来实现的。BCrypt 算法就是一种典型的慢哈希函数，它做哈希计算时接受盐值 Salt 和执行成本 Cost 两个参数（代码层面 Cost 一般是混入在 Salt 中，譬如上面例子中的 Salt 就是混入了 10 轮运算的盐值，10 轮的意思是 210次哈希，Cost 参数是放在指数上的，最大取值就 31）。如果我们控制 BCrypt 的执行时间大概是 0.1 秒完成一次哈希计算的话，按照 1 秒生成 10 个哈希值的速度，算完所有的 10 位大小写字母和数字组成的弱密码大概需要 P(62,10)/(3600×24×365)/0.1=1,237,204,169 年时间。
   `client_hash = BCrypt(MD5(password) + salt)  // MFfTW3uNI4eqhwDkG7HP9p2mzEUu/r2`
5. 只需防御被拖库后针对固定盐值的批量彩虹表攻击。
   具体做法是为每一个密码（指客户端传来的哈希值）产生一个随机的盐值。
   笔者建议采用“密码学安全伪随机数生成器 ”（Cryptographically Secure Pseudo-Random Number Generator，CSPRNG）来生成一个长度与哈希值长度相等的随机字符串。
   对于 Java 语言，从 Java SE 7 起提供了java.security.SecureRandom类，用于支持 CSPRNG 字符串生成。
   ```java
    SecureRandom random = new SecureRandom();
    byte server_salt[] = new byte[36];
    random.nextBytes(server_salt);   // tq2pdxrblkbgp8vt8kbdpmzdh1w8bex
   ```
6. 将动态盐值混入客户端传来的哈希值再做一次哈希，产生出最终的密文，并和上一步随机生成的盐值一起写入到同一条数据库记录中。
   由于慢哈希算法占用大量处理器资源，笔者并不推荐在服务端中采用。
   不过，如果你阅读了 Fenix's Bookstore 的源码，会发现这步依然采用了 Spring Security 5 中的BcryptPasswordEncoder，但是请注意它默认构造函数中的 Cost 参数值为-1，经转换后实际只进行了 210=1024 次计算，并不会对服务端造成太大的压力。
   ```java
   server_hash = SHA256(client_hash + server_salt);  // 55b4b5815c216cf80599990e781cd8974a1e384d49fbde7776d096e1dd436f67
   DB.save(server_hash, server_salt);
   ```

以上加密存储的过程相对复杂，但是运算压力最大的过程（慢哈希）是在客户端完成的，对服务端压力很小，也不惧怕因网络通信被截获而导致明文密码泄漏。

密码存储后，以后验证的过程与加密是类似的，步骤如下：

1. 客户端，用户在登录页面中输入密码明文：123456，经过与注册相同的加密过程，向服务端传输加密后的结果。
   `authentication_hash = MFfTW3uNI4eqhwDkG7HP9p2mzEUu/r2`
2. 服务端，接受到客户端传输上来的哈希值，从数据库中取出登录用户对应的密文和盐值，采用相同的哈希算法，对客户端传来的哈希值、服务端存储的盐值计算摘要结果。
   `result = SHA256(authentication_hash + server_salt);  // 55b4b5815c216cf80599990e781cd8974a1e384d49fbde7776d096e1dd436f67`
3. 比较上一步的结果和数据库储存的哈希值是否相同，如果相同那么密码正确，反之密码错误。
   `authentication = compare(result, server_hash) // yes`



### 传输
传输（Transport Security）
系统如何保证通过网络传输的信息无法被第三方窃听、篡改和冒充？

前文中笔者已经为传输安全层挖下了不少坑，譬如：
- 基于信道的认证是怎样实现的？
- 为什么 HTTPS 是绝大部分信息系统防御通信被窃听和篡改的唯一可行手段？
- 传输安全层难道不也是一种自动化的加密吗？
- 为何说客户端如何加密都不能代替 HTTPS？

本节将以“假设链路上的安全得不到保障，攻击者如何摧毁之前认证、授权、凭证、保密中所提到的种种安全机制”为场景，讲解传输层安全所要解决的问题，同时也是对前面这些疑问句的回答。


#### 摘要、加密与签名
我们从 JWT 令牌的一小段“题外话”来引出现代密码学算法的三种主要用途：摘要、加密与签名。
JWT 令牌携带信息的可信度源自于它是被签名过的信息，因此是不可篡改的，是令牌签发者真实意图的体现。
然而，你是否了解过签名具体做了什么？为什么有签名就能够让负载中的信息变得不可篡改和不可抵赖呢？要解释数字签名 （Digital Signature），必须先从密码学算法的另外两种基础应用“摘要”和“加密”说起。

摘要 也称之为数字摘要（Digital Digest）或数字指纹（Digital Fingerprint）。JWT 令牌中默认的签名信息是对令牌头、负载和密钥三者通过令牌头中指定的哈希算法（HMAC SHA256）计算出来的摘要值
`signature = SHA256(base64UrlEncode(header) + "." + base64UrlEncode(payload) , secret)`

理想的哈希算法都具备两个特性：
一是==易变性==，这是指算法的输入端发生了任何一点细微变动，都会引发雪崩效应 （Avalanche Effect），使得输出端的结果产生极大的变化
二是==不可逆性==，摘要的过程是单向的，不可能从摘要的结果中逆向还原出输入值来。

加密与摘要的本质区别在于==加密是可逆的，逆过程就是解密==。
在经典密码学时代，加密的安全主要是依靠机密性来保证的，即依靠==保护加密算法或算法的执行参数==不被泄漏来保障信息的安全。
而现代密码学不依靠机密性，加解密算法都是完全公开的，安全建立在特定问题的计算==复杂度==之上，具体是指算法根据输入端计算输出结果耗费的算力资源很小，但根据输出端的结果反过来推算原本的输入，耗费的算力就极其庞大。
一个经常在课堂中用来说明计算复杂度的例子是大数的质因数分解 ，我们可以轻而易举的地（以 O(nlogn)的复杂度 ）计算出两个大素数的乘积
`97667323933 * 128764321253 = 12576066674829627448049`

根据算术基本定理 ，质因数的分解形式是唯一的，且前面计算条件中给出的运算因子已经是质数，所以 12576066674829627448049 的分解形式就只有唯一的形式，即上面所示的唯一答案。

然而如何对大数进行质因数分解，迄今没有找到多项式时间的算法，甚至无法确切地知道这个问题属于哪个复杂度类 （Complexity Class）

根据加密与解密是否采用同一个密钥，现代密码学算法可分为==对称加密算法和非对称加密==两大类型，这两类算法各自有很明确的优劣势与应用场景。
对称加密的缺点显而易见，加密和解密使用相同的密钥，当通信的成员数量增加时，为保证两两通信都都采用独立的密钥，密钥数量就与成员数量的平方成正比，这必然面临==密钥管理==的难题。而更尴尬的难题是当通信双方原本就不存在安全的信道时，如何才能将一个只能让通信双方才能知道的密钥传输给对方？如果有通道可以安全地传输密钥，那为何不使用现有的通道传输信息？这个“蛋鸡悖论 ”曾在很长的时间里严重阻碍了密码学在真实世界中推广应用。

20 世纪 70 年代中后期出现的非对称加密算法从根本上解决了密钥分发的难题，它将密钥分成公钥和私钥，公钥可以完全公开，无须安全传输的保证。私钥由用户自行保管，不参与任何通信传输。根据这两个密钥加解密方式的不同，使得算法可以提供两种不同的功能：

- 公钥加密，私钥解密，
  这种就是==加密==，用于向私钥所有者发送信息，这个信息可能被他人篡改，但是无法被他人得知。如果甲想给乙发一个安全保密的数据，那么应该甲乙各自有一个私钥，==甲先用乙的公钥加密这段数据，再用自己的私钥加密这段加密后的数据==。最后再发给乙，这样确保了内容即不会被读取，也不能被篡改。

- 私钥加密，公钥解密，
  这种就是==签名==，用于让所有公钥所有者验证私钥所有者的身份，并且用来防止私钥所有者发布的内容被篡改。但是不用来保证内容不被他人获得。

这两种用途理论上肯定是成立的，现实中却一般不成立，单靠非对称加密算法，既做不了加密也做不了签名。
原因是不论是加密还是解密，==非对称加密算法的计算复杂度都相当高==，==性能比对称加密要差上好几个数量级==（不是好几倍）。
加解密性能不仅影响速度，还导致了现行的非对称加密算法都没有支持分组加密模式。
分组是指由于明文长度与密钥长度在安全上具有相关性，通俗地说就是多长的密钥决定了它能加密多长的明文，如果明文太短就需要进行填充，太长就需要进行分组。
因非对称加密本身的效率所限，难以支持分组，所以主流的非对称加密算法都只能加密不超过密钥长度的数据，这决定了非对称加密不能直接用于大量数据的加密。

在加密方面，现在一般会结合对称与非对称加密的优点，以混合加密来保护信道安全，
具体做法是==用非对称加密==来安全地传递少量数据给通信的另一方，然后再以这些数据为==密钥==，采用==对称加密来==安全高效地大量加密传输数据，这种由多种加密算法组合的应用形式被称为“==密码学套件==”。非对称加密在这个场景中发挥的作用称为“==密钥协商==”。

在签名方面，现在一般会结合摘要与非对称加密的优点，以对摘要结果做加密的形式来保证签名的适用性。
由于对任何长度的输入源做摘要之后都能得到固定长度的结果，所以只要对摘要的结果进行签名，即相当于对整个输入源进行了背书，保证一旦内容遭到篡改，摘要结果就会变化，签名也就马上失效了。

现在，让我们再回到开篇关于 JWT 令牌的几个问题中来。
有了哈希摘要、对称和非对称加密，JWT 令牌的签名就能保证负载中的信息不可篡改、不可抵赖吗？其实还是不行的，这个场景里，数字签名的安全性仍存在一个==致命的漏洞==：公钥虽然是公开的，但在网络世界里“公开”具体是一种什么操作？如何保证每一个获取公钥的服务，拿到的公钥就是授权服务器所希望它拿到的？

在==网络传输是不可信任==的前提下，==公钥==在网络传输过程中==可能已经被篡改==，如果获取公钥的网络请求被攻击者截获并篡改，返回了攻击者自己的公钥，那以后攻击者就可以用自己的私钥来签名，让资源服务器无条件信任它的所有行为了。


数字证书
当我们无法以“签名”的手段来达成信任时，就只能求助于其他途径。不妨想想真实的世界中，我们是如何达成信任的，其实不外乎以下两种：
- 基于共同私密信息的信任
    譬如某个陌生号码找你，说是你的老同学，生病了要找你借钱。
    你能够信任他的方式是向对方询问一些你们两个应该知道，且只有你们两个知道的私密信息，如果对方能够回答上来，他有可能真的是你的老同学，否则他十有八九就是个诈骗犯。
- 基于权威公证人的信任
    如果有个陌生人找你，说他是警察，让你把存款转到他们的安全账号上。
    你能够信任他的方式是去一趟公安局，如果公安局担保他确实是个警察，那他有可能真的是警察，否则他十有八九就是个诈骗犯。

网络世界中，我们并不能假设授权服务器和资源服务器是互相认识的，所以通常不太会采用第一种方式，
而第二种就是目前标准的保证公钥可信分发的标准，这个标准有一个名字：==公开密钥基础设施== （Public Key Infrastructure，PKI）。

又称公开密钥基础架构、公钥基础建设、公钥基础设施、公开密码匙基础建设或公钥基础架构，是一组由硬件、软件、参与者、管理政策与流程组成的基础架构，其目的在于创造、管理、分配、使用、存储以及撤销数字证书。
密码学上，公开密钥基础建设借着数字证书认证中心（Certificate Authority，CA）将用户的个人身份跟公开密钥链接在一起。对每个证书中心用户的身份必须是唯一的。链接关系通过注册和发布过程创建，根据担保级别的差异，创建过程可由 CA 的各种软件或者在人为监督下完成。PKI 的确定链接关系的这一角色称为注册管理中心（Registration Authority，RA）。RA 确保公开密钥和个人身份链接，可以防抵赖。

“去 CA 中心进行认证”本身也是一种网络操作，这与之前的“去获取公钥”本质上不是没什么差别吗？其实还是有差别的，世间公钥成千上万不可枚举，而权威的 CA 中心则应是可数的，“可数”意味着可以不通过网络，而是在==浏览器与操作系统出厂时就预置好==，或者提前安装好（如银行的证书）

PKI 中采用的证书格式是X.509 标准格式 ，它定义了证书中应该包含哪些信息，并描述了这些信息是如何编码的，里面最关键的就是认证机构的数字签名和公钥信息两项内容。一个数字证书具体包含以下内容：
- 版本号 Version
  该证书使用了哪种版本的 X.509 标准（版本 1、版本 2 或是版本 3）
  `Version: 3 (0x2)`
- 序列号 Serial Number
  由证书颁发者分配的本证书的唯一标识符。
  `Serial Number: 04:00:00:00:00:01:15:4b:5a:c3:94`
- 签名算法标识符 Signature Algorithm ID
  用于签发证书的算法标识，由对象标识符加上相关的参数组成，用于说明本证书所用的数字签名算法。
  `Signature Algorithm: sha1WithRSAEncryption`
- 认证机构的数字签名 Certificate Signature
  使用证书发布者私钥生成的签名
- 认证机构 Issuer Name
  证书颁发者的可识别名。
  Issuer: C=BE, O=GlobalSign nv-sa, CN=GlobalSign Organization Validation CA - SHA256 - G2
- 有效期限 Validity Period
   证书起始日期和时间以及终止日期和时间，指明证书在这两个时间内有效。
   ```text
   Validity
      Not Before: Nov 21 08:00:00 2020 GMT
      Not After : Nov 22 07:59:59 2021 GMT
   ```
- 主题信息 Subject
  证书持有人唯一的标识符（Distinguished Name），这个名字在整个互联网上应该是唯一的，通常使用的是网站的域名。
  `Subject: C=CN, ST=GuangDong, L=Zhuhai, O=Awosome-Fenix, CN=*.icyfenix.cn`
- 公钥信息 Public-Key
  包括证书持有人的公钥、算法(指明密钥属于哪种密码系统)的标识符和其他相关的密钥参数。


#### 传输安全层

2006年，TLS 的第一个升级版 1.1 发布（RFC 4346 ），但却沦为了被遗忘的孩子，很少人使用 TLS 1.1，甚至到了 TLS 1.1 从来没有已知的协议漏洞被提出的程度。

2008 年，TLS 1.1 发布 2 年之后，TLS 1.2 标准发布（RFC 5246 ），迄今超过 90%的互联网 HTTPS 流量是由 TLS 1.2 所支持的，现在仍在使用的浏览器几乎都完美支持了该协议。

2018 年，最新的 TLS 1.3（RFC 8446 ）发布，比起前面版本相对温和的升级，TLS 1.3 做了出了一些激烈的改动，修改了从 1.0 起一直没有大变化的==两轮四次（2-RTT）握手==，首次连接仅需==一轮（1-RTT）握手==即可完成，在==有连接复用支持==时，甚至将 ==TLS 1.2 原本的 1-RTT 下降到了 0-RTT==，显著提升了访问速度。


接下来，笔者以 TLS 1.2 为例，介绍传输安全层是如何保障所有信息都是第三方无法窃听（加密传输）、无法篡改（一旦篡改通信算法会立刻发现）、无法冒充（证书验证身份）的。TLS 1.2 在传输之前的握手过程一共需要进行上下两轮、共计四次通信，时序如图 5-16 所示。

![f38928d16145e216d3456228c56ca36b.png](../_resources/f38928d16145e216d3456228c56ca36b.png)


1. 客户端请求：Client Hello
   客户端向服务器请求进行加密通信，在这个请求里面，它会以明文的形式，向服务端提供以下信息。
   - 支持的协议版本，譬如 TLS 1.2。但是要注意，==1.0 至 3.0 分别代表 SSL1.0 至 3.0==，==TLS1.0 则是 3.1，一直到 TLS1.3 的 3.4==。
   - 一个客户端生成的 32 Bytes 随机数，这个随机数将稍后用于产生加密的密钥。
   - 一个可选的 SessionID，注意不要和前面 Cookie-Session 机制混淆了，这个 SessionID 是指传输安全层的 Session，是为了 TLS 的==连接复用==而设计的。
   - 一系列支持的密码学算法套件 ，例如TLS_RSA_WITH_AES_128_GCM_SHA256，代表着密钥交换算法是 RSA，加密算法是 AES128-GCM，消息认证码算法是 SHA256
   - 一系列支持的数据压缩算法
   - 其他可扩展的信息，为了保证协议的稳定，后续对协议的功能扩展大多都添加到这个变长结构中。譬如 TLS 1.0 中由于发送的数据并不包含服务器的域名地址，导致了一台服务器只能安装一张数字证书，这对虚拟主机来说就很不方便，所以 TLS 1.1 起就增加了名为“Server Name”的扩展信息，以便一台服务器给不同的站点安装不同的证书。

2. 服务器回应：Server Hello
   服务器接收到客户端的通信请求后，如果客户端声明支持的协议版本和加密算法组合与服务端相匹配的话，就向客户端发出回应。
   如果不匹配，将会返回一个握手失败的警告提示。这次回应同样以明文发送的，包括以下信息：
   - 服务端确认使用的 TLS 协议版本。
   - 第二个 32 Bytes 的随机数，稍后用于产生加密的密钥。
   - 一个 SessionID，以后可通过连接复用减少一轮握手。
   - 服务端在列表中选定的密码学算法套件。
   - 服务端在列表中选定的数据压缩方法。
   - 其他可扩展的信息。
   - 如果协商出的加密算法组合是依赖证书认证的，服务端还要发送出自己的 X.509 证书，而证书中的公钥是什么，也必须根据协商的加密算法组合来决定。
   - 密钥协商消息，这部分内容对于不同密码学套件有着不同的价值，譬如对于 ECDH + anon 这样得密钥协商算法组合（基于椭圆曲线的ECDH 算法
   - 可以在双方通信都公开的情况下协商出一组只有通信双方知道的密钥）就不需要依赖证书中的公钥，而是通过 Server Key Exchange 消息协商出密钥。

3. 客户端确认：Client Handshake Finished
   由于密码学套件的组合复杂多样，这里仅以 RSA 算法为密钥交换算法为例介绍后续过程。
   客户端收到服务器应答后，先要验证服务器的证书合法性。
   如果证书不是可信机构颁布的，或者证书中信息存在问题，譬如域名与实际域名不一致、或者证书已经过期、或通过在线证书状态协议得知证书已被吊销，等等，都会向访问者显示一个“证书不可信任”的警告，由用户自行选择是否还要继续通信。
   如果证书没有问题，客户端就会从证书中取出服务器的公钥，并向服务器发送以下信息：
   - 客户端证书（可选）。
      部分服务端并不是面向全公众，只对特定的客户端提供服务，此时客户端需要发送它自身的证书来证明身份。
      如果不发送，或者验证不通过，服务端可自行决定是否要继续握手，或者返回一个握手失败的信息。
      客户端需要证书的 TLS 通信也称为“==双向 TLS==”（Mutual TLS，常简写为 mTLS），这是==云原生基础设施的主要认证方法==，也是基于信道认证的==最主流==形式。
   - 第三个 32 Bytes 的随机数，
      这个随机数不再是明文发送，而是以服务端传过来的公钥加密的，它被称为 PreMasterSecret，将与前两次发送的随机数一起，根据特定算法 计算出 48 Bytes 的 MasterSecret ，这个 MasterSecret 即为后续内容传输时的==对称加密算法所采用的私钥==。
   - 编码改变通知，表示随后的信息都将用双方商定的加密方法和密钥发送。
   - 客户端握手结束通知，表示客户端的握手阶段已经结束。这一项同时也是前面发送的所有内容的哈希值，以供服务器校验。

4. 服务端确认：Server Handshake Finished
   服务端向客户端回应最后的确认通知，包括以下信息。
    - 编码改变通知，表示随后的信息都将用双方商定的加密方法和密钥发送。
    - 服务器握手结束通知，表示服务器的握手阶段已经结束。这一项同时也是前面发送的所有内容的哈希值，以供客户端校验。

至此，整个 TLS 握手阶段宣告完成，一个安全的连接就已成功建立。


在传输性能上会有下降，但在功能上完全不会感知到有 TLS 的存在。建立在这层安全传输层之上的 HTTP 协议，就被称为“HTTP over SSL/TLS”，也即是大家所熟知的 HTTPS。

HTTPS 并非不是只有“启用了 HTTPS”和“未启用 HTTPS”的差别，采用不同的协议版本、不同的密码学套件、证书是否有效、服务端/客户端对面对无效证书时的处理策略如何都导致了不同 HTTPS 站点的安全强度的不同，因此并不能说只要启用了 HTTPS 就必定能够安枕无忧。



### 验证
验证（Verification）
系统如何确保提交到每项服务中的数据是合乎规则的，不会对系统稳定性、数据一致性、正确性产生风险？

缺失的校验影响数据质量，过度的校验不会使得系统更加健壮，某种意义上反而会制造垃圾代码，甚至有副作用。
```text
前  端： 提交一份用户数据（姓名:某, 性别:男, 签名:xxx, 手机:xxx, 邮箱:null）
控制器： 发现邮箱是空的，抛ValidationException("邮箱没填")
前  端： 已修改，重新提交
安  全： 发送验证码时发现手机号少一位，抛RemoteInvokeException("无法发送验证码")
前  端： 已修改，重新提交
服务层： 邮箱怎么有重复啊，抛BusinessRuntimeException("不允许开小号")
前  端： 已修改，重新提交
持久层： 签名字段超长了插不进去，抛SQLException("插入数据库失败，SQL：xxx")
…… ……
前  端： 你们这些坑管挖不管埋的后端，各种异常都往前抛！
用  户： 这系统牙膏厂生产的？
```

最基础的数据问题可以在前端做表单校验来处理，但服务端验证肯定也是要做的，看完了上面的段子后，请想一想，服务端应该在哪一层去做校验？可能会有这样的答案：
  -  在 Controller 层做，在 Service 层不做。理由是从 Service 开始会有同级重用，出现 ServiceA.foo(params)调用 ServiceB.bar(params)时，就会对 params 重复校验了两次。
  -  在 Service 层做，在 Controller 层不做。理由是无业务含义的格式校验已在前端表单验证处理过，有业务含义的校验，放在 Controller 层无论如何不合适。
  -  在 Controller、Service 层各做各的。Controller 做格式校验，Service 层做业务校验，听起来很合理，但这其实就是上面段子中被嘲笑的行为。
  -  还有其他一些意见，譬如还有提在持久层做校验，理由是这是最终入口，把守好写入数据库的质量最重要。


笔者提倡的做法是把校验行为从分层中剥离出来，不是在哪一层做，而是==在 Bean 上做==。
即 ==Java Bean Validation==。从 2009 年的JSR 303 的 1.0，到 2013 年的JSR 349 更新的 1.1，到目前最新的 2017 年发布的JSR 380 ，定义了 Bean 验证的全套规范。单独将验证提取、封装，可以获得不少好处：

- 对于无业务含义的格式验证，可以做到预置。
- 对于有业务含义的业务验证，可以做到重用，
  一个 Bean 被用于多个方法用作参数或返回值是很常见的，针对 Bean 做校验比针对方法做校验更有价值。
  利于集中管理，譬如统一认证的异常体系，统一做国际化、统一给客户端的返回格式等等。
- 避免对输入数据的防御污染到业务代码，如果你的代码里面如果很多下面这样的条件判断，就应该考虑重构了：
  ```java
  // 一些已执行的逻辑
  if (someParam == null) {
    throw new RuntimeExcetpion("error");
  }
  ```
- 利于多个校验器统一执行，统一返回校验结果，避免用户踩地雷、挤牙膏式的试错体验。

国内的项目使用 Bean Validation 的并不少见，但多数程序员都只使用到它的 Built-In Constraint 来做一些与业务逻辑无关的通用校验，即下面这堆注解，含义基本上看类名就能明白
```text
@Null、@NotNull、@AssertTrue、@AssertFalse、@Min、@Max、@DecimalMin、
@DecimalMax、@Negative、@NegativeOrZero、@Positive、@PositiveOrZero、@Size、
@Digits、@Past、@PastOrPresent、@Future、@FutureOrPresent、@Pattern、@NotEmpty、
@NotBlank、@Email
```

与业务相关的校验往往才是最复杂的校验，将简单的校验交给 Bean Validation，而把复杂的校验留给自己，这简直是买椟还珠故事的程序员版本。
其实以 Bean Validation 的标准方式来做业务校验是非常优雅的，以 Fenix's Bookstore 的在用户资源上的两个方法为例：
```java
/**
* 创建新的用户
*/
@POST
public Response createUser(@Valid @UniqueAccount Account user) {
	return CommonResponse.op(() -> service.createAccount(user));
}

/**
* 更新用户信息
*/
@PUT
@CacheEvict(key = "#user.username")
public Response updateUser(@Valid @AuthenticatedAccount @NotConflictAccount Account user) {
	return CommonResponse.op(() -> service.updateAccount(user));
}
```
注意其中的三个自定义校验注解，它们的含义分别是：
   - @UniqueAccount：传入的用户对象必须是唯一的，不与数据库中任何已有用户的名称、手机、邮箱产生重复。
   - @AuthenticatedAccount：传入的用户对象必须与当前登录的用户一致。
   - @NotConflictAccount：传入的用户对象中的信息与其他用户是无冲突的，譬如将一个注册用户的邮箱，修改成与另外一个已存在的注册用户一致的值，这便是冲突。

下面代码是这三个自定义注解对应校验器的实现类：
```java
public static class AuthenticatedAccountValidator extends AccountValidation<AuthenticatedAccount> {
    public void initialize(AuthenticatedAccount constraintAnnotation) {
        predicate = c -> {
            AuthenticAccount loginUser = (AuthenticAccount) SecurityContextHolder.getContext().getAuthentication().getPrincipal();
            return c.getId().equals(loginUser.getId());
        };
    }
}

public static class UniqueAccountValidator extends AccountValidation<UniqueAccount> {
    public void initialize(UniqueAccount constraintAnnotation) {
        predicate = c -> !repository.existsByUsernameOrEmailOrTelephone(c.getUsername(), c.getEmail(), c.getTelephone());
    }
}

public static class NotConflictAccountValidator extends AccountValidation<NotConflictAccount> {
    public void initialize(NotConflictAccount constraintAnnotation) {
        predicate = c -> {
            Collection<Account> collection = repository.findByUsernameOrEmailOrTelephone(c.getUsername(), c.getEmail(), c.getTelephone());
            // 将用户名、邮件、电话改成与现有完全不重复的，或者只与自己重复的，就不算冲突
            return collection.isEmpty() || (collection.size() == 1 && collection.iterator().next().getId().equals(c.getId()));
        };
    }
}
```

这样业务校验便和业务逻辑就完全分离开来，在需要校验时用@Valid注解自动触发，或者通过代码手动触发执行，可根据你们项目的要求，将这些注解应用于控制器、服务层、持久层等任何层次的代码之中。
此外，校验结果不满足时的提示信息，也便于统一处理，如提供默认值、提供国际化支持（这里没做）、提供统一的客户端返回格式（创建一个用于ConstraintViolationException的异常处理器来实现，代码中有但这里没有贴出来），以及批量执行全部校验，避免出开篇那个段子中挤牙膏的尴尬。

对于 Bean 与 Bean 校验器，笔者另外有==两条编码建议==。==第一条==是对校验项==预置好默认的提示信息==，这样当校验不通过时用户能获得明确的修正提示

```java
/**
 * 表示一个用户的信息是无冲突的
 *
 * “无冲突”是指该用户的敏感信息与其他用户不重合，譬如将一个注册用户的邮箱，修改成与另外一个已存在的注册用户一致的值，这便是冲突
 **/
@Documented
@Retention(RUNTIME)
@Target({FIELD, METHOD, PARAMETER, TYPE})
@Constraint(validatedBy = AccountValidation.NotConflictAccountValidator.class)
public @interface NotConflictAccount {
    String message() default "用户名称、邮箱、手机号码与现存用户产生重复";
    Class<?>[] groups() default {};
    Class<? extends Payload>[] payload() default {};
}
```

另外一条建议是将不带业务含义的格式校验注解放到 Bean 的类定义之上，将带业务逻辑的校验放到 Bean 的类定义的外面。这两者的区别是放在类定义中的注解能够自动运行，而放到类外面则需要像前面代码那样，明确标出注解时才会运行。譬如用户账号实体中的部分代码为：
```java
public class Account extends BaseEntity {
	@NotEmpty(message = "用户不允许为空")
    private String username;

    @NotEmpty(message = "用户姓名不允许为空")
    private String name;

    private String avatar;

    @Pattern(regexp = "1\\d{10}", message = "手机号格式不正确")
    private String telephone;

    @Email(message = "邮箱格式不正确")
    private String email;
}
```

这些校验注解都直接放在类定义中，每次执行校验的时候它们都会被运行。由于 Bean Validation 是 Java 的标准规范，它执行的频率可能比编写代码的程序所预想的要更高，
譬如使用 Hibernate 来做持久化时，便会自动执行 Data Object 上的校验注解。
对于那些不带业务含义的注解，运行是不需要其他外部资源参与的，不会调用远程服务、访问数据库，这种校验重复执行并没有什么成本。

但带业务逻辑的校验，通常就需要外部资源参与执行，这不仅仅是多消耗一点时间和运算资源的问题，由于很难保证依赖的每个服务都是幂等的，重复执行校验很可能会带来额外的副作用。因此应该放到外面让使用者自行判断是否要触发。

还有一些“需要触发一部分校验”的非典型情况，譬如“新增”操作 A 需要执行全部校验规则，“修改”操作 B 中希望不校验某个字段，“删除”操作 C 中希望改变某一条校验规则，这时候要就要启用分组校验来处理，设计一套“新增”、“修改”、“删除”这样的标识类，置入到校验注解的groups参数中去实现。


## 分布式共识算法

http://icyfenix.cn/distribution/consensus/

前置知识
关于分布式中 CAP 问题，请先阅读“分布式事务”中的介绍，后文中提及的一致性、可用性、网络分区等概念，均在此文中有过介绍。


学习两三种具有代表性的分布式共识算法，为后续分布式环境中操作共享数据准备好理论基础。

单个节点的系统宕机无法访问数据的原因可能有很多，譬如程序出错、硬件损坏、网络分区、电源故障，等等，
一年中出现系统宕机的概率也许还要高于 5%，这决定了软件系统也必须有多台机器能够拥有一致的数据副本，才有可能对外提供可靠的服务。

分布式系统里面，我们必须考虑动态的数据如何在不可靠的网络通信条件下，依然能在各个节点之间正确复制的问题。将我们要讨论的场景作如下修改：
> 如果你有一份会随时变动的数据，要确保它正确地存储于网络中的几台不同机器之上，你会怎么做？


可靠性与可用性的矛盾造成了==增加机器数量==反而带来==可用性的降低==，
为缓解这个矛盾，在分布式系统里主流的数据复制方法是以操作转移（Operation Transfer）为基础的。
我们想要改变数据的状态，除了直接将目标状态赋予它之外，还有另一种常用的方法是通过某种操作，令源状态转换为目标状态。
能够使用确定的操作，促使状态间产生确定的转移结果的计算模型，在计算机科学中被称为状态机（State Machine）。

状态机复制
状态机有一个特性：任何初始状态一样的状态机，如果执行的命令序列一样，则最终达到的状态也一样。
如果将此特性应用在多参与者进行协商共识上，可以理解为系统中存在多个具有完全相同的状态机（参与者），这些状态机能最终保持一致的关键就是起始状态完全一致和执行命令序列完全一致。

根据状态机的特性，要让多台机器的最终状态一致，只要确保它们的==初始状态是一致==的，并且==接收到的操作指令序列也是一致==的即可，无论这个操作指令是新增、修改、删除抑或是其他任何可能的程序行为，都可以理解为要将一连串的操作日志正确地广播给各个分布式节点。


让系统各节点不受局部的网络分区、机器崩溃、执行性能或者其他因素影响，都能最终表现出整体一致的过程，就被称为各个节点的协商共识（Consensus）。

共识（==Consensus==）与一致性（==Consistency==）的区别：
一致性是指数据不同副本之间的差异，而
共识是指达成一致性的方法与过程。

很多中文资料把 Consensus 同样翻译为一致性
如果你在网上看到“分布式一致性算法”，应明白其指的其实是“Distributed Consensus Algorithm”。



### Paxos

Distributed Consensus Algorithm
There is only one consensus protocol, and that's “Paxos” — all other approaches are just broken versions of Paxos
世界上只有一种共识协议，就是 Paxos，其他所有共识算法都是 Paxos 的退化版本。


#### 算法流程

Paxos 算法将分布式系统中的节点分为三类：
- 提案节点：称为 Proposer，
  ==提出对某个值进行设置操作的节点==，设置值这个行为就被称之为提案（Proposal），值一旦设置成功，就是不会丢失也不可变的。请注意，Paxos 是典型的基于操作转移模型而非状态转移模型来设计的算法，这里的“设置值”不要类比成程序中变量赋值操作，==应该类比成日志记录操作==，在后面介绍的 Raft 算法中就直接把“提案”叫作“日志”了。
- 决策节点：称为 Acceptor，
  是应答提案的节点，==决定==该提案是否==可被投票==、是否==可被接受==。
  提案一旦得到==过半数决策节点==的接受，即称该提案被批准（Accept），提案被批准即意味着该值不能再被更改，也不会丢失，且最终所有节点都会接受该它。
- 记录节点：被称为 Learner，
  不参与提案，也不参与决策，只是单纯地从提案、决策节点中学习已经达成共识的提案，譬如少数派节点从网络分区中恢复时，将会进入这种状态。

所有的节点都是平等的，它们都可以承担以上某一种或者多种的角色，不过为了便于确保有明确的多数派，决策节点的数量应该被设定为奇数个，且在系统初始化时，网络中每个节点都知道整个网络所有决策节点的数量、地址等信息。

在分布式环境下，如果我们说各个节点“就某个值（提案）达成一致”，
指的是“不存在某个时刻有一个值为 A，另一个时刻又为 B 的情景”。解决这个问题的复杂度主要来源于以下两个方面因素的共同影响：
- 系统内部各个节点通信是不可靠的，
  不论对于系统中企图设置数据的提案节点抑或决定是否批准设置操作的决策节点，其发出、收到的信息可能延迟送达、也可能会丢失，但不去考虑消息有传递错误的情况。
- 系统外部各个用户访问是可并发的，
  如果系统只会有一个用户，或者每次只对系统进行串行访问，那单纯地应用 Quorum 机制，少数节点服从多数节点，就已经足以保证值被正确地读写。


必须提供一个其他节点能抢占锁的机制，以避免因通信问题而出现死锁。

分布式环境中的锁必须是可抢占的
Paxos 算法包括==两个阶段==，其中，
第一阶段“==准备==”（Prepare）就相当于上面抢占锁的过程。如果某个提案节点准备发起提案，必须先==向所有==的==决策==节点广播一个许可申请（称为 Prepare 请求）。提案节点的 Prepare 请求中会附带==一个全局唯一的数字 n== 作为提案 ID，决策节点收到后，将会给予==提案==节点==两个承诺与一个应答==。

两个承诺是指：
- 承诺不会再接受提案 ID 小于或等于 n 的 ==Prepare== 请求。
- 承诺不会再接受提案 ID 小于 n 的 ==Accept== 请求。

一个应答是指：
- 不违背以前作出的承诺的前提下，回复已经批准过的提案中 ID 最大的那个提案所设定的值和提案 ID，如果该值从来没有被任何提案设定过，则返回空值。如果违反此前做出的承诺，即收到的提案 ID 并不是决策节点收到过的最大的，那允许直接对此 Prepare 请求==不予理会==。

当提案节点收到了多数派决策节点的应答（称为 Promise 应答）后，可以开始==第二阶段==“批准”（==Accept==）过程，这时有如下两种可能的结果：
- 如果提案节点发现所有响应的决策节点此前都没有批准过该值（即为空），那说明它是第一个设置值的节点，可以随意地决定要设定的值，将自己选定的值与提案 ID，构成一个二元组“(id, value)”，再次广播给全部的决策节点（称为 Accept 请求）。
- 如果提案节点发现响应的决策节点中，已经有至少一个节点的应答中包含有值了，那它就不能够随意取值了，必须无条件地从应答中找出提案 ID 最大的那个值并接受，构成一个二元组“(id, maxAcceptValue)”，再次广播给全部的决策节点（称为 Accept 请求）。

当每一个决策节点收到 Accept 请求时，都会在不违背以前作出的承诺的前提下，接收并持久化对当前提案 ID 和提案附带的值。如果违反此前做出的承诺，即收到的提案 ID 并不是决策节点收到过的最大的，那允许直接对此 Accept 请求不予理会。

当提案节点收到了多数派决策节点的应答（称为 Accepted 应答）后，协商结束，共识决议形成，将形成的决议发送给所有记录节点进行学习。



![Screenshot from 2023-10-01 21-21-20.png](../_resources/Screenshot%20from%202023-10-01%2021-21-20.png)




#### 工作实例

假设一个分布式系统有==五个节点==，分别命名为 S1、S2、S3、S4、S5，
这个例子中==只讨论正常通信==的场景，==不涉及网络分区==。
全部节点都==同时扮演==着==提案==节点和==决策==节点的身份。
此时，有==两个并发的请求==分别希望将同一个值分别设定为 X（由 S1作为提案节点提出）和 Y（由 S5作为提案节点提出），以 P 代表准备阶段，以 A 代表批准阶段，这时候可能发生以下情况：

> 情况一

S1选定的提案 ID 是 3.1（全局唯一 ID 加上节点编号），先取得了多数派决策节点的 Promise 和 Accepted 应答，此时 S5选定提案 ID 是 4.5，发起 Prepare 请求，收到的多数派应答中至少会包含 1 个此前应答过 S1的决策节点，假设是 S3，那么 S3提供的 Promise 中必将包含 S1已设定好的值 X，S5就必须无条件地用 X 代替 Y 作为自己提案的值，由此整个系统对“取值为 X”这个事实达成一致，如图 6-2 所示。

![99cce03e13d58efb22929fb6dfc7db6f.png](../_resources/99cce03e13d58efb22929fb6dfc7db6f.png)


> 情况二

事实上，对于情况一，X 被选定为最终值是必然结果，但从图 6-2 中可以看出，X 被选定为最终值并不是必定需要多数派的共同批准，只取决于 S5提案时 Promise 应答中是否已包含了批准过 X 的决策节点，譬如图 6-3 所示，S5发起提案的 Prepare 请求时，X 并未获得多数派批准，但由于 S3已经批准的关系，最终共识的结果仍然是 X。

![d639cfa2c84cd832f14a951fdd221b7b.png](../_resources/d639cfa2c84cd832f14a951fdd221b7b.png)


> 情况三

当然，另外一种可能的结果是 S5提案时 Promise 应答中并未包含批准过 X 的决策节点，譬如应答 S5提案时，节点 S1已经批准了 X，节点 S2、S3未批准但返回了 Promise 应答，此时 S5以更大的提案 ID 获得了 S3、S4、S5的 Promise，这三个节点均未批准过任何值，那么 S3将不会再接收来自 S1的 Accept 请求，因为它的提案 ID 已经不是最大的了，这三个节点将批准 Y 的取值，整个系统最终会对“取值为 Y”达成一致，如图 6-4 所示。

![bd96885ce8943a1a9bb33e3781655996.png](../_resources/bd96885ce8943a1a9bb33e3781655996.png)


> 情况四

从情况三可以推导出另一种极端的情况，如果两个提案节点交替使用更大的提案 ID 使得准备阶段成功，但是批准阶段失败的话，这个过程理论上可以无限持续下去，形成活锁（Live Lock），如图 6-5 所示。在算法实现中会引入随机超时时间来避免活锁的产生。

![de938d10004bf965b7e16f925f20f14b.png](../_resources/de938d10004bf965b7e16f925f20f14b.png)



Basic Paxos 的价值在于开拓了分布式共识算法的发展思路，但它因有如下缺陷，一般不会直接用于实践：
Basic Paxos 只能对单个值形成决议，并且决议的形成至少需要两次网络请求和应答（准备和批准阶段各一次），高并发情况下将产生==较大的网络开销==，极端情况下甚至可能形成==活锁==。
总之，Basic Paxos 是一种==很学术化但对工业化并不友好==的算法，现在几乎==只用来做理论研究==。
实际的应用都是基于 ==Multi Paxos 和 Fast Paxos== 算法的，接下来我们将会了解 Multi Paxos 与一些它的理论等价的算法（如 Raft、ZAB 等算法）。



### Multi Paxos

一种 Paxos 的改进版本“Multi Paxos”算法，希望能够找到一种两全其美的办法，既不破坏 Paxos 中“众节点平等”的原则，又能在提案节点中实现主次之分，限制每个节点都有不受控的提案权利，这两个目标听起来似乎是矛盾的，但现实世界中的选举就很符合这种在平等节点中挑选意见领袖的情景。

Multi Paxos 对 Basic Paxos 的核心改进是增加了“==选主==”的过程，
提案节点会通过定时轮询（心跳），确定当前网络中的所有节点里是否存在有一个主提案节点，一旦没有发现主节点存在，节点就会在心跳超时后使用 Basic Paxos 中定义的准备、批准的两轮网络交互过程，向所有其他节点广播自己希望竞选主节点的请求，希望整个分布式系统对“由我作为主节点”这件事情协商达成一致共识，如果得到了决策节点中多数派的批准，便宣告竞选成功。
当选主完成之后，除非主节点失联之后发起重新竞选，否则从此往后，就==只有主节点本身才能够提出提案==。此时，无论哪个提案节点==接收到客户端的操作请求==，都会将请求==转发给主节点==来完成提案，而主节点提案的时候，也就无需再次经过准备过程，因为可以视作是经过选举时的那一次准备之后，后续的提案都是对相同提案 ID 的一连串的批准过程。也可以通俗理解为选主过后，就不会再有其他节点与它竞争，相当于是处于无并发的环境当中进行的有序操作，所以此时系统中要对某个值达成一致，只需要进行一次批准的交互即可，如图 6-6 所示。

![e761914dbf608d241e6066565318476a.png](../_resources/e761914dbf608d241e6066565318476a.png)


可能有人注意到这时候的二元组(id, value)已经变成了三元组(id, i, value)，这是因为需要给主节点增加一个“==任期编号==”，这个编号必须是严格单调递增的，以应付主节点陷入网络分区后重新恢复，但另外一部分节点仍然有多数派，且已经完成了重新选主的情况，此时必须以任期编号大的主节点为准。当节点有了选主机制的支持，在整体来看，就可以进一步简化节点角色，==不去区分提案、决策和记录节点==了，统统以“节点”来代替，节点==只有主（Leader）和从（Follower）==的区别，此时协商共识的时序图如图 6-7 所示。

![84b77fc4ff9df2d331752e08ed6ea01a.png](../_resources/84b77fc4ff9df2d331752e08ed6ea01a.png)

当以下三个问题同时被解决时，即等价于达成共识：
- 如何选主（Leader Election）。
- 如何把数据复制到各个节点上（Entity Replication）。
- 如何保证过程是安全的（Safety）。

如果你已经理解了 Paxos 算法的操作步骤，相信对选主并不会有什么疑惑，因为这本质上仅仅是分布式系统对“谁来当主节点”这件事情的达成的共识而已

在正常情况下，当客户端向主节点发起一个操作请求，譬如提出“将某个值设置为 X”，此时==主节点==将 X ==写入==自己的==变更日志==，但==先不提交==，接着把变更 X 的信息在下一次心跳包中广播给所有的从节点，并要求从节点回复确认收到的消息，==从节点==收到信息后，将操作==写入自己的变更日志==，然后==给主节点==发送==确认签收==的消息，主节点==收到过半数的==签收消息后，==提交自己的变更==、==应答客户端==并且给从节点==广播==可以提交的消息，从节点收到提交消息后提交自己的变更，==数据在节点间的复制==宣告完成。

在异常情况下，网络出现了分区，部分节点失联，但只要仍能正常工作的节点的数量能够满足多数派（过半数）的要求，分布式系统就仍然可以正常工作，这时候数据复制过程如下：

- 假设有 S1、S2、S3、S4、S5五个节点，S1是主节点，由于网络故障，导致 S1、S2和 S3、S4、S5之间彼此无法通信，形成网络分区。

- 一段时间后，S3、S4、S5三个节点中的某一个（譬如是 S3）最先达到心跳超时的阈值，获知当前分区中已经不存在主节点了，它向所有节点发出自己要竞选的广播，并收到了 S4、S5节点的批准响应，加上自己一共三票，即得到了多数派的批准，竞选成功，此时系统中同时存在 S1和 S3两个主节点，但由于网络分区，它们不会知道对方的存在。

- 这种情况下，客户端发起操作请求：
  -  如果客户端连接到了 S1、S2之一，都将由 S1处理，但由于操作只能获得最多两个节点的响应，不构成多数派的批准，所以任何变更都无法成功提交。
  -  如果客户端连接到了 S3、S4、S5之一，都将由 S3处理，此时操作可以获得最多三个节点的响应，构成多数派的批准，是有效的，变更可以被提交，即系统可以继续提供服务。
  -  事实上，以上两种“如果”情景很少机会能够并存。网络分区是由于软、硬件或者网络故障而导致的，内部网络出现了分区，但==两个分区仍然能分别与外部网络的客户端正常通信的情况甚为少见==。更多的场景是算法能容忍网络里==下线==了一部分节点，按照这个例子来说，如果下线了两个节点，系统正常工作，下线了三个节点，那剩余的两个节点也不可能继续提供服务了。

- 假设现在故障恢复，分区解除，五个节点可以重新通信了：
  -  S1和 S3都向所有节点发送心跳包，从各自的心跳中可以得知两个主节点里 S3的任期编号更大，它是最新的，此时五个节点均只承认 S3是唯一的主节点。
  -  S1、S2回滚它们所有未被提交的变更。
  -  S1、S2从主节点发送的心跳包中获得它们失联期间发生的所有变更，将变更提交写入本地磁盘。
  -  此时分布式系统各节点的状态达成最终一致。


如何保证过程是安全的

- 协定性（Safety）：所有的坏事都不会发生（something "bad" will never happen）。
- 终止性（Liveness）：所有的好事都终将发生，但不知道是啥时候（something "good" will must happen, but we don't know when）。

以选主问题为例，Safety 保证了选主的结果一定是有且只有唯一的一个主节点，不可能同时出现两个主节点；
而 Liveness 则要保证选主过程是一定可以在某个时刻能够结束的。
由前面对活锁的介绍可以得知，在 Liveness 这个属性上选主问题是存在理论上的瑕疵的，可能会由于活锁而导致一直无法选出明确的主节点，所以 Raft 论文中只写了对 Safety 的保证，但由于工程实现上的处理，现实中是几乎不可能会出现终止性的问题。





### Gossip 协议

Gossip
Trying to squash a rumor is like trying to unring a bell.


Paxos、Raft、ZAB 等分布式算法经常会被称作是“==强一致性==”的分布式共识协议，其实这样的描述抠细节概念的话是很别扭的，会有语病嫌疑，但我们都明白它的意思其实是在说“==尽管系统内部节点可以存在不一致的状态，但从系统外部看来，不一致的情况并不会被观察到，所以整体上看系统是强一致性的==”。

与它们相对的，还有另一类被冠以“==最终一致性==”的分布式共识协议，这表明系统中不一致的状态有==可能会在一定时间内被外部直接观察到==。一种典型且极为常见的最终一致的分布式系统就是==DNS== 系统，在各节点缓存的 TTL 到期之前，都有可能与真实的域名翻译结果存在不一致。在本节中，笔者将介绍在==比特币==网络和许多重要==分布式框架==中都有应用的另一种具有代表性的“最终一致性”的分布式共识协议：==Gossip== 协议。

Gossip 的特点：要同步的信息如同流言一般传播、病毒一般扩散。

笔者按照习惯也把 Gossip 也称作是“共识协议”，但首先必须强调它所解决的问题并不是直接与 Paxos、Raft 这些共识算法等价的，只是基于 Gossip 之上可以通过某些方法去实现与 Paxos、Raft 相类似的目标而已。

相比 Paxos、Raft 等算法，Gossip 的过程十分简单，它可以看作是以下两个步骤的简单循环：

- 如果有某一项信息需要在整个网络中所有节点中传播，那从信息源开始，选择一个固定的传播周期（譬如 1 秒），随机选择它相连接的 k 个节点（称为 Fan-Out）来传播消息。

。。几时结束 这条信息的传播 ？ 上面的传播周期 是指 一条消息收到后 固定周期往外发， 还是 固定周期，把 收到的消息 再发送出去(只发一次) 。 
。。应该是前者， 后者的话，不能保证 传播到整个网络中。
。。但是前者的话， 什么时候 结束这条消息的 传播？
。
。单个节点会多次传播，但不会重复传播，如果之前已经传染过邻居A，那下次就不会再传染了。

- 每一个节点收到消息后，如果这个消息是它之前没有收到过的，将在下一个周期内，选择==除了==发送消息给它的那个节点外的其他==相邻 k 个==节点发送相同的消息，直到最终网络中所有节点都收到了消息，尽管这个过程需要一定时间，但是理论上最终网络的所有节点都会拥有相同的消息。

我们很容易发现 Gossip 对网络节点的==连通性和稳定性几乎没有任何要求==，它一开始就将网络某些节点只能与一部分节点部分连通 （Partially Connected Network）而不是以全连通网络 （Fully Connected Network）作为前提；
能够容忍网络上节点的随意地增加或者减少，随意地宕机或者重启，新增加或者重启的节点的状态最终会与其他节点同步达成一致。
Gossip 把网络上所有节点都视为平等而普通的一员，没有任何中心化节点或者主节点的概念，这些特点使得 Gossip 具有==极强的鲁棒性==，而且==非常适合在公众互联网中应用==。


Gossip 的缺点，
消息最终是通过多个轮次的散播而到达全网的，因此它必然会存在全网==各节点状态不一致==的情况，而且由于是随机选取发送消息的节点，所以尽管可以在整体上测算出统计学意义上的传播速率，但对于个体消息来说，==无法准确地预计到需要多长时间才能达成全网一致==。
另外一个缺点是==消息的冗余==，同样是由于随机选取发送消息的节点，也就不可避免的存在消息重复发送给同一节点的情况，增加了网络的传输的压力，也给消息节点带来额外的处理负载。

达到一致性耗费的时间与网络传播中消息冗余量这两个缺点存在一定对立，如果要改善其中一个，就会恶化另外一个
Gossip 设计了两种可能的==消息传播==模式：反熵（Anti-Entropy）和传谣（Rumor-Mongering）

熵（Entropy）是生活中少见但科学中很常用的概念，它代表着事物的混乱程度。反熵的意思就是==反混乱==，以提升网络各个节点之间的相似度为目标，所以在反熵模式下，会==同步节点的全部数据==，以消除各节点之间的差异，目标是整个网络各节点完全的一致。
但是，在节点本身就会发生变动的前提下，这个目标将使得整个网络中==消息的数量非常庞大==，给网络带来巨大的传输开销。

而传谣模式是以传播消息为目标，仅仅发送==新到达节点的数据==，即只对外发送变更信息，这样消息数据量将显著缩减，网络开销也相对较小。



## 从类库到服务
通过服务来实现组件
Microservice architectures will use libraries, but their primary way of componentizing their own software is by breaking down into services.
微服务架构也会使用到类库，但构成软件系统组件的主要方式是将其拆分为一个个服务。

微服务架构其中一个重要设计原则是“==通过服务来实现独立自治的组件==”（Componentization via Services），强调应采用“服务”（Service）而不再是“类库”（Library）来构建组件化的程序，这两者的差别在于类库是在编译期静态链接到程序中的，通过调用本地方法来使用其中的功能，而服务是进程外组件，通过调用远程方法来使用其中的功能。

以下三个问题是必须考虑并得到妥善解决的：

- 对消费者来说，外部的服务由谁提供？具体在什么网络位置？
- 对生产者来说，内部哪些服务需要暴露？哪些应当隐藏？应当以何种形式暴露服务？以什么规则在集群中分配请求？
- 对调用过程来说，如何保证每个远程服务都接收到相对平均的流量，获得尽可能高的服务质量与可靠性？

这三个问题的解决方案，在微服务架构中通常被称为“服务发现”、“服务的网关路由”和“服务的负载均衡”。


### 服务发现

如何确定目标方法的确切位置，便是与编译链接有着等同意义的研究课题，解决该问题的过程便被称作“服务发现”（Service Discovery）。


#### 服务发现的意义

所有的远程服务调用都是使用==全限定名==（Fully Qualified Domain Name，FQDN ）、==端口号与服务标识==所构成的三元组来确定一个远程服务的精确坐标的。
- ==全限定名==代表了网络中某台==主机==的精确位置，
- ==端口==代表了主机上某一个提供了 TCP/UDP 网络服务的==程序==，
- ==服务标识==则代表了该程序所提供的某个具体的==方法入口==。

其中“全限定名、端口号”的含义对所有的远程服务来说都一致，而“服务标识”则与具体的应用层协议相关，不同协议具有不同形式的标识，
譬如 REST 的远程服务，标识是 URL 地址；RMI 的远程服务，标识是 Stub 类中的方法；SOAP 的远程服务，标识是 WSDL 中定义方法，等等。

远程服务标识的多样性，决定了“服务发现”也可以有两种不同的理解，
- 一种是以 UDDI 为代表的“百科全书式”的服务发现，上至提供服务的企业信息（企业实体、联系地址、分类目录等等），下至服务的程序接口细节（方法名称、参数、返回值、技术规范等等）都在服务发现的管辖范围之内；
- 另一种是类似于 DNS 这样“门牌号码式”的服务发现，只满足从某个代表服务提供者的全限定名到服务实际主机 IP 地址的翻译转换，并不关心服务具体是哪个厂家提供的，也不关心服务有几个方法，各自由什么参数构成，默认这些细节信息是服务消费者本身已完全了解的，此时服务坐标就可以==退化为更简单的“全限定名+端口号==”。
当今，==后一种服务发现占主流地位==，本文后续所说的服务发现，如无说明，均是特指的是后者。

原本服务发现只依赖 DNS 将一个全限定名翻译为一至多个 IP 地址或者 SRV 等其他类型的记录便可，位于 DNS 之后的负载均衡器也实质上承担了一部分服务发现的职责，完成了外部 IP 地址到各个服务内部实际 IP 的转换，
这种做法在软件追求不间断长时间运行的时代是很合适的，但随着微服务的逐渐流行，服务的非正常宕机、重启和正常的上线、下线变得越发频繁，仅靠着 DNS 服务器和负载均衡器等基础设施就显得逐渐疲于应对，无法跟上服务变动的步伐了。
人们最初是尝试使用 ZooKeeper 这样的分布式 K/V 框架，通过软件自身来完成服务注册与发现，ZooKeeper 也的确曾短暂统治过远程服务发现，是微服务早期的主流选择，但毕竟 ZooKeeper 是很底层的分布式工具，用户自己还需要做相当多的工作才能满足服务发现的需求。
到了 2014 年，在 Netflix 内部经受过长时间实际考验的、专门用于服务发现的 ==Eureka== 宣布开源，并很快被纳入 Spring Cloud，成为 Spring 默认的远程服务发现的解决方案。
从此 Java 程序员再无须再在服务注册这件事情上花费太多的力气。
到 2018 年，Spring Cloud Eureka 进入维护模式以后，HashiCorp 的 Consul 和阿里巴巴的 Nacos 很就快从 Eureka 手上接过传承的衣钵。

服务发现框架已经发展得相当成熟，考虑到几乎方方面面的问题，
不仅支持通过 DNS 或者 HTTP 请求进行符号与实际地址的转换，
还支持各种各样的服务健康检查方式，
支持集中配置、
K/V 存储、
跨数据中心的数据交换等多种功能，
可算是应用自身去解决服务发现的一个顶峰。
如今，云原生时代来临，基础设施的灵活性得到大幅度的增强，最初的==使用基础设施来透明化地做服务发现==的方式又重新被人们所重视，如何在基础设施和网络协议层面，对应用尽可能无感知、方便地实现服务发现是目前服务发现的一个主要发展方向。


#### 可用与可靠

这里要讨论的第一个问题是“服务发现”具体是指进行过什么操作？这其实包含三个必须的过程。

- 服务的注册
  当服务启动的时候，它应该通过某些形式（如调用 API、产生事件消息、在 ZooKeeper/Etcd 的指定位置记录、存入数据库，等等）将自己的坐标信息通知到服务注册中心，
  这个过程可能由应用程序本身来完成，称为==自注册模式==，譬如 Spring Cloud 的@EnableEurekaClient 注解；
  也可能由容器编排框架或第三方注册工具来完成，称为==第三方注册模式==，譬如 Kubernetes 和 Registrator。
- 服务的维护
  尽管服务发现框架通常都有提供下线机制，但并没有什么办法保证每次服务都能优雅地下线 （Graceful Shutdown）而不是由于宕机、断网等原因突然失联。
  所以服务发现框架必须要自己去==保证所维护的服务列表的正确性==，以避免告知消费者服务的坐标后，得到的服务却不能使用的尴尬情况。
  现在的服务发现框架，往往都能支持多种协议（HTTP、TCP 等）、多种方式（长连接、心跳、探针、进程状态等）去==监控服务是否健康存活==，==将不健康的服务自动从服务注册表中剔除==。
- 服务的发现
  这里的发现是特指狭义上消费者从服务发现框架中，把一个==符号==（譬如 Eureka 中的 ServiceID、Nacos 中的服务名、或者通用的 FQDN）==转换为服务实际坐标的过程==，这个过程现在一般是通过 ==HTTP== API 请求或者通过 ==DNS Lookup== 操作来完成，也还有一些相对少用的方式，譬如 Kubernetes 也支持==注入环境变量==来做服务发现


以上三点只是列举了服务发现必须提供的功能，在此之余还会有一些可选的扩展功能，譬如在服务发现时进行的==负载均衡、流量管控、键值存储、元数据管理、业务分组==，等等，这部分后续章节会有专门介绍，不在此展开。

服务==提供者==在服务注册中心中注册、续约和下线自己的真实坐标，
服务==消费者==根据某种符号从服务注册中心中获取到真实坐标，
无论是服务注册中心、服务提供者还是服务消费者，它们都是系统服务中的一员，相互间的关系应是对等的。


但在真实的系统里，注册中心的地位是特殊的，不能为完全视其为一个普通的服务。
注册中心不依赖其他服务，但==被所有其他服务共同依赖==，是系统中==最基础的服务==（类似地位的大概就数配置中心了，现在服务发现框架也开始同时==提供配置中心==的功能，以避免配置中心又去专门摆弄出一集群的节点来），几乎没有可能在业务层面进行容错。
这意味着服务注册中心一旦崩溃，整个系统都不再可用，因此，必须尽最大努力保证服务发现的可用性。实际用于生产的分布式系统，服务注册中心都是以集群的方式进行部署的，通常使用==三个或者五个==节点（通常最多七个，一般也不会更多了，否则日志复制的开销太高）来保证高可用，如图 7-2 所示：

作为用户，我们当然期望服务注册中心一直可用永远健康的同时，也能够在访问每一个节点中都能取到可靠一致的数据，而不是从注册中心拿到的服务地址可能已经下线，这两个需求就构成了 CAP 矛盾
以最有代表性的 Netflix Eureka 和 Hashicorp Consul 为例：


Eureka 的选择是优先保证==高可用性==，相对牺牲系统中服务状态的一致性。
Eureka 的各个节点间采用==异步复制==来交换服务注册信息，当有新服务注册进来时，并不需要等待信息在其他节点复制完成，而是马上在该服务发现节点宣告服务可见，只是==不保证在其他节点上多长时间后才会可见==。
同时，当有旧的服务发生变动，譬如下线或者断网，==只会由超时机制来控制何时从哪一个服务注册表中移除==，变动信息不会实时的同步给所有服务端与客户端。
这样的设计使得不论是 Eureka 的==服务端==还是==客户端==，==都能够持有自己的服务注册表缓存，并以 TTL（Time to Live）机制来进行更新==，哪怕服务注册中心完全崩溃，客户端在仍然可以维持最低限度的可用。
Eureka 的服务发现模型==对节点关系相对固定，服务一般不会频繁上下线的系统是很合适的==，以较小的同步代价换取了最高的可用性；
Eureka 能够选择这种模型的底气在于万一客户端拿到了已经发生变动的错误地址，也能够通过 Ribbon 和 Hystrix 模块配合来兜底，实现==故障转移==（Failover）或者==快速失败==（Failfast）。


Consul 的选择是优先保证==高可靠==性，相对牺牲系统服务发现的可用性。
Consul 采用==Raft== 算法，要求多数派节点写入成功后服务的注册或变动才算完成，严格地保证了在集群外部读取到的服务发现结果必定是一致的；
同时采用 ==Gossip== 协议，支持多数据中心之间更大规模的服务同步。
Consul 优先保证高可靠性一定程度上是基于产品现实情况而做的技术决策，它不像 Netflix OSS 那样有着全家桶式的微服务组件，万一从服务发现中取到错误地址，就没有其他组件为它兜底了。
Eureka 与 Consul 的差异带来的影响主要不在于服务注册的快慢（当然，快慢确实是有差别），而在于你如何看待以下这件事情：
- 假设系统形成了 A、B 两个网络分区后，A 区的服务只能从区域内的服务发现节点获取到 A 区的服务坐标，B 区的服务只能取到在 B 区的服务坐标，这对你的系统会有什么影响？
  - 如果这件事情对你并没有太大的影响，
    甚至有可能还是有益的，就应该倾向于选择 AP 式的服务发现。譬如假设 A、B 就是不同的机房，是机房间的网络交换机导致服务发现集群出现的分区问题，但==每个分区中的服务仍然能独立提供完整且正确的服务能力==，此时尽管不是有意而为，但网络分区在事实上避免了跨机房的服务请求，反而还带来了服务调用链路优化的效果。
  - 如果这件事情也可能对你影响非常之大，
    甚至可能带来比整个系统宕机更坏的结果，就应该倾向于选择 CP 式的服务发现。譬如系统中大量依赖了集中式缓存、消息总线、或者其他有状态的服务，一旦这些服务全部或者部分被分隔到某一个分区中，会对整个系统的操作的正确性产生直接影响的话，那==与其最后弄出一堆数据错误，还不如直接停机==来得痛快。



#### 注册中心实现

可用性与一致性的矛盾，是分布式系统永恒的话题，在服务发现这个场景里，权衡的==主要关注==点是相对更能容忍出现==服务列表不可用的后果==，还是出现==服务数据不准确的后果==，其次才到性能高低，功能是否强大，使用是否方便等因素。

直接以服务发现、服务注册中心为目标的组件库，或者间接用来实现这个目标的工具主要有以下三类：
- 在分布式 K/V 存储框架上自己开发的服务发现，这类的代表是 ZooKeeper、Doozerd、Etcd。
  这些 K/V 框架提供了分布式环境下读写操作的共识算法，
  ==Etcd== 采用的是我们学习过的 Raft 算法，
  ==ZooKeeper== 采用的是 ZAB 算法，这也是一种 Multi Paxos 的派生算法，所以采用这种方案，就不必纠结 CP 还是 AP 的问题，它们==都是 CP== 的（也曾有公司采用 ==Redis== 来做服务发现，这种==自然是 AP== 的）。
  这类框架的宣传语中往往会主动提及“高可用性”，潜台词其实是“在保证一致性和分区容忍性的前提下，尽最大努力实现最高的可用性”，譬如 Etcd 的宣传语就是“高可用的集中配置和服务发现”（Highly-Available Key Value Store for Shared Configuration and Service Discovery）。
  这些 K/V 框架的一个共同特点是在整体较高复杂度的架构和算法的外部，维持着极为简单的应用接口，只有基本的 CRUD 和 Watch 等少量 API，所以要在上面完成功能齐全的服务发现，很多基础的能力，譬如服务如何注册、如何做健康检查，等等都必须自己去实现，如今一般也==只有“大厂”才会直接基于这些框架==去做服务发现了。

- 以基础设施（主要是指 DNS 服务器）来实现服务发现，这类的代表是 SkyDNS、CoreDNS。
  在 Kubernetes 1.3 之前的版本使用 SkyDNS 作为默认的 DNS 服务，其工作原理是从 API Server 中监听集群服务的变化，然后根据服务生成 NS、SRV 等 DNS 记录存放到 ==Etcd== 中，kubelet 会为每个 Pod 设置 DNS 服务的地址为 SkyDNS 的地址，需要调用服务时，只需查询 DNS 把域名转换成 IP 列表便可实现分布式的服务发现。
  在 Kubernetes 1.3 之后，SkyDNS 不再是默认的 DNS 服务器，而是由不使用 Etcd，只将 DNS 记录存储在==内存中的 KubeDNS== 代替，
  到了 1.11 版，就更推荐采用扩展性很强的 ==CoreDNS==，此时可以通过各种插件来决定是否要采用 Etcd 存储、重定向、定制 DNS 记录、记录日志，等等。
  采用这种方案，是 ==CP 还是 AP 就取决于后端采用何种存储==，如果是基于 ==Etcd== 实现的，那自然==是 CP== 的，如果是==基于内存异步复制==的方案实现的，那就是 ==AP== 的（仅针对 DNS 服务器本身，不考虑本地 DNS 缓存的 TTL 刷新）。
  以基础设施来做服务发现，==好处是对应用透明==，任何语言、框架、工具都肯定是支持 HTTP、DNS 的，所以完全不受程序技术选型的约束，但==坏处是透明的并不一定是简单的==，你必须自己考虑如何去做客户端==负载均衡==、==如何调用==远程方法等这些问题，而且必须遵循或者说受限于这些基础设施本身所采用的实现机制，譬如服务健康检查里，服务的缓存期限就应该由 TTL 来决定，这是 DNS 协议所规定的，如果想改用 KeepAlive 长连接来实时判断服务是否存活就相对麻烦。

- 专门用于服务发现的框架和工具，这类的代表是 Eureka、Consul 和 Nacos。
  你可以自己决定是 CP 还是 AP 的问题，譬如 ==CP 的 Consul==、==AP 的 Eureka==，还有==同时支持 CP 和 AP 的 Nacos==（Nacos 采用类 Raft 协议做的 CP，采用自研的 Distro 协议做的 AP，这里“同时”是“都支持”的意思，它们必须二取其一，不是说 CAP 全能满足）。
  将它们划归一类是由于它们对应用并不是透明的，尽管 Consul 的主体逻辑是在服务进程之外，以边车的形式提供的，尽管 Consul、Nacos 也支持基于 DNS 的服务发现，尽管==这些框架都基本上做到了以声明代替编码==，譬如在 Spring Cloud 中只改动 pom.xml、配置文件和注解即可实现，但它们依然是可以被应用程序感知的。
  所以或多或少还需要考虑你所用的程序语言、技术框架的集成问题。但这个特点其实并不见得全是坏处，譬如采用 Eureka 做服务注册，那在远程调用服务时你就可以用 OpenFeign 做客户端，它们本身就已做好了集成，写个声明式接口就能跑；在做负载均衡时你就可以采用 Ribbon 做客户端，要换均衡算法改个配置就成，这些“不透明”实际上都为编码开发带来了一定便捷，而前提是你选用的语言和框架必须支持。如果老板提出要在 Rust 上用 Eureka，那就只能无奈叹息了（原本这里我写的是 Node、Go、Python 等，查了一下这些居然都有==非官方的 Eureka 客户端==，用的人多什么问题都会有解决方案）。




### 网关路由

http://icyfenix.cn/distribution/connect/service-routing.html


网关（Gateway）这个词在计算机科学中，尤其是计算机网络中很常见，它用来表示位于内部区域边缘，与外界进行交互的某个物理或逻辑设备，譬如你家里的路由器就属于家庭内网与互联网之间的网关。


#### 网关的职责

在微服务环境中，网关的存在感就极大地增强了，甚至成为了微服务集群中必不可少的设施之一。
微服务架构下，每个服务节点都可能由不同团队负责，都有着自己独立的、互不相同的接口，如果服务集群==缺少一个统一对外交互的代理人角色==，那外部的服务==消费者就必须知道所有==微服务节点在集群中的==精确坐标==（在服务发现中解释过“服务坐标”的概念），
这样，消费者不仅会受到服务集群的网络限制（不能确保集群中每个节点都有外网连接）、安全限制（不仅是服务节点的安全，外部自身也会受到如浏览器同源策略 的约束）、依赖限制（服务坐标这类信息不属于对外接口承诺的内容，随时可能变动，不应该依赖它），就算是调用服务的程序员，自己也不会愿意记住每一个服务的坐标位置来编写代码。
由此可见，微服务中网关的==首要职责==就是作为==统一的出口==对外提供服务，将外部访问网关地址的流量，根据适当的规则路由到内部集群中正确的服务节点之上，因此，微服务中的网关，也常被称为“服务网关”或者“API 网关”，微服务中的网关首先应该是个路由器，
在满足此前提的基础上，网关还可以根据需要作为==流量过滤器==来使用，提供某些额外的可选的功能，譬如==安全、认证、授权、限流、监控、缓存==，等等（这部分内容在后续章节中有专门讲解，这里不会涉及）。简而言之：
`网关 = 路由器（基础职能） + 过滤器（可选职能）`

针对“路由”这个基础职能，服务网关主要考量的是能够支持路由的“网络协议层次”和“性能与可用性”两方面的因素。
网络协议层次是指负载均衡中介绍过的四层流量转发与七层流量代理，
仅从技术实现角度来看，对于路由这项工作，负载均衡器与服务网关在实现上是没有什么差别的，很多服务网关本身就是基于老牌的负载均衡器来实现的，譬如基于 Nginx、HAProxy 开发的 Ingress Controller，基于 Netty 开发的 Zuul 2.0 等；
但从目的角度看，负载均衡器与服务网关会有一些==区别==，具体在于前者是为了根据均衡算法对流量进行平均地路由，后者是为了==根据流量中的某种特征进行正确地路由==。
网关必须能够识别流量中的特征，这意味着网关能够支持的网络通信协议的层次将会直接限制后端服务节点能够选择的服务通信方式。如果服务集群只提供像 Etcd 这样直接基于 TCP 的访问的服务，那只部署四层网关便可满足，网关以 IP 报文中源地址、目标地址为特征进行路由；如果服务集群要提供 HTTP 服务的话，那就必须部署一个七层网关，网关根据 HTTP 报文中的 URL、Header 等信息为特征进行路由；如果服务集群还要提供更上层的 WebSocket、SOAP 等服务，那就必须要求网关同样能够支持这些上层协议，才能从中提取到特征。

举个例子，以下是一段基于 SpringCloud 实现的 Fenix's Bookstore中用到的 Netflix Zuul 网关的配置，Zuul 是 HTTP 网关，`/restful/accounts/**` 和 `/restful/pay/**` 是 HTTP 中 URL 的特征，而配置中的 serviceId 就是路由的目标服务。

```yaml
  routes:
    account:
      path: /restful/accounts/**
      serviceId: account
      stripPrefix: false
      sensitiveHeaders: "*"

    payment:
      path: /restful/pay/**
      serviceId: payment
      stripPrefix: false
      sensitiveHeaders: "*"
```


网关的另一个主要关注点是它的性能与可用性。
由于网关是所有服务对外的总出口，是流量必经之地，所以网关的路由性能将导致全局的、系统性的影响，如果经过网关路由会有 1 毫秒的性能损失，就意味着整个系统所有服务的响应延迟都会增加 1 毫秒。
网关的性能与它的工作模式和自身实现算法都有关系，但毫无疑问工作模式是最关键的因素，如果能够采用 DSR 三角传输模式，原理上就决定了性能一定会比代理模式来的强（DSR、IP Tunnel、NAT、代理等这些都是网络基础知识，笔者曾在介绍负载均衡器时详细讲解过）。
不过，因为今天 REST 和 JSON-RPC 等基于 HTTP 协议的服务接口在对外部提供的服务中占绝对主流的地位，所以我们所讨论的服务网关默认==都必须支持七层路由==，通常就默认无法直接进行流量转发，只能采用代理模式。
在这个前提约束下，网关的性能主要取决于它们如何代理网络请求，也即它们的网络 I/O 模型，下面笔者正好借这个场景介绍一下网络 I/O 的基础知识


#### 网络 I/O 模型

在套接字接口抽象下，==网络 I/O 的出入口就是 Socket 的读和写，Socket 在操作系统接口中被抽象为数据流，网络 I/O 可以理解为对流的操作==。
每一次网络访问，从远程主机返回的数据会先存放到==操作系统内核的缓冲区==中，然后内核的缓冲区==复制==到==应用程序的地址空间==，
所以当发生一次网络请求发生后，将会按顺序经历“等待数据从远程主机到达缓冲区”和“将数据从缓冲区拷贝到应用程序地址空间”两个阶段，
根据实现这两个阶段的不同方法，人们把网络 I/O 模型总结为==两类、五种模型==：
两类是指==同步 I/O==与==异步 I/O==，
五种是指在 ==同==步 IO 中又分有划分出==阻塞 I/O、非阻塞 I/O、多路复用 I/O和信号驱动 I/O四种细分模型==。
这里笔者先解释一下同步和异步、阻塞和非阻塞的概念。
==同步是指==调用端发出请求之后，得到结果之前必须一直等待，
与之相对的就是==异步==，发出调用请求之后将立即返回，不会马上得到处理结果，结果将通过状态变化和回调来通知调用者。
阻塞和非阻塞是==针对请求处理==过程，指==收到==调用请求之后，返回结果之前，当前处理线程是否==会被挂起==。

这种概念上的叙述估计还是不太好理解的，笔者以“你如何领到盒饭”为情景，将之类比解释如下：

- 异步 I/O（Asynchronous I/O）：
  好比你在美团外卖订了个盒饭，付款之后你自己该干嘛还干嘛去，饭做好了骑手自然会到门口打电话通知你。
  ==异步 I/O 中数据到达缓冲区后，不需要由调用进程主动进行从缓冲区复制数据的操作，而是复制完成后由操作系统向线程发送信号，所以它一定是非阻塞的==。

- 同步 I/O（Synchronous I/O）：
  好比你自己去饭堂打饭，这时可能有如下情形发生： 
  - 阻塞 I/O（Blocking I/O）：
    你去到饭堂，发现饭还没做好，你也干不了别的，只能打个瞌睡（线程休眠），直到饭做好，这就是被阻塞了。阻塞 I/O 是最直观的 I/O 模型，逻辑清晰，也比较节省 CPU 资源，但缺点就是线程休眠所带来的上下文切换，这是一种需要切换到内核态的重负载操作，不应当频繁进行。
  - 非阻塞 I/O（Non-Blocking I/O）：
    你去到饭堂，发现饭还没做好，你就回去了，然后每隔 3 分钟来一次饭堂看饭做好了没，直到饭做好。非阻塞 I/O 能够避免线程休眠，对于一些很快就能返回结果的请求，非阻塞 I/O 可以节省切换上下文切换的消耗，但是对于较长时间才能返回的请求，非阻塞 I/O 反而白白浪费了 CPU 资源，所以目前并不常用。
  - 多路复用 I/O（Multiplexing I/O）：
    多路复用 I/O 本质上是阻塞 I/O 的一种，但是它的好处是可以在同一条阻塞线程上处理多个不同端口的监听。类比的情景是你名字叫雷锋，代表整个宿舍去饭堂打饭，去到饭堂，发现饭还没做好，还是继续打瞌睡，但哪个舍友的饭好了，你就马上把那份饭送回去，然后继续打着瞌睡哼着歌等待其他的饭做好。==多路复用 I/O 是目前的高并发网络应用的主流==，它下面还可以细分 ==select、epoll、kqueue== 等不同实现，这里就不作展开了。
  - 信号驱动 I/O（Signal-Driven I/O）：
    你去到饭堂，发现饭还没做好，但你跟厨师熟，跟他说饭做好了叫你，然后回去该干嘛干嘛，等收到厨师通知后，你把饭从饭堂拿回宿舍。这里厨师的通知就是那个“信号”，信号驱动 I/O 与异步 I/O 的区别是“从缓冲区获取数据”这个步骤的处理，前者收到的通知是可以开始进行复制操作了，即要你自己从饭堂拿回宿舍，在复制完成之前线程处于阻塞状态，所以它仍属于同步 I/O 操作，而后者收到的通知是复制操作已经完成，即外卖小哥已经把饭送到了。


异步 I/O 模型是最方便的，
但异步 I/O 受限于操作系统，Windows NT 内核早在 3.5 以后，就通过IOCP 实现了真正的异步 I/O 模型。
而 Linux 系统下，是在 Linux Kernel 2.6 才首次引入，目前也还并不算很完善，因此在 Linux 下实现高并发网络编程时仍是以多路复用 I/O 模型模式为主。


七层服务网关处理一次请求代理时，包含了两组网络操作，分别是作为服务端对外部请求的应答，和作为客户端对内部服务的请求，理论上这两组网络操作可以采用不同的模型去完成，但一般来说并没有必要这样做。


在 Zuul 1.0 时，它采用的是阻塞 I/O 模型来进行最经典的“一条线程对应一个连接”（Thread-per-Connection）的方式来代理流量，采用阻塞 I/O 意味着它会有线程休眠，就有上下文切换的成本，所以如果后端服务普遍属于计算密集型（CPU Bound，可以通俗理解为服务耗时比较长，主要消耗在 CPU 上）时，这种模式能够相对节省网关的 CPU 资源，但如果后端服务普遍都是 I/O 密集型（I/O Bound，可以理解服务都很快返回，主要消耗在 I/O 上），它就会由于频繁的上下文切换而降低性能。

在 Zuul 的 2.0 版本，最大的改进就是基于 Netty Server 实现了异步 I/O 模型来处理请求，大幅度减少了线程数，获得了更高的性能和更低的延迟。根据 Netflix 官方自己给出的数据，Zuul 2.0 大约要比 Zuul 1.0 快上 20%左右。

甚至还有一些网关，支持自行配置，或者根据环境选择不同的网络 I/O 模型，典型的就是 Nginx，可以支持在配置文件中指定 select、poll、epoll、kqueue 等并发模型。

网关的性能高低一般只去定性分析，要定量地说哪一种网关性能最高、高多少是很困难的，就像我们都认可 Chrome 要比 IE 快，但脱离了具体场景，快上多少就很难说的清楚。

网关还有最后一点必须关注的是它的==可用性==问题。
任何系统的网络调用过程中都至少会有一个单点存在，这是由用户只通过唯一的一个地址去访问系统所决定的。
即使是淘宝、亚马逊这样全球多数据中心部署的大型系统也不例外。对于更普遍的小型系统（小型是相对淘宝这些而言）来说，作为后端对外服务代理人角色的==网关经常被视为整个系统的入口==，往往很容易成为网络访问中的==单点==，这时候它的==可用性就尤为重要==。
由于==网关的地址具有唯一性==，就不像之前服务发现那些注册中心那样直接做个集群，随便访问哪一台都可以解决问题。为此，对网关的可用性方面，我们应该考虑到以下几点

- 网关应尽可能轻量，尽管网关作为服务集群统一的出入口，可以很方便地做安全、认证、授权、限流、监控，等等的功能，但给网关附加这些能力时还是要仔细权衡，取得功能性与可用性之间的平衡，过度增加网关的职责是危险的。
- 网关选型时，应该尽可能选择较成熟的产品实现，譬如 Nginx Ingress Controller、KONG、Zuul 这些经受过长期考验的产品，而不能一味只考虑性能选择最新的产品，性能与可用性之间的平衡也需要权衡。
- 在需要高可用的生产环境中，应当考虑在网关之前部署负载均衡器或者等价路由器（ECMP），让那些更成熟健壮的设施（往往是硬件物理设备）去充当整个系统的入口地址，这样网关也可以进行扩展了。

#### BFF 网关
提到网关的唯一性、高可用与扩展，笔者顺带也说一下近年来随着微服务一起火起来的概念“BFF”（Backends for Frontends）。
这个概念目前还没有权威的中文翻译，在我们讨论的上下文里，它的意思是，==网关不必为所有的前端提供无差别的服务，而是应该针对不同的前端，聚合不同的服务，提供不同的接口和网络访问协议支持==。
譬如，运行于浏览器的 Web 程序，由于浏览器一般只支持 HTTP 协议，服务网关就应提供 REST 等基于 HTTP 协议的服务，但同时我们亦可以针对运行于桌面系统的程序部署另外一套网关，它能与 Web 网关有完全不同的技术选型，能提供出基于更高性能协议（如 gRPC）的接口来获得更好的体验。
在网关这种边缘节点上，针对同一样的后端集群，裁剪、适配、聚合出适应不一样的前端的服务，有助于后端的稳定，也有助于前端的赋能。



### 客户端负载均衡

一个例子：
1. 将warehouse这个服务名称转换为恰当的服务地址，用户访问首页时已经被 DNS 服务器分配到了广州机房，请求出库服务时，应优先选择同机房的服务进行调用
2. 网关将该请求与配置中的特征进行比对，由 URL 中的/restful/stockpile/**得知该请求访问的是商品出库服务，因此，将请求的 IP 地址转换为内网中 warehouse 服务集群的入口地址
3. 集群中部署有多个 warehouse 服务，收到调用请求后，负载均衡器要在多个服务中根据均衡策略找出要响应本次调用的服务
4. 如果访问warehouse-gz-lan-node1服务，没有返回需要的结果，而是抛出 500 错。
5. 根据预置的故障转移（Failover）策略，重试将调用分配给能够提供该服务的其他节点，称其为warehouse-gz-lan-node2。
6. warehouse-gz-lan-node2服务返回商品出库成功。

步骤 1、2、3、5，分别对应了服务发现、网关路由、负载均衡和服务容错

以上网络调用过程似乎过于烦琐了，一个从广州机房内网发出的服务请求，绕到了网络边缘的网关、负载均衡器这些设施上，再被分配回内网中另外一个服务去响应，不仅消耗了带宽，降低了性能，也增加了链路上的风险和运维的复杂度。
可是，如果流量不经过这些设施，它们相应的职责就无法发挥作用，譬如不经过负载均衡器的话，连请求应该具体交给哪一个服务去处理都无法确定，这有办法简化吗？


#### 客户端负载均衡器

对于任何一个大型系统，负载均衡器都是必不可少的设施。
以前，负载均衡器大多只部署在整个服务集群的前端，将用户的请求分流到各个服务进行处理，这种经典的部署形式现在被称为==集中式的负载均衡==。

随着微服务日渐流行，服务集群的收到的请求来源不再局限于外部，越来越多的访问请求是==由集群内部的某个服务发起，由集群内部的另一个服务进行响应的==，对于这类流量的负载均衡，既有的方案依然是可行的，但针对内部流量的特点，直接在服务集群内部消化掉，肯定是更合理更受开发者青睐的办法。
由此一种全新的、独立位于每个服务前端的、分散式的负载均衡方式正逐渐变得流行起来，这就是本节我们要讨论的主角：客户端负载均衡器（Client-Side Load Balancer）

![98eec472ad5dc92ca06a10fdb635fc5f.png](../_resources/98eec472ad5dc92ca06a10fdb635fc5f.png)

客户端负载均衡器的理念提出以后，此前的集中式负载均衡器也有了一个方便与它对比的名字“服务端负载均衡器”（Server-Side Load Balancer）。
客户端负载均衡器的特点，也是它与服务端负载均衡器的==关键差别==所在：客户端均衡器是和服务实例一一对应的，而且与服务实例并存于同一个进程之内。
这个特点能为它带来很多好处，如：
- 均衡器与服务之间信息交换是进程内的方法调用，不存在任何额外的网络开销。
- 不依赖集群边缘的设施，所有内部流量都仅在服务集群的内部循环，避免了出现前文那样，集群内部流量要“绕场一周”的尴尬局面。
- 分散式的均衡器意味着天然避免了集中式的单点问题，它的带宽资源将不会像集中式均衡器那样敏感，这在以七层均衡器为主流、不能通过 IP 隧道和三角传输这样方式节省带宽的微服务环境中显得更具优势。
- 客户端均衡器要更加灵活，能够针对每一个服务实例单独设置均衡策略等参数，访问某个服务，是不是需要具备亲和性，选择服务的策略是随机、轮询、加权还是最小连接等等，都可以单独设置而不影响其它服务。

客户端均衡器也不是银弹，它得到上述诸多好处的同时，缺点同样也是不少的：
- 它与服务运行于同一个进程之内，意味着它的选型受到服务所使用的编程语言的限制，譬如用 Golang 开发的微服务就不太可能搭配 Spring Cloud Load Balancer 来使用，要为每种语言都实现对应的能够支持复杂网络情况的均衡器是非常难的。客户端均衡器的这个缺陷有违于微服务中技术异构不应受到限制的原则。
- 从个体服务来看，由于是共用一个进程，均衡器的稳定性会直接影响整个服务进程的稳定性，消耗的 CPU、内存等资源也同样影响到服务的可用资源。从集群整体来看，在服务数量达成千乃至上万规模时，客户端均衡器消耗的资源总量是相当可观的。
- 由于请求的来源可能是来自集群中任意一个服务节点，而不再是统一来自集中式均衡器，这就使得内部网络安全和信任关系变得复杂，当攻破任何一个服务时，更容易通过该服务突破集群中的其他部分。
- 服务集群的拓扑关系是动态的，每一个客户端均衡器必须持续跟踪其他服务的健康状况，以实现上线新服务、下线旧服务、自动剔除失败的服务、自动重连恢复的服务等均衡器必须具备的功能。由于这些操作都需要通过访问服务注册中心来完成，数量庞大的客户端均衡器一直持续轮询服务注册中心，也会为它带来不小的负担。


#### 代理负载均衡器
直到最近两三年，服务网格（Service Mesh）开始逐渐盛行，另外一种被称为“代理客户端负载均衡器”（Proxy Client-Side Load Balancer，后文简称“代理均衡器”）的客户端均衡器变体形式开始引起不同编程语言的微服务开发者共同关注，它解决了此前客户端均衡器的大多数缺陷。
代理均衡器对此前的客户端负载均衡器的改进是将原本嵌入在服务进程中的均衡器提取出来，作为一个==进程之外==，同一==Pod 之内==的特殊服务，放到边车代理中去实现，它的流量关系如图 7-5 所示。

![95a6b224113c01252f5ef7e44123c9cf.png](../_resources/95a6b224113c01252f5ef7e44123c9cf.png)

虽然代理均衡器与服务实例不再是进程内通信，而是通过网络协议栈进行数据交换的，数据要经过操作系统的协议栈，要进行打包拆包、计算校验和、维护序列号等网络数据的收发步骤，流量比起之前的客户端均衡器确实多增加了一系列处理步骤。
不过，Kubernetes 严格保证了同一个 Pod 中的容器不会跨越不同的节点，这些容器共享着同一个网络名称空间，因此代理均衡器与服务实例的交互，实质上是对本机回环设备的访问，仍然要比真正的网络交互高效且稳定得多。
代理均衡器付出的代价较小，但从服务进程中分离出来所获得的收益却是非常显著的：

- 代理均衡器不再受编程语言的限制
- 在服务拓扑感知方面代理均衡器也要更有优势。
  由于边车代理接受控制平面的统一管理，当服务节点拓扑关系发生变化时，控制平面就会主动向边车代理发送更新服务清单的控制指令，这避免了此前客户端均衡器必须长期主动轮询服务注册中心所造成的浪费。
- 在安全性、可观测性上，由于边车代理都是一致的实现，有利于在服务间建立双向 TLS 通信，也有利于对整个调用链路给出更详细的统计信息。

总体而言，边车代理这种通过同一个 Pod 的独立容器实现的负载均衡器是目前处理微服务集群内部流量最理想的方式，只是服务网格本身仍是初生事物，还不足够成熟，对操作系统、网络和运维方面的知识要求也较高，但有理由相信随着时间的推移，未来这将会是微服务的主流通信方式。


#### 地域与区域

几乎所有云计算设备都有类似的概念。Region 和 Zone 是公有云计算先驱亚马逊 AWS提出的概念 ，它们的含义是指：

- Region 是地域的意思，
  譬如华北、东北、华东、华南，这些都是地域范围。
  面向全球或全国的大型系统的服务集群往往会部署在多个不同地域，譬如本节开头列举的案例场景，大型系统就是通过不同地域的机房来缩短用户与服务器之间的物理距离，提升响应速度，对于小型系统，地域一般就只在异地容灾时才会涉及到。
  需要注意，==不同地域之间是没有内网连接的==，所有流量都只能经过公众互联网相连，如果微服务的流量跨越了地域，实际就跟调用外部服务商提供的互联网服务没有任何差别了。
  所以集群内部流量是不会跨地域的，服务发现、负载均衡器默认也是==不会支持跨地域==的服务发现和负载均衡。

- Zone 是区域的意思，
  它是==可用区域==（Availability Zones）的简称，区域指在地理上位于同一地域内，但==电力和网络是互相独立==的物理区域，譬如在华东的上海、杭州、苏州的不同机房就是同一个地域的几个可用区域。
  ==同一个地域的 可用区域之间具有内网连接==，流量不占用公网带宽，因此区域是微服务集群内流量能够触及的最大范围。
  但你的应用是只部署在同一区域内，还是部署到几个不同可用区域中，要取决于你是否有做==异地双活==的需求，以及对==网络延时==的容忍程度。

可用区域对应于城市级别的区域的范围，一些场景中仍是过大了一些，即使是同一个区域中的机房，也可能存在具有差异的不同子网络，所以在部分微服务框架也提供了 ==Group、Sub-zone== 等做进一步的细分控制，这些参数的意思通常是加权或优先访问同一个子区域的服务，但如果子区域中没有合适的，仍然会访问到可用区域中的其他服务。

地域和区域原本是云计算中的概念，对于一些中小型的微服务系统，尤其是非互联网的企业信息系统，很多仍然没有使用云计算设施，只部署在某个专有机房内部，只为特定人群提供服务，这就不需要涉及地理上地域、区域的概念了。此时完全可以自己灵活延拓 Region、Zone 参数的含义，达到优化虚拟化基础设施流量的目的。譬如，将服务发现的区域设置与 Kubernetes 的标签、选择器配合，实现内部服务请求其他服务时，优先使用同一个 Node 中提供的服务进行应答，以降低真实的网络消耗。


## 流量治理
容错性设计
Since services can fail at any time, it's important to be able to detect the failures quickly and, if possible, automatically restore service
由于服务随时都有可能崩溃，因此快速的失败检测和自动恢复就显得至关重要。


“容错性设计”（Design for Failure）是微服务的另一个==核心原则==，也是笔者书中多次反复强调的开发观念转变。
不过，即使已经有一定的心理准备，大多数首次将微服务架构引入实际生产系统的开发者，在服务发现、网关路由等支持下，踏出了服务化的第一步以后，很可能仍会经历一段阵痛期，随着拆分出的服务越来越多，随之而来会面临以下==两个问题==的困扰：

- 由于某一个服务的崩溃，导致所有用到这个服务的其他服务都无法正常工作，一个点的错误经过层层传递，最终波及到调用链上与此有关的所有服务，这便是雪崩效应。如何防止雪崩效应便是微服务架构容错性设计原则的具体实践，否则服务化程度越高，整个系统反而越不稳定。
- 服务虽然没有崩溃，但由于处理能力有限，面临超过预期的突发请求时，大部分请求直至超时都无法完成处理。这种现象产生的后果跟交通堵塞是类似的，如果一开始没有得到及时的治理，后面就需要长时间才能使全部服务都恢复正常。


### 服务容错

#### 容错策略
必须了解一些常用的==容错策略==和==容错设计模式==，作为具体设计与编码实践的指导

容错策略指的是“面对故障，我们该做些什么”，
容错设计模式指的是“要实现某种容错策略，我们该如何去做”

常见的容错策略有以下几种：
- 故障转移（Failover）
  故障转移是指如果调用的服务器出现故障，系统不会立即向调用者返回失败结果，而是自动切换到其他服务副本，尝试其他副本能否返回成功调用的结果，从而保证了整体的高可用性。
  故障转移的容错策略应该有一定的调用次数限制，譬如允许最多重试三个服务，如果都发生报错，那还是会返回调用失败。原因不仅是因为重试是有执行成本的，更是因为过度的重试反而可能让系统处于更加不利的状况。(超时)
- 快速失败（Failfast）
  一些业务场景是不允许做故障转移的，故障转移策略能够实施的前提是要求服务具备幂等性，对于非幂等的服务，重复调用就可能产生脏数据，此时就应该以快速失败作为首选的容错策略。
- 安全失败（Failsafe）
  在一个调用链路中的服务通常也有主路和旁路之分，并不见得其中每个服务都是不可或缺的，有部分服务失败了也不影响核心业务的正确性
  对这类逻辑，一种理想的容错策略是即使旁路逻辑调用实际失败了，也当作正确来返回，如果需要返回值的话，系统就自动返回一个符合要求的数据类型的对应零值，然后自动记录一条服务调用出错的日志备查即可，这种策略被称为安全失败。
- 沉默失败（Failsilent）
  如果大量的请求需要等到超时（或者长时间处理后）才宣告失败，很容易由于某个远程服务的请求堆积而消耗大量的线程、内存、网络等资源，进而影响到整个系统的稳定。面对这种情况，一种合理的失败策略是当请求失败后，就默认服务提供者一定时间内无法再对外提供服务，不再向它分配请求流量，将错误隔离开来，避免对系统其他部分产生影响，此即为沉默失败策略。
- 故障恢复（Failback）
  故障恢复一般不单独存在，而是作为其他容错策略的补充措施，一般在微服务管理框架中，如果设置容错策略为故障恢复的话，通常默认会采用快速失败加上故障恢复的策略组合。它是指当服务调用出错了以后，将该次调用失败的信息存入一个消息队列中，然后由系统自动开始异步重试调用。
- 并行调用（Forking）
  上面五种以“Fail”开头的策略是针对调用失败时如何进行弥补的，以下这两种策略则是在调用之前就开始考虑如何获得最大的成功概率。
  并行调用策略很符合人们日常对一些重要环节进行的“双重保险”或者“多重保险”的处理思路，它是指==一开始就同时向多个服务副本发起调用==，只要有其中==任何一个返回成功==，那调用便宣告成功，这是一种在关键场景中使用更高的执行成本换取执行时间和成功概率的策略。
- 广播调用（Broadcast）
  广播调用与并行调用是相对应的，都是同时发起多个调用，但并行调用是任何一个调用结果返回成功便宣告成功，广播调用则是要求==所有的请求全部都成功==，这次调用才算是成功，任何一个服务提供者出现异常都算调用失败，广播调用通常会被用于实现“刷新分布式缓存”这类的操作。


|策略|优点|缺点|场景|
|--|--|--|--|
|故障转移|系统自动处理，调用者对失败的信息不可见|增加调用时间，额外的资源开销|调用幂等服务；对调用时间不敏感的场景|
|快速失败|调用者有对失败的处理完全控制权；不依赖服务的幂等性|调用者必须正确处理失败逻辑，如果一味只是对外抛异常，容易引起雪崩|调用非幂等的服务；超时阈值较低的场景|
|安全失败|不影响主路逻辑|只适用于旁路调用|调用链中的旁路服务|
|沉默失败|控制错误不影响全局|出错的地方将在一段时间内不可用|频繁超时的服务|
|故障恢复|调用失败后自动重试，也不影响主路逻辑|重试任务可能产生堆积，重试仍然可能失败|调用链中的旁路服务；对实时性要求不高的主路逻辑也可以使用|
|并行调用|尽可能在最短时间内获得最高的成功率|额外消耗机器资源，大部分调用可能都是无用功|资源充足且对失败容忍度低的场景|
|广播调用|支持同时对批量的服务提供者发起调用|资源消耗大，失败概率高|只适用于批量操作的场景|



#### 容错设计模式

为了实现各种各样的容错策略，开发人员总结出了一些被实践证明是有效的服务容错设计模式，譬如微服务中常见的断路器模式、舱壁隔离模式，重试模式，等等，以及将在下一节介绍的流量控制模式，如滑动时间窗模式、漏桶模式、令牌桶模式，等等。


##### 断路器模式

断路器模式是微服务架构中最基础的容错设计模式，以至于像 Hystrix 这种服务治理工具往往被人们忽略了它的服务隔离、请求合并、请求缓存等其他服务治理职能，直接将它称之为微服务断路器或者熔断器。

断路器的基本思路是很简单的，就是通过代理（断路器对象）来一对一地（一个远程服务对应一个断路器对象）接管服务调用者的远程请求。
断路器会持续监控并统计服务返回的成功、失败、超时、拒绝等各种结果，当出现故障（失败、超时、拒绝）的次数达到断路器的阈值时，它状态就自动变为“OPEN”，后续此断路器代理的远程访问都将==直接返回调用失败==，而==不会发出真正的远程服务请求==。
通过断路器对远程服务的熔断，==避免因持续的失败或拒绝而消耗资源==，==因持续的超时而堆积请求==，最终的目的就是==避免雪崩效应==的出现。
由此可见，断路器本质是一种快速失败策略的实现方式，它的工作过程可以通过下面图 8-1 来表示：

。。retry，等待到timeout。这样 运行状态的异常 就扩散出来了。

从调用序列来看，断路器就是一种有限状态机，断路器模式就是根据自身状态变化自动调整代理请求策略的过程。一般要设置以下三种断路器的状态：
- CLOSED：
  表示==断路器关闭==，此时的远程请求==会真正发送==给服务提供者。断路器刚刚建立时默认处于这种状态，此后将持续监视远程请求的数量和执行结果，决定是否要进入 OPEN 状态。
- OPEN：
  表示断路器开启，此时不会进行远程请求，直接给服务调用者返回调用失败的信息，以实现快速失败策略。
- HALF OPEN：
  这是一种==中间状态==。断路器必须带有自动的故障恢复能力，当进入 OPEN 状态一段时间以后，将“自动”（一般是由下一次请求而不是计时器触发的，所以这里自动带引号）切换到 HALF OPEN 状态。
  该状态下，会==放行一次远程调用==，然后==根据这次调用的结果成功与否，转换为 CLOSED 或者 OPEN 状态==，以实现断路器的弹性恢复。


OPEN 和 CLOSED 转换条件是什么？
最简单直接的方案是只要遇到一次调用失败，那就默认以后所有的调用都会接着失败，断路器直接进入 OPEN 状态，但这样做的效果是很差的，虽然避免了故障扩散和请求堆积，却使得外部看来系统将表现极其不稳定

现实中，比较可行的办法是在以下两个条件==同时满足==时，断路器状态转变为 OPEN：
- 一段时间（譬如 10 秒以内）内请求数量达到一定阈值（譬如 20 个请求）。这个条件的意思是如果请求本身就很少，那就用不着断路器介入。
- 一段时间（譬如 10 秒以内）内请求的故障率（发生失败、超时、拒绝的统计比例）到达一定阈值（譬如 50%）。这个条件的意思是如果请求本身都能正确返回，也用不着断路器介入。

括号中举例的数值是 Netflix Hystrix 的默认值

服务治理中两个常见的易混淆概念：==服务熔断和服务降级==之间的联系与差别。
断路器做的事情是自动进行==服务熔断==，这是一种==快速失败的容错策略的实现方法==。
在快速失败策略明确反馈了故障信息==给上游服务==以后，==上游服务必须能够主动处理调用失败的后果==，而不是坐视故障扩散，这里的“处理”指的就是一种典型的==服务降级==逻辑，降级逻辑可以包括，但不应该仅仅限于是把异常信息抛到用户界面去，而应该==尽力想办法通过其他路径解决问题==，譬如把原本要处理的业务记录下来，留待以后重新处理是最低限度的通用降级逻辑。


服务降级不一定是在出现错误后才被动执行的，许多场景里面，人们所谈论的降级更可能是指需要主动迫使服务进入降级逻辑的情况。
譬如，出于应对可预见的峰值流量，或者是系统检修等原因，要关闭系统部分功能或关闭部分旁路服务，这时候就有可能会主动迫使这些服务降级。
当然，此时服务降级就不一定是出于服务容错的目的了，更可能属于下一节要将的讲解的流量控制的范畴。


#### 舱壁隔离模式

微服务治理中常听见的概念：服务隔离。
舱壁隔离模式是常用的实现服务隔离的设计模式，舱壁这个词是来自造船业的舶来品，它原本的意思是设计舰船时，要在每个区域设计独立的水密舱室，一旦某个舱室进水，也只是影响这个舱室中的货物，而不至于让整艘舰艇沉没。

这种思想就很符合容错策略中失败静默策略。

调用外部服务的故障大致可以分为
“==失败==”（如 400 Bad Request、500 Internal Server Error 等错误）、
“==拒绝==”（如 401 Unauthorized、403 Forbidden 等错误）以及
“==超时==”（如 408 Request Timeout、504 Gateway Timeout 等错误）三大类，

其中“超时”引起的故障尤其容易给调用者==带来全局性的风险==。
这是由于目前主流的网络访问大多是基于 ==TPR 并发模型==（Thread per Request）来实现的，只要请求一直不结束（无论是以成功结束还是以失败结束），就要一直占用着==某个线程不能释放==。
而线程是典型的整个系统的全局性资源，尤其是 Java 这类将线程映射为操作系统内核线程来实现的语言环境中，为了==不让某一个远程服务的局部失败演变成全局性的影响，就必须设置某种止损方案==，这便是==服务隔离的意义==。

对于这类情况，
一种可行的解决办法是为==每个服务单独设立线程池==，这些线程池默认不预置活动线程，只用来控制单个服务的最大连接数。
譬如，对出问题的“服务 I”设置了一个最大线程数为 5 的线程池，这时候它的超时故障就只会最多阻塞 5 条用户线程，而不至于影响全局。此时，其他不依赖“服务 I”的用户线程依然能够正常对外提供服务

使用局部的线程池来控制服务的最大连接数有许多好处，当服务出问题时能够隔离影响，当服务恢复后，还可以通过清理掉局部线程池，瞬间恢复该服务的调用，而如果是 Tomcat 的全局线程池被占满，再恢复就会十分麻烦。
但是，局部线程池有一个显著的弱点，它额外增加了 CPU 的开销，每个独立的线程池都要进行排队、调度和下文切换工作。
根据 Netflix 官方给出的数据，一旦启用 Hystrix 线程池来进行服务隔离，大概会为每次服务调用增加约 3 毫秒至 10 毫秒的延时，如果调用链中有 20 次远程服务调用，那每次请求就要多付出 60 毫秒至 200 毫秒的代价来换取服务隔离的安全保障。


一种==更轻量的==可以用来控制服务最大连接数的办法：==信号量机制==（Semaphore）。
如果不考虑清理线程池、客户端主动中断线程这些额外的功能，仅仅是为了==控制一个服务并发调用的最大次数==，可以只为每个远程服务==维护一个线程安全的计数器即可==，并不需要建立局部线程池。
具体做法是当服务开始调用时计数器加 1，服务返回结果后计数器减 1，==一旦计数器超过设置的阈值就立即开始限流==，在回落到阈值范围之前都不再允许请求了。
由于不需要承担线程的排队、调度、切换工作，所以单纯维护一个作为计数器的信号量的性能损耗，相对于局部线程池来说几乎可以忽略不计。


#### 重试模式

使用断路器模式实现==快速失败==策略，
使用舱壁隔离模式实现==静默失败==策略，
在断路器中举例的主动对非关键的旁路服务进行降级，亦可算作是对==安全失败==策略的一种体现。
那还==剩下故障转移和故障恢复==两种策略的实现尚未涉及。
接下来，笔者以重试模式来介绍这两种容错策略的主流实现方案。

故障转移和故障恢复策略都需要对服务进行重复调用，差别是这些重复调用有可能是==同步==的，也可能是==后台异步==进行；有可能会重复==调用同一个服务==，也可能会调用到==服务的其他副本==。
无论具体是通过怎样的方式调用、调用的服务实例是否相同，都可以归结为重试设计模式的应用范畴。
重试模式适合解决系统中的==瞬时故障==，简单的说就是有==可能自己恢复==（Resilient，称为自愈，也叫做回弹性）的==临时性失灵==，==网络抖动、服务的临时过载==（典型的如返回了 503 Bad Gateway 错误）这些都属于瞬时故障。
重试模式实现并不困难，即使完全不考虑框架的支持，靠程序员自己编写十几行代码也能够完成。
在实践中，重试模式面临的风险反而大多来源于太过简单而导致的==滥用==。
我们==判断是否应该且是否能够对一个服务进行重试==时，应同时满足以下几个前提条件：

- ==仅在主路逻辑的关键服务上进行同步的重试==，不是关键的服务，一般不把重试作为首选容错方案，尤其不该进行同步重试。
- 仅对由==瞬时故障导致的失败==进行重试。
  尽管一个故障是否属于可自愈的瞬时故障并不容易精确判定，但从 ==HTTP 的状态码==上至少可以获得一些初步的结论，譬如，当发出的请求收到了 401 Unauthorized 响应，说明服务本身是可用的，只是你没有权限调用，这时候再去重试就没有什么意义。功能完善的服务治理工具会提供具体的重试策略配置（如 Envoy 的Retry Policy ），可以根据包括 HTTP 响应码在内的各种具体条件来设置不同的重试参数。
- 仅对具备==幂等性==的服务进行重试。
  如果服务调用者和提供者不属于同一个团队，那服务是否幂等其实也是一个难以精确判断的问题，但仍可以找到一些总体上通用的原则。譬如，RESTful 服务中的 ==POST 请求是非幂等==的，而 ==GET、HEAD、OPTIONS、TRACE 由于不会改变资源状态，这些请求应该被设计成幂等==的；==PUT 请求一般也是幂等==的，因为 n 个 PUT 请求会覆盖相同的资源 n-1 次；==DELETE 也可看作是幂等的==，同一个资源首次删除会得到 200 OK 响应，此后应该得到 204 No Content 响应。
  这些都是 HTTP 协议中定义的通用的指导原则，虽然对于具体服务如何实现并无强制约束力，但我们自己建设系统时，遵循业界惯例本身就是一种良好的习惯。
- 重试必须有明确的==终止条件==，常用的终止条件有两种： 
  - 超时终止：
    并不限于重试，所有调用远程服务都应该要有超时机制==避免无限期的等待==。这里只是强调重试模式更加应该配合上超时机制来使用，否则重试对系统很可能反而是有害的，笔者已经在前面介绍故障转移策略时举过具体的例子，这里就不重复了。
  - 次数终止：
    重试必须要有一定限度，不能无限制地做下去，通常最多就只==重试 2 至 5 次==。
    重试不仅会给调用者带来负担，对于服务提供者也是同样是负担。所以应避免将重试次数设的太大。
    此外，如果服务提供者返回的==响应头中带有Retry-After== 的话，尽管它没有强制约束力，我们也应该充分尊重服务端的要求，做个“有礼貌”的调用者。


由于重试模式可以在网络链路的多个环节中去实现，
譬如客户端发起调用时自动重试，网关中自动重试、负载均衡器中自动重试，等等，
而且现在的微服务框架都足够便捷，只需设置一两个开关参数就可以开启对某个服务甚至全部服务的重试机制。
所以，对于没有太多经验的程序员，有可能根本意识不到其中==会带来多大的负担==。
这里笔者举个具体例子：一套基于 Netflix OSS 建设的微服务系统，如果同时在 Zuul、Feign 和 Ribbon 上都打开了重试功能，且不考虑重试被超时终止的话，那总重试次数就相当于它们的重试次数的乘积。假设按它们都重试 4 次，且 Ribbon 可以转移 4 个服务副本来计算，理论上最多会产生高达 4×4×4×4=256 次调用请求。

熔断、隔离、重试、降级、超时等概念都是建立具有韧性的微服务系统必须的保障措施。
目前，这些措施的正确运作，还主要是依靠开发人员对服务逻辑的了解，以及运维人员的经验去静态调整配置参数和阈值，但是面对能够自动扩缩（Auto Scale）的大型分布式系统，静态的配置越来越难以起到良好的效果，这就需要系统不仅要有能力自动根据服务负载来调整服务器的数量规模，同时还要有能力根据服务调用的统计结果，或者启发式搜索 的结果来自动变更容错策略和参数，这方面研究现在还处于各大厂商在内部分头摸索的初级阶段，是服务治理的未来重要发展方向之一。



### 流量控制

任何一个系统的运算、存储、网络资源都不是无限的，当系统资源不足以支撑外部超过预期的突发流量时，便应该要有取舍，建立面对超额流量自我保护的机制，这个机制就是微服务中常说的“==限流==”

一个健壮的系统需要做到恰当的流量控制，更具体地说，需要妥善解决以下三个问题：

- 依据什么限流？：
  要不要控制流量，要控制哪些流量，控制力度要有多大，等等这些操作都没法在系统设计阶段静态地给出确定的结论，必须根据系统此前一段时间的运行状况，甚至未来一段时间的预测情况来动态决定。
- 具体如何限流？：
  解决系统具体是如何做到允许一部分请求能够通行，而另外一部分流量实行受控制的失败降级，这必须了解掌握常用的服务限流算法和设计模式。
- 超额流量如何处理？：
  超额流量可以有不同的处理策略，也许会直接返回失败（如 429 Too Many Requests），或者被迫使它们进入降级逻辑，这种被称为否决式限流。也可能让请求排队等待，暂时阻塞一段时间后继续处理，这种被称为阻塞式限流。


#### 流量统计指标

首先要弄清楚到底哪些指标能反映系统的流量压力大小

- 每秒事务数 TPS, transaction per second
  TPS 是衡量==信息系统==吞吐量的最终标准。“事务”可以理解为一个逻辑上具备原子性的业务操作
- 每秒请求数 HPS, hits per second
  HPS 是指每秒从客户端发向服务端的请求数（请将 Hits 理解为 Requests 而不是 Clicks）。
  如果只要一个请求就能完成一笔业务，那 HPS 与 TPS 是等价的，但在一些场景（尤其常见于网页中）里，一笔业务可能需要多次请求才能完成。
- 每秒查询数 QPS, queries per second
  QPS 是指==一台==服务器能够响应的查询次数。如果只有一台服务器来应答请求，那 QPS 和 HPS 是等价的，但在分布式系统中，一个请求的响应往往要由后台多个服务节点共同协作来完成。


直接针对 TPS 来限流实际上是很难操作的。

主流系统大多倾向使用 HPS 作为首选的限流指标


#### 限流设计模式

流量计数器、滑动时间窗、漏桶和令牌桶



##### 流量计数器

我们计算得出了该系统能承受的最大持续流量是 80 TPS，
那就控制任何一秒内，发现超过 80 次业务请求就直接拒绝掉超额部分。
这种做法很直观，也确实有些简单的限流就是这么实现的，但它并不严谨，以下两个结论就很可能出乎对限流算法没有了解的同学意料之外：

1. 即使每一秒的统计流量都没有超过 80 TPS，也不能说明系统没有遇到过大于 80 TPS 的流量压力。
   如果系统连续两秒都收到 60 TPS 的访问请求，但这两个 60 TPS 请求分别是前 1 秒里面的后 0.5 秒，以及后 1 秒中的前面 0.5 秒所发生的。这样虽然每个周期的流量都不超过 80 TPS 请求的阈值，但是系统确实曾经在 1 秒内实在在发生了超过阈值的 120 TPS 请求。
2. 即使连续若干秒的统计流量都超过了 80 TPS，也不能说明流量压力就一定超过了系统的承受能力。
   如果 10 秒的时间片段中，前 3 秒 TPS 平均值到了 100，而后 7 秒的平均值是 30 左右，此时系统是否能够处理完这些请求而不产生超时失败？答案是可以的，因为条件中给出的超时时间是 10 秒，而最慢的请求也能在 8 秒左右处理完毕。如果只基于固定时间周期来控制请求阈值为 80 TPS，反而会误杀一部分请求，造成部分请求出现原本不必要的失败。

流量计数器的缺陷根源在于它只是针对时间点进行离散的统计
为了弥补该缺陷，一种名为“滑动时间窗”的限流模式被设计出来，它可以实现平滑的基于时间片段统计。


##### 滑动时间窗

滑动时间窗口模式的限流完全解决了流量计数器的缺陷，可以保证任意时间片段内，只需经过简单的调用计数比较，就能控制住请求次数一定不会超过限流的阈值，在单机限流或者分布式服务单点网关中的限流中很常用。
不过，这种限流也有其缺点，它通常只适用于==否决式==限流，超过阈值的流量就必须强制失败或降级，很难进行阻塞等待处理，也就很难在细粒度上==对流量曲线进行整形==，==起不到削峰填谷==的作用。

下面笔者继续介绍两种适用于阻塞式限流的限流模式

##### 漏桶

在计算机网络中，专门有一个术语 流量整形 （Traffic Shaping）用来描述如何限制网络设备的流量突变，使得网络报文以比较均匀的速度向外发送。
流量整形通常都需要用到缓冲区来实现，当报文的发送速度过快时，首先在缓冲区中暂存，然后再在控制算法的调节下均匀地发送这些被缓冲的报文。
常用的控制算法有漏桶算法 （Leaky Bucket Algorithm）和令牌桶算法 （Token Bucket Algorithm）两种，这两种算法的思路截然相反，但达到的效果又是相似的。

漏桶在代码实现上非常简单，它其实就是一个以请求对象作为元素的先入先出队列（FIFO Queue），队列长度就相当于漏桶的大小，当队列已满时便拒绝新的请求进入。
漏桶实现起来很容易，==困难==在于如何确定漏桶的两个参数：==桶的大小和水的流出速率==。
如果桶设置得太大，那服务依然可能遭遇到流量过大的冲击，不能完全发挥限流的作用；如果设置得太小，那很可能就会误杀掉一部分正常的请求，这种情况与流量计数器模式中举过的例子是一样的。
流出速率在漏桶算法中一般是个固定值，对本节开头场景应用题中那样固定拓扑结构的服务是很合适的，但同时你也应该明白那是经过最大限度简化的场景，现实中系统的处理速度往往受到其内部拓扑结构变化和动态伸缩的影响，所以能够支持变动请求处理速率的令牌桶算法往往可能会是更受程序员青睐的选择



##### 令牌桶

如果说漏桶是小学应用题中的奇怪水池，那令牌桶就是你去银行办事时摆在门口的那台排队机。
它与漏桶一样都是基于缓冲区的限流算法，只是方向刚好相反，漏桶是从水池里往系统出水，令牌桶则是系统往排队机中放入令牌。

假设我们要限制系统在 X 秒内最大请求次数不超过 Y，那就每间隔 X/Y 时间就往桶中放一个令牌，
当有请求进来时，首先要从桶中取得一个准入的令牌，然后才能进入系统处理。
任何时候，一旦请求进入桶中却发现没有令牌可取了，就应该马上失败或进入服务降级逻辑。
与漏桶类似，令牌桶同样有最大容量，这意味着当系统比较空闲时，桶中令牌累积到一定程度就不再无限增加，预存在桶中的令牌便是请求最大缓冲的余量。

上面这段话，可以转化为以下步骤来指导程序编码：
- 让系统以一个由限流目标决定的速率向桶中注入令牌，譬如要控制系统的访问不超过 100 次每秒，速率即设定为 100 个令牌每秒，每个令牌注入间隔为 1/100=10 毫秒。
- 桶中最多可以存放 N 个令牌，N 的具体数量是由超时时间和服务处理能力共同决定的。如果桶已满，第 N+1 个进入的令牌会被丢弃掉。
- 请求到时先从桶中取走 1 个令牌，如果桶已空就进入降级逻辑。

令牌桶模式的实现看似比较复杂，每间隔固定时间就要放新的令牌到桶中，但其实并不需要真的用一个专用线程或者定时器来做这件事情，==只要在令牌中增加一个时间戳记录，每次获取令牌前，比较一下时间戳与当前时间，就可以轻易计算出这段时间需要放多少令牌进去==，然后一次性放入即可，所以真正编码并不会显得复杂





#### 分布式限流


前面讨论过的那些限流算法，直接使用在单体架构的集群上是完全可行的，
但到了微服务架构下，它们就最多只能应用于集群最入口处的网关上，对整个服务集群进行流量控制，而无法细粒度地管理流量在内部微服务节点中的流转情况。

我们把前面介绍的限流模式都统称为单机限流，把能够精细控制分布式集群中每个服务消耗量的限流算法称为分布式限流。

这两种限流算法实现上的核心差别在于如何管理限流的统计指标，
单机限流很好办，指标都是存储在服务的内存当中，
而分布式限流的目的就是要让各个服务节点的协同限流，无论是将限流功能封装为专门的远程服务，抑或是在系统采用的分布式框架中有专门的限流支持，都需要将原本在每个服务节点自己内存当中的统计数据给开放出来，让全局的限流服务可以访问到才行。

一种常见的简单分布式限流方法是将所有服务的统计结果都存入集中式缓存（如 Redis）中，以实现在集群内的共享，并通过分布式锁、信号量等机制，解决这些数据的读写访问时并发控制的问题。
在可以共享统计数据的前提下，原本用于单机的限流模式理论上也是可以应用于分布式环境中的，可是其代价也显而易见：每次服务调用都必须要额外增加一次网络开销，所以这种方法的效率肯定是不高的，流量压力大时，限流本身反倒会显著降低系统的处理能力。


只要集中式存储统计信息，就不可避免地会产生网络开销，
为了缓解这里产生的性能损耗，一种可以考虑的办法是在令牌桶限流模式基础上进行“货币化改造”，即不把令牌看作是只有准入和不准入的“通行证”，而看作数值形式的“货币额度”。
当==请求进入集群==时，首先在 API ==网关处领取到一定数额的“货币==”，为了体现不同等级用户重要性的差别，他们的额度可以有所差异，譬如让 ==VIP 用户的额度更高==甚至是无限的。
我们将用户 A 的额度表示为 QuanityA。由于任何一个服务在响应请求时都需要消耗集群一定量的处理资源，所以访问每个服务时都要求消耗一定量的“货币”，假设服务 X 要消耗的额度表示为 CostX，那当用户 A 访问了 N 个服务以后，他剩余的额度 LimitN即表示为：
`LimitN = QualityA - Cost1 - ... - Costx`
此时，我们可以把剩余额度 LimitN作为内部限流的指标，规定在任何时候，只要一旦剩余额度 LimitN小于等于 0 时，就不再允许访问其他服务了。
此时必须先发生一次网络请求，==重新向令牌桶申请一次额度==，成功后才能继续访问，==申请不成功则进入降级逻辑==。
除此之外的任何时刻，即 LimitN不为零时，都无须额外的网络访问，因为计算 LimitN是完全可以在本地完成的。

基于额度的限流方案对限流的精确度有一定的影响，可能存在业务操作已经进行了一部分服务调用，却无法从令牌桶中再获取到新额度，因“资金链断裂”而导致业务操作失败。
这种失败的代价是比较高昂的，它白白浪费了部分已经完成了的服务资源，
但总体来说，它仍是一种并发性能和限流效果上都相对折衷可行的分布式限流方案。
上一节提到过，对于分布式系统容错是必须要有、无法妥协的措施。但限流与容错不一样，做分布式限流从不追求“越彻底越好”，往往需要权衡方案的代价与收益。


## 可靠通讯

微服务提倡分散治理（Decentralized Governance），不追求统一的技术平台，提倡让团队有自由选择的权利，不受制于语言和技术框架。
在开发阶段构建服务时，分散治理打破了由技术栈带来的约束，好处是不言自明的。
但在运维阶段部署服务时，尤其是考量安全问题时，由 Java、Golang、Python、Node.js 等多种语言和框架共同组成的微服务系统，出现安全漏洞的概率肯定要比只采用其中某种语言、某种框架所构建的单体系统更高。
为了避免由于单个服务节点出现漏洞被攻击者突破，进而导致整个系统和内网都遭到入侵，我们就必须打破一些传统的安全观念，以构筑更加可靠的服务间通信机制。



### 零信任网络

#### 零信任安全模型的特征

零信任安全的==中心思想==是==不应当以某种固有特征来自动信任任何流量==，除非==明确得到了能代表请求来源（不一定是人，更可能是另一个服务）的身份凭证，否则一律不会有默认的信任关系==。


传统网络安全模型与云原生时代零信任模型对比
|传统、边界安全模型|云原生、零信任安全模型|具体需求|
|--|--|--|
|基于防火墙等设施，认为边界内可信|服务到服务通信需认证，环境内的服务之间默认没有信任|保护网络边界（仍然有效）；服务之间默认没有互信|
|用于特定的 IP 和硬件（机器）|资源利用率、重用、共享更好，包括 IP 和硬件|受信任的机器运行来源已知的代码|
|基于 IP 的身份|基于服务的身份|同上|
|服务运行在已知的、可预期的服务器上|服务可运行在环境中的任何地方，包括私有云/公有云混合部署|同上|
|安全相关的需求由应用来实现，每个应用单独实现|由基础设施来实现，基础设施中集成了共享的安全性要求。|集中策略实施点（Choke Points），一致地应用到所有服务|
|对服务如何构建、评审、实施的安全需求的约束力较弱|安全相关的需求一致地应用到所有服务|同上|
|安全组件的可观测性较弱|有安全策略及其是否生效的全局视图|同上|
|发布不标准，发布频率较低|标准化的构建和发布流程，每个微服务变更独立，变更更频繁|简单、自动、标准化的变更发布流程|
|工作负载通常作为虚拟机部署或部署到物理主机，并使用物理机或管理程序进行隔离|封装的工作负载及其进程在共享的操作系统中运行，并有管理平台提供的某种机制来进行隔离|在共享的操作系统的工作负载之间进行隔离|


笔者对其中主要观点按照自己的理解转述如下：
- 零信任网络不等同于放弃在边界上的保护设施
  虽然防火墙等位于网络边界的设施是属于边界安全而不是零信任安全的概念，但它仍然是一种提升安全性的有效且必要的做法。
  在微服务集群的前端部署防火墙，把内部服务节点间的流量与来自互联网的流量隔离开来，这种做法无论何时都是值得提倡的，至少能够让内部服务避开来自互联网未经授权流量的饱和攻击，如最典型的DDoS 拒绝服务攻击 。
- 身份只来源于服务
  传统应用一般是部署在特定的服务器上的，这些机器的 IP、MAC 地址很少会发生变化，此时的系统的拓扑状态是相对静态的。
  基于这个前提，安全策略才会使用 IP 地址、主机名等作为身份标识符（Identifiers），无条件信任具有特性身份表示的服务。
  如今的微服务系统，尤其是云原生环境中的微服务系统，虚拟化基础设施已得到大范围应用，这使得服务所部署的 IP 地址、服务实例的数量随时都可能发生变化，因此，身份只能来源于服务本身所能够出示的身份凭证（通常是数字证书），而不再是服务所在的 IP 地址、主机名或者其它特征。
- 服务之间也没有固有的信任关系
  这点决定了只有已知的、明确授权的调用者才能访问服务，阻止攻击者通过某个服务节点中的代码漏洞来越权调用到其他服务。
  如果某个服务节点被成功入侵，这一原则可阻止攻击者执行扩大其入侵范围，与微服务设计模式中使用断路器、舱壁隔离实现容错来避免雪崩效应类似，在安全方面也应当采用这种“互不信任”的模式来隔离入侵危害的影响范围。
- 集中、共享的安全策略实施点
  这点与微服务的“分散治理”刚好相反，微服务提倡每个服务自己独立的负责自身所有的功能性与非功能性需求。而 Google 这个观点相当于为分散治理原则做了一个补充——分散治理，但涉及安全的非功能性需求（如身份管理、安全传输层、数据安全层）最好除外。
  一方面，要写出高度安全的代码极为不易，为此付出的精力甚至可能远高于业务逻辑本身
  另一方面，而且还是更重要的一个方面是让服务各自处理安全问题很容易会出现实现不一致或者出现漏洞时要反复修改多处地方，还有一些安全问题如果不立足于全局是很难彻底解决的
  因此 Google 明确提出应该有集中式的“安全策略实施点”（原文中称之为 Choke Points），安全需求应该从微服务的应用代码下沉至云原生的基础设施里，这也契合其论文的标题“Cloud-Native Security”。
- 受信的机器运行来源已知的代码
  限制了服务只能使用认证过的代码和配置，并且只能运行在认证过的环境中。
  分布式软件系统除了促使软件架构发生了重大变化之外，对软件的发布流程也有较大的改变，使其严重依赖持续集成与持续部署 （Continuous Integration / Continuous Delivery，CI/CD）。
- 自动化、标准化的变更管理
  这点也是为何提倡通过基础设施而不是应用代码去实现安全功能的另一个重要理由。
  如果将安全放在应用上，由于应用本身的分散治理，这决定了安全也必然是难以统一和标准化的。
  做不到标准化就意味着做不到自动化，相反，一套独立于应用的安全基础设施，可以让运维人员轻松地了解基础设施变更对安全性的影响，并且可以在几乎不影响生产环境的情况下发布安全补丁程序。
- 强隔离性的工作负载
  “工作负载”的概念贯穿了 Google 内部的 Borg 系统与后来 Kubernetes 系统，它是指在虚拟化技术支持下运行的一组能够协同提供服务的镜像。
  下一个部分介绍云原生基础设施时，笔者会详细介绍容器化，它仅仅是虚拟化的一个子集，容器比起传统虚拟机的隔离能力是有所降低的，这种设计对性能非常有利，却对安全相对不利，因此在强调安全性的应用里，会有专门关注强隔离性的容器运行工具出现。


#### Google 的实践探索

为了保护服务集群内的代码与基础设施，Google 设计了一系列的内部工具，才最终得以实现前面所说的那些安全原则：

- 为了在网络边界上保护内部服务免受 DDoS 攻击，设计了名为 Google Front End（名字意为“最终用户访问请求的终点”）的边缘代理，负责保证此后所有流量都在 TLS 之上传输，并自动将流量路由到适合的可用区域之中。
- 为了强制身份只来源于服务，设计了名为 Application Layer Transport Security（应用层传输安全）的服务认证机制，这是一个用于双向认证和传输加密的系统，自动将服务与它的身份标识符绑定，使得所有服务间流量都不必再使用服务名称、主机 IP 来判断对方的身份。
- 为了确保服务间不再有默认的信任关系，设计了 Service Access Policy（服务访问策略）来管理一个服务向另一个服务发起请求时所需提供的认证、鉴权和审计策略，并支持全局视角的访问控制与分析，以达成“集中、共享的安全策略实施点”这条原则。
- 为了实现仅以受信的机器运行来源已知的代码，设计了名为 Binary Authorization（二进制授权）的部署时检查机制，确保在软件供应链的每一个阶段，都符合内部安全检查策略，并对此进行授权与鉴权。同时设计了名为 Host Integrity（宿主机完整性）的机器安全启动程序，在创建宿主机时自动验证包括 BIOS、BMC、Bootloader 和操作系统内核的数字签名。
- 为了工作负载能够具有强隔离性，设计了名为gVisor 的轻量级虚拟化方案，这个方案与此前由 Intel 发起的Kata Containers 的思路异曲同工。目的都是解决容器共享操作系统内核而导致隔离性不足的安全缺陷，做法都是为每个容器提供了一个独立的虚拟 Linux 内核，譬如 gVisor 是用 Golang 实现了一个名为Sentry 的能够提供传统操作系统内核的能力的进程，严格来说无论是 gVisor 还是 Kata Containers，尽管披着容器运行时的外衣，但本质上都是轻量级虚拟机。



在微服务时代以前，传统的的软件系统与研发模式的确是很难承受零信任安全模型的代价的，只有到了云原生时代，虚拟化的基础设施长足发展，能将复杂性隐藏于基础设施之内，开发者不需要为达成每一条安全原则而专门开发或引入可感知的安全设施；只有容器与虚拟化网络的性能足够高，可以弥补安全隔离与安全通信的额外损耗的前提下，零信任网络的安全模型才有它生根发芽的土壤。



### 服务安全

前置知识
本文涉及到 SSL/TLS、PKI、CA、OAuth2、RBAC、JWT 等概念，直接依赖于“安全架构”部分的认证、授权、凭证、传输四节对安全基础知识的铺垫，这四篇文章中介绍过的内容，笔者在本篇中将不再重复，建议读者先行阅读。

本节里，我们将从实践和编码的角度出发，介绍在前微服务时代（以 Spring Cloud 为例 ）和云原生时代（以 Istio over Kubernetes 为例）分别是如何实现安全传输、认证和授权的，通过这两者的对比，探讨在微服务架构下，应如何将业界的安全技术标准引入并实际落地，实现零信任网络下安全的服务访问。

#### 建立信任

此前我们曾讨论过，真实世界里，能够达成信任的基本途径不外乎基于 共同私密信息 的信任和基于 权威公证人 的信任两种；
网络世界里，因为客户端和服务端之间一般没有什么共同私密信息，所以真正能采用的就只能是基于权威公证人的信任，它有个标准的名字：公开密钥基础设施 （Public Key Infrastructure，PKI）。

PKI 是构建传输安全层 （Transport Layer Security，TLS）的必要基础。
在任何网络设施都不可信任的假设前提下，无论是 DNS 服务器、代理服务器、负载均衡器还是路由器，传输路径上的每一个节点都有可能监听或者篡改通信双方传输的信息。
要保证通信过程不受到中间人攻击的威胁，启用 TLS 对传输通道本身进行加密，让发送者发出的内容只有接受者可以解密是唯一具备可行性的方案。
建立 TLS 传输，说起来似乎不复杂，只要在部署服务器时预置好CA 根证书，以后用该 CA 为部署的服务签发 TLS 证书便是。
但落到实际操作上，这事情就属于典型的“必须集中在基础设施中自动进行的安全策略实施点”，面对数量庞大且能够自动扩缩的服务节点，依赖运维人员手工去部署和轮换根证书必定是难以为继的。
除了随服务节点动态扩缩而来的运维压力外，微服务中 TLS 认证的频次也显著高于传统的应用，比起公众互联网中主流单向的 TLS 认证，在零信任网络中，往往要启用双向 TLS 认证 （Mutual TLS Authentication，常简写为 mTLS），即不仅要确认服务端的身份，还需要确认调用者的身份。

- 单向 TLS 认证：
  只需要服务端提供证书，客户端通过服务端证书验证服务器的身份，但服务器并不验证客户端的身份。==单向 TLS 用于公开的服务==，即==任何客户端都被允许连接到服务进行访问==，它保护的重点是客户端免遭冒牌服务器的欺骗。

- 双向 TLS 认证：
  客户端、服务端双方都要提供证书，双方各自通过对方提供的证书来验证对方的身份。双向 TLS 用于==私密的服务==，即服务==只允许特定身份的客户端访问==，它除了保护客户端不连接到冒牌服务器外，也保护服务端不遭到非法用户的越权访问。



下面我们结合 Fenix's Bookstore 的代码，聚焦于“认证”和“授权”两个最基本的安全需求，看它们在微服务架构下，有或者没有基础设施支持时，各是如何实现的

#### 认证
根据认证的目标对象可以把认证分为两种类型，
一种是以机器作为认证对象，即访问服务的流量来源是另外一个服务，称为==服务认证==（Peer Authentication，直译过来是“节点认证”）；
另一种是以人类作为认证对象，即访问服务的流量来自于最终用户，称为==请求认证==（Request Authentication）。
无论哪一种认证，无论是否有基础设施的支持，均要有可行的方案来确定服务调用者的身份，建立起信任关系才能调用服务。


##### 服务认证

Istio 版本的 Fenix's Bookstore 采用了双向 TLS 认证作为服务调用双方的身份认证手段。
不过，Istio 毕竟是新生事物，你准备在自己的生产系统中启用 mTLS 之前，要先想一下是否整个服务集群全部节点都受 Istio 管理？
如果每一个服务提供者、调用者均受 Istio 管理，那 mTLS 就是最理想的认证方案。你只需要参考以下简单的 PeerAuthentication CRD 配置，即可对某个Kubernetes 名称空间 范围内所有的流量均启用 mTLS：

```yaml
apiVersion: security.istio.io/v1beta1
kind: PeerAuthentication
metadata:
  name: authentication-mtls
  namespace: bookstore-servicemesh
spec:
  mtls:
    mode: STRICT
```

如果你的分布式系统还没有达到完全云原生的程度，其中仍存在部分不受 Istio 管理（即未注入 Sidecar）的服务端或者客户端（这是颇为常见的），你也可以将 mTLS 传输声明为“宽容模式”（Permissive Mode）。
宽容模式的含义是受 Istio 管理的服务会允许同时接受明文和 mTLS 两种流量，明文流量仅用于与那些不受 Istio 管理的节点进行交互，你需要自行想办法解决明文流量的认证问题；而对于服务网格内部的流量，就可以使用 mTLS 认证。
宽容模式为普通微服务向服务网格迁移提供了良好的灵活性，让运维人员能够逐个服务进行 mTLS 升级，原本没有启用 mTLS 的服务在启用 mTLS 时甚至可以不中断现存已建立的明文传输连接，完全不会被最终用户感知到。一旦所有服务都完成迁移，便可将整个系统设置为严格 TLS 模式，即上面代码中的mode: STRICT。


在 Spring Cloud 版本的 Fenix's Bookstore 里，因为没有基础设施的支持，一切认证工作就不得不在应用层面去实现。笔者选择的方案是借用OAtuh2 协议的客户端模式来进行认证，其大体思路有如下两步：
- 每一个要调用服务的客户端都与认证服务器约定好一组只有自己知道的密钥（Client Secret），这个约定过程应该是由运维人员在线下自行完成，通过参数传给服务，而不是由开发人员在源码或配置文件中直接设定。笔者在演示工程的代码注释中专门强调了这点，以免有读者被示例代码中包含密钥的做法所误导。密钥就是客户端的身份证明，客户端调用服务时，会先使用该密钥向认证服务器申请到 JWT 令牌，然后通过令牌证明自己的身份，最后访问服务。如以下代码所示，它定义了五个客户端，其中四个是集群内部的微服务，均使用客户端模式，且注明了授权范围是SERVICE（授权范围在后面介绍授权中会用到），第一个是前端代码的微服务，使用密码模式，授权范围是BROWSER。

```java
/**
 * 客户端列表
 */
private static final List<Client> clients = Arrays.asList(
    new Client("bookstore_frontend", "bookstore_secret", new String[]{GrantType.PASSWORD, GrantType.REFRESH_TOKEN}, new String[]{Scope.BROWSER}),
    // 微服务一共有Security微服务、Account微服务、Warehouse微服务、Payment微服务四个客户端
    // 如果正式使用，这部分信息应该做成可以配置的，以便快速增加微服务的类型。clientSecret也不应该出现在源码中，应由外部配置传入
    new Client("account", "account_secret", new String[]{GrantType.CLIENT_CREDENTIALS}, new String[]{Scope.SERVICE}),
    new Client("warehouse", "warehouse_secret", new String[]{GrantType.CLIENT_CREDENTIALS}, new String[]{Scope.SERVICE}),
    new Client("payment", "payment_secret", new String[]{GrantType.CLIENT_CREDENTIALS}, new String[]{Scope.SERVICE}),
    new Client("security", "security_secret", new String[]{GrantType.CLIENT_CREDENTIALS}, new String[]{Scope.SERVICE})
);
```

- 每一个对外提供服务的服务端，都扮演着 OAuth 2 中的资源服务器的角色，它们均声明为要求提供客户端模式的凭证，如以下代码所示。客户端要调用受保护的服务，就必须先出示能证明调用者身份的 JWT 令牌，否则就会遭到拒绝，这个操作本质上是授权，但是在授权过程中已实现了服务的身份认证。

```java
public ClientCredentialsResourceDetails clientCredentialsResourceDetails() {
    return new ClientCredentialsResourceDetails();
}
```

由于每一个微服务都同时具有服务端和客户端两种身份，既消费其他服务，也提供服务供别人消费，所以这些代码在每个微服务中都应有包含（放在公共 infrastructure 工程里）。
Spring Security 提供的过滤器会自动拦截请求、驱动认证、授权检查的执行，申请和验证 JWT 令牌等操作无论在开发期对程序员，还是运行期对用户都能做到相对透明。
尽管如此，以上做法仍然是一种应用层面的、不加密传输的解决方案。
前文提到在零信任网络中，面对可能的中间人攻击，TLS 是唯一可行的办法，言下之意是即使应用层的认证能一定程度上保护服务不被身份不明的客户端越权调用，但对传输过程中内容被监听、篡改、以及被攻击者在传输途中拿到 JWT 令牌后再去冒认调用者身份调用其他服务都是无法防御的。
简而言之，这种方案==不适用于零信任==安全模型，只能在默认内网节点间具备信任关系的边界安全模型上才能良好工作。


##### 用户认证
对于来自最终用户的请求认证，Istio 版本的 Fenix's Bookstore 仍然能做到单纯依靠基础设施解决问题，整个认证过程无需应用程序参与（生成 JWT 令牌还是在应用中生成的，因为 Fenix's Bookstore 并没有使用独立的用户认证服务器，只有应用本身才拥有用户信息）。
当来自最终用户的请求进入服务网格时，Istio 会自动根据配置中的JWKS （JSON Web Key Set）来验证令牌的合法性，如果令牌没有被篡改过且在有效期内，就信任 Payload 中的用户身份，并从令牌的 Iss 字段中获得 Principal。

关于 Iss、Principals 等概念，在架构安全性中都有介绍过，如果忘记了可以回看前文复习一下。
JWKS 倒是之前从没有提到过的名词术语，它代表了一个==密钥仓库==。
我们知道分布式系统中，JWT 应采用非对称的签名算法（RSA SHA256、ECDSA SHA256 等，默认的 HMAC SHA256 属于对称加密），认证服务器使用私钥对 Payload 进行签名，资源服务器使用公钥对签名进行验证。
常与 JWT 配合使用的 ==JWK（JSON Web Key）就是一种存储密钥的纯文本格式==，本质上和JKS （Java Key Storage）、P12 （Predecessor of PKCS#12）、PEM （Privacy Enhanced Mail）这些常见的密钥格式在功能上并没有什么差别。
JWKS 顾名思义就是一组 JWK 的集合，支持 JWKS 的系统，能通过 JWT 令牌 Header 中的 KID（Key ID）来自动匹配出应该使用哪个 JWK 来验证签名。

以下是 Istio 版本的 Fenix's Bookstore 中的用户认证配置，其中jwks字段配的就是 JWKS 全文（实际生产中并不推荐这样做，应该使用jwksUri来配置一个 JWKS 地址，以方便密钥轮换），根据这里配置的密钥信息，Istio 就能够验证请求中附带的 JWT 是否合法。

```yaml
apiVersion: security.istio.io/v1beta1
kind: RequestAuthentication
metadata:
  name: authentication-jwt-token
  namespace: bookstore-servicemesh
spec:
  jwtRules:
    - issuer: "icyfenix@gmail.com"
      # Envoy默认只认“Bearer”作为JWT前缀，之前其他地方用的都是小写，这里专门兼容一下
      fromHeaders:
        - name: Authorization
          prefix: "bearer "
      # 在rsa-key目录下放了用来生成这个JWKS的证书，最初是用java keytool生成的jks格式，一般转jwks都是用pkcs12或者pem格式，为方便使用也一起附带了
      jwks: |
        {
            "keys": [
                {
                    "e": "AQAB",
                    "kid": "bookstore-jwt-kid",
                    "kty": "RSA",
                    "n": "i-htQPOTvNMccJjOkCAzd3YlqBElURzkaeRLDoJYskyU59JdGO-p_q4JEH0DZOM2BbonGI4lIHFkiZLO4IBBZ5j2P7U6QYURt6-AyjS6RGw9v_wFdIRlyBI9D3EO7u8rCA4RktBLPavfEc5BwYX2Vb9wX6N63tV48cP1CoGU0GtIq9HTqbEQs5KVmme5n4XOuzxQ6B2AGaPBJgdq_K0ZWDkXiqPz6921X3oiNYPCQ22bvFxb4yFX8ZfbxeYc-1rN7PaUsK009qOx-qRenHpWgPVfagMbNYkm0TOHNOWXqukxE-soCDI_Nc--1khWCmQ9E2B82ap7IXsVBAnBIaV9WQ"
                }
            ]
        }
      forwardOriginalToken: true
```



---

Spring Cloud 版本的 Fenix's Bookstore 就略微麻烦一些，它依然是采用 JWT 令牌作为用户身份凭证的载体，认证过程依然在 Spring Security 的过滤器里中自动完成，
详细过程就不展开了，主要路径是：过滤器 → 令牌服务 → 令牌实现。

Spring Security 已经做好了认证所需的绝大部分的工作，
真正要开发者去编写的代码是令牌的具体实现，即代码中名为RSA256PublicJWTAccessToken的实现类。
它的作用是加载 Resource 目录下的公钥证书public.cert（实在是怕“抄作业不改名字”的行为，笔者再一次强调==不要==将密码、密钥、证书这类==敏感信息打包到程序==中，示例代码只是为了演示，实际生产应该由运维人员管理密钥），验证请求中的 JWT 令牌是否合法。

```java
@Named
public class RSA256PublicJWTAccessToken extends JWTAccessToken {
    RSA256PublicJWTAccessToken(UserDetailsService userDetailsService) throws IOException {
        super(userDetailsService);
        Resource resource = new ClassPathResource("public.cert");
        String publicKey = new String(FileCopyUtils.copyToByteArray(resource.getInputStream()));
        setVerifierKey(publicKey);
    }
}
```

如果 JWT 令牌合法，Spring Security 的过滤器就会放行调用请求，并从令牌中提取出 Principals，放到自己的安全上下文中（即SecurityContextHolder.getContext()）。
开发实际项目时，你可以根据需要自行决定 Principals 的具体形式，既可以像 Istio 中那样直接从令牌中取出来，以字符串形式原样存放，节省一些数据库或者缓存的查询开销；
也可以统一做些额外的转换处理，以方便后续业务使用，譬如将 Principals 自动转换为系统中用户对象。
Fenix's Bookstore 转换操作是在 JWT 令牌的父类JWTAccessToken中完成的。可见尽管由应用自己来做请求验证会有一定的代码量和侵入性，但同时自由度确实也会更高一些


为方便不同版本实现之间的对比，在 Istio 版本中保留了 Spring Security 自动从令牌转换 Principals 为用户对象的逻辑，因此必须在 YAML 中包含`forwardOriginalToken: true`的配置，告诉 Istio 验证完 JWT 令牌后不要丢弃掉请求中的 Authorization Header，原样转发给后面的服务处理


#### 授权

如果我们准备
把一部分微服务视为==私有服务==，限制它只接受来自集群内部其他服务的请求，
另外一部分微服务视为==公共服务==，允许它可接受来自集群外部的最终用户发出的请求；
又或者我们想要控制一部分服务==只允许移动应用调用==，另外一部分服务==只允许浏览器调用==。
那一种可行的方案就是为不同的调用场景设立角色，进行授权控制（另一种常用的方案是做 BFF 网关）。

在 Istio 版本的 Fenix's Bookstore 中，通过以下配置，
限制了来自bookstore-servicemesh名空间的内部流量只允许访问accounts、products、pay和settlements四个端点的 GET、POST、PUT、PATCH 方法，
而对于来自istio-system名空间（Istio Ingress Gateway 所在的名空间）的外部流量就不作限制，直接放行。

```yaml
apiVersion: security.istio.io/v1beta1
kind: AuthorizationPolicy
metadata:
  name: authorization-peer
  namespace: bookstore-servicemesh
spec:
  action: ALLOW
  rules:
    - from:
        - source:
            namespaces: ["bookstore-servicemesh"]
      to:
        - operation:
            paths:
              - /restful/accounts/*
              - /restful/products*
              - /restful/pay/*
              - /restful/settlements*
            methods: ["GET","POST","PUT","PATCH"]
    - from:
        - source:
            namespaces: ["istio-system"]
```


但对外部的请求（不来自bookstore-servicemesh名空间的流量），又进行了另外一层控制，如果请求中没有包含有效的登录信息，就限制不允许访问accounts、pay和settlements三个端点，如以下配置所示：

```yaml
apiVersion: security.istio.io/v1beta1
kind: AuthorizationPolicy
metadata:
  name: authorization-request
  namespace: bookstore-servicemesh
spec:
  action: DENY
  rules:
    - from:
        - source:
            notRequestPrincipals: ["*"]
            notNamespaces: ["bookstore-servicemesh"]
      to:
        - operation:
            paths:
              - /restful/accounts/*
              - /restful/pay/*
              - /restful/settlements*
```

Istio 已经提供了比较完善的目标匹配工具，
如上面配置中用到的源from、目标to，还有未用到的条件匹配when，
以及其他如通配符、IP、端口、名空间、JWT 字段，等等。

要说灵活和功能强大，肯定还是不可能跟在应用中由代码实现的授权相媲美，但对绝大多数场景已经够用了。
在便捷性、安全性、无侵入、统一管理等方面，Istio 这种在基础设施上实现授权方案显然就要更具优势。


---

Spring Cloud 版本的 Fenix's Bookstore 中，授权控制自然还是使用 Spring Security、通过应用程序代码来实现的。
常见的 Spring Security 授权方法有两种，

一种是使用它的ExpressionUrlAuthorizationConfigurer，即类似如下编码所示的写法来进行集中配置，这与上面在 Istio 的 AuthorizationPolicy CRD 中写法在体验上是比较相似的，也是几乎所有 Spring Security 资料中都有介绍的最主流方式，适合对批量端点进行控制，不过在示例代码中并没有采用（没有什么特别理由，就是笔者的个人习惯而已）。

```java
http.authorizeRequests()
	.antMatchers("/restful/accounts/**").hasScope(Scope.BROWSER)
	.antMatchers("/restful/pay/**").hasScope(Scope.SERVICE)
```

另一种写法，即示例代码中采用的方法，是通过 Spring 的全局方法级安全 （Global Method Security）以及JSR 250 的@RolesAllowed注解来做授权控制。
这种写法对代码的侵入性更强，要以注解的形式分散写到每个服务甚至是每个方法中，但好处是能以更方便的形式做出更加精细的控制效果。
譬如要控制服务中某个方法只允许来自服务或者来自浏览器的调用，那直接在该方法上标注@PreAuthorize注解即可，还支持SpEL 表达式 来做条件。
表达式中用到的SERVICE、BROWSER代表授权范围，就是在声明客户端列表时传入的，具体可参见开头声明客户端列表的代码清单。

```java
/**
 * 根据用户名称获取用户详情
 */
@GET
@Path("/{username}")
@Cacheable(key = "#username")
@PreAuthorize("#oauth2.hasAnyScope('SERVICE','BROWSER')")
public Account getUser(@PathParam("username") String username) {
	return service.findAccountByUsername(username);
}

/**
 * 创建新的用户
 */
@POST
@CacheEvict(key = "#user.username")
@PreAuthorize("#oauth2.hasAnyScope('BROWSER')")
public Response createUser(@Valid @UniqueAccount Account user) {
	return CommonResponse.op(() -> service.createAccount(user));
}
```



## 可观测性

学术界一般会将可观测性分解为三个更具体方向进行研究，分别是：==事件日志、链路追踪和聚合度量==

- 日志（Logging）：
  日志的职责是记录离散事件，通过这些记录事后分析出程序的行为，
  譬如曾经调用过什么方法，曾经操作过哪些数据，等等。
  打印日志被认为是程序中最简单的工作之一，==调试问题时常有人会说“当初这里记得打点日志就好了==”，可见这就是一项举手之劳的任务。
  输出日志的确很容易，但收集和分析日志却可能会很复杂，面对成千上万的集群节点，面对迅速滚动的事件信息，面对数以 TB 计算的文本，传输与归集都并不简单。
  对大多数程序员来说，分析日志也许就是最常遇见也最有实践可行性的“大数据系统”了。

- 追踪（Tracing）：
  单体系统时代追踪的范畴基本只局限于栈追踪 （Stack Tracing），调试程序时，在 IDE 打个断点，看到的 Call Stack 视图上的内容便是追踪；编写代码时，处理异常调用了 Exception::printStackTrace()方法，它输出的堆栈信息也是追踪。
  微服务时代，追踪就不只局限于调用栈了，一个外部请求需要内部若干服务的联动响应，这时候==完整的调用轨迹==将跨越多个服务，同时包括服务间的网络传输信息与各个服务内部的调用堆栈信息，
  因此，分布式系统中的追踪在国内常被称为“==全链路追踪==”（后文就直接称“链路追踪”了），许多资料中也称它为“==分布式追踪== ”（Distributed Tracing）。
  追踪的主要目的是排查故障，如分析调用链的哪一部分、哪个方法出现错误或阻塞，输入输出是否符合预期，等等。

- 度量（Metrics）：
  度量是指对系统中某一类信息的统计聚合。
  譬如，证券市场的每一只股票都会定期公布财务报表，通过财报上的营收、净利、毛利、资产、负债等等一系列数据来体现过去一个财务周期中公司的经营状况，这便是一种信息聚合。
  Java 天生自带有一种基本的度量，就是由虚拟机直接提供的 JMX（Java Management eXtensions）度量，诸如==内存大小、各分代的用量、峰值的线程数、垃圾收集的吞吐量、频率==，等等都可以从 JMX 中获得。度量的==主要目的是监控（Monitoring）和预警==（Alert），如某些度量指标达到风险阈值时触发事件，以便自动处理或者提醒管理员介入。


经过多年的角逐，日志、度量两个领域的胜利者算是基本尘埃落定。
日志收集和分析大多被统一到 ==Elastic Stack（ELK==）技术栈上，如果说未来还能出现什么变化的话，也就是其中的 Logstash 能看到有被 Fluentd 取代的趋势，让 ELK 变成 EFK，但整套 Elastic Stack 技术栈的地位已是相当稳固。

度量方面，跟随着 Kubernetes 统一容器编排的步伐，==Prometheus== 也击败了度量领域里以 Zabbix 为代表的众多前辈，即将成为云原生时代度量监控的事实标准，虽然从市场角度来说 Prometheus 还没有达到 Kubernetes 那种“拔剑四顾，举世无敌”的程度，但是从社区活跃度上看，Prometheus 已占有绝对的优势，在 Google 和 CNCF 的推动下，未来前途可期。


追踪是与具体网络协议、程序语言密切相关的
各个服务之间是使用 HTTP 还是 gRPC 来进行通信会直接影响追踪的实现，各个服务是使用 Java、Golang 还是 Node.js 来编写，也会直接影响到进程内调用栈的追踪方式。
这决定了追踪工具本身有较强的侵入性，通常是以插件式的探针来实现；也决定了追踪领域很难出现一家独大的情况，通常要有多种产品来针对不同的语言和网络

市面上主流的工具既有像 Datadog 这样的一揽子商业方案，也有 AWS X-Ray 和 Google Stackdriver Trace 这样的云计算厂商产品，还有像 SkyWalking、Zipkin、Jaeger 这样来自开源社区的优秀产品。

其实这里很多不同领域的产品是跨界的，
譬如 ELK 可以通过 Metricbeat 来实现度量的功能，
Apache SkyWalking 的探针就有同时支持度量和追踪两方面的数据来源，
由OpenTracing 进化而来OpenTelemetry 更是融合了日志、追踪、度量三者所长，有望成为三者兼备的统一可观测性解决方案。


### 事件日志

从打印日志到分析查询之间，还隔着收集、缓冲、聚合、加工、索引、存储等若干个步骤

1. app 输出日志
2. beats 收集日志
3. redis 缓冲
4. logstash 聚合，加工
5. ElasticSearch 索引，存储
6. kibana 分析，查询


#### 输出

好的日志应该能做到像“流水账”一样，无有遗漏地记录信息，格式统一，内容恰当。
其中“恰当”是一个难点，它要求日志不应该过多，也不应该过少。

一些常见的“不应该有”的例子：

- 避免打印敏感信息
- 避免引用慢操作
  日志中打印的信息应该是上下文中可以直接取到的，不需要去远程服务或数据库中获取，不需要序列化json
- 避免打印追踪诊断信息
  日志中==不要打印方法输入参数、输出结果、方法执行时长之类的调试信息==。
  这个观点是反直觉的，不少公司甚至会将其作为最佳实践来提倡，但是笔者仍坚持将其归入反模式中。
  日志的职责是记录事件，追踪诊断应由追踪系统去处理，哪怕贵公司完全没有开发追踪诊断方面功能的打算，笔者也建议使用BTrace 或者Arthas 这类“On-The-Fly”的工具来解决。
  之所以将其归为反模式，是因为上面说的敏感信息、慢操作等的主要源头就是这些原本想用于调试的日志。
- 避免误导他人

。。但是不打印 参数，结果，我还能打印什么？。。 直接说，我收到一个事件，但是 事件的id  我不告诉你 ？？？


以下是部分笔者建议应该输出到日志中的内容：
- 处理请求时的 TraceID
- 系统运行过程中的关键事件
  日志的职责就是记录事件，进行了哪些操作、发生了与预期不符的情况、运行期间出现未能处理的异常或警告、定期自动执行的任务，等等，都应该在日志中完整记录下来。
- 启动时输出配置信息


#### 收集与缓冲

Logstash 除了==部署在各个节点中作为收集的客户端==（Shipper）以外，它还同时设有独立部署的节点，扮演归集转换日志的服务端（Master）角色。

。。第一次知道Logstash 是 Filebeat的 上一代

Logstash 与它的插件是基于 JRuby 编写的，要跑在单独的 Java 虚拟机进程上，而且 Logstash 的默认的堆大小就到了 1GB。
对于归集部分（Master）这种消耗并不是什么问题，但作为每个节点都要部署的日志收集器就显得太过负重了。

后来，Elastic.co 公司将所有需要在服务节点中处理的工作整理成以Libbeat 为核心的Beats 框架 ，并使用 Golang 重写了一个功能较少，却更轻量高效的日志收集器，这就是今天流行的==Filebeat== 。

除了 Filebeat 外，Elastic.co 还提供有
用于收集 Linux 审计数据的Auditbeat 、
用于无服务计算架构的Functionbeat 、
用于心跳检测的Heartbeat 、
用于聚合度量的Metricbeat 、
用于收集 Linux Systemd Journald 日志的Journalbeat 、
用于收集 Windows 事件日志的Winlogbeat ，
用于网络包嗅探的Packetbeat ，
等等，如果再算上大量由社区维护的Community Beats ，那几乎是你能想像到的数据都可以被收集到，以至于 ELK 也可以一定程度上代替度量和追踪系统，实现它们的部分职能，这对于中小型分布式系统来说是便利的，但对于大型系统，笔者建议还是让专业的工具去做专业的事情。

日志收集器不仅要保证能覆盖全部数据来源，还要尽力保证日志数据的连续性，这其实并不容易做到。
譬如淘宝这类大型的互联网系统，每天的日志量超过了 10,000TB（10PB）量级，日志收集器的部署实例数能到达百万量级

。。我不信，不过文章真给了一个数据源，是infoq的，要登录才能下载ppt。没下。
。。10000 / 24 / 3600 .   0.11574 T      115.74g/s
。。而且不可能24小时的负载都平稳的。
。。1万台服务器，那么每台就是 11.57m/s  。。imsb？ursb！
。。不知道淘宝有多少台服务器。


日志不追求绝对的完整精确，只追求在代价可承受的范围内保证尽可能地保证较高的数据质量。
一种最常用的缓解压力的做法是将日志接收者从 Logstash 和 Elasticsearch 转移至抗压能力更强的队列缓存，
譬如在 ==Logstash 之前架设一个 Kafka 或者 Redis== 作为缓冲层，面对突发流量，Logstash 或 Elasticsearch 处理能力出现瓶颈时自动削峰填谷，甚至当它们短时间停顿，也不会丢失日志数据。


#### 加工与聚合

将日志集中收集之后，存入 Elasticsearch 之前，一般还要对它们进行加工转换和聚合处理。
这是因为日志是非结构化数据，一行日志中通常会包含多项信息，如果不做处理，那在 Elasticsearch 就只能以全文检索的原始方式去使用日志，既不利于统计对比，也不利于条件过滤。

Logstash 的基本职能是把日志行中的非结构化数据，通过 Grok 表达式语法转换为上面表格那样的结构化数据，进行结构化的同时，还可能会根据需要，调用其他插件来完成时间处理（统一时间格式）、类型转换（如字符串、数值的转换）、查询归类（譬如将 IP 地址根据地理信息库按省市归类）等额外处理工作，
然后以 JSON 格式输出到 Elasticsearch 中（这是最普遍的输出形式，Logstash 输出也有很多插件可以具体定制不同的格式）。
有了这些经过 Logstash 转换，已经结构化的日志，Elasticsearch 便可针对不同的数据项来建立索引，进行条件查询、统计、聚合等操作的了。


提到聚合，这也是 Logstash 的另一个常见职能。
日志中存储的是离散事件，离散的意思是每个事件都是相互独立的，譬如有 10 个用户访问服务，他们操作所产生的事件都在日志中会分别记录。

如果想从离散的日志中获得统计信息，譬如想知道这些用户中正常返回（200 OK）的有多少、出现异常的（500 Internal Server Error）的有多少，再生成个可视化统计图表，
一种解决方案是通过 ==Elasticsearch 本身的处理能力做实时的聚合统计==，这很便捷，不过要消耗 Elasticsearch 服务器的运算资源。
另一种解决方案是在收集日志后==自动生成某些常用的、固定的聚合指标==，这种聚合就会在 ==Logstash 中通过聚合插件==来完成。
这两种聚合方式都有不少实际应用，前者一般用于应对即席查询，后者用于应对固定查询。

。。真有这个 即席查询   Ad-hoc search    baidu下。

#### 存储与查询

Elasticsearch 是整个 Elastic Stack 技术栈的核心，其他步骤的工具，如 Filebeat、Logstash、Kibana 都有替代品，有自由选择的余地，唯独 Elasticsearch 在日志分析这方面完全没有什么值得一提的竞争者，几乎就是解决此问题的唯一答案。

Elasticsearch 只提供了 API 层面的查询能力，它通常搭配同样出自 Elastic.co 公司的 Kibana 一起使用，可以将 Kibana 视为 Elastic Stack 的 GUI 部分

Kibana 宣传的核心能力是“探索数据并可视化”，即把存储在 Elasticsearch 中的数据被检索、聚合、统计后，定制形成各种图形、表格、指标、统计，以此观察系统的运行状态，找出日志事件中潜藏的规律和隐患。按 Kibana 官方的宣传语来说就是“一张图片胜过千万行日志”。




### 链路追踪


现代分布式链路追踪公认的起源是 Google 在 2010 年发表的论文《Dapper : a Large-Scale Distributed Systems Tracing Infrastructure》，这篇论文介绍了 Google 从 2004 年开始使用的分布式追踪系统 Dapper 的实现原理。

后续的所有追踪系统，zipkin(twitter),pinpoint(naver),鹰眼(阿里)，CAT(大众点评)，skywalking(个人开源，后进入apache)，都受到这篇论文的 直接影响。

一个==完整==的分布式追踪系统应该由==数据收集、数据存储和数据展示==三个相对独立的子系统构成，而==狭义==上讲的追踪则就只是特指链路==追踪数据的收集==部分。
譬如Spring Cloud Sleuth 就属于狭义的追踪系统，通常会搭配 Zipkin 作为数据展示，搭配 Elasticsearch 作为数据存储来组合使用，
而前面提到的那些 Dapper 的徒子徒孙们大多都属于广义的追踪系统，广义的追踪系统又常被称为“==APM 系统==”（Application Performance Management）。


#### 追踪与跨度

为了有效地进行分布式追踪，Dapper 提出了“追踪”与“跨度”两个概念。
从客户端发起请求抵达系统的边界开始，记录请求流经的每一个服务，直到到向客户端返回响应为止，这==整个过程就称为一次“追踪==”（Trace，为了不产生混淆，后文就直接使用英文 Trace 来指代了）。
由于每次 Trace 都可能会调用数量不定、坐标不定的多个服务，为了能够记录具体调用了哪些服务，以及调用的顺序、开始时点、执行时长等信息，==每次开始调用服务前都要先埋入一个调用记录==，这个记录称为一个“跨度”（Span）。
Span 的数据结构应该足够简单，以便于能放在日志或者网络协议的报文头里；也应该足够完备，起码应含有时间戳、起止时间、Trace 的 ID、当前 Span 的 ID、父 Span 的 ID 等能够满足追踪需要的信息。每一次 Trace 实际上都是由若干个有顺序、有层级关系的 Span 所组成一颗“追踪树”（Trace Tree）

为每次服务调用记录 Trace 和 Span，并以此构成追踪树结构，听着好像也不是很复杂，然而考虑到实际情况，追踪系统在功能性和非功能性上都有不小的挑战。
功能上的挑战来源于服务的异构性，各个服务可能采用不同程序语言，服务间交互可能采用不同的网络协议，每兼容一种场景，都会增加功能实现方面的工作量。而非功能性的挑战具体就来源于以下这四个方面：
- 低性能损耗
- 对应用透明
- 随应用扩缩
- 持续的监控


#### 数据收集

追踪系统根据数据收集方式的差异，可分为三种主流的实现方式，分别是基于日志的追踪（Log-Based Tracing），基于服务的追踪（Service-Based Tracing）和基于边车代理的追踪（Sidecar-Based Tracing）

- 基于日志的追踪的思路是将 Trace、Span 等信息直接输出到应用日志中，然后随着所有节点的日志归集过程汇聚到一起，再从全局日志信息中反推出完整的调用链拓扑关系。
  日志追踪对网络消息完全没有侵入性，对应用程序只有很==少量的侵入性==，对性能影响也非常低。但其缺点是直接依赖于日志归集过程，日志本身不追求绝对的连续与一致，这也使得基于日志的追踪往往==不如其他==两种追踪实现来的==精准==。

- 基于服务的追踪是目前==最为常见==的追踪实现方式，被 Zipkin、SkyWalking、Pinpoint 等主流追踪系统广泛采用。
  服务追踪的实现思路是通过某些手段给目标应用==注入追踪探针==（Probe），针对 Java 应用一般就是通过 Java Agent 注入的。
  探针在结构上可视为一个寄生在目标服务身上的==小型微服务系统==，它一般会==有自己专用的服务注册、心跳检测等功能==，有专门的数据收集协议，把从目标系统中监控得到的服务调用信息，通过另一次独立的 HTTP 或者 RPC 请求发送给追踪系统。
  因此，基于服务的追踪会比基于日志的追踪==消耗更多的资源==，也有==更强的侵入性==，换来的收益是追踪的==精确性与稳定性都有所保证==，不必再依靠日志归集来传输追踪数据。


- 基于边车代理的追踪是服务网格的专属方案
  也是最理想的分布式追踪模型，它对应用完全透明，无论是日志还是服务本身都不会有任何变化；
  它与程序语言无关，无论应用采用什么编程语言实现，只要它还是通过网络（HTTP 或者 gRPC）来访问服务就可以被追踪到；
  它有自己独立的数据通道，追踪数据通过控制平面进行上报，避免了追踪对程序通信或者日志归集的依赖和干扰，保证了最佳的精确性。如
  果要说这种追踪实现方式还有什么缺点的话，那就是服务网格现在还不够普及，未来随着云原生的发展，相信它会成为追踪系统的主流实现方式之一。还有就是边车代理本身的对应用透明的工作原理决定了它只能实现服务调用层面的追踪，像上面 Pinpoint 截图那样本地方法调用级别的追踪诊断是做不到的。


#### 追踪规范化

2019 年，OpenTracing 和 OpenCensus 又忽然宣布握手言和，它们共同发布了可观测性的终极解决方案OpenTelemetry ，并宣布会各自冻结 OpenTracing 和 OpenCensus 的发展。
OpenTelemetry 野心颇大，不仅包括追踪规范，还包括日志和度量方面的规范、各种语言的 SDK、以及采集系统的参考实现，它距离一个完整的追踪与度量系统，仅仅是缺了界面端和指标预警这些会与用户直接接触的后端功能，OpenTelemetry 将它们留给具体产品去实现，勉强算是没有对一众 APM 厂商赶尽杀绝，留了一条活路。





### 聚合度量

度量（Metrics）的目的是揭示系统的总体运行状态。

度量总体上可分为客户端的指标收集、服务端的存储查询以及终端的监控预警三个相对独立的过程

Prometheus 在度量领域的统治力虽然还暂时不如日志领域中 Elastic Stack 的统治地位那么稳固，但在云原生时代里，基本也已经能算是事实标准了，接下来，笔者将主要以 Prometheus 为例，介绍这三部分组件的总体思路、大致内容与理论标准。


#### 指标收集

确定目标系统前我们无法决定要收集什么指标，但指标的数据类型（Metrics Types）是可数的，所有通用的度量系统都是面向指标的数据类型来设计的：
- 计数度量器（Counter）
- 瞬态度量器（Gauge）
- 吞吐率度量器（Meter）
- 直方图度量器（Histogram）
- 采样点分位图度量器（Quantile Summary）
还有 Timer、Set、Fast Compass、Cluster Histogram 等其他各种度量器

采用不同的度量系统，支持度量器类型的范围肯定会有差别，譬如 Prometheus 支持了上面提到五种度量器中的 Counter、Gauge、Histogram 和 Summary 四种。



如何将这些指标告诉服务端
通常有两种解决方案：拉取式采集（Pull-Based Metrics Collection）和推送式采集（Push-Based Metrics Collection）

Pull 是指度量系统主动从目标系统中拉取指标，相对地，Push 就是由目标系统主动向度量系统推送指标。
这两种方式并没有绝对的好坏优劣

以前很多老牌的度量系统，如Ganglia 、Graphite 、StatsD 等是基于 Push 的，
而以 Prometheus、Datadog 、Collectd 为代表的另一派度量系统则青睐 Pull 式采集（Prometheus 官方解释选择 Pull 的原因 ）


由推和拉决定该谁主动以后，另一个问题是指标应该以怎样的网络访问协议、取数接口、数据结构来获取？如同计算机科学中其他这类的问题类似，一贯的解决方向是“定义规范”，应该由行业组织和主流厂商一起协商出专门用于度量的协议，目标系统按照协议与度量系统交互。

没有了标准，有一些度量系统，譬如老牌的 Zabbix 就选择同时支持了 SNMP、JMX、IPMI 等多种不同的度量协议，另一些度量系统，以 Prometheus 为代表就相对强硬，选择任何一种协议都不去支持，只允许通过 HTTP 访问度量端点这一种访问方式。

Exporter 是 Prometheus 提出的概念，它是目标应用的代表，既可以独立运行，也可以与应用运行在同一个进程中，只要集成 Prometheus 的 Client Library 便可。Exporter 以 HTTP 协议（Prometheus 在 2.0 版本之前支持过 Protocol Buffer，目前已不再支持）返回符合 Prometheus 格式要求的文本数据给 Prometheus 服务器。

得益于 Prometheus 的良好社区生态，现在已经有大量各种用途的 Exporter，让 Prometheus 的监控范围几乎能涵盖所有用户所关心的目标

数据库 	MySQL Exporter、Redis Exporter、MongoDB Exporter、MSSQL Exporter 等
硬件 	Apcupsd Exporter，IoT Edison Exporter， IPMI Exporter、Node Exporter 等
消息队列 	Beanstalkd Exporter、Kafka Exporter、NSQ Exporter、RabbitMQ Exporter 等
存储 	Ceph Exporter、Gluster Exporter、HDFS Exporter、ScaleIO Exporter 等
HTTP 服务 	Apache Exporter、HAProxy Exporter、Nginx Exporter 等
API 服务 	AWS ECS Exporter， Docker Cloud Exporter、Docker Hub Exporter、GitHub Exporter 等
日志 	Fluentd Exporter、Grok Exporter 等
监控系统 	Collectd Exporter、Graphite Exporter、InfluxDB Exporter、Nagios Exporter、SNMP Exporter 等
其它 	Blockbox Exporter、JIRA Exporter、Jenkins Exporter， Confluence Exporter 等



#### 存储查询

度量的存储是需要专门研究解决的问题。至于如何解决，让我们先来观察一段 Prometheus 的真实度量数据
```json
{
	// 时间戳
	"timestamp": 1599117392,
	// 指标名称
	"metric": "total_website_visitors",
	// 标签组
	"tags": {
		"host": "icyfenix.cn",
		"job": "prometheus"
	},
	// 指标值
	"value": 10086
}
```

观察这段度量数据的特征：每一个度量指标由时间戳、名称、值和一组标签构成，除了==时间==之外，指标不与任何其他因素相关。
指标的数据总量固然是不小的，但它没有嵌套、没有关联、没有主外键，不必关心范式和事务，这些都是可以针对性优化的地方。
事实上，业界早就已经存在了专门针对该类型数据的数据库了，即“==时序数据库==”（Time Series Database）。

##### 时序数据库
时序数据库用于存储跟随时间而变化的数据，并且以时间（时间点或者时间区间）来建立索引的数据库。
时序数据库最早是应用于工业（电力行业、化工行业）应用的各类型实时监测、检查与分析设备所采集、产生的数据，这些工业数据的典型特点是产生频率快（每一个监测点一秒钟内可产生多条数据）、严重依赖于采集时间（每一条数据均要求对应唯一的时间）、测点多信息量大（常规的实时监测系统均可达到成千上万的监测点，监测点每秒钟都在产生数据）。
时间序列数据是历史烙印，具有不变性,、唯一性、有序性。时序数据库同时具有数据结构简单，数据量大的特点。

写操作，时序数据通常只是追加，很少删改或者根本不允许删改。针对数据热点只集中在近期数据、多写少读、几乎不删改、数据只顺序追加这些特点，时序数据库被允许做出很激进的存储、访问和保留策略（Retention Policies）：

- 以日志结构的合并树 （Log Structured Merge Tree，LSM-Tree）代替传统关系型数据库中的B+Tree作为存储结构，LSM 适合的应用场景就是写多读少，且几乎不删改的数据。
- 设置激进的数据保留策略，譬如根据过期时间（TTL）自动删除相关数据以节省存储空间，同时提高查询性能。对于普通数据库来说，数据会存储一段时间后就会被自动删除这种事情是不可想象的。
- 对数据进行再采样（Resampling）以节省空间，譬如最近几天的数据可能需要精确到秒，而查询一个月前的数据时，只需要精确到天，查询一年前的数据时，只要精确到周就够了，这样将数据重新采样汇总就可以极大节省存储空间。

时序数据库中甚至还有一种并不罕见却更加极端的形式，叫作==轮替型数据库 （Round Robin Database，RRD==），以==环形缓冲==（在“服务端缓存”一节介绍过）的思路实现，只能存储固定数量的最新数据，超期或超过容量的数据就会被轮替覆盖，因此也有着固定的数据库容量，却能接受无限量的数据输入。



Prometheus 服务端自己就内置了一个强大时序数据库实现，跃居时序数据库排行榜的前三。
该时序数据库提供了名为 PromQL 的数据查询语言，能对时序数据进行丰富的查询、聚合以及逻辑运算

要查找网站icyfenix.cn访问人数，会是如下写法
```text
// 查询命令：
total_website_visitors{host=“icyfenix.cn”}

// 返回结果：
total_website_visitors{host=“icyfenix.cn”,job="prometheus"}=(10086)
```

Prometheus 流行之前最老牌的度量系统 Zabbix 用的就是传统关系数据库来存储指标。



#### 监控预警
指标度量是手段，最终目的是做分析和预警。

广义上的度量系统由面向目标系统进行指标采集的客户端（Client，与目标系统进程在一起的 Agent，或者代表目标系统的 Exporter 等都可归为客户端），负责调度、存储和提供查询能力的服务端（Server，Prometheus 的服务端是带存储的，但也有很多度量服务端需要配合独立的存储来使用的），以及面向最终用户的终端（Backend，UI 界面、监控预警功能等都归为终端）组成。
狭义上的度量系统就只包括客户端和服务端，不包含终端。

Prometheus 应算是处于狭义和广义的度量系统之间，尽管它确实内置了一个界面解决方案“Console Template”，以模版和 JavaScript 接口的形式提供了一系列预设的组件（菜单、图表等），让用户编写一段简单的脚本就可以实现可用的监控功能。不过这种可用程度，往往不足以支撑正规的生产部署

大多是 Prometheus 配合 Grafana 来进行展示的，这是 Prometheus 官方推荐的组合方案，但该组合也并非唯一选择，
如果要搭配 Kibana 甚至 SkyWalking（8.x 版之后的 SkyWalking 支持从 Prometheus 获取度量数据）来使用也都是完全可行的。

Prometheus 提供了专门用于预警的 Alert Manager，将 Alert Manager 与 Prometheus 关联后，可以设置某个指标在多长时间内达到何种条件就会触发预警状态，触发预警后，根据路由中配置的接收器，譬如邮件接收器、Slack 接收器、微信接收器、或者更通用的WebHook 接收器等来自动通知用户。




# 不可变基础设施

## 从微服务到云原生

云原生技术有利于各组织在公有云、私有云和混合云等新型动态环境中，构建和运行可弹性扩展的应用。云原生的代表技术包括容器、服务网格、微服务、不可变基础设施和声明式 API。

这些技术能够构建容错性好、易于管理和便于观察的松耦合系统。结合可靠的自动化手段，云原生技术使工程师能够轻松地对系统作出频繁和可预测的重大变更。



前一章以“分布式的基石”为题，介绍了微服务中关键的技术问题与解决方案，解决这些问题原本应该是架构师与程序员的本职工作。
在本章，笔者会以==容器、编排系统和服务网格的发展==为主线，介绍虚拟化容器与服务网格是如何==模糊掉软件与硬件之间的界限==，如何在基础设施与通讯层面上==帮助微服务隐藏复杂性==，解决原本只能由程序员通过软件编程来解决的分布式问题。



## 虚拟化容器

容器是云计算、微服务等诸多软件业界核心技术的共同基石，容器的首要目标是让软件分发部署过程从传统的发布安装包、靠人工部署转变为直接发布已经部署好的、包含整套运行环境的虚拟化镜像。

一个计算机软件要能够正确运行，需要有以下三方面的兼容性来共同保障
- ISA 兼容：目标机器指令集兼容性，譬如 ARM 架构的计算机无法直接运行面向 x86 架构编译的程序。
- ABI 兼容：目标系统或者依赖库的二进制兼容性，譬如 Windows 系统环境中无法直接运行 Linux 的程序，又譬如 DirectX 12 的游戏无法运行在 DirectX 9 之上。
- 环境兼容：目标环境的兼容性，譬如没有正确设置的配置文件、环境变量、注册中心、数据库地址、文件系统的权限等等，任何一个环境因素出现错误，都会让你的程序无法正常运行。


笔者把使用仿真（Emulation）以及虚拟化（Virtualization）技术来解决以上三项兼容性问题的方法都统称为虚拟化技术。根据抽象目标与兼容性高低的不同，虚拟化技术又分为下列五类：

- 指令集虚拟化（ISA Level Virtualization）
  通过软件来模拟不同 ISA 架构的处理器工作过程，将虚拟机发出的指令转换为符合本机 ISA 的指令
  代表为QEMU 和Bochs 
- 硬件抽象层虚拟化（Hardware Abstraction Level Virtualization）
  以软件或者直接通过硬件来模拟处理器、芯片组、内存、磁盘控制器、显卡等设备的工作过程。
  可以使用纯软件的二进制翻译来模拟虚拟设备,可以由硬件
  代表为VMware ESXi 和Hyper-V
- 操作系统层虚拟化（OS Level Virtualization）
  无论是指令集虚拟化还是硬件抽象层虚拟化，都会运行一套完全真实的操作系统来解决 ABI 兼容性和环境兼容性问题，虽然 ISA 兼容性是虚拟出来的，但 ABI 兼容性和环境兼容性却是真实存在的。
  操作系统层虚拟化的另一个名字就是本章的主角“容器化”（Containerization）
  Docker
  容器化牺牲了一定的隔离性与兼容性，换来的是比前两种虚拟化更高的启动速度、运行性能和更低的执行负担。
- 运行库虚拟化（Library Level Virtualization）
  与操作系统虚拟化采用隔离手段来模拟系统不同，运行库虚拟化选择使用软件翻译的方法来模拟系统，它以一个独立进程来代替操作系统内核来提供目标软件运行所需的全部能力，这种虚拟化方法获得的 ABI 兼容性高低,取决于软件是否能足够准确和全面地完成翻译工作
  WINE, WSL
- 语言层虚拟化（Programming Language Level Virtualization）
  由虚拟机将高级语言生成的中间代码转换为目标机器可以直接执行的指令
  Java 的 JVM 和.NET 的 CLR



### 容器的崛起

1. 隔离文件：chroot
容器的起点可以追溯到 1979 年Version 7 UNIX 系统中提供的chroot命令，这个命令是英文单词“Change Root”的缩写，
功能是当某个进程经过chroot操作之后，它的根目录就会被锁定在命令参数所指定的位置，以后它或者它的子进程将不能再访问和操作该目录之外的其他文件。

2000 年，Linux Kernel 2.3.41 版内核引入了pivot_root技术来实现文件隔离，pivot_root直接切换了根文件系统 （rootfs），有效地避免了chroot命令可能出现的安全性漏洞。
本文后续提到的容器技术，如 LXC、Docker 等也都是优先使用pivot_root来实现根文件系统切换的。


2. 隔离访问：namespaces
2002 年，Linux Kernel 2.4.19 版内核引入了一种全新的隔离机制：Linux 名称空间 （Linux Namespaces）。

Linux 的名称空间是一种由内核直接提供的全局资源封装，是内核针对进程设计的访问隔离机制。
进程在一个独立的 Linux 名称空间中朝系统看去，会觉得自己仿佛就是这方天地的主人，
拥有这台 Linux 主机上的一切资源，不仅文件系统是独立的，还有着独立的 PID 编号（譬如拥有自己的 0 号进程，即系统初始化的进程）、UID/GID 编号（譬如拥有自己独立的 root 用户）、网络（譬如完全独立的 IP 地址、网络栈、防火墙等设置），等等，此时进程的心情简直不能再好了。

直到目前最新的 Linux Kernel 5.6 版内核为止，Linux 名称空间支持以下八种资源的隔离（内核的官网Kernel.org 上仍然只列出了前六种 ，从 Linux 的 Man 命令能查到全部八种 ）。

|名称空间|隔离内容|内核版本|
|--|--|--|
|Mount |	隔离文件系统，功能上大致可以类比chroot |	2.4.19|
|UTS |	隔离主机的Hostname、Domain names | 2.6.19|
|IPC |	隔离进程间通信的渠道（详见“远程服务调用”中对 IPC 的介绍） |	2.6.19|
|PID |	隔离进程编号，无法看到其他名称空间中的 PID，意味着无法对其他进程产生影响 |	2.6.24|
|Network | 隔离网络资源，如网卡、网络栈、IP 地址、端口，等等 |	2.6.29|
|User |	隔离用户和用户组 |	3.8|
|Cgroup |	隔离cgroups信息，进程有自己的cgroups的根目录视图（在/proc/self/cgroup 不会看到整个系统的信息）。cgroups的话题很重要，稍后笔者会安排一整节来介绍| 	4.6|
|Time |	隔离系统时间，2020 年 3 月最新的 5.6 内核开始支持进程独立设置系统时间 	|5.6|


现在距离完美的隔离性就只差最后一步了：资源的隔离。


3. 隔离资源：cgroups

必须能独立控制分配给各个进程的资源使用配额，
不然的话，一个进程发生了内存溢出或者占满了处理器，其他进程就莫名其妙地被牵连挂起，这样肯定算不上是完美的隔离。

Linux 系统解决以上问题的方案是控制群组 （Control Groups，目前常用的简写为cgroups），它与名称空间一样都是直接由内核提供的功能，用于隔离或者说==分配并限制某个进程组能够使用的资源配额==，资源配额包括处理器时间、内存大小、磁盘 I/O 速度，等等

|控制组子系统 	|功能|
|--|--|
|blkio |	为块设备（如磁盘，固态硬盘，USB 等等）设定 I/O 限额。|
|cpu |	控制cgroups中进程的处理器占用比率。|
|cpuacct |	自动生成cgroups中进程所使用的处理器时间的报告。|
|cpuset |	为cgroups中的进程分配独立的处理器（包括多路系统的处理器，多核系统的处理器核心）。|
|devices |	设置cgroups中的进程访问某个设备的权限（读、写、创建三种权限）。|
|freezer |	挂起或者恢复cgroups中的进程。|
|memory |	设定cgroups中进程使用内存的限制，并自动生成内存资源使用报告。|
|net_cls |	使用等级识别符标记网络数据包，可允许 Linux 流量控制程序识别从具体 cgroups中生成的数据包。|
|net_prio |	用来设置网络流量的优先级。|
|hugetlb |	主要针对于 HugeTLB 系统进行限制。|
|perf_event |	允许 Perf 工具基于cgroups分组做性能监测。|



4. 封装系统：LXC

也决定了 LXC 不可能形成今天的容器生态的，所以，接下来舞台的聚光灯终于落到了 Docker 身上。



5. 封装应用：Docker

对开源早期的 Docker 而言，确实没有什么能构成壁垒的技术。
它的容器化能力直接来源于 LXC，
它镜像分层组合的文件系统直接来源于AUFS ，
Docker 开源后不久，就有人仅用了一百多行 Shell 脚本便实现了 Docker 的核心功能（名为Bocker ，提供了docker build/pull/images/ps/run/exec/logs/commit/rm/rmi等功能）。


为什么要用 Docker 而不是 LXC？（Why would I use Docker over plain LXC？）
Docker 除了包装来自 Linux 内核的特性之外，它的价值还在于：
- 跨机器的绿色部署：
  Docker 定义了一种将应用及其所有的环境依赖都打包到一起的格式，仿佛它原本就是绿色软件一样。LXC 并没有提供这样的能力，使用 LXC 部署的新机器很多细节都依赖人的介入，虚拟机的环境几乎肯定会跟你原本部署程序的机器有所差别。
- 以应用为中心的封装：
  Docker 封装应用而非封装机器的理念贯穿了它的设计、API、界面、文档等多个方面。相比之下，LXC 将容器视为对系统的封装，这局限了容器的发展。
- 自动构建：
  Docker 提供了开发人员从在容器中构建产品的全部支持，开发人员无需关注目标机器的具体配置，即可使用任意的构建工具链，在容器中自动构建出最终产品。
- 多版本支持：
  Docker 支持像 Git 一样管理容器的连续版本，进行检查版本间差异、提交或者回滚等操作。从历史记录中你可以查看到该容器是如何一步一步构建成的，并且只增量上传或下载新版本中变更的部分。
- 组件重用：
  Docker 允许将任何现有容器作为基础镜像来使用，以此构建出更加专业的镜像。
- 共享：
  Docker 拥有公共的镜像仓库，成千上万的 Docker 用户在上面上传了自己的镜像，同时也使用他人上传的镜像。
- 工具生态：
  Docker 开放了一套可自动化和自行扩展的接口，在此之上，还有很多工具来扩展其功能，譬如容器编排、管理界面、持续集成等等。



Docker 被分解为由 Docker Client、Docker Daemon、Docker Registry、Docker Container 等子系统，以及 Graph、Driver、libcontainer 等各司其职的模块组成，
此时再说一百多行脚本能实现 Docker 核心功能，再说 Docker 没有太高的技术含量，就已经不再合适了。

2014 年，Docker 开源了自己用 Golang 开发的libcontainer ，这是一个越过 LXC 直接操作namespaces和cgroups的核心模块，有了 libcontainer 以后，Docker 就能直接与系统内核打交道，不必依赖 LXC 来提供容器化隔离能力了。

2015 年，在 Docker 的主导和倡议下，多家公司联合制定了“开放容器交互标准 ”（Open Container Initiative，OCI），这是一个关于容器格式和运行时的规范文件，其中包含运行时标准（runtime-spec ）、容器镜像标准（image-spec ）和镜像分发标准（distribution-spec ，分发标准还未正式发布）。运行时标准定义了应该如何运行一个容器、如何管理容器的状态和生命周期、如何使用操作系统的底层特性（namespaces、cgroup、pivot_root等）；容器镜像标准规定了容器镜像的格式、配置、元数据的格式，可以理解为对镜像的静态描述；镜像分发标准则规定了镜像推送和拉取的网络交互过程。

为了符合 OCI 标准，Docker 推动自身的架构继续向前演进，首先将 libcontainer 独立出来，封装重构成runC 项目 ，并捐献给了 Linux 基金会管理。runC 是 OCI Runtime 的首个参考实现，提出了“让标准容器无所不在”（Make Standard Containers Available Everywhere）的口号。

2016 年，Docker 把 containerd 捐献给了 CNCF 管理，runC 与 containerd 两个项目的捐赠托管，即带有 Docker 对开源信念的追求，也带有 Docker 在众多云计算大厂夹击下自救的无奈，这两个项目将成为未来 Docker 消亡和存续的伏笔

虽然 Docker 赢得了容器战争，但 Docker Swarm 却输掉了容器编排战争。


6. 封装集群：Kubernetes

如果说以 Docker 为代表的容器引擎将软件的发布流程从分发二进制安装包转变为直接分发虚拟化后的整个运行环境，令应用得以实现跨机器的绿色部署；
那以 Kubernetes 为代表的容器编排框架，就是把大型软件系统运行所依赖的==集群环境也进行了虚拟化==，令集群得以实现跨数据中心的绿色部署，并能够根据实际情况自动扩缩。


![3bd9e00e6d1947170115ffa9e9ea332a.png](../_resources/3bd9e00e6d1947170115ffa9e9ea332a.png)

直至 Kubernetes 1.5 之前，Kubernetes 管理容器的方式都是通过内部的 DockerManager 向 Docker Engine 以 HTTP 方式发送指令，通过 Docker 来操作镜像的增删改查的，如上图最右边线路的箭头所示
`Kubernetes Master → kubelet → DockerManager → Docker Engine → containerd → runC`


2016 年，Kubernetes 1.5 版本开始引入“容器运行时接口 ”（Container Runtime Interface，CRI），这是一个定义容器运行时应该如何接入到 kubelet 的规范标准
由于 CRI 是在 Docker 之后才发布的规范，Docker 是肯定不支持 CRI 的，所以 Kubernetes 又提供了 DockerShim 服务作为 Docker 与 CRI 的适配层
`Kubernetes Master → kubelet → KubeGenericRuntimeManager → DockerShim → Docker Engine → containerd → runC`


2017 年，由 Google、RedHat、Intel、SUSE、IBM 联合发起的CRI-O （Container Runtime Interface Orchestrator）项目发布了首个正式版本。从名字就可以看出，它肯定是完全遵循 CRI 规范进行实现的，另一方面，它可以支持所有符合 OCI 运行时标准的容器引擎，默认仍然是与 runC 搭配工作的
`Kubernetes Master → kubelet → KubeGenericRuntimeManager → CRI-O→ runC`


2018 年，由 Docker 捐献给 CNCF 的 containerd，在 CNCF 的精心孵化下发布了 1.1 版，1.1 版与 1.0 版的最大区别是此时它已完美地支持了 CRI 标准
ubernetes 从 1.10 版本宣布开始支持 containerd 1.1
`Kubernetes Master → kubelet → KubeGenericRuntimeManager → containerd → runC`


今天，要使用哪一种容器运行时取决于你安装 Kubernetes 时宿主机上的容器运行时环境，但对于云计算厂商来说，譬如国内的阿里云 ACK 、腾讯云 TKE 等直接提供的 Kubernetes 容器环境，采用的容器运行时普遍都已是 containerd，毕竟运行性能对它们来说就是核心生产力和竞争力。


### 以容器构建系统
自从 Docker 提出“以封装应用为中心”的容器发展理念，成功取代了“以封装系统为中心”的 LXC 以后，==一个容器封装一个单进程应用==已经成为被广泛认可的最佳实践。
然而单体时代过去之后，分布式系统里应用的概念已不再等同于进程，此时的应用==需要多个进程共同协作==，通过==集群的形式对外提供服务==，以虚拟化方法实现这个目标的过程就被称为==容器编排==（Container Orchestration）。


#### 隔离与协作
笔者并不打算过多介绍 Kubernetes 具体有哪些功能，向你说明 Kubernetes 由 Pod、Node、Deployment、ReplicaSet 等各种类型的资源组成可用的服务、集群管理平面与节点之间如何工作、每种资源该如何配置使用等等，并不是笔者的本意

笔者真正希望说清楚的问题是“为什么 Kubernetes 会设计成现在这个样子？”、“为什么以容器构建系统应该这样做？”


> 场景一：假设你现在有两个应用，其中一个是 Nginx，另一个是为该 Nginx 收集日志的 Filebeat，你希望将它们封装为容器镜像，以方便日后分发。

最直接的方案就将 Nginx 和 Filebeat 直接编译成同一个容器镜像，这是可以做到的，而且并不复杂，然而这样做会埋下很大隐患：它违背了 Docker 提倡的单个容器封装单进程应用的最佳实践。

Docker 设计的 Dockerfile 只允许有一个 ENTRYPOINT，这并非无故添加的人为限制，而是因为 Docker ==只能通过监视 PID 为 1 的进程==（即由 ENTRYPOINT 启动的进程）的运行状态来==判断容器的工作状态==是否正常，容器退出执行清理，容器崩溃自动重启等操作都必须先判断状态。



> 场景二：假设你现在有两个 Docker 镜像，其中一个封装了 HTTP 服务，为便于称呼，我们叫它 Nginx 容器，另一个封装了日志收集服务，我们叫它 Filebeat 容器。现在要求 Filebeat 容器能收集 Nginx 容器产生的日志信息。

场景二依然不难解决，只要在 Nginx 容器和 Filebeat 容器启动时，分别将它们的日志目录和收集目录挂载为宿主机==同一个磁盘位置==的 Volume 即可，这种操作在 Docker 中是==十分常用的容器间信息交换手段==。
不过，容器间信息交换不仅仅是文件系统，假如此时我又引入了一个新的工具confd ——Linux 下的一种配置管理工具，作用是==根据配置中心（Etcd、ZooKeeper、Consul）的变化自动更新 Nginx 的配置==，这里便又会遇到新的问题。
confd 需要向 Nginx 发送 HUP 信号以便通知 Nginx 配置已经发生了变更，而发送 HUP 信号自然要求 confd 与 Nginx 能够==进行 IPC 通信才行==。
尽管共享 IPC 名称空间不如共享 Volume 常见，但 Docker 同样支持了该功能，docker run 提供了==--ipc参数，用于把多个容器挂载到同一个父容器的 IPC 名称空间之下，以实现容器间共享 IPC 名称空间的需求==。
类似地，如果要==共享 UTS 名称空间==，可以使用--uts参数，要==共享网络名称空间==的话，就使用--net参数。

以上便是 Docker 针对场景二这种不跨机器的多容器协作所给出的解决方案，自动地为多个容器设置好共享名称空间其实就是Docker Compose 提供的核心能力。

这种针对具体应用需求来共享名称空间的方案，的确可以工作，却并不够优雅，也谈不上有什么扩展性。
容器的本质是对 cgroups 和 namespaces 所提供的隔离能力的一种封装，在 Docker 提倡的单进程封装的理念影响下，容器蕴含的隔离性也多了仅针对于==单个进程==的额外局限，然而 Linux 的 cgroups 和 namespaces 原本都是==针对进程组而不仅仅是单个进程==来设计的，==同一个进程组中的多个进程天然就可以共享着相同的访问权限与资源配额==。
如果现在我们把容器与进程在概念上对应起来，那==容器编排的第一个扩展点，就是要找到容器领域中与“进程组”相对应的概念，这是实现容器从隔离到协作的第一步，在 Kubernetes 的设计里，这个对应物叫作 Pod==。

。。好像没有看到 进程组。。《Linux编程设计》 中。


##### Pod

Pod 的概念在容器正式出现之前的 Borg 系统中就已经存在，从 Google 的发表的《Large-Scale Cluster Management at Google with Borg 》可以看出，Kubernetes 时代的 Pod 整合了 Borg 时代的“Prod”（Production Task 的缩写）与“Non-Prod”的职能。由于 Pod 一直没有权威的中文翻译，笔者在后续文章中会尽量用英文指代，偶尔需要中文的场合就使用 Borg 中 Prod 的译法，即“==生产任务==”来指代。


有了“容器组”的概念，场景二的问题便只需要将多个容器放到同一个 Pod 中即可解决。
扮演容器组的角色，满足容器共享名称空间的需求，是 Pod 的两大最基本职责之一，同处于一个 Pod 内的多个容器，相互之间以超亲密的方式协作。请注意，“超亲密”在这里并非某种带强烈感情色彩的形容词，而是有一种有具体定义的协作程度。
对于普通==非亲密==的容器，它们一般以==网络交互==方式（其他譬如共享分布式存储来交换信息也算跨网络）协作；
对==亲密==协作的容器，是指它们被==调度到同一个集群节点==上，可以通过==共享本地磁盘==等方式协作；
而==超亲密==的协作是特指多个==容器位于同一个 Pod== 这种特殊关系，它们将==默认共享==：
- UTS 名称空间：
  所有容器都有==相同的主机名和域名==。
- 网络名称空间：
  所有容器都共享==一样的网卡、网络栈、IP== 地址，等等。因此，同一个 Pod 中不同容器占用的==端口不能冲突==。
- IPC 名称空间：
  所有容器都可以通过==信号量或者 POSIX 共享内存等方式通信==。
- 时间名称空间：
  所有容器都共享==相同的系统时间==。


同一个 Pod 的容器，只有 ==PID 名称空间和文件名称空间默认是隔离的==。
PID 的隔离令每个容器都有独立的进程 ID 编号，它们封装的应用进程就是 PID 为 1 的进程，可以通过 Pod 元数据定义中的spec.shareProcessNamespace来改变这点。
一旦要求==共享 PID 名称空间==，==容器封装的应用进程就不再具有 PID 为 1 的特征==了，这有可能导致部分依赖该特征的应用出现异常。
在文件名称空间方面，容器要求文件名称空间的隔离是很理所当然的需求，因为容器需要相互独立的文件系统以避免冲突。
但容器间可以共享存储卷，这是通过 Kubernetes 的 Volume 来实现的。



Kubernetes 中 Pod 名称空间共享的实现细节

Pod 内部多个容器共享 UTS、IPC、网络等名称空间是通过一个名为 Infra Container 的容器来实现的，这个容器是整个 Pod 中第一个启动的容器，只有几百 KB 大小（代码只有很短的几十行，见这里），Pod 中的其他容器都会以 Infra Container 作为父容器，UTS、IPC、网络等名称空间实质上都是来自 Infra Container 容器。

https://github.com/kubernetes/kubernetes/tree/master/build/pause

如果容器设置为共享 PID 名称空间的话，Infra Container 中的进程将作为 PID 1 进程，其他容器的进程将以它的子进程的方式存在，此时将由 Infra Container 来负责进程管理（譬如清理僵尸进程）、感知状态和传递状态。

由于 Infra Container 的代码除了注册 SIGINT、SIGTERM、SIGCHLD 等信号的处理器外，就只是一个以 pause()方法为循环体的无限循环，永远处于 Pause 状态，所以也常被称为“Pause Container”。


Pod 的另外一个基本职责是==实现原子性调度==，如果容器编排不跨越集群节点，是否具有原子性都无关紧要。
但是在集群环境中，容器可能跨机器调度时，这个特性就变得非常重要。
如果以容器为单位来调度的话，不同容器就有可能被分配到不同机器上。两台机器之间本来就是物理隔离，依靠网络连接的，这时候谈什么名称空间共享、cgroups配额共享都失去了意义，我们由此从场景二又演化出以下场景三。


> 场景三：假设你现在有 Filebeat、Nginx 两个 Docker 镜像，在一个具有多个节点的集群环境下，要求每次调度都必须让 Filebeat 和 Nginx 容器运行于同一个节点上。

两个关联的协作任务必须一起调度的需求在容器出现之前就存在已久，譬如在传统的多线程（或多进程）并发调度 中，如果两个线程（或进程）的工作是强依赖的，单独给谁分配处理时间、而另一个被挂起都会导致程序无法工作，如此就有了协同调度 （Coscheduling）的概念，以==保证一组紧密联系的任务能够被同时分配资源==。

使用通过乐观并发（Optimistic Concurrency）、冲突回滚的方式做到高效率，也同样高度复杂的协同调度。
但是如果将运行资源的需求声明定义在 Pod 上，直接以 Pod 为最小的原子单位来实现调度的话，由于多个 Pod 之间必定不存在超亲密的协同关系，只会通过网络非亲密地协作，那就根本没有协同的说法，自然也不需要考虑复杂的调度了

==Pod 是隔离与调度的基本单位==，也是我们接触的第一种 Kubernetes 资源。Kubernetes 将==一切皆视为资源==，
==不同资源之间依靠层级关系相互组合协作==，这个思想是贯穿 Kubernetes 整个系统的==两大核心设计理念之一==，
不仅在容器、Pod、主机、集群等计算资源上是这样，在工作负载、持久存储、网络策略、身份权限等其他领域中也都有着一致的体现。

![9d4c030a8d60cdfda7ad1116bfd1a32e.png](../_resources/9d4c030a8d60cdfda7ad1116bfd1a32e.png)


由于 Pod 是 Kubernetes 中最重要的资源，又是资源模型中一种仅在逻辑上存在、没有物理对应的概念（因为对应的“进程组”也只是个逻辑概念），是其他编排系统没有的概念，所以笔者专门花费了一些篇幅去介绍它的设计意图
Node、Cluster 等都有切实的物理对应物，很容易就能形成共同的认知，笔者也就不必逐一介绍了，仅将它们的设计意图列举如下：
- 容器（Container）：
  延续了自 Docker 以来==一个容器封装一个应用进程==的理念，是镜像管理的最小单位。
- 生产任务（Pod）：
  补充了容器化后缺失的与==进程组对应==的“==容器组==”的概念，Pod 中容器共享 UTS、IPC、网络等名称空间，是==资源调度的最小单位==。
- 节点（Node）：
  对应于==集群中的单台机器==，这里的机器即可以是生产环境中的==物理机==，也可以是云计算环境中的==虚拟节点==，节点是处理器和内存等资源的资源池，是==硬件单元的最小单位==。
- 集群（Cluster）：
  对应于整个集群，Kubernetes 提倡理念是==面向集群来管理应用==。
  当你要部署应用的时候，只需要==通过声明式 API 将你的意图写成一份元数据==（Manifests），将它提交给集群即可，而无需关心它具体分配到哪个节点（尽管通过标签选择器完全可以控制它分配到哪个节点，但一般不需要这样做）、如何实现 Pod 间通信、如何保证韧性与弹性，等等，所以集群是==处理元数据的最小单位==。
- 集群联邦（Federation）：
  对应于多个集群，通过联邦可以统一管理多个 Kubernetes 集群，联邦的一种常见应用是支持跨可用区域多活、跨地域容灾的需求。




#### 韧性与弹性

在 Kubernetes 的支持下，你确实可以直接创建 Pod 将应用运行起来，但这样的应用非常脆弱，无论是软件缺陷、意外操作或者硬件故障，都可能导致在复杂协作的过程中某个容器出现异常，进而出现系统性的崩溃

本节介绍的另一个 Kubernetes 核心设计理念。下面，我们就从如何解决以下场景四的问题开始。

> 场景四：假设有一个由数十个 Node、数百个 Pod、近千个 Container 所组成的分布式系统，要避免系统因为外部流量压力、代码缺陷、软件更新、硬件升级、资源分配等各种原因而出现中断，作为管理员，你希望编排系统能为你提供何种支持？

永不出错的服务是不切实际的
只能退而求其次，让编排系统在这些服务出现问题，运行状态不正确的时候，能自动将它们调整成正确的状态

这种需求听起来也是贪心的，却已经具备足够的可行性，应对的解决办法在工业控制系统 里已经有非常成熟的应用，叫作控制回路 （Control Loop）。

以房间中空调自动调节温度为例子,控制回路的一般工作过程的：当你设置好了温度，就是告诉空调你对温度的“期望状态”（Desired State），而传感器测量出的房间实际温度是“当前状态”（Current State）。根据当前状态与期望状态的差距，控制器对空调制冷的开关进行调节控制，就能让其当前状态逐渐接近期望状态。

..tiao

故障恢复、滚动更新、自动扩缩这些特性，在云原生中时代里常被概括成服务的弹性（Elasticity）与韧性（Resilience），ReplicaSet、Deployment、Autoscaling 的用法，也属于是所有 Kubernetes 教材资料都会讲到的“基础必修课”。




### 以应用为中心的封装

Kubernetes 被誉为云原生时代的操作系统

Kubernetes 被诟病得最多的就是复杂，自诞生之日起就以陡峭的学习曲线而闻名。


举个具体例子，用 Kubernetes 部署一套Spring Cloud 版的 Fenix's Bookstore，
你需要分别部署一个到多个的配置中心、注册中心、服务网关、安全认证、用户服务、商品服务、交易服务，
对每个微服务都配置好相应的 Kubernetes 工作负载与服务访问，为每一个微服务的 Deployment、ConfigMap、StatefulSet、HPA、Service、ServiceAccount、Ingress 等资源都编写好元数据配置。
这个过程最难的地方不仅在于繁琐，还在于要写出合适的元数据描述文件，
既需要懂的开发（网关中服务调用关系、使用容器的镜像版本、运行依赖的环境变量这些参数等等，只有开发最清楚），
又需要懂运维（要部署多少个服务，配置何种扩容缩容策略、数据库的密钥文件地址等等，只有运维最清楚），
有时候还需要懂平台（需要什么的调度策略，如何管理集群资源，通常只有平台组、中间件组或者核心系统组的同学才会关心），一般企业根本找不到合适的角色来为它管理、部署和维护应用。




#### Kustomize


最初，由 Kubernetes 官方给出“如何封装应用”的解决方案是“用配置文件来配置配置文件”，这不是绕口令，你可以理解为一种针对 YAML 的模版引擎的变体。
Kubernetes 官方认为应用就是一组具有相同目标的 Kubernetes 资源的集合，如果逐一管理、部署每项资源元数据过于繁琐的话，那就提供一种便捷的方式，把应用中不变的信息与易变的信息分离开来解决管理问题，把应用所有涉及的资源自动生成一个多合一（All-in-One）的整合包来解决部署问题。

完成这项工作的工具叫作Kustomize ，它原本只是一个独立的小程序，从 Kubernetes 1.14 起，被吸纳入kubectl命令之中，成为随着 Kubernetes 提供的内置功能。Kustomize 使用Kustomization 文件 来组织与应用相关的所有资源，Kustomization 本身也是一个以 YAML 格式编写的配置文件，里面定义了构成应用的全部资源，以及资源中需根据情况被覆盖的变量值。


ustomize 的主要价值是根据环境来生成不同的部署配置。
只要建立多个 Kustomization 文件，开发人员就能以基于基准进行派生 （Base and Overlay）的方式，对不同的模式（譬如生产模式、调试模式）、不同的项目（同一个产品对不同客户的客制化）定制出不同的资源整合包。
在配置文件里，无论是开发关心的信息，还是运维关心的信息，只要是在元数据中有描述的内容，最初都是由开发人员来编写的，然后在编译期间由负责 CI/CD 的产品人员针对项目进行定制，最后在部署期间由运维人员通过 kubectl 的补丁（Patch）机制更改其中需要运维去关注的属性，譬如构造一个补丁来增加 Deployment 的副本个数，构造另外一个补丁来设置 Pod 的内存限制，等等。

```text
k8s
 ├── base
 │     ├── deployment.yaml
 │     ├── kustomization.yaml
 │     └── service.yaml
 └── overlays
       └── prod
       │     ├── load-loadbalancer-service.yaml
       │     └── kustomization.yaml
       └── debug
             └── kustomization.yaml
```


#### Helm 与 Chart

Deis 公司 开发的Helm 和它的应用格式 Chart。

Helm 一开始的目标就很明确：如果说 Kubernetes 是云原生操作系统的话，那 Helm 就要成为这个操作系统上面的应用商店与包管理工具。

Chart 用于封装 Kubernetes 应用涉及到的所有资源，通常以目录内的文件集合的形式存在。目录名称就是 Chart 的名称（没有版本信息），譬如官方仓库中 WordPress Chart 的目录结构是这样的：

```text
WordPress
 ├── templates
 │     ├── NOTES.txt
 │     ├── deployment.yaml
 │     ├── externaldb-secrets.yaml
 │     └── 版面原因省略其他资源文件
 │     └── ingress.yaml
 └── Chart.yaml
 └── requirements.yaml
 └── values.yaml
```


#### Operator 与 CRD

Operator 不应当被称作是一种工具或者系统，它应该算是一种封装、部署和管理 Kubernetes 应用的方法，尤其是针对最复杂的有状态应用去封装运维能力的解决方案

Operator 是通过 Kubernetes 1.7 开始支持的自定义资源（Custom Resource Definitions，CRD，此前曾经以 TPR，即 Third Party Resource 的形式提供过类似的能力），把应用封装为另一种更高层次的资源，再把 Kubernetes 的控制器模式从面向于内置资源，扩展到了面向所有自定义资源，以此来完成对复杂应用的管理。下

Operator 设计理念
Operator 是使用自定义资源（CR，笔者注：CR 即 Custom Resource，是 CRD 的实例）管理应用及其组件的自定义 Kubernetes 控制器。高级配置和设置由用户在 CR 中提供。Kubernetes Operator 基于嵌入在 Operator 逻辑中的最佳实践将高级指令转换为低级操作。Kubernetes Operator 监视 CR 类型并采取特定于应用的操作，确保当前状态与该资源的理想状态相符。


有状态应用（Stateful Application）与无状态应用（Stateless Application）说的是应用程序是否要自己持有其运行所需的数据，如果程序每次运行都跟首次运行一样，不会依赖之前任何操作所遗留下来的痕迹，那它就是无状态的；反之，如果程序推倒重来之后，用户能察觉到该应用已经发生变化，那它就是有状态的。


站在 Kubernetes 的角度看，是否有状态的本质差异在于有状态应用会对某些外部资源有绑定性的直接依赖，
譬如 Elasticsearch 建立实例时必须依赖特定的存储位置，重启后仍然指向同一个数据文件的实例才能被认为是相同的实例。
另外，有状态应用的多个应用实例之间往往有着特定的拓扑关系与顺序关系，譬如 Etcd 的节点间选主和投票，节点们都需要得知彼此的存在。
为了管理好那些与应用实例密切相关的状态信息，Kubernetes 从 1.9 版本开始正式发布了 StatefulSet 及对应的 StatefulSetController。与普通 ReplicaSet 中的 Pod 相比，由 StatefulSet 管理的 Pod 具备以下几项额外特性：
- Pod 会按顺序创建和按顺序销毁
- Pod 具有稳定的网络名称
- Pod 具有稳定的持久存储


当 StatefulSet 出现以后，Kubernetes 就能满足 Pod 重新创建后仍然保留上一次运行状态的需求

..tiao




#### 开放应用模型

本节介绍的最后一种应用封装的方案，是阿里云和微软在 2019 年 10 月上海 QCon 大会上联合发布的开放应用模型 （Open Application Model，OAM），它不仅是中国云计算企业参与制定乃至主导发起的国际技术规范，也是业界首个云原生应用标准定义与架构模型。


OAM 定义的应用
一个Application由一组Components构成，每个Component的运行状态由Workload描述，每个Component可以施加Traits来获取额外的运维能力，同时我们可以使用Application Scopes将Components划分到一或者多个应用边界中，便于统一做配置、限制、管理。把Components、Traits和Scopes组合在一起实例化部署，形成具体的Application Configuration，以便解决应用的多实例部署与升级。

..tiao



## 容器间网络

### Linux 网络虚拟化

#### 网络通信模型


![c398e19a03049f3f332362f78da79b55.png](../_resources/c398e19a03049f3f332362f78da79b55.png)


几乎整个网络栈（应用层以下）都位于系统内核空间之中，之所以采用这种设计，主要是从数据安全隔离的角度出发来考虑的。
由==内核去处理==网络报文的收发，无疑会有==更高的执行开销==，譬如数据在内核态和用户态之间来回拷贝的额外成本，因此会==损失一些性能==，但是能够保证应用程序无法窃听到或者去伪造另一个应用程序的通信内容。
针对特别关注收发性能的应用场景，也有==直接在用户空间中实现全套协议栈的旁路方案==，譬如开源的Netmap 以及 Intel 的DPDK ，都能做到零拷贝收发网络数据包。

图中传输模型的箭头展示的是数据流动的方向，它体现了信息从程序中发出以后，到被另一个程序接收到之前，将经历如下几个阶段：
- Socket
  应用层的程序是通过 Socket 编程接口来和内核空间的网络协议栈通信的。Linux Socket 是从 BSD Socket 发展而来的，现在 Socket 已经不局限于某个操作系统的专属功能，成为各大主流操作系统共同支持的通用网络编程接口，是网络应用程序实际上的交互基础。应用程序通过读写收、发缓冲区（Receive/Send Buffer）来与 Socket 进行交互，在 UNIX 和 Linux 系统中，出于“一切皆是文件”的设计哲学，对 Socket 操作被实现为对文件系统（socketfs）的读写访问操作，通过文件描述符（File Descriptor）来进行。
- TCP/UDP
  传输层协议族里最重要的协议无疑是传输控制协议 （Transmission Control Protocol，TCP）和用户数据报协议 （User Datagram Protocol，UDP）两种，它们也是在 Linux 内核中被直接支持的协议。此外还有流控制传输协议 （Stream Control Transmission Protocol，SCTP）、数据报拥塞控制协议 （Datagram Congestion Control Protocol，DCCP）等等。
  不同的协议处理流程大致是一样的，只是封装的报文以及头、尾部信息会有所不同，这里以 TCP 协议为例，内核发现 Socket 的发送缓冲区中有新的数据被拷贝进来后，会把数据封装为 TCP Segment 报文，常见网络协议的报文基本上都是由报文头（Header）和报文体（Body，也叫荷载“Payload”）两部分组成。系统内核将缓冲区中用户要发送出去的数据作为报文体，然后把传输层中的必要控制信息，譬如代表哪个程序发、由哪个程序收的源、目标端口号，用于保证可靠通信（重发与控制顺序）的序列号、用于校验信息是否在传输中出现损失的校验和（Check Sum）等信息封装入报文头中。
- IP
  IP：网络层协议最主要就是网际协议 （Internet Protocol，IP），其他还有因特网组管理协议 （Internet Group Management Protocol，IGMP）、大量的路由协议（EGP、NHRP、OSPF、IGRP、……）等等。
  以 IP 协议为例，它会将来自上一层（本例中的 TCP 报文）的数据包作为报文体，再次加入自己的报文头，譬如指明数据应该发到哪里的路由地址、数据包的长度、协议的版本号，等等，封装成 IP 数据包后发往下一层。
- Device
  网络设备（Device）是网络访问层中面向系统一侧的接口，这里所说的设备与物理硬件设备并不是同一个概念，Device 只是一种向操作系统端开放的==接口==，其背后既可能代表着真实的物理硬件，也可能是某段具有特定功能的程序代码，譬如即使不存在物理网卡，也依然可以存在回环设备（Loopback Device）。
  许多网络抓包工具，如tcpdump 、Wirshark 便是在此处工作的，前面介绍微服务流量控制时曾提到过的网络流量整形，通常也是在这里完成的。
  Device 主要的作用是抽象出统一的界面，让程序代码去选择或影响收发包出入口，譬如决定数据应该从哪块网卡设备发送出去；还有就是准备好网卡驱动工作所需的数据，譬如来自上一层的 IP 数据包、下一跳 （Next Hop）的 MAC 地址（这个地址是通过ARP Request 得到的）等等。
- Driver
  网卡驱动程序（Driver）是网络访问层中面向硬件一侧的接口，网卡驱动程序会通过DMA 将主存中的待发送的数据包复制到驱动内部的缓冲区之中。数据被复制的同时，也会将上层提供的 IP 数据包、下一跳 MAC 地址这些信息，加上网卡的 MAC 地址、VLAN Tag 等信息一并封装成为==以太帧== （Ethernet Frame），并自动计算校验和。对于需要确认重发的信息，如果没有收到接收者的确认（ACK）响应，那==重发==的处理也是在这里自动完成的。



#### 干预网络通信

从 Linux Kernel 2.4 版开始，内核开放了一套通用的、可供代码干预数据在协议栈中流转的过滤器框架。这套名为 Netfilter 的框架是 Linux 防火墙和网络的主要维护者 Rusty Russell 提出并主导设计的，它围绕网络层（IP 协议）的周围，埋下了五个钩子 （Hooks），每当有数据包流到==网络层==，经过这些钩子时，就会自动触发由内核模块注册在这里的回调函数，程序代码就能够通过回调来干预 Linux 的网络通信。笔者先将这五个钩子的名字与含义列出：
- PREROUTING：
  来自设备的数据包进入协议栈后立即触发此钩子。PREROUTING 钩子在进入 IP 路由之前触发，这意味着只要接收到的数据包，无论是否真的发往本机，都会触发此钩子。
  一般用于目标网络地址转换（Destination NAT，DNAT）。
- INPUT：
  报文经过 IP 路由后，如果确定是发往本机的，将会触发此钩子，
  一般用于加工发往本地进程的数据包。
- FORWARD：
  报文经过 IP 路由后，如果确定不是发往本机的，将会触发此钩子，
  一般用于处理转发到其他机器的数据包。
- OUTPUT：
  从本机程序发出的数据包，在经过 IP 路由前，将会触发此钩子，
  一般用于加工本地进程的输出数据包。
- POSTROUTING：
  从本机网卡出去的数据包，无论是本机的程序所发出的，还是由本机转发给其他机器的，都会触发此钩子，
  一般用于源网络地址转换（Source NAT，SNAT）。

![449cf89c7237b7683bfd31fb9446d84a.png](../_resources/449cf89c7237b7683bfd31fb9446d84a.png)


Netfilter 允许在同一个钩子处注册多个回调函数，因此向钩子注册回调函数时必须提供明确的优先级，以便触发时能按照优先级从高到低进行激活。
虽然现在看来 Netfilter 只是一些简单的事件回调机制而已，然而这样一套简单的设计，却成为了整座 Linux 网络大厦的核心基石，Linux 系统提供的许多网络能力，如数据包过滤、封包处理（设置标志位、修改 TTL 等）、地址伪装、网络地址转换、透明代理、访问控制、基于协议类型的连接跟踪，带宽限速，等等，都是在 Netfilter 基础之上实现的。

以 Netfilter 为基础的应用有很多，其中使用最广泛的毫无疑问要数 Xtables 系列工具，譬如iptables 、ebtables、arptables、ip6tables 等等。

以下列出了部分 iptables 预置的行为：
- DROP：直接将数据包丢弃。
- REJECT：给客户端返回 Connection Refused 或 Destination Unreachable 报文。
- QUEUE：将数据包放入用户空间的队列，供用户空间的程序处理。
- RETURN：跳出当前链，该链里后续的规则不再执行。
- ACCEPT：同意数据包通过，继续执行后续的规则。
- JUMP：跳转到其他用户自定义的链继续执行。
- REDIRECT：在本机做端口映射。
- MASQUERADE：地址伪装，自动用修改源或目标的 IP 地址来做 NAT
- LOG：在/var/log/messages 文件中记录日志信息。

iptables 内置了五张不可扩展的规则表（其中 security 表并不常用，很多资料只计算了前四张表），如下所列：
- raw 表：用于去除数据包上的连接追踪机制（Connection Tracking）。
- mangle 表：用于修改数据包的报文头信息，如服务类型（Type Of Service，ToS）、生存周期（Time to Live，TTL）以及为数据包设置 Mark 标记，典型的应用是链路的服务质量管理（Quality Of Service，QoS）。
- nat 表：用于修改数据包的源或者目的地址等信息，典型的应用是网络地址转换（Network Address Translation）。
- filter 表：用于对数据包进行过滤，控制到达某条链上的数据包是继续放行、直接丢弃或拒绝（ACCEPT、DROP、REJECT），典型的应用是防火墙。
- security 表：用于在数据包上应用SELinux，这张表并不常用。

以上五张规则表是具有优先级的：raw→mangle→nat→filter→security，也即是上面列举它们的顺序
在 iptables 中新增规则时，需要按照规则的意图指定要存入到哪张表中，如果没有指定，默认将会存入 filter 表。
此外，每张表能够使用到的链也有所不同




#### 虚拟化网络设备

。。缩略

网卡：tun/tap、veth
主流的虚拟网卡方案有tun/tap 和veth 两种

交换机：Linux Bridge
Linux Bridge 便是 Linux 系统下的虚拟化交换机

网络：VXLAN
。。这个很多很多

副本网卡：MACVLAN



#### 容器间通信

Docker 的网络方案在操作层面上是指能够直接通过`docker run --network`参数指定的网络，或者先`docker network create`创建后再被容器使用的网络。
安装 Docker 过程中会自动在宿主机上创建一个名为 docker0 的网桥，以及三种不同的 Docker 网络，分别是 bridge、host 和 none，你可以通过docker network ls命令查看到这三种网络，具体如下所示：

```text
$ docker network ls
NETWORK ID          NAME          DRIVER      SCOPE
2a25170d4064        bridge        bridge      local
a6867d58bd14        host          host        local
aeb4f8df39b1        none          null        local
```

这三种网络，对应着 Docker 提供的三种开箱即用的网络方案，它们分别为：
- 桥接模式，使用--network=bridge指定，
  这种也是未指定网络参数时的默认网络。桥接模式下，Docker 会为新容器分配独立的网络名称空间，创建好 veth pair，一端接入容器，另一端接入到 docker0 网桥上。Docker 为每个容器自动分配好 IP 地址，默认配置下地址范围是 172.17.0.0/24，docker0 的地址默认是 172.17.0.1，并且设置所有容器的网关均为 docker0，这样所有接入同一个网桥内的容器直接依靠二层网络来通信，在此范围之外的容器、主机就必须通过网关来访问，具体过程笔者在介绍 Linux Bridge 时已经举例详细讲解过。
- 主机模式，使用--network=host指定。
  主机模式下，Docker 不会为新容器创建独立的网络名称空间，这样容器一切的网络设施，如网卡、网络栈等都直接使用宿主机上的真实设施，容器也就不会拥有自己独立的 IP 地址。此模式下与外界通信无须进行 NAT 转换，没有性能损耗，但缺点也十分明显，没有隔离就无法避免网络资源的冲突，譬如端口号就不允许重复。
- 空置模式，使用--network=none指定，
  空置模式下，Docker 会给新容器创建独立的网络名称空间，但是不会创建任何虚拟的网络设备，此时容器能看到的只有一个回环设备（Loopback Device）而已。提供这种方式是为了方便用户去做自定义的网络配置，如自己增加网络设备、自己管理 IP 地址，等等。

除了三种开箱即用的网络外，Docker 还支持以下由用户自行创建的网络：
- 容器模式，创建容器后使用--network=container:容器名称指定。
  容器模式下，新创建的容器将会加入指定的容器的网络名称空间，共享一切的网络资源，但其他资源，如文件、PID 等默认仍然是隔离的。
  两个容器间可以直接使用回环地址（localhost）通信，端口号等网络资源不能有冲突。
- MACVLAN 模式：使用docker network create -d macvlan创建，
  此网络允许为容器指定一个副本网卡，容器通过副本网卡的 MAC 地址来使用宿主机上的物理设备，在追求通信性能的场合，这种网络是最好的选择。
  Docker 的 MACVLAN 只支持 Bridge 通信模式，因此在功能表现上与桥接模式相类似。
- Overlay 模式：使用docker network create -d overlay创建，
  Docker 说的 Overlay 网络实际上就是特指 VXLAN，这种网络模式主要用于 Docker Swarm 服务之间进行通信。
  然而由于 Docker Swarm 败于 Kubernetes，并未成为主流，所以这种网络模式实际很少使用。





### 容器网络与生态
http://icyfenix.cn/immutable-infrastructure/network/cni.html




#### CNM 与 CNI

如今容器网络的事实标准CNI （Container Networking Interface）与 CNM 在目标上几乎是完全重叠的，由此决定了 CNI 与 CNM 之间只能是你死我活的竞争关系，
这与容器运行时中提及的 CRI 和 OCI 的关系明显不同，CRI 与 OCI 目标并不一样，两者有足够空间可以和平共处。

CNM 规范已是明日黄花



促使 Kubernetes 拒绝 CNM 的理由也同样有来自于技术和非技术方面的。

技术方面，
Docker 的网络模型做出了许多对 Kubernetes 无效的假设：Docker 的网络有本地网络（不带任何跨节点协调能力，譬如 Bridge 模式就没有全局统一的 IP 分配）和全局网络（跨主机的容器通信，例如 Overlay 模式）的区别，本地网络对 Kubernetes 来说毫无意义，而全局网络又默认依赖 libkv 来实现全局 IP 地址管理等跨机器的协调工作。这里的 libkv 是 Docker 建立的 lib*家族中另一位成员，用来对标 Etcd、ZooKeeper 等分布式 K/V 存储，这对于已经拥有了 Etcd 的 Kubernetes 来说如同鸡肋。

非技术方面，
Kubernetes 决定放弃 CNM 的原因很大程度上还是由于他们与 Docker 在发展理念上的冲突，Kubernetes 当时已经开始推进 Docker 从必备依赖变为可选引擎的重构工作，而 Docker 则坚持 CNM 只能基于 Docker 来设计。Tim Hockin 在文章中举了一个例子：CNM 的网络驱动没有向外部暴露网络所连接容器的具体名称，只使用一个内部分配的 ID 来代替，这让外部（包括网络插件和容器编排系统）很难将网络连接的容器与自己管理的容器对应关联起来，当他们向 Docker 开发人员反馈这个问题时，问题被以“工作符合预期结果”（Working as Intended）为理由直接关闭掉，Tim Hockin 还专门列出了这些问题的详细清单，如libnetwork #139 、libnetwork #486 、libnetwork #514 、libnetwork #865 、docker #18864 ，这种设计被 Kubernetes 认为是人为地给非 Docker 的第三方容器引擎使用 CNM 设置障碍。整个沟通过程中，Docker 表现得也极为强硬，明确表示他们对偏离当前路线或委托控制的想法都不太欢迎。上面这些“非技术”的问题，即使没有 Docker 的支持，Kubernetes 自己也并非不能从“技术上”去解决，但 Docker 的理念令 Kubernetes 感到忧虑，因为 Kubernetes 在 Docker 之上扩展的很多功能，Kubernetes 却并不想这些功能永远绑定在 Docker 之上。



#### 网络插件生态

支持 CNI 的网络插件已多达数十种
跨主机通信的网络实现方式来去也就下面这三种
- Overlay 模式
  这是一种虚拟化的上层逻辑网络，
  好处在于它不受底层物理网络结构的约束，有更大的自由度，更好的易用性；
  坏处是由于额外的包头封装导致信息密度降低，额外的隧道封包解包会导致传输性能下降。
  在虚拟化环境（例如 OpenStack）中的网络限制往往较多，譬如不允许机器之间直接进行二层通信，只能通过三层转发。在这类被限制网络的环境里，基本上就只能选择 Overlay 网络插件，常见的 Overlay 网络插件有 Flannel（VXLAN 模式）、Calico（IPIP 模式）、Weave 等等。
- 路由模式
  路由模式其实属于 Underlay 模式的一种特例
  相比起 Overlay 网络，路由模式的主要区别在于它的跨主机通信是直接通过路由转发来实现的，因而无须在不同主机之间进行隧道封包。
  好处是性能相比 Overlay 网络有明显提升，
  坏处是路由转发要依赖于底层网络环境的支持，并不是你想做就能做到的。
  路由网络要求要么所有主机都位于同一个子网之内，都是二层连通的，要么不同二层子网之间由支持边界网关协议 （Border Gateway Protocol，BGP）的路由相连，并且网络插件也同样支持 BGP 协议去修改路由表。
  常见的路由网络有 Flannel（HostGateway 模式）、Calico（BGP 模式）等等。
- Underlay 模式
  这里的 Underlay 模式特指让容器和宿主机处于同一网络，两者拥有相同的地位的网络方案。
  Underlay 网络要求容器的网络接口能够直接与底层网络进行通信，因此该模式是直接依赖于虚拟化设备与底层网络能力的。
  常见的 Underlay 网络插件有 MACVLAN、SR-IOV （Single Root I/O Virtualization）等。
  对于真正的大型数据中心、大型系统，Underlay 模式才是==最有发展潜力==的网络模式。
  这种方案能够最大限度地利用硬件的能力，往往有着==最优秀的性能表现==。但也是由于它直接依赖于硬件与底层网络环境，必须根据软、硬件情况来进行部署，==难以做到== Overlay 网络那样==开箱即用==的灵活性


MACVLAN 和 SR-IOV 这样的 Underlay 网络插件的吞吐量最高、延迟最低，仅从网络性能上看它们肯定是最优秀的，相对而言 Flannel-VXLAN 这样的 Overlay 网络插件，其吞吐量只有 MACVLAN 和 SR-IOV 的 70%左右，延迟更是高了两至三倍之多。Overlay 为了易用性、灵活性所付出的代价还是不可忽视的，但是对于那些不以网络 I/O 为性能瓶颈的系统而言，这样的代价并非一定不可接受，就看你心中对通用性与性能是如何权衡取舍。



## 持久化存储

容器是镜像的运行时实例，为了保证镜像能够重复地产生出具备一致性的运行时实例，必须要求镜像本身是持久而稳定的，这决定了在容器中发生的一切数据变动操作都不能真正写入到镜像当中，否则必然会破坏镜像稳定不变的性质。

容器中的数据修改操作，大多是基于写入时复制 （Copy-on-Write）策略来实现的，容器会利用叠加式文件系统 （OverlayFS）的特性，在用户意图对镜像进行修改时，自动将变更的内容写入到独立区域，再与原有数据叠加到一起，使其外观上看来像是“覆盖”了原有内容。
这种改动通常都是临时的，一旦容器终止运行，这些存储于独立区域中的变动信息也将被一并移除，不复存在。由此可见，如果不去进行额外的处理，容器默认是不具备持久化存储能力的。



### Kubernetes 存储设计

Kubernetes 在规划持久化存储能力的时候，依然遵循着它的一贯设计哲学，用户负责以资源和声明式 API 来描述自己的意图，Kubernetes 负责根据用户意图来完成具体的操作。
不过，就算仅仅是描述清楚用户的存储意图也并不是一件容易的事，相比起 Kubernetes 提供其他能力的资源，其内置的存储资源显得格外地复杂，甚至可以说是有些烦琐的。

概念：Volume 、PersistentVolume 、PersistentVolumeClaim 、Provisioner 、StorageClass 、Volume Snapshot 、Volume Snapshot Class 、Ephemeral Volumes 、FlexVolume Driver 、Container Storage Interface 、CSI Volume Cloning 、Volume Limits 、Volume Mode 、Access Modes 、Storage Capacity

操作：Mount、Bind 、Use 、Provision 、Claim 、Reclaim 、Reserve 、Expand 、Clone 、Schedule 、Reschedule 




#### Mount 和 Volume

Mount 和 Volume 都是来源自操作系统的常用术语，
Mount 是动词，表示将某个外部存储挂载到系统中，
Volume 是名词，表示物理存储的逻辑抽象，目的是为物理存储提供有弹性的分割方式。

Docker 内建支持了三种挂载类型，分别是 
Bind（--mount type=bind）、
Volume（--mount type=volume）和 
tmpfs（--mount type=tmpfs）

其中 tmpfs 用于在内存中读写临时数据，与本节主要讨论的对象持久化存储并不相符，所以后面我们只着重关注 Bind 和 Volume 两种挂载类型。


Bind Mount 是 Docker 最早提供的（发布时就支持）挂载类型，
作用是把宿主机的某个目录（或文件）挂载到容器的指定目录（或文件）下，
譬如以下命令中参数-v表达的意思就是将外部的 HTML 文档挂到 Nginx 容器的默认网站根目录下：
`docker run -v /icyfenix/html:/usr/share/nginx/html nginx:latest`

虽然命令中-v参数是--volume的缩写，但-v最初只是用来创建 Bind Mount 而不是创建 Volume Mount 的

从 Docker 17.06 版本开始，它在 Docker Swarm 中借用了--mount参数过来，这个参数默认创建的是 Volume Mount，可以通过明确的 type 子参数来指定另外两种挂载类型。上面命令可以等价于--mount版本如下形式：
`docker run --mount type=bind,source=/icyfenix/html,destination=/usr/share/nginx/html nginx:latest`

Bind Mount 只能让容器与本地宿主机之间建立了某个目录的映射，如果想要在不同宿主机上的容器共享同一份存储，就必须先把共享存储挂载到每一台宿主机操作系统的某个目录下，然后才能逐个挂载到容器内使用


Bind Mount 的设计里，Docker 只有容器的控制权，存放容器生产数据的主机目录是完全独立的，与 Docker 没有任何关系，既不受 Docker 保护，也不受 Docker 管理。
数据很容易被其他进程访问到，甚至是被修改和删除。
如果用户想对挂载的目录进行备份、迁移等管理运维操作，也只能在 Docker 之外靠管理员人工进行，这都增加了数据安全与操作意外的风险。
因此，Docker 希望能有一种抽象的资源来代表在宿主机或网络中存储的区域，以便让 Docker 能管理这些资源，由此就很自然地联想到了操作系统里 Volume 的概念。

提出 Volume 最核心的一个目的是为了提升 Docker 对不同存储介质的支撑能力
云计算时代，网络存储渐成数据中心的主流选择，不同的网络存储有各自的协议和交互接口，而且并非所有存储系统都适合先挂载到操作系统，然后再挂载到容器的
Docker 把解决如何访问存储的功能模块称为存储驱动（Storage Driver）。通过docker info命令，你能查看到当前 Docker 所支持的存储驱动。


#### 静态存储分配
Kubernetes 将 Volume 分为持久化的 PersistentVolume 和非持久化的普通 Volume 两类。为了不与前面定义的 Volume 这个概念产生混淆，后面特指 Kubernetes 中非持久化的 Volume 时，都会带着“普通”前缀。

普通 Volume 的设计目标不是为了持久地保存数据，而是==为同一个 Pod 中多个容器提供可共享的存储资源==，因此 Volume 具有十分明确的生命周期——与挂载它的 Pod 相同的生命周期，这意味着尽管普通 Volume 不具备持久化的存储能力，但至少比 Pod 中运行的任何容器的存活期都更长，Pod 中不同的容器能共享相同的普通 Volume，当容器重新启动时，普通 Volume 中的数据也会能够得到保留。
当然，==一旦整个 Pod 被销毁，普通 Volume 也将不复存在，数据在逻辑上也会被销毁掉==，至于实质上会否会真正删除数据，就取决于存储驱动具体是如何实现 Unmount、Detach、Delete 接口的，由于本节的主题为“持久化存储”，所以无持久化能力的普通 Volume 就不再展开了。


PersistentVolume 是指能够将数据进行持久化存储的一种资源对象，它可以独立于 Pod 存在，生命周期与 Pod 无关，因此也决定了 PersistentVolume 不应该依附于任何一个宿主机节点，否则必然会对 Pod 调度产生干扰限制。


PersistentVolume 是由管理员负责提供的集群存储。
PersistentVolumeClaim 是由用户负责提供的存储请求。

PersistentVolume 是 Volume 这个抽象概念的具象化表现，通俗地说就它是已经被管理员分配好的==具体的存储==，这里的“具体”是指有明确的存储系统地址，有明确的容量、访问模式、存储位置等信息；
而 PersistentVolumeClaim 则是 ==Pod 对其所需存储能力的声明==，通俗地说就是满足这个 Pod 正常运行要满足怎样的条件，譬如要消耗多大的存储空间、要支持怎样的访问方式。
因此两者并不是谁引用谁的固定关系，而是根据实际情况动态匹配的，两者配合工作的具体过程如下。


1. 管理员准备好要使用的存储系统，它应是某种网络文件系统（NFS）或者云储存系统，一般来说应该具备跨主机共享的能力。
2. 管理员根据存储系统的实际情况，手工预先分配好若干个 PersistentVolume，并定义好每个 PersistentVolume 可以提供的具体能力。譬如以下例子所示：
```yaml
apiVersion: v1
kind: PersistentVolume
metadata:
  name: nginx-html
spec:
  capacity:
    storage: 5Gi                          # 最大容量为5GB
  accessModes:
    - ReadWriteOnce                       # 访问模式为RWO
  persistentVolumeReclaimPolicy: Retain	  # 回收策略是Retain
  nfs:                                    # 存储驱动是NFS
    path: /html
    server: 172.17.0.2
```

3. 用户根据业务系统的实际情况，创建 PersistentVolumeClaim，声明 Pod 运行所需的存储能力。譬如以下例子所示：
```yaml
kind: PersistentVolumeClaim
apiVersion: v1
metadata:
  name: nginx-html-claim
spec:
  accessModes:
    - ReadWriteOnce    # 支持RWO访问模式
  resources:
    requests:
      storage: 5Gi     # 最小容量5GB
```

4. Kubernetes 创建 Pod 的过程中，会根据系统中 PersistentVolume 与 PersistentVolumeClaim 的供需关系对两者进行撮合，
  如果系统中存在满足 PersistentVolumeClaim 声明中要求能力的 PersistentVolume 则撮合成功，将它们绑定。
  如果撮合不成功，Pod 就不会被继续创建，直至系统中出现新的或让出空闲的 PersistentVolume 资源。

5. 以上几步都顺利完成的话，意味着 Pod 的存储需求得到满足，继续 Pod 的创建过程



Kubernetes 对 PersistentVolumeClaim 与 PersistentVolume 撮合的结果是产生一对一的绑定关系，“一对一”的意思是 PersistentVolume 一旦绑定在某个 PersistentVolumeClaim 上，直到释放以前都会被这个 PersistentVolumeClaim 所独占，不能再与其他 PersistentVolumeClaim 进行绑定。
这意味着即使 PersistentVolumeClaim 申请的存储空间比 PersistentVolume 能够提供的要少，依然要求整个存储空间都为该 PersistentVolumeClaim 所用，这有可能会造成资源的浪费。

譬如，某个 PersistentVolumeClaim 要求 3GB 的存储容量，当前 Kubernetes 手上只剩下一个 5GB 的 PersistentVolume 了，此时 Kubernetes 只好将这个 PersistentVolume 与申请资源的 PersistentVolumeClaim 进行绑定，平白浪费了 2GB 空间。
假设后续有另一个 PersistentVolumeClaim 申请 2GB 的存储空间，那它也只能等待管理员分配新的 PersistentVolume，或者有其他 PersistentVolume 被回收之后才被能成功分配。


#### 动态存储分配

对于中小规模的 Kubernetes 集群，PersistentVolume 已经能够满足有状态应用的存储需求，PersistentVolume 依靠人工介入来分配空间的设计算是简单直观，却算不上是先进，一旦应用规模增大，PersistentVolume 很难被自动化的问题就会突显出来。

Kubernetes 有能力随着流量压力和硬件资源状况，自动扩缩 Pod 的数量，但是当 Kubernetes 自动扩展出一个新的 Pod 后，并没有办法让 Pod 去自动挂载一个还未被分配资源的 PersistentVolume。想解决这个问题，要么允许多个不同的 Pod 都共用相同的 PersistentVolumeClaim，这种方案确实只靠 PersistentVolume 就能解决，却损失了隔离性，难以通用；要么就要求每个 Pod 用到的 PersistentVolume 都是已经被预先建立并分配好的，这种方案靠管理员提前手工分配好大量的存储也可以实现，却损失了自动化能力。

在 2017 年 Kubernetes 发布 1.6 版本后，终于提供了今天被称为动态存储分配（Dynamic Provisioning）的解决方案，让系统管理员摆脱了人工分配的 PersistentVolume 的窘境，与之相对，人们把此前的分配方式称为静态存储分配（Static Provisioning）。

所谓的动态存储分配方案，是指在用户声明存储能力的需求时，不是期望通过 Kubernetes 撮合来获得一个管理员人工预置的 PersistentVolume，而是由特定的资源分配器（Provisioner）自动地在存储资源池或者云存储系统中分配符合用户存储需要的 PersistentVolume，然后挂载到 Pod 中使用，完成这项工作的资源被命名为 StorageClass，它的具体工作过程如下：

1. 管理员根据存储系统的实际情况，先准备好对应的 Provisioner。
  Kubernetes 官方已经提供了一系列预置的 In-Tree Provisioner ，放置在kubernetes.io的 API 组之下。其中部分 Provisioner 已经有了官方的 CSI 驱动，譬如 vSphere 的 Kubernetes 自带驱动为kubernetes.io/vsphere-volume，VMware 的官方驱动为csi.vsphere.vmware.com。
2. 管理员不再是手工去分配 PersistentVolume，而是根据存储去配置 StorageClass。
  Pod 是可以动态扩缩的，而存储则是相对固定的，哪怕使用的是具有扩展能力的云存储，也会将它们视为存储容量、IOPS 等参数可变的固定存储来看待，譬如你可以将来自不同云存储提供商、不同性能、支持不同访问模式的存储配置为各种类型的 StorageClass，这也是它名字中“Class”（类型）的由来，譬如以下例子所示：
```yaml
apiVersion: storage.k8s.io/v1
kind: StorageClass
metadata:
  name: standard
provisioner: kubernetes.io/aws-ebs  #AWS EBS的Provisioner
parameters:
  type: gp2
reclaimPolicy: Retain
```
3. 用户依然通过 PersistentVolumeClaim 来声明所需的存储，但是应在声明中明确指出该由哪个 StorageClass 来代替 Kubernetes 处理该 PersistentVolumeClaim 的请求，譬如以下例子所示：
```yaml
apiVersion: v1
kind: PersistentVolumeClaim
metadata:
  name: standard-claim
spec:
  accessModes:
  - ReadWriteOnce
  storageClassName: standard  #明确指出该由哪个StorageClass来处理该PersistentVolumeClaim的请求
  resource:
    requests:
      storage: 5Gi
```
4. 如果 PersistentVolumeClaim 中要求的 StorageClass 及它用到的 Provisioner 均是可用的话，那这个 StorageClass 就会接管掉原本由 Kubernetes 撮合 PersistentVolume 与 PersistentVolumeClaim 的操作，按照 PersistentVolumeClaim 中声明的存储需求，自动产生出满足该需求的 PersistentVolume 描述信息，并发送给 Provisioner 处理。
5. Provisioner 接收到 StorageClass 发来的创建 PersistentVolume 请求后，会操作其背后存储系统去分配空间，如果分配成功，就生成并返回符合要求的 PersistentVolume 给 Pod 使用。
6. 以上几步都顺利完成的话，意味着 Pod 的存储需求得到满足，继续 Pod 的创建过程


Dynamic Provisioning 与 Static Provisioning 并==不是==各有用途的互补设计，而是对同一个问题先后出现的两种解决方案。
你完全可以只用 Dynamic Provisioning 来实现所有的 Static Provisioning 能够实现的存储需求，包括那些不需要动态分配的场景，甚至之前例子里使用 HostPath 在本地静态分配存储，都可以指定no-provisioner作为 Provisioner 的 StorageClass，以 Local Persistent Volume 来代替，譬如以下例子所示：

```yaml
apiVersion: storage.k8s.io/v1
kind: StorageClass
metadata:
  name: local-storage
provisioner: kubernetes.io/no-provisioner
volumeBindingMode: WaitForFirstConsumer
```

使用 Dynamic Provisioning 来分配存储无疑是更合理的设计，不仅省去了管理员的人工操作的中间层，也不再需要将 PersistentVolume 这样的概念暴露给最终用户

由 Dynamic Provisioning 来分配存储还能获得更高的可管理性，譬如前面提到的回收策略，当希望 PersistentVolume 跟随 Pod 一同被销毁时，以前经常会配置回收策略为 Recycle 来回收空间，即让系统自动执行rm -rf /volume/*命令，这种方式往往过于粗暴，遇到更精细的管理需求，譬如“删除到回收站”或者“敏感信息粉碎式彻底删除”这样的功能实现起来就很麻烦。而 Dynamic Provisioning 中由于有 Provisioner 的存在，如何创建、如何回收都是由 Provisioner 的代码所管理的，这就带来了更高的灵活性。现在 Kubernetes 官方已经明确建议废弃掉 Recycle 策略，如有这类需求就应改由 Dynamic Provisioning 去实现了。

Static Provisioning 的主要使用场景已局限于管理员能够手工管理存储的小型集群，它符合很多小型系统，尤其是私有化部署系统的现状，但并不符合当今运维自动化所提倡的思路。Static Provisioning 的存在，某种意义上也可以视为是对历史的一种兼容，在可见的将来，Kubernetes 肯定仍会把 Static Provisioning 作为用户分配存储的一种主要方案供用户选用。



### 容器存储与生态

#### Kubernetes 存储架构

正式开始讲解 Kubernetes 的 In-Tree、Out-of-Tree 存储插件前，
我们有必要先去了解一点 Kubernetes 存储架构的知识，大体上弄清一个
真实的存储系统是如何接入到新创建的 Pod 中，成为可以读写访问的 Volume 的；
以及当 Pod 被销毁时，Volume 如何被回收，回归到存储系统之中的。

Kubernetes 参考了传统操作系统接入或移除新存储设备做法，把接入或移除外部存储这件事情分解为以下三种操作：
- 首先，决定应`准备（Provision）`何种存储，Provision 可类比为给操作系统扩容而购买了新的存储设备。这步确定了接入存储的来源、容量、性能以及其他技术参数，它的逆操作是`移除（Delete）`存储。
- 然后，将准备好的存储`附加（Attach）`到系统中，Attach 可类比为将存储设备接入操作系统，此时尽管设备还不能使用，但你已经可以用操作系统的fdisk -l命令查看到设备。这步确定了存储的设备名称、驱动方式等面向系统一侧的信息，它的逆操作是`分离（Detach）`存储设备。
- 最后，将附加好的存储`挂载（Mount）`到系统中，Mount 可类比为将设备挂载到系统的指定位置，也就是操作系统中mount命令的作用。这步确定了存储的访问目录、文件系统格式等面向应用一侧的信息，它的逆操作是`卸载（Unmount）`存储设备。

以上提到的 Provision、Delete、Attach、Detach、Mount、Unmount 六种操作，并不是直接由 Kubernetes 来实现，实际行为均是在存储插件中完成的，它们会分别被 Kubernetes 通过两个控制器及一个管理器来进行调用，这些控制器、管理器的作用分别是：
PV 控制器（PersistentVolume Controller）
AD 控制器（Attach/Detach Controller）
Volume 管理器（Volume Manager）


#### FlexVolume 与 CSI
FlexVolume 是 Kubernetes 很早期版本（1.2 版开始提供，1.8 版达到 GA 状态）就开始支持的扩展机制，它是只针对 Kubernetes 的私有的存储扩展，目前已经处于冻结状态，可以正常使用但不再发展新功能了

CSI 则是从 Kubernetes 1.9 开始加入（1.13 版本达到 GA 状态）的扩展机制，如同之前介绍过的 CRI 和 CNI 那样，CSI 是公开的技术规范，任何容器运行时、容器编排引擎只要愿意支持，都可以使用 CSI 规范去扩展自己的存储能力，这是目前 Kubernetes 重点发展的扩展机制。


CSI 规范可以分为需要容器系统去实现的组件，以及需要存储提供商去实现的组件两大部分。
前者包括了存储整体架构、Volume 的生命周期模型、驱动注册、Volume 创建、挂载、扩容、快照、度量等内容，这些 Kubernetes 都已经完整地实现了，大体上包括以下几个组件：

- Driver Register：负责注册第三方插件，CSI 0.3 版本之后已经处于 Deprecated 状态，将会被Node Driver Register所取代。
- External Provisioner：调用第三方插件的接口来完成数据卷的创建与删除功能。
- External Attacher：调用第三方插件的接口来完成数据卷的挂载和操作。
- External Resizer：调用第三方插件的接口来完成数据卷的扩容操作。
- External Snapshotter：调用第三方插件的接口来完成快照的创建和删除。
- External Health Monitor：调用第三方插件的接口来提供度量监控数据。

需要存储提供商去实现的组件才是 CSI 的主体部分，即前文中多次提到的“第三方插件”。这部分着重定义了外部存储挂载到容器过程中所涉及操作的抽象接口和具体的通讯方式，主要包括以下三个 gRPC 接口：
- CSI Identity 接口：
  用于描述插件的基本信息，譬如插件版本号、插件所支持的 CSI 规范版本、插件是否支持存储卷创建、删除功能、是否支持存储卷挂载功能，等等。此外 Identity 接口还用于检查插件的健康状态，开发者可以通过实现 Probe 接口对外提供存储的健康度量信息。
- CSI Controller 接口：
  用于从存储系统的角度对存储资源进行管理，譬如准备和移除存储（Provision、Delete 操作）、附加与分离存储（Attach、Detach 操作）、对存储进行快照，等等。存储插件并不一定要实现这个接口的所有方法，对于存储本身就不支持的功能，可以在 CSI Identity 接口中声明为不提供。
- CSI Node 接口：
  用于从集群节点的角度对存储资源进行操作，譬如存储卷的分区和格式化、将存储卷挂载到指定目录上、或者将存储卷从指定目录上卸载，等等。



#### 从 In-Tree 到 Out-of-Tree

当 Kubernetes 成为市场主流以后——准确的时间点是从 1.14 版本开始，Kubernetes 启动了 In-Tree 存储驱动的 CSI 外置迁移工作，
按照计划，在 1.21 到 1.22 版本（大约在 2021 年中期）时，Kubernetes 中主要的存储驱动，如 AWS EBS、GCE PD、vSphere 等都会迁移至符合 CSI 规范的 Out-of-Tree 实现，不再提供 In-Tree 的支持

这又面临了此前提过的该如何兼容旧功能的策略问题，譬如下面 YAML 定义了一个 Pod：

```yaml
apiVersion: v1
kind: Pod
metadata:
  name: nginx-pod-example
spec:
  containers:
  - name: nginx
    image: nginx:latest
    volumeMounts:
    - name: html-pages-volume
      mountPath: /usr/share/nginx/html
    - name: config-volume
      mountPath: /etc/nginx
    volumes:
    - name: html-pages-volume
      hostPath:                 # 来自本地的存储
        path: /srv/nginx/html
        type: Directory
    - name: config-volume
      awsElasticBlockStore:     # 来自AWS ESB的存储
        volumeID: vol-0b39e0b08745caef4
        fsType: ext4
```

其中用到了类型为 hostPath 的 Volume，这相当于 Docker 中驱动类型为 local 的 Volume，不需要专门的驱动；而类型为 awsElasticBlockStore 的 Volume，从名字上就能看出是指存储驱动为 AWS EBS 的 Volume，当 CSI 迁移完成，awsElasticBlockStore 从 In-Tree 卷驱动中移除掉之后，它就应该按照 CSI 的写法改写成如下形式：
```yaml
    - name: config-volume
      csi:
        driver: ebs.csi.aws.com
        volumeAttributes:
          - volumeID: vol-0b39e0b08745caef4
          - fsType: ext4
```
这样的要求有悖于升级版本不应影响还在大范围使用的已有功能这条原则，所以 Kubernetes 1.17 中又提出了称为CSIMigration 的解决方案，让 Out-of-Tree 的驱动能够自动伪装成 In-Tree 的接口来提供服务。


#### 容器插件生态

目前出现过的存储系统和设备均可以划分到==块存储、文件存储和对象存储==这三种存储类型之中，划分的根本依据其实并非各种存储是如何储存数据的——那完全是存储系统私有的事情，更合理的划分依据是各种存储提供何种形式的接口供外部访问数据，不同的外部访问接口将反过来影响到存储的内部结构、性能与功能表现。
虽然块存储、文件存储和对象存储可以彼此协同工作，但它们各自都有自己明确的擅长领域与优缺点，理解它们的工作原理，因地制宜地选择最适合的存储才能让系统达到最佳的工作状态。笔者按照它们出现的时间顺序分别介绍如下：

- 块存储：
  块存储是数据存储的最古老形式，数据都储存在固定长度的一个或多个块 （Block）中
  我们熟悉的硬盘就是最经典的块存储设备，以机械硬盘为例，一个块就是一个扇区，大小通常在 512 Bytes 至 4096 Bytes 之间。
  老式机械硬盘用柱面-磁头-扇区号 （Cylinder-Head-Sector，CHS）组成的编号进行寻址，现代机械硬盘只用一个逻辑块编号 （Logical Block Addressing，LBA）进行寻址。
  为了便于管理，硬盘通常会以多个块（这些块甚至可以来自不同的物理设备，譬如磁盘阵列的情况）来组成一个逻辑分区（Partition），将分区进行高级格式化 之后就形成了卷（Volume）
  块存储由于贴近底层硬件，没有文件、目录、访问权限等的牵绊，所以性能通常都是==最优秀==的，==吞吐量高，延迟低==。
  尽管人类作为信息系统的最终用户，并不会直接面对块来操作数据，多数应用程序也是==基于文件==而不是块来读写数据的，但是==操作系统内核==中许多地方就直接通过==块设备== （Block Device）接口来访问硬盘，一些追求 I/O 性能的软件，譬如==高性能的数据库==也会支持==直接读写块设备以提升磁盘 I/O==。
  块存储的特点是具有==排它性==，一旦块设备被某个客户端挂载后，其它客户端就无法再访问上面的数据了，因此，Kubernetes 中挂载的块存储大多访问模式都要求必须是 RWO（ReadWriteOnce）的。

- 文件存储：
  文件存储是最贴近人类用户的数据存储形式，数据存储在长度不固定的文件之中，用户可以针对文件进行新增、写入、追加、移动、复制、删除、重命名等各种操作，通常文件存储还会提供有文件查找、目录管理、权限控制等额外的高级功能。
  文件存储的访问不像块存储那样有五花八门的协议，POSIX 接口（Portable Operating System Interface，POSIX）已经成为了事实标准，被各种商用的存储系统和操作系统共同支持。具体 POSIX 的文件操作接口笔者就不去举例罗列了，你不妨类比 Linux 下的各种文件管理命令来自行想象一下。
  绝大多数传统的文件存储都是基于块存储之上去实现的
  对于可能发生变动的场景，就必须考虑如何跨多个不连续的块来构成为文件。
  这种需求在数据结构角度看只需在每个块中记录好下一个块的地址，形成链表结构即可满足。
  但是链表的缺点是只能依次顺序访问，这样访问文件中任何内容都要从头读取多个块，显然过于低效了。真正被广泛运用的解决方案是把形成链表的指针整合起来统一存放，这便形成了文件分配表 （File Allocation Table，FAT）的概念。
  人们把定义文件分配表应该如何实现、储存哪些信息、提供什么功能的标准称为文件系统 （File System），FAT32、NTFS、exFAT、ext2/3/4、XFS、BTRFS 等都是很常用的文件系统。
  计算机需要把路径进行分解，然后逐级向下查找，最后才能查找到需要的文件，要从文件分配表中确定具体数据存储的位置，要判断文件的访问权限，要记录每次修改文件的用户与时间，这些额外操作对于性能产生负面影响也是无可避免的，因此，如果一个系统选择不采用文件存储的话，那磁盘 I/O 性能一般就是最主要的决定因素。

- 对象储存：
  对象存储 是相对较新的数据存储形式，是一种随着云数据中心的兴起而发展起来的存储，是以非结构化数据为目标的存储方案。
  这里的“对象”可以理解为==一个元数据及与其配对的一个逻辑数据块的组合==，元数据提供了对象所包含的上下文信息，譬如数据的类型、大小、权限、创建人、创建时间，等等，数据块则存储了对象的具体内容。
  你也可以简单地理解为数据和元数据这两样东西共同构成了一个对象。==每个对象都有属于自己的全局唯一标识，这个标识会直接开放给最终用户使用==，作为访问该对象的主要凭据，通常会是 UUID 的形式。
  对象存储的访问接口就是根据该唯一标识，对逻辑数据块进行的读写删除操作，通常接口都会十分简单，甚至连修改操作都不会提供。
  对象存储基本上==只会在分布式存储系统之上去实现==，由于对象存储天生就有明确的“元数据”概念，不必依靠文件系统来提供数据的描述信息，因此，完全可以将一大批对象的元数据集中存放在某一台（组）服务器上，再辅以多台 OSD（Object Storage Device）服务器来存储对象的数据块部分。当外部要访问对象时，多台 OSD 能够同时对外发送数据，因此对象存储不仅易于共享、容量庞大，还能提供非常高的吞吐量。不过，由于需要先经过元数据查询确定 OSD 存放对象的确切位置，该过程可能涉及多次网络传输，延迟方面就会表现得相对较差。
  由于对象的元数据仅描述对象本身的信息，与其他对象都没有关联，换而言之每个对象都是==相互独立==的，==自然也就不存在目录的概念==，可见对象存储天然就是扁平化的，与软件系统中很常见的 K/V 访问相类似，不过许多对象存储==会提供 Bucket 的概念==，用户可以在逻辑上把它看作是“单层的目录”来使用。
  由于对象存储天生的分布式特性，以及极其低廉的扩展成本，使它很适合于CDN一类的应用，拿来存放图片、音视频等媒体内容，以及网页、脚本等静态资源。


关于选择服务提供商的问题，笔者不作建议，你根据价格、合作关系、技术和品牌知名度等因素自行去处理。关于应该选择三种存储类型中哪一种的问题，笔者这里以世界云计算市场占有率第一的亚马逊为例，简要对比介绍它不同存储类型产品的差异：

- 亚马逊的块存储服务是Amazon Elastic Block Store （AWS EBS）
  你购买 EBS 之后，在 EC2（亚马逊的云计算主机）里看见的是一块原始的、未格式化的块设备。这点就决定了 EBS 并不能做为一个独立存储而存在，它总是和 EC2 同时被创建的，EC2 的操作系统也只能安装在 EBS 之上。
  EBS 适合作为系统引导卷，适合追求磁盘 I/O 的大型工作负载以及追求低时延的应用，譬如 Oracle 等可以直接访问块设备的大型数据库更是尤其合适。但 EBS 只允许被单个节点挂载，难以共享，这点在单机时代是天经地义的，但在云计算和分布式时代就成为了很要命的缺陷。除了少数特殊的工作负载外（如前面说的 Oracle 数据库），笔者并不建议将它作为容器编排系统的主要外置存储来使用。

- 亚马逊的文件存储服务是Amazon Elastic File System （AWS EFS）
  你购买 EFS 之后，只要在 EFS 控制台上创建好文件系统，并且管理好网络信息（如 IP 地址、子网）就可以直接使用，无需依附于任何 EC2 云主机。EFS 本质是完全托管在云端的网络文件系统 （Network File System，NFS），可以在任何兼容 POSIX 的操作系统中直接挂载它，而不会在/dev中看到新设备存在。按照本节开头 Kubernetes 存储架构中的操作来说就是你只需要考虑 Mount，无需考虑 Attach 了。
  得益于 NFS 的天然特性，EFS 的扩缩可以是完全自动、实时的，创建新文件时无需预置存储，删除已有文件时也不必手动缩容以节省费用。在高性能网络的支持下，EFS 的性能已经能够达到相当高的水平，尽管由于网络访问的限制，性能最高的 EFS 依然比不过最高水平的 EBS，但仍然能充分满足绝大多数应用运行的需要。还有最重要的一点优势是由于脱离了块设备的束缚，EFS 能够轻易地被成百上千个 EC2 实例共享，考虑到 EFS 的性能、动态弹性、可共享这些因素，笔者给出的明确建议是它可以作为==大部分容器工作负载的首选存储==。

- 亚马逊的对象存储服务是Amazon Simple Storage Service （AWS S3）
  S3 通常是以 REST Endpoint 的形式对外部提供文件访问服务的，这种方式下你应该直接==使用程序代码来访问 S3==，而不是靠操作系统或者容器编排系统去挂载它。如果你真的希望这样做，也可以通过存储网关（如AWS Storage Gateway ）将 S3 的存储能力转换为 NFS、SMB、iSCSI 等访问协议，经过转换后，操作系统或者容器就能够将其作为 Volume 来挂载了。
  S3 也许是 AWS 最出名、使用面最广的存储服务，这个结果不是由于它的性能优异，事实上 S3 的性能比起 EBS 和 EFS 来说是相对最差的，但它的优势在于它名字中“Simple”所标榜的简单，我们挂载外部存储的目的十有八九就是为了给程序提供存储服务，使用 S3 不必写一行代码就能够直接通过 HTTP Endpoint 进行读写访问，且完全不需要考虑容量、维护和数据丢失的风险，这就是简单的价值。
  S3 的另一大优势就是它的价格相对于 EBS 和 EFS 来说往往要低一至两个数量级，因此程序的备份还原、数据归档、灾难恢复、静态页面的托管、多媒体分发等功能就非常适合使用 S3 来完成。



## 资源与调度

调度是容器编排系统最核心的功能之一，“编排”一词本身便包含有“调度”的含义。调度是指为新创建出来的 Pod 寻找到一个最恰当的宿主机节点来运行它，这个过程成功与否、结果恰当与否，关键取决于容器编排系统是如何管理与分配集群节点的资源的。
可以认为调度是必须以容器编排系统的资源管控为前提，那我们就首先从 Kubernetes 的资源模型谈起。


### 资源模型
开篇先来理清一个概念：资源是什么。
资源在 Kubernetes 中是极为常用的术语，广义上讲，Kubernetes 系统中所有你能够接触的方方面面都被抽象成了资源，
譬如
表示工作负荷的资源（Pod、ReplicaSet、Service、……），
表示存储的资源（Volume、PersistentVolume、Secret、……），
表示策略的资源（SecurityContext、ResourceQuota、LimitRange、……），
表示身份的资源（ServiceAccount、Role、ClusterRole、……），等等。

“一切皆为资源”的设计是 Kubernetes 能够顺利==施行声明式 API 的必要前提==，Kubernetes 以资源为载体，建立了一套同时囊括了抽象元素（如策略、依赖、权限）和物理元素（如软件、硬件、网络）的领域特定语言 。
通过不同层级间资源的使用关系来描述上至整个集群甚至是集群联邦，下至某一块内存区域或者一小部分的处理器核心的状态，这些对资源状态的描述的集合，共同构成了一幅信息系统工作运行的全景图。

从编排系统的角度来看，Node 是资源的提供者，Pod 是资源的使用者，调度是将两者进行恰当的撮合。
Node 通常能够提供的三方面的资源：计算资源（如处理器、图形处理器、内存）、存储资源（如磁盘容量、不同类型的介质）和网络资源（如带宽、网络地址），
其中与调度关系最密切的是处理器和内存，虽然它们同属于计算资源，但两者在调度时又有一些微妙的差别：处理器这样的资源被称作可压缩资源（Compressible Resources），特点是当可压缩资源不足时，Pod 只会处于“饥饿状态”，运行变慢，但不会被系统杀死，即容器被直接终止，或被要求限时退出。
而像内存这样的资源，则被称作不可压缩资源（Incompressible Resources），特点是当不可压缩资源不足，或者超过了容器自己声明的最大限度时，Pod 就会因为内存溢出（Out-Of-Memory，OOM）而被系统直接杀掉。

Kubernetes 给处理器资源设定的默认计量单位是“逻辑处理器的个数”。至于具体“一个逻辑处理器”应该如何理解，就要取决于节点的宿主机是如何解释的，通常会是/proc/cpuinfo中看到的处理器数量。它有可能会是多路处理器系统上的一个处理器、多核处理器中的一个核心、云计算主机上的一个虚拟化处理器 （Virtual CPU，vCPU），或者处理器核心里的一条超线程 （Hyper-Threading）。

在具体设置方面，Kubernetes 沿用了云计算中处理器限额设置的一贯做法。如果不明确标注单位，譬如直接写 0.5，默认单位就是Core，即 0.5 个处理器；也可以明确使用Millcores为单位，譬如写成 500 m 同样代表 0.5 个处理器，因为 Kubernetes 规定了1 Core = 1000 Millcores。而对于内存来说，它早已经有了广泛使用的计量单位，即 Bytes，如果设置中不明确标注单位就会默认以 Bytes 计数。为了实际设置的方便，Kubernetes 还支持Ei、Pi、Ti、Gi、Mi、Ki，以及E、P、T、G、M、K为单位，这两者略微有一点点差别，以Mi和M为例，它们分别是Mebibytes与Megabytes的缩写，前者表示 ==1024×1024== Bytes，后者表示 ==1000×1000== Bytes。


### 服务质量与优先级

设定资源计量单位的目的是为了管理员能够==限制某个 Pod 对资源的过度占用，避免影响到其他 Pod 的正常运行==。
Pod 是由一到多个容器所组成，资源最终是交由 Pod 的各个容器去使用，所以==资源的需求是设定在容器上==的，具体的配置是 Pod 的spec.containers[].resource.limits/requests.cpu/memory字段。
但是对资源需求的==配额则不是针对容器==的，而是==针对 Pod== 整体，Pod 的资源配额无需手动设置，它就是它包含的每个容器资源需求的累加值。

为容器设定最大的资源配额的做法从 cgroups 诞生后已经屡见不鲜，但你是否注意到 Kubernetes 给出的配置中有limits和requests两个设置项？这两者的区别其实很简单：
requests是给调度器用的，Kubernetes 选择哪个节点运行 Pod，只会根据requests的值来进行决策；
limits才是给 cgroups 用的，Kubernetes 在向 cgroups 的传递资源配额时，会按照limits的值来进行设置。

一条经验法则：用户提交工作负载时设置的资源配额，并不是容器调度一定必须严格遵守的值，因为根据实际经验，大多数的工作负载运行过程中真正使用到的资源，其实都远小于它所请求的资源配额。

不大可能仅仅是因为 Kubernetes 将一个资源配额的设置，拆分成limits和requests两个设置项就能解决这个矛盾的，Kubernetes 为此还进行了许多额外的处理。
一旦选择不按照最保守、最安全的方式去分配资源，就意味着容器编排系统必须为有可能出现的极端情况而买单，如果允许节点给 Pod 分配资源总和超过自己最大的可提供资源的话，假如某个时刻这些 Pod 的总消耗真的超标了，便会不可避免地导致节点无法继续遵守调度时对 Pod 许下的资源承诺，此时，Kubernetes 迫不得已要==杀掉一部分 Pod== 腾出资源来保证其余 Pod 能正常运行，这个操作就是稍后会介绍的驱逐机制（Eviction）。
要进行驱逐，首先 Kubernetes 就必须拿出==资源不足时该先牺牲哪些 Pod、该保留哪些 Pod== 的明确准则，由此就形成了 Kubernetes 的==服务质量等级==（Quality of Service Level，QoS Level）和==优先级==（Priority）的概念。
试想 Kubernetes 若不是为了理性对抗人类“多多益善”的心理，尽可能提高硬件利用效率，而是直接按申请的最大资源去安排调度，那原本它是无需理会这些麻烦事的。

质量等级是 Pod 的一个隐含属性，也是 Kubernetes 优先保障重要的服务，放弃一些没那么重要的服务的衡量准绳。
不知道你是否想到这样一个细节：如果==不去设置limits和requests==会怎样？答案是不设置处理器和内存的资源，就意味着==没有上限==，该 Pod 可以使用节点上所有可用的计算资源。
但你先别高兴得太早，这类 Pod 能以最灵活的方式去使用资源，但也正是这类 Pod 扮演着最不稳定的风险来源的角色。在论文《Large-Scale Cluster Management at Google with Borg 》中，Google 明确地提出了针对这类 Pod 的一种近乎带惩罚性质的处理建议：当节点硬件资源不足时，==优先杀掉这类 Pod==，说得文雅一点的话，就是给予这类 Pod 最低的服务质量等级。

ubernetes 目前提供的服务质量等级一共分为三级，
由高到低分别为 Guaranteed、Burstable 和 BestEffort。
如果 Pod 中所有的容器==都设置了limits和requests，且两者的值相等==，那此 Pod 的服务质量等级便为==最高==的 Guaranteed；
如果 Pod 中有部分容器的 ==requests 值小于limits值==，或者==只设置了requests而未设置limits==，那此 Pod 的服务质量等级为==第二级== Burstable；
如果是刚才说的那种情况，limits和requests==两个都没设置就是最低的== BestEffort 了。

通常建议将数据库应用等==有状态的应用==，或者一些==重要的要保证不能中断的业务==的服务质量等级定为 ==Guaranteed==，这样除非 Pod 使用超过了它们的limits所描述的不可压缩资源，或者节点的内存压力大到 Kubernetes 已经杀光所有等级更低的 Pod 了，否则它们都不会被系统自动杀死。

相对地，应将一些临时的、不那么重要的任务设置为 ==BestEffort==，这样有利于它们调度时能在更大的节点范围中寻找宿主机，也利于它们在宿主机中利用更多的资源快速地完成任务，然后退出，尽量缩减影响范围；当然，遇到系统资源紧张时，它们也更容易被系统杀掉。


除了==服务质量等级以外==，Kubernetes 还允许系统管理员自行决定 Pod 的==优先级==，这是通过类型为 PriorityClass 的资源来实现的。
优先级决定了 Pod 之间并不是平等的关系，而且这种不平等还不是谁会占用更多一点的资源的问题，而是会直接影响 Pod 调度与生存的关键。

优先级会影响调度这很容易理解，它是指当多个 Pod 同时被调度的话，高优先级的 Pod 会优先被调度。
Pod 越晚被调度，就越大概率因节点资源已被占用而不能成功。
但优先级影响更大的另一方面是指 Kubernetes 的抢占机制（Preemption），
正常未设置优先级的情况下，如果 Pod 调度失败，就会暂时处于 Pending 状态被搁置起来，直到集群中有新节点加入或者旧 Pod 退出。
但是，如果有一个被设置了明确优先级的 Pod 调度失败无法创建的话，Kubernetes 就会在系统中寻找出一批牺牲者（Victims），将它们杀掉以便给更高优先级的 Pod 让出资源。
寻找的原则是根据在优先级低于待调度 Pod 的所有已调度 Pod 里，按照优先级从低到高排序，从最低的杀起，直至腾出的资源足以满足待调度 Pod 的成功调度为止，或者已经找不到更低优先级的 Pod 为止。



### 驱逐机制

前面笔者动不动就提要杀掉某个 Pod，听起来实在是欠优雅的，在 Kubernetes 中专业的称呼是“驱逐”（Eviction，即资源回收）。
Pod 的驱逐机制是通过 kubelet 来执行的，kubelet 是部署在每个节点的集群管理程序，由于本身就运行在节点中，所以最容易感知到节点的资源实时耗用情况。
kubelet 一旦发现某种不可压缩资源将要耗尽，就会主动终止节点上较低服务质量等级的 Pod，以保证其他更重要的 Pod 的安全。
被驱逐的 Pod 中所有的容器都会被终止，Pod 的状态会被更改为 Failed。

我们已经接触过内存这一种最重要的不可压缩资源，
默认配置下，前面所说的“资源即将耗尽”的“即将”，具体阈值是可用内存小于 100 Mi。
除了可用内存（memory.available）外，其他不可压缩资源还包括有：宿主机的可用磁盘空间（nodefs.available）、文件系统可用inode数量（nodefs.inodesFree），以及可用的容器运行时镜像存储空间（imagefs.available）。
后面三个的阈值都是按照实际容量的百分比来计算的，具体的默认值如下：

```text
memory.available < 100Mi
nodefs.available < 10%
nodefs.inodesFree < 5%
imagefs.available < 15%
```

管理员可以在 kubelet 启动时，通过命令行参数来修改这些默认值，譬如可用内存只剩余 100 Mi 时才启动驱逐对于多数生产系统来说都过于危险了，笔者建议在生产环境中考虑通过以下命令调整为剩余 10%内存时即开始驱逐：
`$ kubelet --eviction-hard=memory.available<10%`


驱逐机制中就有了软驱逐（Soft Eviction）、硬驱逐（Hard Eviction）以及优雅退出期（Grace Period）的概念：

- 软驱逐：
  通常配置一个较低的警戒线（譬如可用内存仅剩 20%），触及此线时，系统将进入一段观察期。如果只是暂时的资源抖动，在观察期内能够恢复到正常水平的话，那就不会真正启动驱逐操作。否则，资源持续超过警戒线一段时间，就会触发 Pod 的优雅退出（Grace Shutdown），系统会通知 Pod 进行必要的清理工作（譬如将缓存的数据落盘），然后自行结束。在优雅退出期结束后，系统会强制杀掉还未曾自行了断的 Pod。

- 硬驱逐：
  通常配置一个较高的终止线（譬如可用内存仅剩 10%），一旦触及此红线，立即强制杀掉 Pod，不理会优雅退出。

软驱逐是为了减少资源抖动对服务的影响，硬驱逐是为了保障核心系统的稳定，它们并不矛盾，一般会同时使用，譬如以下例子所示：

```shell
$ kubelet --eviction-hard=memory.available<10% \
		  --eviction-soft=memory.available<20% \
		  --eviction-soft-grace-period=memory.available=1m30s \
		  --eviction-max-pod-grace-period=600
```
Kubernetes 提供了--eviction-minimum-reclaim参数用于设置一旦驱逐发生之后，至少清理出来多少资源才会终止。

Kubernetes 中很少会单独创建 Pod，通常都是由 ReplicaSet、Deployment 等更高层资源来管理的，这意味着当 Pod 被驱逐之后，它不会从此彻底消失，Kubernetes 将自动生成一个新的 Pod 来取代，并经过调度选择一个节点继续运行。
如果没有额外的处理，那很大概率这个 Pod 会被系统调度到当前这个节点上重新创建，因为上一次调度就选择了这个节点
Kubernetes 还提供了另一个参数--eviction-pressure-transition-period来约束调度器，在驱逐发生之后多长时间内不得往该节点调度 Pod。


### 默认调度器

本节的最后一部分，我们回过头来探讨开篇提出的问题：Kubernetes 是如何撮合 Pod 与 Node 的，这其实也是最困难的一个问题。
调度是为新创建出来的 Pod 寻找到一个最恰当的宿主机节点去运行它，这句话里就包含有“运行”和“恰当”两个调度中关键过程，它们具体是指：

- 运行：从集群所有节点中找出一批剩余资源可以满足该 Pod 运行的节点。为此，Kubernetes 调度器设计了一组名为 Predicate 的筛选算法。
- 恰当：从符合运行要求的节点中找出一个最适合的节点完成调度。为此，Kubernetes 调度器设计了一组名为 Priority 的评价算法。


提出了一种共享状态（Shared State）的双循环调度机制。这种调度机制后来不仅应用在 Google 的 Omega 系统（Borg 的下一代集群管理系统）中，也同样被 Kubernetes 继承了下来，它整体的工作流程如图 14-1 所示：

![be47a084471afaa3ede473c3e83b2c81.png](../_resources/be47a084471afaa3ede473c3e83b2c81.png)


状态共享的双循环中第一个控制循环可被称为“Informer Loop”，它是一系列Informer的集合，这些 Informer 持续监视 Etcd 中与调度相关资源（主要是 Pod 和 Node）的变化情况，一旦 Pod、Node 等资源出现变动，就会触发对应 Informer 的 Handler。
Informer Loop 的职责是根据 Etcd 中的资源变化去更新调度队列（Priority Queue）和调度缓存（Scheduler Cache）中的信息，譬如当有新 Pod 生成，就将其入队（Enqueue）到调度队列中，如有必要，还会根据优先级触发上一节提到的插队和抢占操作。又譬如有新的节点加入集群，或者已有节点资源信息发生变动，Informer 也会将这些信息更新同步到调度缓存之中。

另一个控制循环可被称为“Scheduler Loop”，它的核心逻辑是不停地将调度队列中的 Pod 出队（Pop），然后使用 Predicate 算法进行节点选择。
Predicate 本质上是一组节点过滤器（Filter），它根据预设的过滤策略来筛选节点，Kubernetes 中默认有三种过滤策略，分别是：
- 通用过滤策略：
  最基础的调度过滤策略，用来检查节点是否能满足 Pod 声明中需要的资源。譬如处理器、内存资源是否满足，主机端口与声明的 NodePort 是否存在冲突，Pod 的选择器或者nodeAffinity指定的节点是否与目标相匹配，等等。
- 卷过滤策略：
  与存储相关的过滤策略，用来检查节点挂载的 Volume 是否存在冲突（譬如将一个块设备挂载到两个节点上），或者 Volume 的可用区域是否与目标节点冲突，等等。在“Kubernetes 存储设计”中提到的 Local PersistentVolume 的调度检查，便是在这里处理的。
- 节点过滤策略：
  与宿主机相关的过滤策略，最典型的是 Kubernetes 的污点与容忍度机制（Taints and Tolerations），譬如默认情况下 Kubernetes 会设置 Master 节点不允许被调度，这就是通过在 Master 中施加污点来避免的。之前提到的控制节点处于驱逐状态，或者在驱逐后一段时间不允许调度，也是在这个策略里实现的。


Predicate 算法所使用的一切数据均来自于调度缓存，绝对不会去远程访问节点本身。只有 Informer Loop 与 Etcd 的监视操作才会涉及到远程调用，Scheduler Loop 中除了最后的异步绑定要发起一次远程的 Etcd 写入外，其余全部都是进程内访问，这一点是调度器执行效率的重要保证。

调度缓存就是两个控制循环的共享状态（Shared State），这样的设计避免了每次调度时主动去轮询所有集群节点，保证了调度器的执行效率。
但是并不能完全避免因节点信息同步不及时而导致调度过程中实际资源发生变化的情况，譬如节点的某个端口在获取调度信息后、发生实际调度前被意外占用了。
为此，当调度结果出来以后，kubelet 真正创建 Pod 以前，还必须执行一次 Admit 操作，在该节点上重新做一遍 Predicate 来进行二次确认。

经过 Predicate 算法筛选出来符合要求的节点集，会交给 Priorities 算法来打分（0-10 分）排序，以便挑选出“最恰当”的一个。
“恰当”是带有主观色彩的词语，Kubernetes 也提供了不同的打分规则来满足不同的主观需求，譬如最常用的 LeastRequestedPriority 规则，它的计算公式是：
`score = (cpu((capacity-sum(requested))×10/capacity) + memory((capacity-sum(requested))×10/capacity))/2`

从公式上很容易看出这就是在选择处理器和内存空闲资源最多的节点，因为这些资源剩余越多，得分就越高。经常与它一起工作的是 BalancedResourceAllocation 规则，它的公式是：
`score = 10 - variance(cpuFraction,memoryFraction,volumeFraction)×10`

此公式中 cpuFraction、memoryFraction、volumeFraction 的含义分别是 Pod 请求的处理器、内存和存储资源占该节点上对应可用资源的比例，variance 函数的作用是计算资源之间的差距，差距越大，函数值越大。
由此可知 BalancedResourceAllocation 规则的意图是希望调度完成后，所有节点里各种资源分配尽量均衡，避免节点上出现诸如处理器资源被大量分配、而内存大量剩余的尴尬状况。
Kubernetes 内置的其他的评分规则还有 ImageLocalityPriority、NodeAffinityPriority、TaintTolerationPriority 等等

经过 Predicate 的筛选、Priorities 的评分之后，调度器已经选出了调度的最终目标节点，最后一步是通知目标节点的 kubelet 可以去创建 Pod 了。
调度器并不会直接与 kubelet 通讯来创建 Pod，它只需要把待调度的 Pod 的nodeName字段更新为目标节点的名字即可，kubelet 本身会监视该值的变化来接手后续工作。

最后，请注意笔者在这一个部分的小标题用的是“默认调度器”，这是强调以上行为仅是 Kubernetes 默认的行为。
对调度过程的大部分行为，你都可以通过 Scheduler Framework 暴露的接口来进行扩展和自定义，如下图所示，绿色的部分就是 Scheduler Framework 暴露的扩展点。
由于 Scheduler Framework 属于 Kubernetes 内部的扩展机制（通过 Golang 的 Plugin 机制来实现的，需静态编译），通用性与本章提到的其他扩展机制（CRI、CNI、CSI 那些）无法相提并论，属于较为高级的 Kubernetes 管理技能了，这里笔者仅在这里简单地提一下，就不多做介绍了。




## 服务网格 Service Mesh
服务网格是一种用于管控服务间通信的的基础设施，职责是为现代云原生应用支持网络请求在复杂的拓扑环境中可靠地传递。
在实践中，服务网格通常会以轻量化网络代理的形式来体现，这些代理与应用程序代码会部署在一起，对应用程序来说，它完全不会感知到代理的存在。

服务网格并不是什么神秘难以理解的黑科技，它只是一种==处理程序间通信的基础设施==，典型的存在形式是==部署在应用旁边，一对一为应用提供服务的边车代理，及管理这些边车代理的控制程序==。
“==边车== ”（Sidecar）本来就是一种常见的容器设计模式 ，用来形容==外挂在容器身上的辅助程序==。
早在容器盛行以前，边车代理就已有了成功的应用案例，譬如 2014 年开始的Netflix Prana 项目 ，由于 Netflix OSS 套件是用 Java 语言开发的，为了让非 JVM 语言的微服务，譬如以 Python、Node.js 编写的程序也同样能接入 Netflix OSS 生态，享受到 Eureka、Ribbon、Hystrix 等框架的支持，Netflix 建立了 Prana 项目，它的作用是为每个服务都提供一个专门的 HTTP Endpoint，使得非 JVM 语言的程序能通过访问该 Endpoint 来获取系统中所有服务的实例、相关路由节点、系统配置参数等在 Netflix 组件中管理的信息。

Netflix Prana 的代理需要由应用程序主动去访问才能发挥作用，但在容器的刻意支持下，服务网格无需应用程序的任何配合，就能强制性地对应用通信进行管理。
它使用了类似网络攻击里==中间人流量劫持==的手段，完全透明（既无需程序主动访问，也不会被程序感知到）地接管掉容器与外界的通信，将管理的粒度从容器级别细化到了每个单独的远程服务级别，使得基础设施干涉应用程序、介入程序行为的能力大为增强。
如此一来，云原生希望用基础设施接管应用程序非功能性需求的目标就能更进一步，从容器粒度延伸到远程访问，分布式系统继容器和容器编排之后，又发掘到另一块更广袤的舞台空间。



### 透明通信的涅槃

服务网格的诞生在某种意义上可以说便是当年透明通信的重生，服务网格试图以容器、虚拟化网络、边车代理等技术所构筑的新一代通信基础设施为武器，重新对已盖棺定论三十多年的程序间远程通信不是透明的原则发起冲击。
今天，这场关于通信的变革仍然在酝酿发展当中，最后到底会是成功的逆袭，抑或是另一场失败，笔者不敢妄言定论，但是作为程序通信发展历史的一名见证者，笔者丝毫不吝对服务网格投去最高的期许与最深的祝愿。


#### 通信的成本

通过以下五个阶段的变化，理解分布式服务的通信是如何逐步演化成本章主角服务网格。

- 第一阶段：将通信的非功能性需求视作业务需求的一部分，通信的可靠性由程序员来保障。
- 第二阶段：将代码中的通信功能抽离重构成公共组件库，通信的可靠性由专业的平台程序员来保障。
- 第三阶段：将负责通信的公共组件库分离到进程之外，程序间通过网络代理来交互，通信的可靠性由专门的网络代理提供商来保障。
- 第四阶段：将网络代理以边车的形式注入到应用容器，自动劫持应用的网络流量，通信的可靠性由专门的通信基础设施来保障
- 第五阶段：将边车代理统一管控起来实现安全、可控、可观测的通信，将数据平面与控制平面分离开来，实现通用、透明的通信，这项工作就由专门的服务网格框架来保障。


#### 数据平面

数据平面由一系列边车代理所构成，核心职责是转发应用的入站（Inbound）和出站（Outbound）数据包，因此数据平面也有个别名叫转发平面（Forwarding Plane）。
同时，为了在不可靠的物理网络中保证程序间通信最大的可靠性，数据平面必须根据控制平面下发策略的指导，在应用无感知的情况下自动完成服务路由、健康检查、负载均衡、认证鉴权、产生监控数据等一系列工作。
为了达成上述的工作目标，至少需要妥善解决以下三个关键问题：
- 代理注入：边车代理是如何注入到应用程序中的？
- 流量劫持：边车代理是如何劫持应用程序的通信流量的？
- 可靠通信：边车代理是如何保证应用程序的通信可靠性的？


现在的服务网格产品存在有以下三种方式将边车代理接入到应用程序中：

- 基座模式（Chassis）：
  这种方式接入的边车代理对程序就是不透明的，它至少会包括一个轻量级的 SDK，通信由 SDK 中的接口去处理。
  基座模式的好处是在程序代码的帮助下，有可能达到更好的性能，功能也相对更容易实现，
  但坏处是对代码有侵入性，对编程语言有依赖性
  采用基座模式的接入目前并不属于主流方式

- 注入模式（Injector）：根据注入方式不同，又可以分为： 
  - 手动注入模式
  - 自动注入模式


#### 流量劫持
边车代理做流量劫持最典型的方式是基于 ==iptables 进行的数据转发==

以 Istio 为例，它在注入边车代理后，除了生成封装 Envoy 的 istio-proxy 容器外，还会生成一个 initContainer，它的作用就是自动修改容器的 iptables
```yaml
initContainers:
  image: docker.io/istio/proxyv2:1.5.1
  name: istio-init
- command:
  - istio-iptables -p "15001" -z "15006"-u "1337" -m REDIRECT -i '*' -x "" -b '*' -d 15090,15020
```

`iptables -t nat -L -v` 命令可以查看到如下所示配置信息

用 iptables 进行流量劫持是最经典、最通用的手段，不过，iptables 重定向流量必须通过回环设备 （Loopback）交换数据，流量不得不多穿越一次协议栈

如何实现更优化的数据平面流量劫持，是服务网格发展的前沿研究课题之一，
其中一种可行的优化方案是使用==eBPF== （Extended Berkeley Packet Filter）技术，在 ==Socket 层面直接完成数据转发==，而不需要再往下经过更底层的 TCP/IP 协议栈的处理，从而减少数据在通信链路的路径长度。
另一种可以考虑的方案是让服务网格与 CNI 插件配合来实现流量劫持，譬如 Istio 就有提供自己实现的 CNI 插件 。只要安装了这个 CNI 插件，整个虚拟化网络都由 Istio 自己来控制，那自然就无需再依赖 iptables，也不必存在 initContainers 配置和 istio-init 容器了。


#### 可靠通信

Envoy 在这方面进行了创新，它将代理的转发的行为规则抽象成 Listener、Router、Cluster 三种资源，以此为基础，又定义了应该如何发现和访问这些资源的一系列 API，现在这些资源和 API 被统称为“xDS 协议族”。
自此以后，数据平面就有了如何描述各种配置和策略的事实标准，控制平面也有了与数据平面交互的标准接口。目前 xDS v3.0 协议族已经包含有以下具体协议：

|简称 |	全称 	|服务描述|
|--|--|--|
|LDS 	|Listener Discovery Service |	监听器发现服务|
|RDS 	|Route Discovery Service |	路由发现服务|
|CDS 	|Cluster Discovery Service |	集群发现服务|
|EDS 	|Endpoint Discovery Service 	|集群成员发现服务|
|ADS 	|Aggregated Discovery Service |	聚合发现服务|
|HDS 	|Health Discovery Service |	健康度发现服务|
|SDS 	|Secret Discovery Service |	密钥发现服务|
|MS 	|  Metric Service 	|度量指标服务|
|RLS 	|Rate Limit Service |	速率限制服务|
|ALS 	|gRPC Access Log Service |	gRPC 访问日志服务|
|LRS 	|Load Reporting service 	|负载报告服务|
|RTDS |	Runtime Discovery Service 	|运行时发现服务|
|CSDS |	Client Status Discovery Service |	客户端状态发现服务|
|ECDS |	Extension Config Discovery Service 	|扩展配置发现服务|


Listener、Router、Cluster 三种资源的具体含义：
- Listener：
  Listener 可以简单理解为 Envoy 的一个监听端口，用于接收来自下游应用程序（Downstream）的数据。Envoy 能够同时支持多个 Listener，不同的 Listener 之间的策略配置是相互隔离的。
  自动发现 Listener 的服务被称为 LDS（Listener Discovery Service），它是所有其他 xDS 协议的基础，如果没有 LDS（也没有在 Envoy 启动时静态配置 Listener 的话），其他所有 xDS 服务也就失去了意义，因为没有监听端口的 Envoy 不能为任何应用提供服务。

- Cluster：
  Cluster 是 Envoy 能够连接到的一组逻辑上提供相同服务的上游（Upstream）主机。Cluster 包含该服务的连接池、超时时间、Endpoints 地址、端口、类型等信息。具体到 Kubernetes 环境下，可以认为 Cluster 与 Service 是对等的概念，Cluster 实际上承担了服务发现的职责。
  自动发现 Cluster 的服务被称为 CDS（Cluster Discovery Service），通常情况下，控制平面会将它从外部环境中获取的所有可访问服务全量推送给 Envoy。与 CDS 紧密相关的另一种服务是 EDS（Endpoint Discovery Service）。当 Cluster 的类型被标识为需要 EDS 时，则说明该 Cluster 的所有 Endpoints 地址应该由 xDS 服务下发，而不是依靠 DNS 服务去解析。

- Router：
  Listener 负责接收来自下游的数据，Cluster 负责将数据转发送给上游的服务，而 Router 则决定 Listener 在接收到下游的数据之后，具体应该将数据交给哪一个 Cluster 处理，由此定义可知，Router 实际上是承担了服务网关的职责。
  自动发现 Router 的服务被称为 RDS（Router Discovery Service），Router 中最核心信息是目标 Cluster 及其匹配规则，即实现网关的路由职能。此外，视 Envoy 中的插件配置情况，也可能包含重试、分流、限流等动作，实现网关的过滤器职能。


#### 控制平面

Istio 自身也是采用微服务架构开发的，将控制平面的职责分解为 Mixer、Pilot、Galley、Citadel 四个模块去实现，其中 
Mixer 负责鉴权策略与遥测；
Pilot 负责对接 Envoy 的数据平面，遵循 xDS 协议进行策略分发；
Galley 负责配置管理，为服务网格提供外部配置感知能力；
Citadel 负责安全加密，提供服务和用户层面的认证和鉴权、管理凭据和 RBAC 等安全相关能力。

不过，经过两、三年的实践应用，很多用户都有反馈 Istio 的微服务架构有过度设计的嫌疑，lstio 在定义项目目标时，曾非常理想化的提出控制平面的各个组件都应可以独立部署，然而在实际应用场景里却并非如此，独立的组件反而带来了部署复杂、职责划分不清晰等问题。

从 1.5 版本起，Istio 重新回归单体架构，将 Pilot、Galley、Citadel 的功能全部集成到新的 Istiod 之中。当然，这也并不是说完全推翻之前的设计，只是将原有的多进程形态优化成单进程的形态，之前各个独立组件变成了 Istiod 的内部逻辑上的子模块而已。
单体化之后出现的新进程 Istiod 就承担所有的控制平面职责，具体包括有：
- 数据平面交互
  - 边车注入
  - 策略分发
  - 配置分发
- 流量控制
  - 请求路由
  - 流量治理
  - 调试能力
- 通信安全
  - 生成 CA 证书
  - SDS 服务代理
  - 认证
  - 授权
- 可观测性
  - 日志收集
  - 链路追踪
  - 指标度量


### 服务网格与生态


#### 服务网格接口

2019 年 5 月的 KubeCon 大会上，微软联合 Linkerd、HashiCorp、Solo、Kinvolk 和 Weaveworks 等一批云原生服务商共同宣布了 Service Mesh Interface 规范，希望能在各家的服务网格产品之上建立一个抽象的 API 层，然后通过这个抽象来解耦和屏蔽底层服务网格实现，让上层的应用、工具、生态系统可以建立在同一个业界标准之上，从而实现应用程序在不同服务网格产品之间的无缝移植与互通。

SMI 与 Kubernetes 是彻底绑定的

在过去两年里，Istio 无论是发展策略上还是设计上（过度设计）的风评并不算好，业界一直在期待 Google 和 Istio 能做出改进，这种期待在持续两年的失望之后，已经有很多用户在考虑 Istio 以外的选择了。
SMI 一发布就吸引了除了 Istio 之外几乎所有的服务网格玩家参与进来了，恐怕并不仅仅是因为微软号召力巨大的缘故。
为了对抗 Istio 的抵制，SMI 自己还提供了一个Istio 的适配器 ，以便使用 Istio 的程序能平滑地迁移的 SMI 之上，所以遗留代码并不能为 Istio 构建出特别坚固的壁垒。

2020 年 4 月，SMI 被托管到 CNCF，成为其中的一个 Sandbox 项目（Sandbox 是最低级别的项目，CNCF 只提供有限度的背书），如果能够经过孵化、毕业阶段的话，SMI 就有望成为公认的行业标准，这也是开源技术社区里民主管理的一点好处。

。。现在，2023-10-6，还是一个 sandbox。


#### 通用数据平面 API



#### 服务网格生态





# 技术方法论

## 向微服务迈进

IBM 大型机之父Fred Brooks 在他的两本著作《没有银弹：软件工程的本质性与附属性工作 》和《人月神话：软件项目管理之道 》里都反复强调着一个观点：“==软件研发中任何一项技术、方法、架构都不可能是银弹==”，这个结论已经被软件工程里无数事实所验证，现在对于微服务也依然成立。



### 目的：微服务的驱动力
微服务的目的是有效的拆分应用，实现敏捷开发和部署。

硬件的成本能够持续稳定地下降，而软件开发的成本则不可能。

软件系统选择微服务架构，通常比较常见的、合理的驱动力来自组织外部、内部两方面，笔者先列举一些外部因素：
- 当意识到没有什么技术能够包打天下
  没有最好的语言，没有最好的框架
- 当个人能力因素成为系统发展的明显制约
- 当遇到来自外部商业层面对内部技术层面提出的要求

在系统和研发团队内部，也会有一些因素促使其向微服务靠拢：
- 变化发展特别快的创新业务系统往往会自主地向微服务架构靠近。
- 大规模的、业务复杂的、历史包袱沉重的系统也可能主动向微服务架构靠近。



### 前提：微服务需要的条件
康威定律：系统的架构趋同于组织的沟通结构。

微服务化的第一个前提条件是决策者与执行者都能意识到康威定律在软件设计中的关键作用。

康威定律尝试使用社会学的方法去解释软件研发中的问题，其核心观点是“沟通决定设计”（Communication Dictates Design），如果技术层面紧密联系在一起的特性，在组织层面上强行分离开来，那结果会是沟通成本的上升，因为会产生大量的跨组织的沟通；如果技术层面本身没什么联系的特性，在组织层面上强行安放在一块，那结果会是管理成本的上升，因为成员越多越不利于一致决策的形成。这些社会学、管理学的规律决定了假如产品和组织能够经受住市场竞争，长期发展的话，最终都会自发地调整成组织与产品互相匹配的状态。哪些特性在团队内部沟通，哪些特性需要跨团队的协作，将最终都会在产品中分别映射成与组织结构一致的应用内、外部的调用与依赖关系。

微服务化的第二个前提条件是组织中具备一些对微服务有充分理解、有一定实践经验的技术专家。

微服务化的第三个前提条件是系统应具有以自治为目标的自动化与监控度量能力。

微服务化的第四个前提条件是复杂性已经成为制约生产力的主要矛盾。


演进式设计
长期来看，多数服务的结局都是报废而非演进。




### 边界：微服务的粒度
勿行极端，过犹不及

当今软件业界，对本节的话题“识别微服务的边界”其实已取得了较为一致的观点，也找到了指导具体实践的方法论，即领域驱动设计 （Domain-Driven Design，DDD）。


我们可以得出第一个结论：微服务粒度的下界是它至少应满足独立——能够独立发布、独立部署、独立运行与独立测试，内聚——强相关的功能与数据在同一个服务中处理，完备——一个服务包含至少一项业务实体与对应的完整操作。

我们得出了第二个结论：微服务粒度的上界是一个 2 Pizza Team 能够在一个研发周期内完成的全部需求范围。


### 治理：理解系统复杂性
治理就是让产品能够符合预期地稳定运行，并能够持续保持在一定的质量水平上。



# 随笔

## Graal VM


# 部署环境

http://icyfenix.cn/appendix/deployment-env-setup/

Docker CE
kubernetes
Istio
Elastic Stack
Prometheus



2023-10-06 15:45













