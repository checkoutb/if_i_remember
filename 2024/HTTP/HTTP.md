HTTP
2022年3月8日
14:22


[[toc]]

=====================


# cookie,session,local

cookie, sessionStorage, localStorage (  后2个合称  Web Storage)

cookie  始终在同源的http请求中携带(  即使不需要)，即cookie  在浏览器和服务器间来回传递。
而sessionStorage，localStorage  不会自动把消息发送给服务器，仅在本地保存。

cookie不能超过4k，且由于每次http请求  都会携带  cookie，所以  cookie只适合  保存很小的数据。
sessionStorage，localStorage  也有  存储大小限制，但比  cookie  大很多，可以达到5MB  或更大。

sessionStorage，仅在当前浏览器窗口  关闭前有效，自然也就不能持久保持
localStorage，窗口或浏览器  关闭  也一直保存，因此用作  持久数据
cookie，在设置的cookie过期前一直有效，即使窗口或浏览器  关闭

sessionStorage  不在  不同的浏览器窗口中  共享，即使是用一个页面。
localStorage，所有  同源  窗口中  都是共享的
cookie  也是所有同源窗口中都是  共享的。

cookie  的作用是与服务器交互，作为http规范的一部分而存在。
web  storage  仅仅是为了在  本地  存储数据而生。

web  storage  支持  事件通知机制，可以将数据更新的通知发送给  监听者。

=====================

=====================

HTTP协议说到底是应用层的协议，而TCP才是真正的传输层协议，只有负责传输的这一层才需要建立连接。

=====================

=====================

# 长连接

轮询：客户端定时向服务器发送Ajax请求，服务器接到请求后马上返回响应信息并关闭连接。
　　优点：后端程序编写比较容易。
　　缺点：请求中有大半是无用，浪费带宽和服务器资源。（而每一次的 HTTP 请求和应答都带有完整的 HTTP 头信息，这就增加了每次传输的数据量）
　　实例：适于小型应用。

长轮询：客户端向服务器发送Ajax请求，服务器接到请求后hold住连接，直到有新消息才返回响应信息并关闭连接（或到了设定的超时时间关闭连接），客户端处理完响应信息后再向服务器发送新的请求。
　　优点：在无消息的情况下不会频繁的请求，节省了网络流量，解决了服务端一直疲于接受请求的窘境
　　缺点：服务器hold连接会消耗资源，需要同时维护多个线程，服务器所能承载的TCP连接数是有上限的，这种轮询很容易把连接数顶满。
　　实例：WebQQ、Hi网页版、Facebook IM。

长连接：在页面里嵌入一个隐蔵iframe，将这个隐蔵iframe的src属性设为对一个长连接的请求，服务器端就能源源不断地往客户端输入数据。
　　优点：消息即时到达，不发无用请求。
　　缺点：服务器维护一个长连接会增加开销。
　　实例：Gmail聊天

Flash Socket：在页面中内嵌入一个使用了Socket类的 Flash 程序JavaScript通过调用此Flash程序提供的Socket接口与服务器端的Socket接口进行通信，JavaScript在收到服务器端传送的信息后控制页面的显示。
　　优点：实现真正的即时通信，而不是伪即时。
　　缺点：客户端必须安装Flash插件；非HTTP协议，无法自动穿越防火墙。
　　实例：网络互动游戏。

WebSocket：
　　WebSocket 协议本质上是一个基于 TCP 的协议。为了建立一个 WebSocket 连接，客户端浏览器首先要向服务器发起一个 HTTP 请求，这个请求和通常的 HTTP 请求不同，包含了一些附加头信息，其中附加头信息”Upgrade: WebSocket”表 明这是一个申请协议升级的 HTTP 请求，服务器端解析这些附加的头信息然后产生应答信息返回给客户端，客户端和服务器端的 WebSocket 连接就建立起来了，双方就可以通过这个连接通道自由的传递信息，并且这个连接会持续存在直到客户端或者服务器端的某一方主动的关闭连接。

=====================

=====================

# http 1.0 vs 1.1 vs 2.0

HTTP 1.0  一次连接只处理一个请求
HTTP 1.1  一次连接可以处理多个请求

## 1.0 和 1.1 的区别

1.1支持长连接  和请求的流水线处理，在一个TCP连接上  可以传送  多个  HTTP请求和响应，减少了建立和关闭连接的消耗和延迟，
1.1中默认开启长连接keep-alive，
1.0需要使用keep-alive参数来告知服务器建立长连接

1.0存在浪费带宽的现象，例如，客户端只需要  某个对象的  一部分，但是服务器将  整个对象送过来，并且  不支持  断点续传功能。

1.1支持  只发送  header信息  (不带任何body  信息)，如果服务器认为客户端有权限请求服务器，则返回100，  客户端收到  100  才开始把  请求body  发送到  服务器，  如果返回401，客户端就可以不用发送  请求body，节约了带宽。

1.0中认为每台服务器都绑定一个  唯一的IP地址，因此，请求中的  URL并没有传递  主机名(hostname)，  1.0  没有host域。随着虚拟主机技术的发展，在一台物理服务器上  可以存在多个  虚拟主机(Multi-homed Web Servers)，并且它们共享一个IP地址。

1.1  请求消息  和  响应消息  都支持  host域，且  请求消息中如果没有  host域  则会  报告一个  错误(400  bad request)

1.0主要使用  header中的  If-Modified-Since，Expires  来作为  缓存判断的标准。

1.1  引入了更多的  缓存控制策略，如  Entity tag, If-Unmodified-Since，  If-Match, If-None-Match  等  可供选择的header来控制缓存策略。

1.1  新增24个错误状态响应码，如果409  表示请求的资源  和资源的当前状态  发生冲突，410  表示  服务器上的某个资源  被永久性删除。

## HTTP 1.1 和 2.0 的区别

2.0使用了  多路复用的技术，做到同一个连接并发处理  多个请求，而且  并发请求的数量比  1.1  大了好几个数量级。
HTTP 1.1  也可以  多建立  几个TCP连接，来处理  更多并发的请求，但是  创建TCP  连接本身也是有开销的。

1.1中，HTTP的请求和响应  都是由  状态行，请求/响应头部，消息主体  3部分组成。一般而言，消息主体都会  经过  gzip  压缩，或者  本身传输的就是  压缩后的  二进制文件，但是  状态行  和  头部  不会压缩，直接纯文本传输。  随着web功能越来越复杂，每个页面产生的  请求数也越来越多，导致消耗在头部的  流量越来越多，尤其是每次传输  UserAgent，Cookie  这类不会  频繁变动的内容。

1.1  不支持  header数据的  压缩，  2.0开始  使用  HPACK  算法  对header  数据进行压缩。

服务器推送是一种在客户端  请求之前  发送数据的  机制，网页使用了  许多资源：HTML，样式表，脚本，图片等。

在1.1  中，这些资源  每一个都必须明确地  请求。这是一个  很慢的过程。  浏览器  从  获取  HTML开始，然后在它解析  和评估页面的时候，增量地获取更多的资源。因为  服务器必须等待  浏览器  做每一个请求，网络经常是空闲的  和  未充分使用的。

2.0引入  server push，它允许  服务器推送资源给  浏览器，在  浏览器  明确地请求之前，  来避免客户端  再次创建连接  发送请求  到服务器端  获取。这样  客户端可以直接从  本地加载这些资源，不用再通过网络

---------------------


# http 1.0, 1.1, 2.0, 3.0

## HTTP 1.0 特点

1.0  是一种  无状态，无连接的  应用层协议。  规定  浏览器和服务器保持短暂的链接。

浏览器的每次请求都要与服务器  建立一个  TCP连接，服务器处理完后  立即断开TCP连接(无连接)，服务器不跟踪每个客户端，不记录过去的请求(无状态)
这种无状态可以借助  cookie / session  来做身份认证和  状态记录

1.0问题
无法复用连接，每次发送请求，都需要一次  TCP  连接，而TCP  连接的  释放过程又是比较费事的。这种  无连接的特性使得  网络的利用率  变低。

队头阻塞，由于  1.0  规定  下一个请求  必须在  前一个  请求响应到达  之后才能发送，假设  前一个请求响应一直不到达，那么下一个请求  就无法发送，导致阻塞。

不支持断点续传，即，每次都会传送全部的页面和数据。

## HTTP 1.1 特点

长连接，1.1增加了  Connection  字段，对于  同一个  host，  通过  设置  keep-alive  保持  HTTP连接不断。避免每次  客户端与服务器  请求  都要重复  建立释放TCP连接。  提高网络的利用率。

如果客户端想要关闭  http连接，可以在  请求头中携带  Connection:false (。。应该是close)  来告知服务器关闭请求。

支持断点续传，通过使用  请求头中的  Range  来实现

可以使用管道传输，多个请求可以同时发送，但是服务器还是  按照  顺序，先回应A请求，再回应B请求。如果前面的回应特别慢，后面会有  许多请求排队等待。造成  队头阻塞

## HTTP 2.0 特点

二进制分帧，  2.0  通过在  应用层和  传输层之间  增加一个  二进制分层帧，突破  1.1  的性能限制，改进传输性能

多路复用(链路共享)  ，真并行传输
流，已建立连接上的  双向字节流
消息，与逻辑消息对应的  完整的  一系列数据帧
帧，2.0通信的  最小单位，每个帧包含头部，至少也会标识出  当前所属的流。

所有2.0通信  都在一个TCP链接上完成，这个连接可以承载  任意流量的  双向数据流。

每个数据流  以消息的形式发送，而消息  由一个  或多个帧  组成。这些帧可以乱序发送，然后再根据  每个帧  头部的  流标识符  (Stream_id)  重新封装。

多路复用(连接共享)  可能会导致  关键帧被阻塞，2.0中每个数据流  都可以设置  优先级  和  依赖，优先级高的  数据流  会被  服务器  优先处理  和返回客户端，数据流  还可以  依赖  其他的子数据流。

可见，2.0  是真正的  并行传输，它能够在  一个  TCP  上进行  任意数量的  http  请求。而这个  强大的  功能  基于  "二进制分帧"  的特性

头部压缩
1.x中，头部元数据  以  纯文本的方式  发送，通常会给  每个请求增加  500 - 8000  字节的负荷。比如  cookie，默认情况下，浏览器会在每次请求的时候，把cookie  附在  header  上  发给  服务器。

2.0  使用  encoder  来减少  需要传输的  header  大小，通讯双方  各自  cache  一份  header_files  表，避免了  重复header的传输，减少了  需要传输的大小。

高效的  压缩算法可以很大的压缩  header，  减少发送  包的数量  从而降低延迟。

服务器推送
服务器除了  请求的响应外，还可以  向客户端推送资源，而无需客户端明确的需求。

## HTTP 3.0

基于google  的  QUIC，  http3背后的主要思想是  放弃  TCP，转而使用  基于  UDP  的  QUIC  协议。

与http2在技术上  允许  未加密的通信不同，QUIC  要求  严格加密后  才能建立连接。此外，加密不仅适用于  http  负载，还适用于  流经连接  的所有数据，从而避免了  一大堆安全问题。  建立持久连接，协商加密协议，甚至  发送第一批数据  都被  合并到  QUIC  的单个  请求/响应  周期中，从而大大减少了  连接等待的时间。如果  客户端具有  本地缓存的  密码参数，则可以通过简化的握手  (0-RTT)  重新建立与  已知主机的连接。

为了解决传输级别的队头阻塞问题，通过  QUIC  连接传输的数据  被分为一些流。  流是持久性  QUIC  连接中  短暂  独立  的  "子连接"。每个流都处理自己的错误纠正  和  传递保证，但使用连接  全局压缩  和  加密属性。  每个客户端发起的  HTTP  请求  都在  单独的流上运行，因此  丢失数据包  不会  影响其他  流/请求  的  数据传输。

。。。QUIC（Quick UDP Internet Connection）是谷歌制定的一种基于UDP的低时延的互联网传输层协议。在2016年11月国际互联网工程任务组(IETF)召开了第一次QUIC工作组会议，受到了业界的广泛关注。这也意味着QUIC开始了它的标准化过程，成为新一代传输层协议。

## 总结
1.0
无状态，无连接
短连接，每次发送请求都要重新建立  tcp  请求，即  3次握手，非常浪费性能
无host  头
不允许断点续传，而且不能只传输  对象的  一部分，要求传输  整个对象。

1.1
长连接，流水线，使用  Connection:keep-alive  使用长连接
请求管道化
增加缓存处理
增加  Host头，支持断点传输
由于长连接，会给服务器造成压力。

2.0
二进制分帧
多路复用(或连接共享)，使用多个stream，每个stream又分帧传输，使用一个  TCP  连接能够处理  多个  HTTP  请求
头部压缩，双方各自维护一个  header  的索引表，使得不需要直接发送值，通过发送  key  缩减头部大小。
服务器推送

3.0
基于google  的  QUIC  协议，QUIC协议通过  UDP  实现
减少了  TCP  三次握手时间，以及  TLS握手时间
解决了  HTTP 2.0  中  前一个  stream  丢包导致  后一个  stream  被阻塞的问题
优化了  重传策略，重传包  与  原包的编号不同，降低了后续重传计算的  消耗
连续迁移，不再使用  TCP  四元组确定一个连接，而是用一个  64位随机数  来确定这个连接
更合适的流量控制

=====================

=====================

=====================

=====================

=====================

=====================

=====================

=====================

=====================

=====================

=====================

=====================

=====================

=====================

已使用 Microsoft OneNote 2016 创建。



# http 头部字段

## 通用头部字段

### Cache-Control

- max-age=x
  缓存有效期 x 秒
- private
  私有缓存，仅向特定用户提供的
- public
  可以向任意用户提供
- no-cache
  request中，说明客户端不接受 缓存，必须最新的内容
  response中，服务器不会对相应资源进行缓存
- no-store
  缓存不能在 本地存储
- only-if-cached
  客户端仅请求 缓存上的内容，如果缓存上没有，就返回 504 Gateway timeout
- must-revalidata
  服务器返回缓存中的内容时，必须确认缓存的有效性
- no-transform
  无论请求还是响应，都不能在传输过程中改变报文体的媒体类型


### Connection

- keep-alive
  持久连接
- close
  关闭持久连接



### Transfer-Encoding
报文在传输过程中的 编码方式

在 http/1.1 中，只对 分块编码 有效

- chunked
  报文分块传输


### Via
为了追踪请求 和 响应 报文的传输路径。
报文经过 代理 或 网关时 会在 Via 添加该服务器信息。


## 请求 头部字段

### Accept

告知服务器，客户端可以处理的 媒体类型 及 优先级

`Accept: text/html,application/xhtml+xml,application/xml;q=0.8,image/webp,*/*;q=0.7`

### Accept-Encoding
客户端支持的 内容编码 及 优先级

`Accept-Encoding: gzip,deflate,sdch,br`

### Accept-Language
客户端可以处理的自然语言集 及优先级

`Accept-Language: zh-CN,zh;q=0.7,en;q=0.6`

### Authorization
认证信息

`Authorization: Basic qweasdasdwqeqeqad`

### If-Match, If-None-Match

`If-Match: ${Etag}`
如果 值 和 etag想等，则服务器处理。


### If-Modified-Since, If-Unmodified-Since

后跟日期。

### If-Range
后跟 etag，如果 值 和etag匹配， 请求的内容就按照 Range 的范围进行返回，否则返回全部内容

```text
If-Range: "asdasdzadw"
Range: bytes=100-50000
```

### Referer
正确的拼写时 Referrer， 但一直这样用。

后跟一个 URI， 这个 URI 就是 发起请求的 URI


### User-Agent

请求方的 浏览器 和 用户代理名称


## 响应 头部字段

### Accept-Ranges

告知 客户端 是否支持范围请求 ( 请求头 带 Range字段)。

- bytes
  支持
- none
  不支持


### Age
告知客户端，源服务器在多久前创建了 该响应


### ETag

服务器资源 对应的 一个 唯一的 字符串。
可以唯一标识资源。

配合 If-None-Match 更新资源，如果 资源没有修改，那么服务器不会 返回数据。


### Location
一般与 重定向 结合使用。
是 重定向的 目标地址

### Server
服务器型号


### Vary
对缓存进行控制，通过该字段，源服务器会向代理服务器传达关于本地缓存使用方法的命令

Vary后方的参数是Accept-Encoding。其意思是返回的缓存要以Accept-Encoding为准。当请求的Accept-Encoding的参数与缓存内容的Accept-Encoding参数一致时就返回缓存内容，否则就请求源服务器。


### WWW-Authenticate

在状态码401 Unauthorized中肯定带有此字段，该字段用来指定客户端的认证方案（Basic或者Digest）



## 实体 头部字段
实体头部字段是报文实体所使用的头部，用来补充与报文实体相关的信息。

### Allow

用于服务器通知客户端服务器这边所支持的所有请求方法（GET、POST等）


### Content-Encoding
报文实体的编码方式

### Content-Language
报文实体使用的自然语言

### Content-Length
报文实体的字节长度


### Content-MD5
MD5

## Cookie相关的头部字段

因为HTTP协议本身是无状态的，在Web站点中使用Cookie来管理服务器与客户端之间的状态

### Set-Cookie
响应报文中会使用到该字段。
当服务器准备开始管理客户端的状态时，会事先告知其各种信息。
下方字段是登录知乎时所返回的所要设置的Cookie信息

- 键值对
  存入cookie中的信息
- Domain
  cookie所属域名。 空就是 创建cookie的服务器的域名
- expire
  有效期， 无就是当前会话有效
- httponly
  让js无法获得cookie，放置跨站脚本攻击 对cookie信息的窃取
- path
  限定 cookie 的发送范围的 文件目录
- Secure
  仅在 https 时 发送cookie

### Cookie
请求报文头中会使用该字段，用于将本地存储的Cookie信息发送给服务端















---

# HTTP3详解

https://blog.csdn.net/qq_62311779/article/details/139910673

2025-3

使用基于UDP的QUIC 主要是为了解决 http2 中的 队头阻塞问题: 由于http2 在单个 TCP上使用了 多路复用，受到TCP拥塞控制的影响，少量的丢包就可能导致整个TCP连接上的 所有流被阻塞

PS: 
http2 利用 二进制分帧 实现多路复用，解决的是 HTTP1.1 的队头线性阻塞 问题。
http1.1 的队头阻塞: 在1.1中，使用率 持久连接 和 管道化，允许在一个 连接中 发送多个请求。但是 对于 串行处理方式，如果一个请求处理变慢 或被阻塞，后续所有的请求都会受到影响。 这是 队头阻塞的一种表现。
http2 还会受到 TCP的队头阻塞的影响: TCP传输过程中，会吧数据拆分为一个个按照顺序排列的数据包，这些数据包通过 网络传输到 接收端，接收端再按照 顺序将这些数据包 组合成原始数据，这样就完成了 数据传输。 但是如果其中某个数据包 没有按顺序到达，接收端会一直等待数据包，这时就阻塞了 后续的请求。 发生了 TCP队头阻塞

---

## QUIC实现

quic的实现位于 用户空间。  tcp udp 位于内核空间
。。http也是 用户空间。应用层的 全在 用户空间。

quic在 用户空间 实现了 类似TCP的 流量控制，拥塞控制，重传机制 等。


TCP/IP 的实现 位于内核空间。 这意味着 OS kernel 处理 所有 TCP/IP 数据包的 发送，接收，处理和路由。
优点:
- 高效的网络数据包处理
- 可靠的内核级错误处理 和拥塞控制

缺点:
- 修改和优化 协议栈需要 OS内核级别的 更改，很复杂，不易部署
- 开发和调试协议栈需要系统级权限，增加了 开发难度。

---

quic 位于用户空间，意味着 所有处理逻辑都在 应用程序级别 完成。
优点
- 灵活性和可扩展性， 开发者可以更容易地 修改，优化，扩展 协议功能，无需修改 OS内核。
- 独立更新， quic的更新 不需要 更新OS
- 应用级控制， app可以更直接地控制 和优化 网络行为。 比如 google的 BoringSSL中 实现了 QUIC的 加密和传输功能。

缺点
- 性能开销， 需要在 用户空间 和 内核空间之间 进行系统调用，增加了 性能开销。 通过 0拷贝可以减少这些额外的开销
- 安全性， 用户空间的代码的 安全性 不如内核空间代码。 因此 QUIC内置了 TLS1.3


---

## http3 改进详解

原先
http2: http语义，多路复用，流量控制
tls: 加密握手，加密事宜
tcp: 通讯握手，拥塞控制，流量控制

现在
http3: http语义
quic: 多路复用，流量控制，通讯握手，拥塞控制，加密握手，加密事宜。

---

### 快速连接建立 (1RTT建立,0RTT恢复)

round-trip time， 往返时间。 数据包 从发送端 传输到 接收端 再 返回给 发送端 花费的 总时间。 即包括了 发送，处理，返回 的时间

低延迟连接建立， quic 结合了 udp和 内置的TLS1.3， 能在 1个RTT 时间内 完成 连接建立， 甚至支持 0-RTT 数据传输。
- 1-RTT 握手， 在一次 往返时间内 完成连接建立。 通过集成TLS1.3，在初始握手时完成 加密密钥的协商
- 0-RTT 数据传输， 如果 之前建立过连接，可以通过 0-RTT 数据传输机制 在 第一次请求时 就发送 应用数据，进一步减少延迟


### 无队头阻塞

改进的多路复用， 通过QUIC的 多路复用能力，解决了 http2中的 队头阻塞问题

实现机制:
- 独立的流控制，每个流有独立的拥塞控制和丢包恢复机制。 意味着 一个流的丢包 不会影响 其他流的数据传输
- 帧级别的重传， quic使用 帧来 传输数据，每个数据包 可以包含 多个帧。 丢失的数据包只影响 该数据包中的 帧，不会影响其他数据包。  TCP会因为丢包而阻塞整个连接。


### 重传机制

http2中的流，是基于 TCP的流
- 多路复用， 使用一个 tcp连接 来承载 多个 并行的流。 每个流对应一个 http请求和响应对。 流通过 流ID 区分， 流ID 在每个 帧的头部 指定
- 队头阻塞， TCP 丢失一个数据包 就会阻塞 整个连接中的 所有流， 直到丢失的数据包被重发
- 流量控制， http2实现了 流量控制机制， 允许发送方 限制 接收方的流量。  流量控制 在 连接级别 和 流级别上 同时实现

具体实现:
- 帧: 数据被分为 多个帧，每个帧属于一个流。 帧的类型包括: 数据帧，头部帧，优先级帧 等
- 重传机制: 依赖TCP的重传机制。 当一个TCP数据包丢失时，整个数据包 (包括多个 http2帧) 需要重传。

。。估计说的是: TCP的重传 是 从 丢失包 开始 重新传一边。  但是 TCP也有 select 啊。 可以只重传 丢失的包

---

http3 中的流， 基于QUIC的流
- 独立的多路复用， quic在UDP上实现，每个流在 QUIC中是 独立的，多个流在同一QUIC连接中 并行传输，互不干扰。
- 无队头阻塞， quic提供独立的 流控制和错误恢复机制， 一个流的丢包只影响该流，不会阻塞其他流。
- 流量控制， quic提供独立的 流量控制，每个流有独立的 流量控制窗口， 允许更精细的 流量管理

具体实现:
- 帧: 每个quic包 包含多个帧，帧的类型包括: 流帧，ack帧，握手帧 等
- 重传机制: quic内置 快速重传机制。 丢失的数据包被 快速检测并重传，不会影响其他包。 每个流都有 独立的包编号 和 确认机制，确保高效的数据传输


### 移动性和连接前移connection id

TCP使用 发送者IP port， 接受者IP port，4元组 来标识 一个conn

quic 使用 64位随机数作为ID来标识 conn

连接保持: 当设备的网络环境变化 (如 从wifi 切为 移动数据网络)， http3可以保持现有的连接不中断

实现机制
- 连接id: 使用连接id 来标识连接，而不是依赖于 ip port。 这允许 连接 在网络变化时 保持不变，只需要更新连接ID即可
- 迁移支持: 当客户端的网络环境发生变化时，可以通过发送新ID来 继续使用现有的连接，而无需重新建立连接。

![c521941e15f216a03af152ac997424c7.png](../_resources/c521941e15f216a03af152ac997424c7.png)


### 更高的安全性 TLS1.3

内置TLS1.3

- TLS1.3集成: quic在传输层直接集成 TLS1.3，简化了加密实现。 每个数据包都是加密的。
- 快速密钥协商: quic能在 建立连接时 快速协商加密密钥，减少 初始握手时间。


### 更好的性能

低延迟和高吞吐量

实现机制
- 拥塞控制和丢包恢复: 现代的 拥塞控制算法(如BBR)，更好的 宽带利用 和 丢包恢复机制。 每个流有独立的拥塞控制，优化整体传输性能
- UDP优化: 不使用TCP，避免了 TCP的 慢启动 和其他性能瓶颈。


### 避免协议僵化

在用户空间实现，允许开发者 快速迭代 和部署。
独立的版本控制，独立于OS进行版本控制和更新


### 高效的错误恢复和流量控制

独立的错误恢复机制， 每个流都有独立的错误恢复机制， 不会影响其他流
细粒度的流量控制， 对每个流单独进行流量管理



## http3阻力

- 网管难度大， 加密级别高，很多安全设备不支持
- UDP被一些网络阻止， 基于UDP的攻击较多(DDoS)，很多网络会阻止UDP
- 浏览器和服务器的支持不完善
















